{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c4fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35daa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6aebd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_initials = 'wheat_30_var_2_species'\n",
    "file_name = file_name_initials+\".csv\"\n",
    "\n",
    "def dir(file_name):\n",
    "    return '../data/'+file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "554bc6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class filter_method(Enum):\n",
    "    none = 0\n",
    "    snv = 1\n",
    "    msc = 2\n",
    "    savgol = 3\n",
    "\n",
    "FILT = 1\n",
    "FILTER = filter_method(FILT).name\n",
    "\n",
    "# to be set if filter chosen is savgol\n",
    "WINDOW = 7\n",
    "ORDER = 2\n",
    "DERIVATIVE = 1\n",
    "\n",
    "#will be used for test dataset in msc\n",
    "reference= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d46a486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_file_name(file_name):\n",
    "    name = \"./dataset/\"+str(file_name)\n",
    "    if FILT != 0:\n",
    "        name+=\"_FILTER_\"+str(FILTER)\n",
    "    if FILTER == \"savgol\":\n",
    "        name+=\"_WINDOW_\"+str(WINDOW)+\"_ORDER_\"+str(ORDER)+\"_DERIVATIVE_\"+str(DERIVATIVE)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c80f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_name):\n",
    "    DATASET_FILE_NAME = dataset_file_name(file_name)\n",
    "    X_train = np.load(DATASET_FILE_NAME+\"_train_dataset.npy\")\n",
    "    y_train = np.load(DATASET_FILE_NAME+\"_train_dataset_label.npy\")\n",
    "    X_test = np.load(DATASET_FILE_NAME+\"_test_dataset.npy\")\n",
    "    y_test = np.load(DATASET_FILE_NAME+\"_test_dataset_label.npy\")\n",
    "    \n",
    "    return (X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77aed958",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train, X_test, y_test) = load_dataset(file_name_initials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58535347",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_set = set(np.concatenate((y_train, y_test), axis =0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e8c8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_CLASSES = len(y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c06a6392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_OF_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e1e570e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48384, 147, 1)\n",
      "(12096, 147, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec820add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Input, Conv1D, Flatten, Dense, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba682707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(input_shape,num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=5, input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=5))\n",
    "    model.add(Conv1D(filters=64, kernel_size=5))\n",
    "    model.add(MaxPooling1D(pool_size=5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(800, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d95ace51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(X_train.shape[1:],NUM_OF_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33a0377c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 143, 32)           192       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 28, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 24, 64)            10304     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 4, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              257000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 800)               800800    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 1602      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069,898\n",
      "Trainable params: 1,069,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20cd1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva = []\n",
    "test_eva = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fd5eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dataframe = pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "863f63f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  1\n",
      "127/127 - 7s - loss: 0.6376 - accuracy: 0.6236 - val_loss: 0.6379 - val_accuracy: 0.6427 - 7s/epoch - 55ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.6407 - accuracy: 0.6414\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.6361 - accuracy: 0.6426\n",
      "\n",
      "Epoch:  2\n",
      "127/127 - 6s - loss: 0.5651 - accuracy: 0.7136 - val_loss: 0.5089 - val_accuracy: 0.7573 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.5113 - accuracy: 0.7546\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.5105 - accuracy: 0.7542\n",
      "\n",
      "Epoch:  3\n",
      "127/127 - 6s - loss: 0.4658 - accuracy: 0.7788 - val_loss: 0.3797 - val_accuracy: 0.8253 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.3833 - accuracy: 0.8213\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.3848 - accuracy: 0.8189\n",
      "\n",
      "Epoch:  4\n",
      "127/127 - 7s - loss: 0.3569 - accuracy: 0.8431 - val_loss: 0.4363 - val_accuracy: 0.7840 - 7s/epoch - 53ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.4412 - accuracy: 0.7826\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.4389 - accuracy: 0.7841\n",
      "\n",
      "Epoch:  5\n",
      "127/127 - 6s - loss: 0.3057 - accuracy: 0.8655 - val_loss: 0.3981 - val_accuracy: 0.8148 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.4005 - accuracy: 0.8145\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.4081 - accuracy: 0.8145\n",
      "\n",
      "Epoch:  6\n",
      "127/127 - 6s - loss: 0.2612 - accuracy: 0.8886 - val_loss: 0.2244 - val_accuracy: 0.9064 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.2281 - accuracy: 0.9039\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.2304 - accuracy: 0.9029\n",
      "\n",
      "Epoch:  7\n",
      "127/127 - 6s - loss: 0.2553 - accuracy: 0.8903 - val_loss: 0.2724 - val_accuracy: 0.8784 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.2773 - accuracy: 0.8746\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.2777 - accuracy: 0.8747\n",
      "\n",
      "Epoch:  8\n",
      "127/127 - 6s - loss: 0.2614 - accuracy: 0.8881 - val_loss: 0.3495 - val_accuracy: 0.8413 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.3526 - accuracy: 0.8389\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.3574 - accuracy: 0.8331\n",
      "\n",
      "Epoch:  9\n",
      "127/127 - 6s - loss: 0.2411 - accuracy: 0.8964 - val_loss: 0.2329 - val_accuracy: 0.9001 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.2370 - accuracy: 0.8982\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.2375 - accuracy: 0.8983\n",
      "\n",
      "Epoch:  10\n",
      "127/127 - 6s - loss: 0.2150 - accuracy: 0.9096 - val_loss: 0.2025 - val_accuracy: 0.9159 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.2053 - accuracy: 0.9130\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.2071 - accuracy: 0.9118\n",
      "\n",
      "Epoch:  11\n",
      "127/127 - 6s - loss: 0.2088 - accuracy: 0.9121 - val_loss: 0.1885 - val_accuracy: 0.9220 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1913 - accuracy: 0.9203\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1941 - accuracy: 0.9178\n",
      "\n",
      "Epoch:  12\n",
      "127/127 - 6s - loss: 0.1921 - accuracy: 0.9209 - val_loss: 0.1847 - val_accuracy: 0.9229 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1879 - accuracy: 0.9216\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1896 - accuracy: 0.9200\n",
      "\n",
      "Epoch:  13\n",
      "127/127 - 6s - loss: 0.1976 - accuracy: 0.9170 - val_loss: 0.1666 - val_accuracy: 0.9310 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1696 - accuracy: 0.9302\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1711 - accuracy: 0.9283\n",
      "\n",
      "Epoch:  14\n",
      "127/127 - 6s - loss: 0.1812 - accuracy: 0.9242 - val_loss: 0.1614 - val_accuracy: 0.9360 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1656 - accuracy: 0.9334\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1653 - accuracy: 0.9343\n",
      "\n",
      "Epoch:  15\n",
      "127/127 - 6s - loss: 0.1999 - accuracy: 0.9172 - val_loss: 0.1884 - val_accuracy: 0.9189 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.1915 - accuracy: 0.9181\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1920 - accuracy: 0.9200\n",
      "\n",
      "Epoch:  16\n",
      "127/127 - 6s - loss: 0.1857 - accuracy: 0.9226 - val_loss: 0.1773 - val_accuracy: 0.9285 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1797 - accuracy: 0.9274\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1804 - accuracy: 0.9308\n",
      "\n",
      "Epoch:  17\n",
      "127/127 - 6s - loss: 0.1736 - accuracy: 0.9275 - val_loss: 0.1482 - val_accuracy: 0.9402 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.1513 - accuracy: 0.9387\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1538 - accuracy: 0.9371\n",
      "\n",
      "Epoch:  18\n",
      "127/127 - 6s - loss: 0.1713 - accuracy: 0.9290 - val_loss: 0.1566 - val_accuracy: 0.9357 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.1594 - accuracy: 0.9348\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1607 - accuracy: 0.9336\n",
      "\n",
      "Epoch:  19\n",
      "127/127 - 6s - loss: 0.1767 - accuracy: 0.9259 - val_loss: 0.1533 - val_accuracy: 0.9362 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1575 - accuracy: 0.9349\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1591 - accuracy: 0.9350\n",
      "\n",
      "Epoch:  20\n",
      "127/127 - 6s - loss: 0.1656 - accuracy: 0.9310 - val_loss: 0.1500 - val_accuracy: 0.9374 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1523 - accuracy: 0.9367\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1564 - accuracy: 0.9341\n",
      "\n",
      "Epoch:  21\n",
      "127/127 - 6s - loss: 0.1678 - accuracy: 0.9301 - val_loss: 0.1401 - val_accuracy: 0.9434 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.1429 - accuracy: 0.9422\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1442 - accuracy: 0.9419\n",
      "\n",
      "Epoch:  22\n",
      "127/127 - 6s - loss: 0.1553 - accuracy: 0.9351 - val_loss: 0.1865 - val_accuracy: 0.9213 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1905 - accuracy: 0.9191\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1910 - accuracy: 0.9178\n",
      "\n",
      "Epoch:  23\n",
      "127/127 - 6s - loss: 0.1641 - accuracy: 0.9319 - val_loss: 0.1735 - val_accuracy: 0.9257 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1791 - accuracy: 0.9234\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1800 - accuracy: 0.9243\n",
      "\n",
      "Epoch:  24\n",
      "127/127 - 6s - loss: 0.1594 - accuracy: 0.9357 - val_loss: 0.1595 - val_accuracy: 0.9342 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1629 - accuracy: 0.9322\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1621 - accuracy: 0.9319\n",
      "\n",
      "Epoch:  25\n",
      "127/127 - 6s - loss: 0.1543 - accuracy: 0.9354 - val_loss: 0.2191 - val_accuracy: 0.9096 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.2258 - accuracy: 0.9066\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 2s 5ms/step - loss: 0.2278 - accuracy: 0.9064\n",
      "\n",
      "Epoch:  26\n",
      "127/127 - 6s - loss: 0.1637 - accuracy: 0.9314 - val_loss: 0.1929 - val_accuracy: 0.9186 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.1934 - accuracy: 0.9179\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1964 - accuracy: 0.9171\n",
      "\n",
      "Epoch:  27\n",
      "127/127 - 6s - loss: 0.1433 - accuracy: 0.9416 - val_loss: 0.1465 - val_accuracy: 0.9389 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1471 - accuracy: 0.9385\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1498 - accuracy: 0.9393\n",
      "\n",
      "Epoch:  28\n",
      "127/127 - 6s - loss: 0.1428 - accuracy: 0.9416 - val_loss: 0.1442 - val_accuracy: 0.9413 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1479 - accuracy: 0.9395\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1498 - accuracy: 0.9397\n",
      "\n",
      "Epoch:  29\n",
      "127/127 - 6s - loss: 0.1404 - accuracy: 0.9409 - val_loss: 0.1247 - val_accuracy: 0.9490 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1273 - accuracy: 0.9481\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1313 - accuracy: 0.9455\n",
      "\n",
      "Epoch:  30\n",
      "127/127 - 6s - loss: 0.1532 - accuracy: 0.9363 - val_loss: 0.1344 - val_accuracy: 0.9445 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.1372 - accuracy: 0.9436\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1396 - accuracy: 0.9417\n",
      "\n",
      "Epoch:  31\n",
      "127/127 - 6s - loss: 0.1548 - accuracy: 0.9358 - val_loss: 0.1332 - val_accuracy: 0.9460 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1339 - accuracy: 0.9456\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1339 - accuracy: 0.9470\n",
      "\n",
      "Epoch:  32\n",
      "127/127 - 6s - loss: 0.1395 - accuracy: 0.9424 - val_loss: 0.1807 - val_accuracy: 0.9238 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1828 - accuracy: 0.9231\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1846 - accuracy: 0.9206\n",
      "\n",
      "Epoch:  33\n",
      "127/127 - 6s - loss: 0.1414 - accuracy: 0.9413 - val_loss: 0.1176 - val_accuracy: 0.9502 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1180 - accuracy: 0.9511\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1216 - accuracy: 0.9496\n",
      "\n",
      "Epoch:  34\n",
      "127/127 - 6s - loss: 0.1454 - accuracy: 0.9410 - val_loss: 0.1364 - val_accuracy: 0.9428 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1393 - accuracy: 0.9417\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1411 - accuracy: 0.9409\n",
      "\n",
      "Epoch:  35\n",
      "127/127 - 6s - loss: 0.1348 - accuracy: 0.9438 - val_loss: 0.1137 - val_accuracy: 0.9549 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1152 - accuracy: 0.9538\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1181 - accuracy: 0.9521\n",
      "\n",
      "Epoch:  36\n",
      "127/127 - 6s - loss: 0.1281 - accuracy: 0.9476 - val_loss: 0.1345 - val_accuracy: 0.9448 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.1355 - accuracy: 0.9445\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1352 - accuracy: 0.9417\n",
      "\n",
      "Epoch:  37\n",
      "127/127 - 6s - loss: 0.1356 - accuracy: 0.9444 - val_loss: 0.1668 - val_accuracy: 0.9318 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.1702 - accuracy: 0.9294\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.1742 - accuracy: 0.9275\n",
      "\n",
      "Epoch:  38\n",
      "127/127 - 7s - loss: 0.1252 - accuracy: 0.9478 - val_loss: 0.1201 - val_accuracy: 0.9520 - 7s/epoch - 59ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.1222 - accuracy: 0.9505\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1255 - accuracy: 0.9486\n",
      "\n",
      "Epoch:  39\n",
      "127/127 - 6s - loss: 0.1287 - accuracy: 0.9483 - val_loss: 0.1701 - val_accuracy: 0.9326 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1733 - accuracy: 0.9292\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1787 - accuracy: 0.9280\n",
      "\n",
      "Epoch:  40\n",
      "127/127 - 6s - loss: 0.1397 - accuracy: 0.9419 - val_loss: 0.1525 - val_accuracy: 0.9392 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1534 - accuracy: 0.9374\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1536 - accuracy: 0.9356\n",
      "\n",
      "Epoch:  41\n",
      "127/127 - 6s - loss: 0.1328 - accuracy: 0.9454 - val_loss: 0.1252 - val_accuracy: 0.9490 - 6s/epoch - 50ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1259 - accuracy: 0.9483\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1285 - accuracy: 0.9478\n",
      "\n",
      "Epoch:  42\n",
      "127/127 - 6s - loss: 0.1252 - accuracy: 0.9488 - val_loss: 0.1100 - val_accuracy: 0.9548 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1098 - accuracy: 0.9548\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1153 - accuracy: 0.9518\n",
      "\n",
      "Epoch:  43\n",
      "127/127 - 6s - loss: 0.1239 - accuracy: 0.9495 - val_loss: 0.1069 - val_accuracy: 0.9571 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1060 - accuracy: 0.9573\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1086 - accuracy: 0.9552\n",
      "\n",
      "Epoch:  44\n",
      "127/127 - 6s - loss: 0.1117 - accuracy: 0.9545 - val_loss: 0.1110 - val_accuracy: 0.9573 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1114 - accuracy: 0.9565\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1107 - accuracy: 0.9554\n",
      "\n",
      "Epoch:  45\n",
      "127/127 - 6s - loss: 0.1208 - accuracy: 0.9518 - val_loss: 0.1017 - val_accuracy: 0.9599 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1021 - accuracy: 0.9591\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1055 - accuracy: 0.9570\n",
      "\n",
      "Epoch:  46\n",
      "127/127 - 6s - loss: 0.1259 - accuracy: 0.9481 - val_loss: 0.1019 - val_accuracy: 0.9593 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1022 - accuracy: 0.9590\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1061 - accuracy: 0.9572\n",
      "\n",
      "Epoch:  47\n",
      "127/127 - 6s - loss: 0.1102 - accuracy: 0.9558 - val_loss: 0.1030 - val_accuracy: 0.9594 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1023 - accuracy: 0.9592\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1049 - accuracy: 0.9575\n",
      "\n",
      "Epoch:  48\n",
      "127/127 - 6s - loss: 0.1350 - accuracy: 0.9448 - val_loss: 0.1241 - val_accuracy: 0.9511 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1232 - accuracy: 0.9502\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1260 - accuracy: 0.9503\n",
      "\n",
      "Epoch:  49\n",
      "127/127 - 6s - loss: 0.1121 - accuracy: 0.9543 - val_loss: 0.0980 - val_accuracy: 0.9613 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0982 - accuracy: 0.9611\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1015 - accuracy: 0.9593\n",
      "\n",
      "Epoch:  50\n",
      "127/127 - 6s - loss: 0.1077 - accuracy: 0.9564 - val_loss: 0.0942 - val_accuracy: 0.9641 - 6s/epoch - 44ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0945 - accuracy: 0.9633\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0958 - accuracy: 0.9611\n",
      "\n",
      "Epoch:  51\n",
      "127/127 - 6s - loss: 0.1062 - accuracy: 0.9569 - val_loss: 0.1060 - val_accuracy: 0.9583 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1065 - accuracy: 0.9574\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1087 - accuracy: 0.9558\n",
      "\n",
      "Epoch:  52\n",
      "127/127 - 6s - loss: 0.1045 - accuracy: 0.9585 - val_loss: 0.1035 - val_accuracy: 0.9595 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1029 - accuracy: 0.9592\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1074 - accuracy: 0.9563\n",
      "\n",
      "Epoch:  53\n",
      "127/127 - 6s - loss: 0.1003 - accuracy: 0.9593 - val_loss: 0.1047 - val_accuracy: 0.9587 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1060 - accuracy: 0.9577\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1092 - accuracy: 0.9554\n",
      "\n",
      "Epoch:  54\n",
      "127/127 - 6s - loss: 0.1124 - accuracy: 0.9547 - val_loss: 0.1012 - val_accuracy: 0.9602 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1013 - accuracy: 0.9597\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1024 - accuracy: 0.9585\n",
      "\n",
      "Epoch:  55\n",
      "127/127 - 6s - loss: 0.1075 - accuracy: 0.9560 - val_loss: 0.0950 - val_accuracy: 0.9614 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0939 - accuracy: 0.9624\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0977 - accuracy: 0.9599\n",
      "\n",
      "Epoch:  56\n",
      "127/127 - 6s - loss: 0.1062 - accuracy: 0.9571 - val_loss: 0.0919 - val_accuracy: 0.9642 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0903 - accuracy: 0.9642\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0940 - accuracy: 0.9640\n",
      "\n",
      "Epoch:  57\n",
      "127/127 - 6s - loss: 0.1068 - accuracy: 0.9576 - val_loss: 0.0883 - val_accuracy: 0.9652 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0867 - accuracy: 0.9662\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0909 - accuracy: 0.9641\n",
      "\n",
      "Epoch:  58\n",
      "127/127 - 6s - loss: 0.1159 - accuracy: 0.9538 - val_loss: 0.0940 - val_accuracy: 0.9650 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0928 - accuracy: 0.9648\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0930 - accuracy: 0.9629\n",
      "\n",
      "Epoch:  59\n",
      "127/127 - 6s - loss: 0.0995 - accuracy: 0.9605 - val_loss: 0.0888 - val_accuracy: 0.9641 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0879 - accuracy: 0.9655\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0904 - accuracy: 0.9635\n",
      "\n",
      "Epoch:  60\n",
      "127/127 - 8s - loss: 0.0937 - accuracy: 0.9638 - val_loss: 0.0952 - val_accuracy: 0.9625 - 8s/epoch - 59ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0942 - accuracy: 0.9622\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0948 - accuracy: 0.9628\n",
      "\n",
      "Epoch:  61\n",
      "127/127 - 8s - loss: 0.1018 - accuracy: 0.9610 - val_loss: 0.0859 - val_accuracy: 0.9671 - 8s/epoch - 67ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0847 - accuracy: 0.9673\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0876 - accuracy: 0.9657\n",
      "\n",
      "Epoch:  62\n",
      "127/127 - 6s - loss: 0.0942 - accuracy: 0.9630 - val_loss: 0.1191 - val_accuracy: 0.9523 - 6s/epoch - 50ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.1196 - accuracy: 0.9520\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1239 - accuracy: 0.9500\n",
      "\n",
      "Epoch:  63\n",
      "127/127 - 6s - loss: 0.1008 - accuracy: 0.9592 - val_loss: 0.0941 - val_accuracy: 0.9634 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0928 - accuracy: 0.9638\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0950 - accuracy: 0.9625\n",
      "\n",
      "Epoch:  64\n",
      "127/127 - 6s - loss: 0.1151 - accuracy: 0.9547 - val_loss: 0.0859 - val_accuracy: 0.9661 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0835 - accuracy: 0.9676\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0877 - accuracy: 0.9669\n",
      "\n",
      "Epoch:  65\n",
      "127/127 - 7s - loss: 0.0885 - accuracy: 0.9660 - val_loss: 0.0829 - val_accuracy: 0.9691 - 7s/epoch - 55ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0808 - accuracy: 0.9702\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0836 - accuracy: 0.9680\n",
      "\n",
      "Epoch:  66\n",
      "127/127 - 6s - loss: 0.0890 - accuracy: 0.9647 - val_loss: 0.0972 - val_accuracy: 0.9622 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0966 - accuracy: 0.9615\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0988 - accuracy: 0.9612\n",
      "\n",
      "Epoch:  67\n",
      "127/127 - 6s - loss: 0.0893 - accuracy: 0.9645 - val_loss: 0.0930 - val_accuracy: 0.9642 - 6s/epoch - 49ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0917 - accuracy: 0.9643\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0963 - accuracy: 0.9627\n",
      "\n",
      "Epoch:  68\n",
      "127/127 - 8s - loss: 0.0934 - accuracy: 0.9631 - val_loss: 0.0782 - val_accuracy: 0.9709 - 8s/epoch - 63ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0758 - accuracy: 0.9724\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0794 - accuracy: 0.9694\n",
      "\n",
      "Epoch:  69\n",
      "127/127 - 9s - loss: 0.0889 - accuracy: 0.9648 - val_loss: 0.0798 - val_accuracy: 0.9685 - 9s/epoch - 72ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0762 - accuracy: 0.9703\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0795 - accuracy: 0.9696\n",
      "\n",
      "Epoch:  70\n",
      "127/127 - 6s - loss: 0.0802 - accuracy: 0.9693 - val_loss: 0.0835 - val_accuracy: 0.9685 - 6s/epoch - 51ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0831 - accuracy: 0.9683\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0877 - accuracy: 0.9662\n",
      "\n",
      "Epoch:  71\n",
      "127/127 - 10s - loss: 0.0899 - accuracy: 0.9644 - val_loss: 0.1128 - val_accuracy: 0.9545 - 10s/epoch - 78ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1089 - accuracy: 0.9562\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1117 - accuracy: 0.9527\n",
      "\n",
      "Epoch:  72\n",
      "127/127 - 6s - loss: 0.0836 - accuracy: 0.9671 - val_loss: 0.0724 - val_accuracy: 0.9731 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0702 - accuracy: 0.9740\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0748 - accuracy: 0.9703\n",
      "\n",
      "Epoch:  73\n",
      "127/127 - 7s - loss: 0.0860 - accuracy: 0.9662 - val_loss: 0.1613 - val_accuracy: 0.9347 - 7s/epoch - 57ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1579 - accuracy: 0.9350\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1514 - accuracy: 0.9368\n",
      "\n",
      "Epoch:  74\n",
      "127/127 - 9s - loss: 0.0958 - accuracy: 0.9623 - val_loss: 0.0902 - val_accuracy: 0.9652 - 9s/epoch - 69ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0863 - accuracy: 0.9672\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0886 - accuracy: 0.9651\n",
      "\n",
      "Epoch:  75\n",
      "127/127 - 7s - loss: 0.0756 - accuracy: 0.9729 - val_loss: 0.0745 - val_accuracy: 0.9713 - 7s/epoch - 56ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0707 - accuracy: 0.9729\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0726 - accuracy: 0.9727\n",
      "\n",
      "Epoch:  76\n",
      "127/127 - 8s - loss: 0.0922 - accuracy: 0.9632 - val_loss: 0.0781 - val_accuracy: 0.9706 - 8s/epoch - 61ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0753 - accuracy: 0.9719\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0770 - accuracy: 0.9717\n",
      "\n",
      "Epoch:  77\n",
      "127/127 - 7s - loss: 0.0789 - accuracy: 0.9700 - val_loss: 0.0683 - val_accuracy: 0.9737 - 7s/epoch - 57ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0658 - accuracy: 0.9755\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0674 - accuracy: 0.9749\n",
      "\n",
      "Epoch:  78\n",
      "127/127 - 6s - loss: 0.0810 - accuracy: 0.9684 - val_loss: 0.0706 - val_accuracy: 0.9736 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0663 - accuracy: 0.9752\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0687 - accuracy: 0.9726\n",
      "\n",
      "Epoch:  79\n",
      "127/127 - 7s - loss: 0.0758 - accuracy: 0.9704 - val_loss: 0.0759 - val_accuracy: 0.9704 - 7s/epoch - 52ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0742 - accuracy: 0.9712\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0806 - accuracy: 0.9684\n",
      "\n",
      "Epoch:  80\n",
      "127/127 - 6s - loss: 0.0757 - accuracy: 0.9718 - val_loss: 0.1085 - val_accuracy: 0.9579 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1006 - accuracy: 0.9603\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1051 - accuracy: 0.9574\n",
      "\n",
      "Epoch:  81\n",
      "127/127 - 6s - loss: 0.0847 - accuracy: 0.9664 - val_loss: 0.0779 - val_accuracy: 0.9699 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0739 - accuracy: 0.9716\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0764 - accuracy: 0.9695\n",
      "\n",
      "Epoch:  82\n",
      "127/127 - 6s - loss: 0.0727 - accuracy: 0.9714 - val_loss: 0.0641 - val_accuracy: 0.9764 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0604 - accuracy: 0.9776\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0631 - accuracy: 0.9769\n",
      "\n",
      "Epoch:  83\n",
      "127/127 - 6s - loss: 0.0762 - accuracy: 0.9710 - val_loss: 0.1098 - val_accuracy: 0.9566 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1066 - accuracy: 0.9578\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1118 - accuracy: 0.9559\n",
      "\n",
      "Epoch:  84\n",
      "127/127 - 6s - loss: 0.0823 - accuracy: 0.9676 - val_loss: 0.0669 - val_accuracy: 0.9751 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0633 - accuracy: 0.9763\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0657 - accuracy: 0.9747\n",
      "\n",
      "Epoch:  85\n",
      "127/127 - 8s - loss: 0.0767 - accuracy: 0.9709 - val_loss: 0.1015 - val_accuracy: 0.9601 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0949 - accuracy: 0.9623\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.1003 - accuracy: 0.9597\n",
      "\n",
      "Epoch:  86\n",
      "127/127 - 6s - loss: 0.0704 - accuracy: 0.9727 - val_loss: 0.0750 - val_accuracy: 0.9713 - 6s/epoch - 51ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0695 - accuracy: 0.9730\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0712 - accuracy: 0.9725\n",
      "\n",
      "Epoch:  87\n",
      "127/127 - 6s - loss: 0.0730 - accuracy: 0.9721 - val_loss: 0.0946 - val_accuracy: 0.9647 - 6s/epoch - 49ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0928 - accuracy: 0.9648\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0975 - accuracy: 0.9616\n",
      "\n",
      "Epoch:  88\n",
      "127/127 - 6s - loss: 0.0739 - accuracy: 0.9712 - val_loss: 0.0750 - val_accuracy: 0.9714 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0695 - accuracy: 0.9730\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0744 - accuracy: 0.9707\n",
      "\n",
      "Epoch:  89\n",
      "127/127 - 6s - loss: 0.0751 - accuracy: 0.9714 - val_loss: 0.0642 - val_accuracy: 0.9763 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0595 - accuracy: 0.9782\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0634 - accuracy: 0.9766\n",
      "\n",
      "Epoch:  90\n",
      "127/127 - 6s - loss: 0.0700 - accuracy: 0.9726 - val_loss: 0.0663 - val_accuracy: 0.9748 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0617 - accuracy: 0.9769\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0630 - accuracy: 0.9759\n",
      "\n",
      "Epoch:  91\n",
      "127/127 - 6s - loss: 0.0733 - accuracy: 0.9720 - val_loss: 0.0818 - val_accuracy: 0.9687 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0764 - accuracy: 0.9714\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0780 - accuracy: 0.9698\n",
      "\n",
      "Epoch:  92\n",
      "127/127 - 7s - loss: 0.0792 - accuracy: 0.9686 - val_loss: 0.0739 - val_accuracy: 0.9716 - 7s/epoch - 56ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0680 - accuracy: 0.9743\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0702 - accuracy: 0.9737\n",
      "\n",
      "Epoch:  93\n",
      "127/127 - 6s - loss: 0.0679 - accuracy: 0.9737 - val_loss: 0.0703 - val_accuracy: 0.9737 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0643 - accuracy: 0.9755\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0713 - accuracy: 0.9718\n",
      "\n",
      "Epoch:  94\n",
      "127/127 - 6s - loss: 0.0738 - accuracy: 0.9719 - val_loss: 0.0731 - val_accuracy: 0.9711 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0665 - accuracy: 0.9746\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0687 - accuracy: 0.9726\n",
      "\n",
      "Epoch:  95\n",
      "127/127 - 6s - loss: 0.0655 - accuracy: 0.9753 - val_loss: 0.0750 - val_accuracy: 0.9700 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0675 - accuracy: 0.9736\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0697 - accuracy: 0.9724\n",
      "\n",
      "Epoch:  96\n",
      "127/127 - 6s - loss: 0.0704 - accuracy: 0.9739 - val_loss: 0.0716 - val_accuracy: 0.9736 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0674 - accuracy: 0.9744\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0726 - accuracy: 0.9719\n",
      "\n",
      "Epoch:  97\n",
      "127/127 - 6s - loss: 0.0594 - accuracy: 0.9776 - val_loss: 0.0577 - val_accuracy: 0.9795 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0528 - accuracy: 0.9810\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0565 - accuracy: 0.9788\n",
      "\n",
      "Epoch:  98\n",
      "127/127 - 6s - loss: 0.0623 - accuracy: 0.9767 - val_loss: 0.0760 - val_accuracy: 0.9697 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0691 - accuracy: 0.9730\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0725 - accuracy: 0.9718\n",
      "\n",
      "Epoch:  99\n",
      "127/127 - 6s - loss: 0.0733 - accuracy: 0.9712 - val_loss: 0.1256 - val_accuracy: 0.9493 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1210 - accuracy: 0.9511\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1208 - accuracy: 0.9511\n",
      "\n",
      "Epoch:  100\n",
      "127/127 - 6s - loss: 0.0755 - accuracy: 0.9705 - val_loss: 0.0793 - val_accuracy: 0.9685 - 6s/epoch - 45ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0744 - accuracy: 0.9714\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0773 - accuracy: 0.9679\n",
      "\n",
      "Epoch:  101\n",
      "127/127 - 6s - loss: 0.0670 - accuracy: 0.9744 - val_loss: 0.0896 - val_accuracy: 0.9660 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0803 - accuracy: 0.9686\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0895 - accuracy: 0.9645\n",
      "\n",
      "Epoch:  102\n",
      "127/127 - 6s - loss: 0.0618 - accuracy: 0.9767 - val_loss: 0.0569 - val_accuracy: 0.9796 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0518 - accuracy: 0.9812\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0576 - accuracy: 0.9776\n",
      "\n",
      "Epoch:  103\n",
      "127/127 - 6s - loss: 0.0624 - accuracy: 0.9762 - val_loss: 0.0821 - val_accuracy: 0.9675 - 6s/epoch - 50ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0771 - accuracy: 0.9699\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0799 - accuracy: 0.9697\n",
      "\n",
      "Epoch:  104\n",
      "127/127 - 6s - loss: 0.0557 - accuracy: 0.9795 - val_loss: 0.0544 - val_accuracy: 0.9807 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0496 - accuracy: 0.9827\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0532 - accuracy: 0.9802\n",
      "\n",
      "Epoch:  105\n",
      "127/127 - 6s - loss: 0.0645 - accuracy: 0.9748 - val_loss: 0.1054 - val_accuracy: 0.9595 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0990 - accuracy: 0.9617\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1051 - accuracy: 0.9608\n",
      "\n",
      "Epoch:  106\n",
      "127/127 - 6s - loss: 0.0644 - accuracy: 0.9765 - val_loss: 0.0756 - val_accuracy: 0.9711 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0679 - accuracy: 0.9738\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0747 - accuracy: 0.9695\n",
      "\n",
      "Epoch:  107\n",
      "127/127 - 6s - loss: 0.0582 - accuracy: 0.9774 - val_loss: 0.0706 - val_accuracy: 0.9727 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0663 - accuracy: 0.9739\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0724 - accuracy: 0.9711\n",
      "\n",
      "Epoch:  108\n",
      "127/127 - 6s - loss: 0.0671 - accuracy: 0.9740 - val_loss: 0.0894 - val_accuracy: 0.9629 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0817 - accuracy: 0.9670\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0843 - accuracy: 0.9645\n",
      "\n",
      "Epoch:  109\n",
      "127/127 - 6s - loss: 0.0592 - accuracy: 0.9784 - val_loss: 0.0634 - val_accuracy: 0.9763 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0587 - accuracy: 0.9776\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0642 - accuracy: 0.9751\n",
      "\n",
      "Epoch:  110\n",
      "127/127 - 6s - loss: 0.0591 - accuracy: 0.9775 - val_loss: 0.0589 - val_accuracy: 0.9785 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0536 - accuracy: 0.9805\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0567 - accuracy: 0.9797\n",
      "\n",
      "Epoch:  111\n",
      "127/127 - 6s - loss: 0.0600 - accuracy: 0.9772 - val_loss: 0.0927 - val_accuracy: 0.9652 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0827 - accuracy: 0.9685\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0893 - accuracy: 0.9662\n",
      "\n",
      "Epoch:  112\n",
      "127/127 - 6s - loss: 0.0721 - accuracy: 0.9725 - val_loss: 0.0592 - val_accuracy: 0.9776 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0527 - accuracy: 0.9809\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0567 - accuracy: 0.9793\n",
      "\n",
      "Epoch:  113\n",
      "127/127 - 6s - loss: 0.0587 - accuracy: 0.9772 - val_loss: 0.0733 - val_accuracy: 0.9710 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0650 - accuracy: 0.9748\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0689 - accuracy: 0.9735\n",
      "\n",
      "Epoch:  114\n",
      "127/127 - 6s - loss: 0.0546 - accuracy: 0.9791 - val_loss: 0.0567 - val_accuracy: 0.9792 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0511 - accuracy: 0.9814\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0546 - accuracy: 0.9792\n",
      "\n",
      "Epoch:  115\n",
      "127/127 - 6s - loss: 0.0570 - accuracy: 0.9786 - val_loss: 0.0492 - val_accuracy: 0.9829 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0424 - accuracy: 0.9851\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0464 - accuracy: 0.9823\n",
      "\n",
      "Epoch:  116\n",
      "127/127 - 6s - loss: 0.0577 - accuracy: 0.9789 - val_loss: 0.0748 - val_accuracy: 0.9709 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0706 - accuracy: 0.9719\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0786 - accuracy: 0.9692\n",
      "\n",
      "Epoch:  117\n",
      "127/127 - 6s - loss: 0.0501 - accuracy: 0.9803 - val_loss: 0.0552 - val_accuracy: 0.9804 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0469 - accuracy: 0.9830\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0503 - accuracy: 0.9800\n",
      "\n",
      "Epoch:  118\n",
      "127/127 - 6s - loss: 0.0592 - accuracy: 0.9773 - val_loss: 0.0606 - val_accuracy: 0.9778 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0535 - accuracy: 0.9797\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0634 - accuracy: 0.9754\n",
      "\n",
      "Epoch:  119\n",
      "127/127 - 6s - loss: 0.0592 - accuracy: 0.9776 - val_loss: 0.0760 - val_accuracy: 0.9714 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0699 - accuracy: 0.9736\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0795 - accuracy: 0.9686\n",
      "\n",
      "Epoch:  120\n",
      "127/127 - 6s - loss: 0.0748 - accuracy: 0.9710 - val_loss: 0.0557 - val_accuracy: 0.9792 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0494 - accuracy: 0.9810\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0560 - accuracy: 0.9774\n",
      "\n",
      "Epoch:  121\n",
      "127/127 - 6s - loss: 0.0538 - accuracy: 0.9796 - val_loss: 0.0526 - val_accuracy: 0.9804 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0455 - accuracy: 0.9829\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0510 - accuracy: 0.9801\n",
      "\n",
      "Epoch:  122\n",
      "127/127 - 6s - loss: 0.0525 - accuracy: 0.9795 - val_loss: 0.0556 - val_accuracy: 0.9790 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0485 - accuracy: 0.9819\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0523 - accuracy: 0.9805\n",
      "\n",
      "Epoch:  123\n",
      "127/127 - 6s - loss: 0.0496 - accuracy: 0.9816 - val_loss: 0.0585 - val_accuracy: 0.9785 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0502 - accuracy: 0.9811\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0577 - accuracy: 0.9778\n",
      "\n",
      "Epoch:  124\n",
      "127/127 - 6s - loss: 0.0490 - accuracy: 0.9811 - val_loss: 0.0500 - val_accuracy: 0.9825 - 6s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0425 - accuracy: 0.9848\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0479 - accuracy: 0.9815\n",
      "\n",
      "Epoch:  125\n",
      "127/127 - 6s - loss: 0.0516 - accuracy: 0.9796 - val_loss: 0.0664 - val_accuracy: 0.9768 - 6s/epoch - 45ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0563 - accuracy: 0.9800\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0634 - accuracy: 0.9764\n",
      "\n",
      "Epoch:  126\n",
      "127/127 - 6s - loss: 0.0498 - accuracy: 0.9813 - val_loss: 0.0596 - val_accuracy: 0.9779 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0532 - accuracy: 0.9793\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0624 - accuracy: 0.9749\n",
      "\n",
      "Epoch:  127\n",
      "127/127 - 6s - loss: 0.0478 - accuracy: 0.9822 - val_loss: 0.0541 - val_accuracy: 0.9803 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0479 - accuracy: 0.9826\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0537 - accuracy: 0.9792\n",
      "\n",
      "Epoch:  128\n",
      "127/127 - 6s - loss: 0.0529 - accuracy: 0.9798 - val_loss: 0.0486 - val_accuracy: 0.9830 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0426 - accuracy: 0.9847\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0507 - accuracy: 0.9810\n",
      "\n",
      "Epoch:  129\n",
      "127/127 - 6s - loss: 0.0484 - accuracy: 0.9822 - val_loss: 0.0954 - val_accuracy: 0.9658 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0851 - accuracy: 0.9689\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0926 - accuracy: 0.9671\n",
      "\n",
      "Epoch:  130\n",
      "127/127 - 6s - loss: 0.0492 - accuracy: 0.9816 - val_loss: 0.0979 - val_accuracy: 0.9638 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0894 - accuracy: 0.9657\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0987 - accuracy: 0.9621\n",
      "\n",
      "Epoch:  131\n",
      "127/127 - 6s - loss: 0.0487 - accuracy: 0.9812 - val_loss: 0.0529 - val_accuracy: 0.9806 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0455 - accuracy: 0.9833\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0507 - accuracy: 0.9816\n",
      "\n",
      "Epoch:  132\n",
      "127/127 - 6s - loss: 0.0443 - accuracy: 0.9837 - val_loss: 0.0556 - val_accuracy: 0.9793 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0471 - accuracy: 0.9823\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0546 - accuracy: 0.9798\n",
      "\n",
      "Epoch:  133\n",
      "127/127 - 6s - loss: 0.0448 - accuracy: 0.9829 - val_loss: 0.0484 - val_accuracy: 0.9827 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0403 - accuracy: 0.9853\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0477 - accuracy: 0.9828\n",
      "\n",
      "Epoch:  134\n",
      "127/127 - 6s - loss: 0.0471 - accuracy: 0.9819 - val_loss: 0.0442 - val_accuracy: 0.9840 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0372 - accuracy: 0.9864\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0448 - accuracy: 0.9839\n",
      "\n",
      "Epoch:  135\n",
      "127/127 - 6s - loss: 0.0504 - accuracy: 0.9810 - val_loss: 0.0495 - val_accuracy: 0.9821 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0421 - accuracy: 0.9847\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0525 - accuracy: 0.9794\n",
      "\n",
      "Epoch:  136\n",
      "127/127 - 6s - loss: 0.0576 - accuracy: 0.9783 - val_loss: 0.0748 - val_accuracy: 0.9722 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0693 - accuracy: 0.9738\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0819 - accuracy: 0.9695\n",
      "\n",
      "Epoch:  137\n",
      "127/127 - 6s - loss: 0.0490 - accuracy: 0.9816 - val_loss: 0.0642 - val_accuracy: 0.9761 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0548 - accuracy: 0.9794\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0586 - accuracy: 0.9778\n",
      "\n",
      "Epoch:  138\n",
      "127/127 - 6s - loss: 0.0480 - accuracy: 0.9819 - val_loss: 0.0516 - val_accuracy: 0.9806 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0427 - accuracy: 0.9840\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0504 - accuracy: 0.9800\n",
      "\n",
      "Epoch:  139\n",
      "127/127 - 6s - loss: 0.0457 - accuracy: 0.9827 - val_loss: 0.0577 - val_accuracy: 0.9793 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0503 - accuracy: 0.9809\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0589 - accuracy: 0.9780\n",
      "\n",
      "Epoch:  140\n",
      "127/127 - 6s - loss: 0.0507 - accuracy: 0.9804 - val_loss: 0.0451 - val_accuracy: 0.9842 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0367 - accuracy: 0.9871\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0449 - accuracy: 0.9819\n",
      "\n",
      "Epoch:  141\n",
      "127/127 - 6s - loss: 0.0522 - accuracy: 0.9800 - val_loss: 0.0651 - val_accuracy: 0.9748 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0569 - accuracy: 0.9773\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0674 - accuracy: 0.9743\n",
      "\n",
      "Epoch:  142\n",
      "127/127 - 6s - loss: 0.0526 - accuracy: 0.9791 - val_loss: 0.0526 - val_accuracy: 0.9808 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0450 - accuracy: 0.9832\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0548 - accuracy: 0.9792\n",
      "\n",
      "Epoch:  143\n",
      "127/127 - 6s - loss: 0.0454 - accuracy: 0.9823 - val_loss: 0.0430 - val_accuracy: 0.9851 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0347 - accuracy: 0.9881\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0424 - accuracy: 0.9847\n",
      "\n",
      "Epoch:  144\n",
      "127/127 - 6s - loss: 0.0435 - accuracy: 0.9832 - val_loss: 0.0444 - val_accuracy: 0.9846 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0369 - accuracy: 0.9869\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0445 - accuracy: 0.9834\n",
      "\n",
      "Epoch:  145\n",
      "127/127 - 6s - loss: 0.0396 - accuracy: 0.9853 - val_loss: 0.0684 - val_accuracy: 0.9747 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0605 - accuracy: 0.9768\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0748 - accuracy: 0.9726\n",
      "\n",
      "Epoch:  146\n",
      "127/127 - 6s - loss: 0.0416 - accuracy: 0.9837 - val_loss: 0.0439 - val_accuracy: 0.9843 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0347 - accuracy: 0.9871\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0412 - accuracy: 0.9839\n",
      "\n",
      "Epoch:  147\n",
      "127/127 - 6s - loss: 0.0477 - accuracy: 0.9819 - val_loss: 0.0495 - val_accuracy: 0.9812 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0409 - accuracy: 0.9845\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0482 - accuracy: 0.9829\n",
      "\n",
      "Epoch:  148\n",
      "127/127 - 6s - loss: 0.0482 - accuracy: 0.9823 - val_loss: 0.0430 - val_accuracy: 0.9843 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0362 - accuracy: 0.9864\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0445 - accuracy: 0.9814\n",
      "\n",
      "Epoch:  149\n",
      "127/127 - 6s - loss: 0.0380 - accuracy: 0.9860 - val_loss: 0.0443 - val_accuracy: 0.9847 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0359 - accuracy: 0.9872\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0451 - accuracy: 0.9831\n",
      "\n",
      "Epoch:  150\n",
      "127/127 - 6s - loss: 0.0462 - accuracy: 0.9825 - val_loss: 0.0464 - val_accuracy: 0.9832 - 6s/epoch - 47ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0406 - accuracy: 0.9853\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0491 - accuracy: 0.9823\n",
      "\n",
      "Epoch:  151\n",
      "127/127 - 6s - loss: 0.0480 - accuracy: 0.9823 - val_loss: 0.0582 - val_accuracy: 0.9777 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0487 - accuracy: 0.9816\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0576 - accuracy: 0.9780\n",
      "\n",
      "Epoch:  152\n",
      "127/127 - 6s - loss: 0.0485 - accuracy: 0.9816 - val_loss: 0.0615 - val_accuracy: 0.9772 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0501 - accuracy: 0.9808\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0577 - accuracy: 0.9792\n",
      "\n",
      "Epoch:  153\n",
      "127/127 - 9s - loss: 0.0387 - accuracy: 0.9854 - val_loss: 0.0453 - val_accuracy: 0.9839 - 9s/epoch - 72ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0368 - accuracy: 0.9864\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0456 - accuracy: 0.9830\n",
      "\n",
      "Epoch:  154\n",
      "127/127 - 6s - loss: 0.0402 - accuracy: 0.9852 - val_loss: 0.0490 - val_accuracy: 0.9816 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0395 - accuracy: 0.9852\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0471 - accuracy: 0.9822\n",
      "\n",
      "Epoch:  155\n",
      "127/127 - 6s - loss: 0.0429 - accuracy: 0.9837 - val_loss: 0.0664 - val_accuracy: 0.9764 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0575 - accuracy: 0.9782\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0695 - accuracy: 0.9740\n",
      "\n",
      "Epoch:  156\n",
      "127/127 - 6s - loss: 0.0471 - accuracy: 0.9818 - val_loss: 0.0480 - val_accuracy: 0.9818 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0384 - accuracy: 0.9850\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0430 - accuracy: 0.9839\n",
      "\n",
      "Epoch:  157\n",
      "127/127 - 6s - loss: 0.0367 - accuracy: 0.9857 - val_loss: 0.0479 - val_accuracy: 0.9825 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0421 - accuracy: 0.9840\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0549 - accuracy: 0.9801\n",
      "\n",
      "Epoch:  158\n",
      "127/127 - 6s - loss: 0.0403 - accuracy: 0.9845 - val_loss: 0.0694 - val_accuracy: 0.9749 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0579 - accuracy: 0.9782\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0670 - accuracy: 0.9750\n",
      "\n",
      "Epoch:  159\n",
      "127/127 - 6s - loss: 0.0391 - accuracy: 0.9854 - val_loss: 0.0420 - val_accuracy: 0.9854 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0336 - accuracy: 0.9879\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0454 - accuracy: 0.9831\n",
      "\n",
      "Epoch:  160\n",
      "127/127 - 6s - loss: 0.0395 - accuracy: 0.9844 - val_loss: 0.0613 - val_accuracy: 0.9760 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0536 - accuracy: 0.9790\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0638 - accuracy: 0.9747\n",
      "\n",
      "Epoch:  161\n",
      "127/127 - 6s - loss: 0.0440 - accuracy: 0.9839 - val_loss: 0.0424 - val_accuracy: 0.9849 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0345 - accuracy: 0.9873\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0458 - accuracy: 0.9822\n",
      "\n",
      "Epoch:  162\n",
      "127/127 - 6s - loss: 0.0368 - accuracy: 0.9861 - val_loss: 0.0655 - val_accuracy: 0.9766 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0540 - accuracy: 0.9798\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0641 - accuracy: 0.9776\n",
      "\n",
      "Epoch:  163\n",
      "127/127 - 6s - loss: 0.0389 - accuracy: 0.9849 - val_loss: 0.0536 - val_accuracy: 0.9803 - 6s/epoch - 50ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0442 - accuracy: 0.9831\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0583 - accuracy: 0.9786\n",
      "\n",
      "Epoch:  164\n",
      "127/127 - 6s - loss: 0.0380 - accuracy: 0.9860 - val_loss: 0.0537 - val_accuracy: 0.9799 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0440 - accuracy: 0.9833\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0556 - accuracy: 0.9788\n",
      "\n",
      "Epoch:  165\n",
      "127/127 - 6s - loss: 0.0375 - accuracy: 0.9854 - val_loss: 0.0369 - val_accuracy: 0.9873 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0287 - accuracy: 0.9901\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0368 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  166\n",
      "127/127 - 6s - loss: 0.0446 - accuracy: 0.9828 - val_loss: 0.0441 - val_accuracy: 0.9842 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0357 - accuracy: 0.9864\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0483 - accuracy: 0.9821\n",
      "\n",
      "Epoch:  167\n",
      "127/127 - 6s - loss: 0.0447 - accuracy: 0.9827 - val_loss: 0.0423 - val_accuracy: 0.9849 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0343 - accuracy: 0.9876\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0432 - accuracy: 0.9831\n",
      "\n",
      "Epoch:  168\n",
      "127/127 - 6s - loss: 0.0436 - accuracy: 0.9830 - val_loss: 0.0585 - val_accuracy: 0.9770 - 6s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0491 - accuracy: 0.9809\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0589 - accuracy: 0.9776\n",
      "\n",
      "Epoch:  169\n",
      "127/127 - 6s - loss: 0.0308 - accuracy: 0.9888 - val_loss: 0.0377 - val_accuracy: 0.9868 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0298 - accuracy: 0.9896\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0400 - accuracy: 0.9843\n",
      "\n",
      "Epoch:  170\n",
      "127/127 - 6s - loss: 0.0303 - accuracy: 0.9885 - val_loss: 0.0654 - val_accuracy: 0.9748 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0532 - accuracy: 0.9794\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0635 - accuracy: 0.9768\n",
      "\n",
      "Epoch:  171\n",
      "127/127 - 6s - loss: 0.0366 - accuracy: 0.9863 - val_loss: 0.0386 - val_accuracy: 0.9869 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0295 - accuracy: 0.9895\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0409 - accuracy: 0.9842\n",
      "\n",
      "Epoch:  172\n",
      "127/127 - 6s - loss: 0.0473 - accuracy: 0.9821 - val_loss: 0.0408 - val_accuracy: 0.9852 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0340 - accuracy: 0.9871\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0447 - accuracy: 0.9835\n",
      "\n",
      "Epoch:  173\n",
      "127/127 - 6s - loss: 0.0399 - accuracy: 0.9842 - val_loss: 0.0476 - val_accuracy: 0.9818 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0385 - accuracy: 0.9850\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0519 - accuracy: 0.9803\n",
      "\n",
      "Epoch:  174\n",
      "127/127 - 6s - loss: 0.0323 - accuracy: 0.9877 - val_loss: 0.0510 - val_accuracy: 0.9809 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0416 - accuracy: 0.9838\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0517 - accuracy: 0.9802\n",
      "\n",
      "Epoch:  175\n",
      "127/127 - 6s - loss: 0.0369 - accuracy: 0.9855 - val_loss: 0.0404 - val_accuracy: 0.9853 - 6s/epoch - 46ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0313 - accuracy: 0.9886\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0414 - accuracy: 0.9847\n",
      "\n",
      "Epoch:  176\n",
      "127/127 - 6s - loss: 0.0282 - accuracy: 0.9899 - val_loss: 0.0395 - val_accuracy: 0.9857 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0301 - accuracy: 0.9890\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0446 - accuracy: 0.9840\n",
      "\n",
      "Epoch:  177\n",
      "127/127 - 6s - loss: 0.0308 - accuracy: 0.9889 - val_loss: 0.0511 - val_accuracy: 0.9810 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0410 - accuracy: 0.9847\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0542 - accuracy: 0.9799\n",
      "\n",
      "Epoch:  178\n",
      "127/127 - 6s - loss: 0.0385 - accuracy: 0.9849 - val_loss: 0.0502 - val_accuracy: 0.9821 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0400 - accuracy: 0.9851\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0515 - accuracy: 0.9807\n",
      "\n",
      "Epoch:  179\n",
      "127/127 - 6s - loss: 0.0350 - accuracy: 0.9865 - val_loss: 0.0397 - val_accuracy: 0.9858 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0310 - accuracy: 0.9885\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0429 - accuracy: 0.9837\n",
      "\n",
      "Epoch:  180\n",
      "127/127 - 6s - loss: 0.0406 - accuracy: 0.9841 - val_loss: 0.0441 - val_accuracy: 0.9845 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0353 - accuracy: 0.9871\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0463 - accuracy: 0.9840\n",
      "\n",
      "Epoch:  181\n",
      "127/127 - 6s - loss: 0.0368 - accuracy: 0.9857 - val_loss: 0.0613 - val_accuracy: 0.9780 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0518 - accuracy: 0.9798\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0675 - accuracy: 0.9770\n",
      "\n",
      "Epoch:  182\n",
      "127/127 - 6s - loss: 0.0322 - accuracy: 0.9882 - val_loss: 0.0426 - val_accuracy: 0.9855 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0339 - accuracy: 0.9876\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0486 - accuracy: 0.9826\n",
      "\n",
      "Epoch:  183\n",
      "127/127 - 6s - loss: 0.0278 - accuracy: 0.9901 - val_loss: 0.0403 - val_accuracy: 0.9858 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0311 - accuracy: 0.9887\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0452 - accuracy: 0.9829\n",
      "\n",
      "Epoch:  184\n",
      "127/127 - 6s - loss: 0.0287 - accuracy: 0.9888 - val_loss: 0.0378 - val_accuracy: 0.9867 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0279 - accuracy: 0.9901\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0386 - accuracy: 0.9859\n",
      "\n",
      "Epoch:  185\n",
      "127/127 - 6s - loss: 0.0314 - accuracy: 0.9886 - val_loss: 0.0395 - val_accuracy: 0.9857 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0296 - accuracy: 0.9890\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0435 - accuracy: 0.9836\n",
      "\n",
      "Epoch:  186\n",
      "127/127 - 6s - loss: 0.0376 - accuracy: 0.9857 - val_loss: 0.0380 - val_accuracy: 0.9861 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0299 - accuracy: 0.9892\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0406 - accuracy: 0.9856\n",
      "\n",
      "Epoch:  187\n",
      "127/127 - 6s - loss: 0.0336 - accuracy: 0.9866 - val_loss: 0.0381 - val_accuracy: 0.9869 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0281 - accuracy: 0.9898\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0393 - accuracy: 0.9856\n",
      "\n",
      "Epoch:  188\n",
      "127/127 - 6s - loss: 0.0315 - accuracy: 0.9878 - val_loss: 0.0424 - val_accuracy: 0.9855 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0307 - accuracy: 0.9892\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0460 - accuracy: 0.9831\n",
      "\n",
      "Epoch:  189\n",
      "127/127 - 6s - loss: 0.0297 - accuracy: 0.9896 - val_loss: 0.0397 - val_accuracy: 0.9855 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0274 - accuracy: 0.9903\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0380 - accuracy: 0.9855\n",
      "\n",
      "Epoch:  190\n",
      "127/127 - 6s - loss: 0.0339 - accuracy: 0.9867 - val_loss: 0.0562 - val_accuracy: 0.9803 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0446 - accuracy: 0.9838\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0575 - accuracy: 0.9796\n",
      "\n",
      "Epoch:  191\n",
      "127/127 - 6s - loss: 0.0354 - accuracy: 0.9856 - val_loss: 0.0378 - val_accuracy: 0.9862 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0295 - accuracy: 0.9893\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0392 - accuracy: 0.9849\n",
      "\n",
      "Epoch:  192\n",
      "127/127 - 6s - loss: 0.0336 - accuracy: 0.9872 - val_loss: 0.0330 - val_accuracy: 0.9880 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0234 - accuracy: 0.9917\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0359 - accuracy: 0.9860\n",
      "\n",
      "Epoch:  193\n",
      "127/127 - 6s - loss: 0.0240 - accuracy: 0.9907 - val_loss: 0.0523 - val_accuracy: 0.9810 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0412 - accuracy: 0.9841\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0564 - accuracy: 0.9803\n",
      "\n",
      "Epoch:  194\n",
      "127/127 - 6s - loss: 0.0298 - accuracy: 0.9886 - val_loss: 0.0441 - val_accuracy: 0.9840 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0335 - accuracy: 0.9874\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0439 - accuracy: 0.9845\n",
      "\n",
      "Epoch:  195\n",
      "127/127 - 6s - loss: 0.0255 - accuracy: 0.9906 - val_loss: 0.0320 - val_accuracy: 0.9885 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0222 - accuracy: 0.9922\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0351 - accuracy: 0.9866\n",
      "\n",
      "Epoch:  196\n",
      "127/127 - 6s - loss: 0.0324 - accuracy: 0.9883 - val_loss: 0.0743 - val_accuracy: 0.9744 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0593 - accuracy: 0.9780\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0740 - accuracy: 0.9757\n",
      "\n",
      "Epoch:  197\n",
      "127/127 - 6s - loss: 0.0500 - accuracy: 0.9806 - val_loss: 0.0367 - val_accuracy: 0.9870 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0279 - accuracy: 0.9900\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0394 - accuracy: 0.9854\n",
      "\n",
      "Epoch:  198\n",
      "127/127 - 6s - loss: 0.0285 - accuracy: 0.9885 - val_loss: 0.0430 - val_accuracy: 0.9843 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0334 - accuracy: 0.9870\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0489 - accuracy: 0.9820\n",
      "\n",
      "Epoch:  199\n",
      "127/127 - 6s - loss: 0.0405 - accuracy: 0.9853 - val_loss: 0.0453 - val_accuracy: 0.9836 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0333 - accuracy: 0.9877\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0462 - accuracy: 0.9831\n",
      "\n",
      "Epoch:  200\n",
      "127/127 - 6s - loss: 0.0261 - accuracy: 0.9902 - val_loss: 0.0405 - val_accuracy: 0.9860 - 6s/epoch - 47ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0301 - accuracy: 0.9886\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0460 - accuracy: 0.9831\n",
      "\n",
      "Epoch:  201\n",
      "127/127 - 6s - loss: 0.0262 - accuracy: 0.9905 - val_loss: 0.0458 - val_accuracy: 0.9842 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0358 - accuracy: 0.9875\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0509 - accuracy: 0.9823\n",
      "\n",
      "Epoch:  202\n",
      "127/127 - 6s - loss: 0.0244 - accuracy: 0.9907 - val_loss: 0.0365 - val_accuracy: 0.9866 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0254 - accuracy: 0.9910\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0383 - accuracy: 0.9857\n",
      "\n",
      "Epoch:  203\n",
      "127/127 - 6s - loss: 0.0260 - accuracy: 0.9902 - val_loss: 0.0360 - val_accuracy: 0.9868 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0259 - accuracy: 0.9908\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0365 - accuracy: 0.9869\n",
      "\n",
      "Epoch:  204\n",
      "127/127 - 6s - loss: 0.0377 - accuracy: 0.9857 - val_loss: 0.0411 - val_accuracy: 0.9845 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0324 - accuracy: 0.9878\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0434 - accuracy: 0.9836\n",
      "\n",
      "Epoch:  205\n",
      "127/127 - 6s - loss: 0.0291 - accuracy: 0.9891 - val_loss: 0.0350 - val_accuracy: 0.9884 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0244 - accuracy: 0.9913\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0375 - accuracy: 0.9861\n",
      "\n",
      "Epoch:  206\n",
      "127/127 - 6s - loss: 0.0263 - accuracy: 0.9894 - val_loss: 0.0369 - val_accuracy: 0.9862 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0270 - accuracy: 0.9896\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0412 - accuracy: 0.9850\n",
      "\n",
      "Epoch:  207\n",
      "127/127 - 6s - loss: 0.0243 - accuracy: 0.9913 - val_loss: 0.0316 - val_accuracy: 0.9887 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0211 - accuracy: 0.9926\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0350 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  208\n",
      "127/127 - 6s - loss: 0.0271 - accuracy: 0.9897 - val_loss: 0.0346 - val_accuracy: 0.9874 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0257 - accuracy: 0.9910\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0378 - accuracy: 0.9854\n",
      "\n",
      "Epoch:  209\n",
      "127/127 - 6s - loss: 0.0320 - accuracy: 0.9880 - val_loss: 0.0350 - val_accuracy: 0.9877 - 6s/epoch - 50ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0258 - accuracy: 0.9908\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0365 - accuracy: 0.9859\n",
      "\n",
      "Epoch:  210\n",
      "127/127 - 7s - loss: 0.0260 - accuracy: 0.9901 - val_loss: 0.0369 - val_accuracy: 0.9869 - 7s/epoch - 52ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0258 - accuracy: 0.9904\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0405 - accuracy: 0.9862\n",
      "\n",
      "Epoch:  211\n",
      "127/127 - 7s - loss: 0.0315 - accuracy: 0.9876 - val_loss: 0.0319 - val_accuracy: 0.9895 - 7s/epoch - 58ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0221 - accuracy: 0.9923\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0345 - accuracy: 0.9866\n",
      "\n",
      "Epoch:  212\n",
      "127/127 - 6s - loss: 0.0277 - accuracy: 0.9898 - val_loss: 0.0369 - val_accuracy: 0.9875 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0263 - accuracy: 0.9907\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0365 - accuracy: 0.9867\n",
      "\n",
      "Epoch:  213\n",
      "127/127 - 6s - loss: 0.0247 - accuracy: 0.9908 - val_loss: 0.0457 - val_accuracy: 0.9840 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0350 - accuracy: 0.9871\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0555 - accuracy: 0.9820\n",
      "\n",
      "Epoch:  214\n",
      "127/127 - 6s - loss: 0.0251 - accuracy: 0.9910 - val_loss: 0.0337 - val_accuracy: 0.9877 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0239 - accuracy: 0.9912\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0377 - accuracy: 0.9866\n",
      "\n",
      "Epoch:  215\n",
      "127/127 - 6s - loss: 0.0229 - accuracy: 0.9914 - val_loss: 0.0314 - val_accuracy: 0.9889 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0201 - accuracy: 0.9927\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0342 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  216\n",
      "127/127 - 6s - loss: 0.0259 - accuracy: 0.9900 - val_loss: 0.0568 - val_accuracy: 0.9800 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0431 - accuracy: 0.9840\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0618 - accuracy: 0.9799\n",
      "\n",
      "Epoch:  217\n",
      "127/127 - 6s - loss: 0.0256 - accuracy: 0.9907 - val_loss: 0.0469 - val_accuracy: 0.9835 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0344 - accuracy: 0.9872\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0498 - accuracy: 0.9820\n",
      "\n",
      "Epoch:  218\n",
      "127/127 - 6s - loss: 0.0307 - accuracy: 0.9882 - val_loss: 0.0464 - val_accuracy: 0.9838 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0342 - accuracy: 0.9871\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0524 - accuracy: 0.9819\n",
      "\n",
      "Epoch:  219\n",
      "127/127 - 6s - loss: 0.0247 - accuracy: 0.9906 - val_loss: 0.0600 - val_accuracy: 0.9789 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0446 - accuracy: 0.9832\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0670 - accuracy: 0.9769\n",
      "\n",
      "Epoch:  220\n",
      "127/127 - 6s - loss: 0.0282 - accuracy: 0.9889 - val_loss: 0.0546 - val_accuracy: 0.9808 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0401 - accuracy: 0.9853\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0578 - accuracy: 0.9784\n",
      "\n",
      "Epoch:  221\n",
      "127/127 - 6s - loss: 0.0217 - accuracy: 0.9917 - val_loss: 0.0434 - val_accuracy: 0.9840 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0327 - accuracy: 0.9872\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0530 - accuracy: 0.9819\n",
      "\n",
      "Epoch:  222\n",
      "127/127 - 6s - loss: 0.0264 - accuracy: 0.9897 - val_loss: 0.0612 - val_accuracy: 0.9815 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0466 - accuracy: 0.9849\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0609 - accuracy: 0.9816\n",
      "\n",
      "Epoch:  223\n",
      "127/127 - 6s - loss: 0.0214 - accuracy: 0.9920 - val_loss: 0.0364 - val_accuracy: 0.9873 - 6s/epoch - 49ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0238 - accuracy: 0.9914\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0365 - accuracy: 0.9865\n",
      "\n",
      "Epoch:  224\n",
      "127/127 - 6s - loss: 0.0307 - accuracy: 0.9882 - val_loss: 0.0380 - val_accuracy: 0.9862 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0259 - accuracy: 0.9906\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0384 - accuracy: 0.9854\n",
      "\n",
      "Epoch:  225\n",
      "127/127 - 6s - loss: 0.0241 - accuracy: 0.9909 - val_loss: 0.0373 - val_accuracy: 0.9861 - 6s/epoch - 47ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0250 - accuracy: 0.9910\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0372 - accuracy: 0.9850\n",
      "\n",
      "Epoch:  226\n",
      "127/127 - 6s - loss: 0.0208 - accuracy: 0.9921 - val_loss: 0.0303 - val_accuracy: 0.9890 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0183 - accuracy: 0.9938\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0327 - accuracy: 0.9877\n",
      "\n",
      "Epoch:  227\n",
      "127/127 - 6s - loss: 0.0277 - accuracy: 0.9894 - val_loss: 0.0423 - val_accuracy: 0.9842 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0337 - accuracy: 0.9862\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0485 - accuracy: 0.9822\n",
      "\n",
      "Epoch:  228\n",
      "127/127 - 6s - loss: 0.0255 - accuracy: 0.9903 - val_loss: 0.0357 - val_accuracy: 0.9876 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0244 - accuracy: 0.9909\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0408 - accuracy: 0.9849\n",
      "\n",
      "Epoch:  229\n",
      "127/127 - 6s - loss: 0.0201 - accuracy: 0.9926 - val_loss: 0.0549 - val_accuracy: 0.9812 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0409 - accuracy: 0.9852\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0616 - accuracy: 0.9802\n",
      "\n",
      "Epoch:  230\n",
      "127/127 - 6s - loss: 0.0218 - accuracy: 0.9921 - val_loss: 0.0300 - val_accuracy: 0.9899 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0184 - accuracy: 0.9939\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0313 - accuracy: 0.9885\n",
      "\n",
      "Epoch:  231\n",
      "127/127 - 6s - loss: 0.0330 - accuracy: 0.9874 - val_loss: 0.0326 - val_accuracy: 0.9893 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0205 - accuracy: 0.9931\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0352 - accuracy: 0.9869\n",
      "\n",
      "Epoch:  232\n",
      "127/127 - 6s - loss: 0.0226 - accuracy: 0.9911 - val_loss: 0.0295 - val_accuracy: 0.9899 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0187 - accuracy: 0.9937\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0326 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  233\n",
      "127/127 - 6s - loss: 0.0183 - accuracy: 0.9932 - val_loss: 0.0354 - val_accuracy: 0.9882 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0225 - accuracy: 0.9924\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0334 - accuracy: 0.9886\n",
      "\n",
      "Epoch:  234\n",
      "127/127 - 6s - loss: 0.0222 - accuracy: 0.9908 - val_loss: 0.0462 - val_accuracy: 0.9839 - 6s/epoch - 46ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0330 - accuracy: 0.9878\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0466 - accuracy: 0.9834\n",
      "\n",
      "Epoch:  235\n",
      "127/127 - 6s - loss: 0.0225 - accuracy: 0.9917 - val_loss: 0.0418 - val_accuracy: 0.9850 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0299 - accuracy: 0.9884\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0511 - accuracy: 0.9826\n",
      "\n",
      "Epoch:  236\n",
      "127/127 - 6s - loss: 0.0343 - accuracy: 0.9870 - val_loss: 0.0366 - val_accuracy: 0.9870 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0245 - accuracy: 0.9912\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0386 - accuracy: 0.9862\n",
      "\n",
      "Epoch:  237\n",
      "127/127 - 6s - loss: 0.0166 - accuracy: 0.9943 - val_loss: 0.0368 - val_accuracy: 0.9871 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0245 - accuracy: 0.9911\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0414 - accuracy: 0.9858\n",
      "\n",
      "Epoch:  238\n",
      "127/127 - 6s - loss: 0.0255 - accuracy: 0.9902 - val_loss: 0.0422 - val_accuracy: 0.9863 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0270 - accuracy: 0.9908\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0430 - accuracy: 0.9852\n",
      "\n",
      "Epoch:  239\n",
      "127/127 - 6s - loss: 0.0216 - accuracy: 0.9916 - val_loss: 0.0297 - val_accuracy: 0.9894 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0199 - accuracy: 0.9928\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0357 - accuracy: 0.9869\n",
      "\n",
      "Epoch:  240\n",
      "127/127 - 6s - loss: 0.0190 - accuracy: 0.9926 - val_loss: 0.0583 - val_accuracy: 0.9806 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0424 - accuracy: 0.9841\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0615 - accuracy: 0.9792\n",
      "\n",
      "Epoch:  241\n",
      "127/127 - 6s - loss: 0.0276 - accuracy: 0.9891 - val_loss: 0.0702 - val_accuracy: 0.9746 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0570 - accuracy: 0.9776\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0819 - accuracy: 0.9721\n",
      "\n",
      "Epoch:  242\n",
      "127/127 - 6s - loss: 0.0198 - accuracy: 0.9929 - val_loss: 0.0307 - val_accuracy: 0.9891 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0182 - accuracy: 0.9936\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0305 - accuracy: 0.9886\n",
      "\n",
      "Epoch:  243\n",
      "127/127 - 6s - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.0331 - val_accuracy: 0.9884 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0212 - accuracy: 0.9924\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0394 - accuracy: 0.9865\n",
      "\n",
      "Epoch:  244\n",
      "127/127 - 6s - loss: 0.0265 - accuracy: 0.9902 - val_loss: 0.0320 - val_accuracy: 0.9885 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0214 - accuracy: 0.9924\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0348 - accuracy: 0.9870\n",
      "\n",
      "Epoch:  245\n",
      "127/127 - 6s - loss: 0.0230 - accuracy: 0.9908 - val_loss: 0.0414 - val_accuracy: 0.9853 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0274 - accuracy: 0.9900\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0422 - accuracy: 0.9861\n",
      "\n",
      "Epoch:  246\n",
      "127/127 - 6s - loss: 0.0192 - accuracy: 0.9927 - val_loss: 0.0714 - val_accuracy: 0.9771 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0538 - accuracy: 0.9816\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0802 - accuracy: 0.9758\n",
      "\n",
      "Epoch:  247\n",
      "127/127 - 6s - loss: 0.0269 - accuracy: 0.9895 - val_loss: 0.0558 - val_accuracy: 0.9802 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0415 - accuracy: 0.9836\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0600 - accuracy: 0.9783\n",
      "\n",
      "Epoch:  248\n",
      "127/127 - 6s - loss: 0.0271 - accuracy: 0.9894 - val_loss: 0.0476 - val_accuracy: 0.9841 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0320 - accuracy: 0.9887\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0412 - accuracy: 0.9849\n",
      "\n",
      "Epoch:  249\n",
      "127/127 - 6s - loss: 0.0202 - accuracy: 0.9924 - val_loss: 0.0275 - val_accuracy: 0.9905 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0159 - accuracy: 0.9946\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0302 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  250\n",
      "127/127 - 6s - loss: 0.0139 - accuracy: 0.9948 - val_loss: 0.0313 - val_accuracy: 0.9892 - 6s/epoch - 48ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0204 - accuracy: 0.9922\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0393 - accuracy: 0.9860\n",
      "\n",
      "Epoch:  251\n",
      "127/127 - 6s - loss: 0.0308 - accuracy: 0.9890 - val_loss: 0.0333 - val_accuracy: 0.9886 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0206 - accuracy: 0.9927\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0357 - accuracy: 0.9873\n",
      "\n",
      "Epoch:  252\n",
      "127/127 - 6s - loss: 0.0153 - accuracy: 0.9944 - val_loss: 0.0322 - val_accuracy: 0.9887 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0195 - accuracy: 0.9928\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0379 - accuracy: 0.9869\n",
      "\n",
      "Epoch:  253\n",
      "127/127 - 6s - loss: 0.0154 - accuracy: 0.9944 - val_loss: 0.0411 - val_accuracy: 0.9862 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0250 - accuracy: 0.9910\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0419 - accuracy: 0.9863\n",
      "\n",
      "Epoch:  254\n",
      "127/127 - 6s - loss: 0.0214 - accuracy: 0.9920 - val_loss: 0.0741 - val_accuracy: 0.9755 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0567 - accuracy: 0.9793\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0700 - accuracy: 0.9776\n",
      "\n",
      "Epoch:  255\n",
      "127/127 - 6s - loss: 0.0178 - accuracy: 0.9932 - val_loss: 0.0442 - val_accuracy: 0.9846 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0307 - accuracy: 0.9881\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0560 - accuracy: 0.9814\n",
      "\n",
      "Epoch:  256\n",
      "127/127 - 6s - loss: 0.0163 - accuracy: 0.9938 - val_loss: 0.0537 - val_accuracy: 0.9820 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0366 - accuracy: 0.9870\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0571 - accuracy: 0.9814\n",
      "\n",
      "Epoch:  257\n",
      "127/127 - 6s - loss: 0.0169 - accuracy: 0.9938 - val_loss: 0.0308 - val_accuracy: 0.9891 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0181 - accuracy: 0.9936\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0347 - accuracy: 0.9875\n",
      "\n",
      "Epoch:  258\n",
      "127/127 - 6s - loss: 0.0181 - accuracy: 0.9930 - val_loss: 0.0353 - val_accuracy: 0.9873 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0232 - accuracy: 0.9916\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0402 - accuracy: 0.9869\n",
      "\n",
      "Epoch:  259\n",
      "127/127 - 6s - loss: 0.0239 - accuracy: 0.9910 - val_loss: 0.1008 - val_accuracy: 0.9692 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0780 - accuracy: 0.9741\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1020 - accuracy: 0.9693\n",
      "\n",
      "Epoch:  260\n",
      "127/127 - 6s - loss: 0.0195 - accuracy: 0.9926 - val_loss: 0.0473 - val_accuracy: 0.9835 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0320 - accuracy: 0.9881\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0430 - accuracy: 0.9845\n",
      "\n",
      "Epoch:  261\n",
      "127/127 - 6s - loss: 0.0202 - accuracy: 0.9919 - val_loss: 0.0987 - val_accuracy: 0.9676 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0859 - accuracy: 0.9698\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1069 - accuracy: 0.9646\n",
      "\n",
      "Epoch:  262\n",
      "127/127 - 6s - loss: 0.0277 - accuracy: 0.9894 - val_loss: 0.0465 - val_accuracy: 0.9843 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0307 - accuracy: 0.9887\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0422 - accuracy: 0.9858\n",
      "\n",
      "Epoch:  263\n",
      "127/127 - 6s - loss: 0.0137 - accuracy: 0.9950 - val_loss: 0.0354 - val_accuracy: 0.9883 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0206 - accuracy: 0.9928\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0340 - accuracy: 0.9887\n",
      "\n",
      "Epoch:  264\n",
      "127/127 - 6s - loss: 0.0266 - accuracy: 0.9900 - val_loss: 0.0405 - val_accuracy: 0.9859 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0276 - accuracy: 0.9894\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0479 - accuracy: 0.9834\n",
      "\n",
      "Epoch:  265\n",
      "127/127 - 6s - loss: 0.0183 - accuracy: 0.9931 - val_loss: 0.0322 - val_accuracy: 0.9895 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0190 - accuracy: 0.9937\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0326 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  266\n",
      "127/127 - 6s - loss: 0.0161 - accuracy: 0.9933 - val_loss: 0.0450 - val_accuracy: 0.9847 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0303 - accuracy: 0.9891\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0518 - accuracy: 0.9829\n",
      "\n",
      "Epoch:  267\n",
      "127/127 - 6s - loss: 0.0207 - accuracy: 0.9922 - val_loss: 0.0315 - val_accuracy: 0.9885 - 6s/epoch - 50ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0187 - accuracy: 0.9930\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0325 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  268\n",
      "127/127 - 7s - loss: 0.0161 - accuracy: 0.9941 - val_loss: 0.0421 - val_accuracy: 0.9863 - 7s/epoch - 52ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0260 - accuracy: 0.9907\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0420 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  269\n",
      "127/127 - 7s - loss: 0.0171 - accuracy: 0.9938 - val_loss: 0.0422 - val_accuracy: 0.9857 - 7s/epoch - 52ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0284 - accuracy: 0.9898\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0457 - accuracy: 0.9844\n",
      "\n",
      "Epoch:  270\n",
      "127/127 - 6s - loss: 0.0158 - accuracy: 0.9938 - val_loss: 0.0283 - val_accuracy: 0.9903 - 6s/epoch - 49ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0156 - accuracy: 0.9947\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0322 - accuracy: 0.9887\n",
      "\n",
      "Epoch:  271\n",
      "127/127 - 6s - loss: 0.0193 - accuracy: 0.9925 - val_loss: 0.0391 - val_accuracy: 0.9859 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0248 - accuracy: 0.9906\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0428 - accuracy: 0.9854\n",
      "\n",
      "Epoch:  272\n",
      "127/127 - 6s - loss: 0.0142 - accuracy: 0.9948 - val_loss: 0.0468 - val_accuracy: 0.9852 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0296 - accuracy: 0.9898\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0520 - accuracy: 0.9841\n",
      "\n",
      "Epoch:  273\n",
      "127/127 - 6s - loss: 0.0225 - accuracy: 0.9919 - val_loss: 0.0370 - val_accuracy: 0.9863 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0236 - accuracy: 0.9914\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0386 - accuracy: 0.9860\n",
      "\n",
      "Epoch:  274\n",
      "127/127 - 6s - loss: 0.0233 - accuracy: 0.9915 - val_loss: 0.0347 - val_accuracy: 0.9882 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0208 - accuracy: 0.9925\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0426 - accuracy: 0.9854\n",
      "\n",
      "Epoch:  275\n",
      "127/127 - 6s - loss: 0.0168 - accuracy: 0.9936 - val_loss: 0.0567 - val_accuracy: 0.9800 - 6s/epoch - 48ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0409 - accuracy: 0.9844\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0647 - accuracy: 0.9767\n",
      "\n",
      "Epoch:  276\n",
      "127/127 - 6s - loss: 0.0173 - accuracy: 0.9932 - val_loss: 0.0326 - val_accuracy: 0.9889 - 6s/epoch - 50ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0189 - accuracy: 0.9933\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0358 - accuracy: 0.9873\n",
      "\n",
      "Epoch:  277\n",
      "127/127 - 6s - loss: 0.0136 - accuracy: 0.9951 - val_loss: 0.0844 - val_accuracy: 0.9750 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0581 - accuracy: 0.9803\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0793 - accuracy: 0.9758\n",
      "\n",
      "Epoch:  278\n",
      "127/127 - 6s - loss: 0.0429 - accuracy: 0.9840 - val_loss: 0.0472 - val_accuracy: 0.9844 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0312 - accuracy: 0.9887\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0521 - accuracy: 0.9821\n",
      "\n",
      "Epoch:  279\n",
      "127/127 - 7s - loss: 0.0132 - accuracy: 0.9952 - val_loss: 0.0398 - val_accuracy: 0.9868 - 7s/epoch - 51ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0256 - accuracy: 0.9906\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0424 - accuracy: 0.9866\n",
      "\n",
      "Epoch:  280\n",
      "127/127 - 6s - loss: 0.0174 - accuracy: 0.9931 - val_loss: 0.0313 - val_accuracy: 0.9891 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0183 - accuracy: 0.9935\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0396 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  281\n",
      "127/127 - 6s - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.0350 - val_accuracy: 0.9887 - 6s/epoch - 51ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0204 - accuracy: 0.9929\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0426 - accuracy: 0.9858\n",
      "\n",
      "Epoch:  282\n",
      "127/127 - 6s - loss: 0.0151 - accuracy: 0.9943 - val_loss: 0.0286 - val_accuracy: 0.9904 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0164 - accuracy: 0.9945\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0342 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  283\n",
      "127/127 - 6s - loss: 0.0259 - accuracy: 0.9900 - val_loss: 0.0289 - val_accuracy: 0.9904 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0164 - accuracy: 0.9947\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0326 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  284\n",
      "127/127 - 6s - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.0290 - val_accuracy: 0.9900 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0154 - accuracy: 0.9948\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0305 - accuracy: 0.9885\n",
      "\n",
      "Epoch:  285\n",
      "127/127 - 6s - loss: 0.0150 - accuracy: 0.9944 - val_loss: 0.0478 - val_accuracy: 0.9838 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0337 - accuracy: 0.9876\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0535 - accuracy: 0.9824\n",
      "\n",
      "Epoch:  286\n",
      "127/127 - 6s - loss: 0.0178 - accuracy: 0.9935 - val_loss: 0.0354 - val_accuracy: 0.9881 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0216 - accuracy: 0.9921\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0419 - accuracy: 0.9865\n",
      "\n",
      "Epoch:  287\n",
      "127/127 - 6s - loss: 0.0162 - accuracy: 0.9938 - val_loss: 0.0462 - val_accuracy: 0.9852 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0282 - accuracy: 0.9899\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0476 - accuracy: 0.9851\n",
      "\n",
      "Epoch:  288\n",
      "127/127 - 6s - loss: 0.0211 - accuracy: 0.9917 - val_loss: 0.0488 - val_accuracy: 0.9855 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0297 - accuracy: 0.9899\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0522 - accuracy: 0.9836\n",
      "\n",
      "Epoch:  289\n",
      "127/127 - 6s - loss: 0.0213 - accuracy: 0.9917 - val_loss: 0.0634 - val_accuracy: 0.9773 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0455 - accuracy: 0.9823\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0652 - accuracy: 0.9778\n",
      "\n",
      "Epoch:  290\n",
      "127/127 - 6s - loss: 0.0151 - accuracy: 0.9940 - val_loss: 0.0306 - val_accuracy: 0.9903 - 6s/epoch - 49ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0167 - accuracy: 0.9945\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0306 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  291\n",
      "127/127 - 6s - loss: 0.0151 - accuracy: 0.9941 - val_loss: 0.0320 - val_accuracy: 0.9891 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0174 - accuracy: 0.9941\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0317 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  292\n",
      "127/127 - 6s - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.0299 - val_accuracy: 0.9907 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0161 - accuracy: 0.9946\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0368 - accuracy: 0.9869\n",
      "\n",
      "Epoch:  293\n",
      "127/127 - 6s - loss: 0.0150 - accuracy: 0.9938 - val_loss: 0.0303 - val_accuracy: 0.9900 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0154 - accuracy: 0.9949\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0291 - accuracy: 0.9892\n",
      "\n",
      "Epoch:  294\n",
      "127/127 - 6s - loss: 0.0163 - accuracy: 0.9939 - val_loss: 0.0393 - val_accuracy: 0.9884 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0208 - accuracy: 0.9932\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0394 - accuracy: 0.9877\n",
      "\n",
      "Epoch:  295\n",
      "127/127 - 6s - loss: 0.0228 - accuracy: 0.9918 - val_loss: 0.0390 - val_accuracy: 0.9865 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0234 - accuracy: 0.9915\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0448 - accuracy: 0.9848\n",
      "\n",
      "Epoch:  296\n",
      "127/127 - 6s - loss: 0.0131 - accuracy: 0.9952 - val_loss: 0.0381 - val_accuracy: 0.9867 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0213 - accuracy: 0.9924\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0386 - accuracy: 0.9871\n",
      "\n",
      "Epoch:  297\n",
      "127/127 - 6s - loss: 0.0199 - accuracy: 0.9923 - val_loss: 0.0337 - val_accuracy: 0.9888 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0175 - accuracy: 0.9942\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0346 - accuracy: 0.9885\n",
      "\n",
      "Epoch:  298\n",
      "127/127 - 6s - loss: 0.0103 - accuracy: 0.9961 - val_loss: 0.0285 - val_accuracy: 0.9904 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0137 - accuracy: 0.9956\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0292 - accuracy: 0.9894\n",
      "\n",
      "Epoch:  299\n",
      "127/127 - 6s - loss: 0.0215 - accuracy: 0.9923 - val_loss: 0.0585 - val_accuracy: 0.9808 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0419 - accuracy: 0.9850\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0651 - accuracy: 0.9788\n",
      "\n",
      "Epoch:  300\n",
      "127/127 - 6s - loss: 0.0177 - accuracy: 0.9933 - val_loss: 0.0355 - val_accuracy: 0.9882 - 6s/epoch - 48ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0202 - accuracy: 0.9928\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0442 - accuracy: 0.9859\n",
      "\n",
      "Epoch:  301\n",
      "127/127 - 6s - loss: 0.0150 - accuracy: 0.9942 - val_loss: 0.0396 - val_accuracy: 0.9872 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0227 - accuracy: 0.9921\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0522 - accuracy: 0.9844\n",
      "\n",
      "Epoch:  302\n",
      "127/127 - 6s - loss: 0.0130 - accuracy: 0.9947 - val_loss: 0.0313 - val_accuracy: 0.9898 - 6s/epoch - 49ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0150 - accuracy: 0.9951\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0342 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  303\n",
      "127/127 - 6s - loss: 0.0138 - accuracy: 0.9943 - val_loss: 0.0265 - val_accuracy: 0.9908 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0127 - accuracy: 0.9958\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0305 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  304\n",
      "127/127 - 6s - loss: 0.0095 - accuracy: 0.9965 - val_loss: 0.0323 - val_accuracy: 0.9892 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0172 - accuracy: 0.9942\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0396 - accuracy: 0.9869\n",
      "\n",
      "Epoch:  305\n",
      "127/127 - 6s - loss: 0.0178 - accuracy: 0.9934 - val_loss: 0.0922 - val_accuracy: 0.9731 - 6s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0727 - accuracy: 0.9769\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0870 - accuracy: 0.9742\n",
      "\n",
      "Epoch:  306\n",
      "127/127 - 6s - loss: 0.0333 - accuracy: 0.9884 - val_loss: 0.0366 - val_accuracy: 0.9869 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0234 - accuracy: 0.9919\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0437 - accuracy: 0.9843\n",
      "\n",
      "Epoch:  307\n",
      "127/127 - 6s - loss: 0.0103 - accuracy: 0.9962 - val_loss: 0.0298 - val_accuracy: 0.9899 - 6s/epoch - 49ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0145 - accuracy: 0.9953\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0289 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  308\n",
      "127/127 - 6s - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0249 - val_accuracy: 0.9912 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0114 - accuracy: 0.9964\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0280 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  309\n",
      "127/127 - 6s - loss: 0.0077 - accuracy: 0.9971 - val_loss: 0.0478 - val_accuracy: 0.9861 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0260 - accuracy: 0.9916\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0532 - accuracy: 0.9852\n",
      "\n",
      "Epoch:  310\n",
      "127/127 - 6s - loss: 0.0168 - accuracy: 0.9938 - val_loss: 0.0388 - val_accuracy: 0.9885 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0214 - accuracy: 0.9932\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0493 - accuracy: 0.9869\n",
      "\n",
      "Epoch:  311\n",
      "127/127 - 6s - loss: 0.0110 - accuracy: 0.9958 - val_loss: 0.0486 - val_accuracy: 0.9845 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0303 - accuracy: 0.9890\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0527 - accuracy: 0.9832\n",
      "\n",
      "Epoch:  312\n",
      "127/127 - 6s - loss: 0.0183 - accuracy: 0.9935 - val_loss: 0.0403 - val_accuracy: 0.9857 - 6s/epoch - 49ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0226 - accuracy: 0.9914\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0466 - accuracy: 0.9831\n",
      "\n",
      "Epoch:  313\n",
      "127/127 - 6s - loss: 0.0243 - accuracy: 0.9907 - val_loss: 0.0346 - val_accuracy: 0.9880 - 6s/epoch - 49ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0184 - accuracy: 0.9933\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0360 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  314\n",
      "127/127 - 6s - loss: 0.0164 - accuracy: 0.9936 - val_loss: 0.0292 - val_accuracy: 0.9897 - 6s/epoch - 49ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0139 - accuracy: 0.9954\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0314 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  315\n",
      "127/127 - 6s - loss: 0.0162 - accuracy: 0.9940 - val_loss: 0.0320 - val_accuracy: 0.9894 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0161 - accuracy: 0.9944\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0356 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  316\n",
      "127/127 - 6s - loss: 0.0151 - accuracy: 0.9945 - val_loss: 0.0312 - val_accuracy: 0.9893 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0168 - accuracy: 0.9942\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0389 - accuracy: 0.9867\n",
      "\n",
      "Epoch:  317\n",
      "127/127 - 6s - loss: 0.0145 - accuracy: 0.9945 - val_loss: 0.0524 - val_accuracy: 0.9840 - 6s/epoch - 50ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0375 - accuracy: 0.9868\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0632 - accuracy: 0.9809\n",
      "\n",
      "Epoch:  318\n",
      "127/127 - 6s - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0259 - val_accuracy: 0.9915 - 6s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0122 - accuracy: 0.9961\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0293 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  319\n",
      "127/127 - 6s - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.0309 - val_accuracy: 0.9902 - 6s/epoch - 49ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0145 - accuracy: 0.9953\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0338 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  320\n",
      "127/127 - 6s - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.0374 - val_accuracy: 0.9884 - 6s/epoch - 50ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 6ms/step - loss: 0.0203 - accuracy: 0.9931\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0442 - accuracy: 0.9860\n",
      "\n",
      "Epoch:  321\n",
      "127/127 - 7s - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.0314 - val_accuracy: 0.9898 - 7s/epoch - 55ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0141 - accuracy: 0.9955\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0292 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  322\n",
      "127/127 - 7s - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.0325 - val_accuracy: 0.9895 - 7s/epoch - 51ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0156 - accuracy: 0.9948\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0352 - accuracy: 0.9887\n",
      "\n",
      "Epoch:  323\n",
      "127/127 - 7s - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.1067 - val_accuracy: 0.9677 - 7s/epoch - 53ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0749 - accuracy: 0.9738\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.1092 - accuracy: 0.9686\n",
      "\n",
      "Epoch:  324\n",
      "127/127 - 12s - loss: 0.0177 - accuracy: 0.9928 - val_loss: 0.0299 - val_accuracy: 0.9902 - 12s/epoch - 93ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.0173 - accuracy: 0.9940\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0401 - accuracy: 0.9869\n",
      "\n",
      "Epoch:  325\n",
      "127/127 - 11s - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.0389 - val_accuracy: 0.9870 - 11s/epoch - 83ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0207 - accuracy: 0.9925\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0414 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  326\n",
      "127/127 - 10s - loss: 0.0244 - accuracy: 0.9908 - val_loss: 0.0318 - val_accuracy: 0.9897 - 10s/epoch - 76ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0170 - accuracy: 0.9944\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0376 - accuracy: 0.9871\n",
      "\n",
      "Epoch:  327\n",
      "127/127 - 10s - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.0240 - val_accuracy: 0.9923 - 10s/epoch - 78ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0123 - accuracy: 0.9962\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0294 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  328\n",
      "127/127 - 9s - loss: 0.0128 - accuracy: 0.9950 - val_loss: 0.0534 - val_accuracy: 0.9828 - 9s/epoch - 74ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0390 - accuracy: 0.9860\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0613 - accuracy: 0.9816\n",
      "\n",
      "Epoch:  329\n",
      "127/127 - 10s - loss: 0.0163 - accuracy: 0.9939 - val_loss: 0.0267 - val_accuracy: 0.9909 - 10s/epoch - 75ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0134 - accuracy: 0.9955\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0311 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  330\n",
      "127/127 - 10s - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.0259 - val_accuracy: 0.9914 - 10s/epoch - 76ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0124 - accuracy: 0.9959\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0307 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  331\n",
      "127/127 - 10s - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.0275 - val_accuracy: 0.9915 - 10s/epoch - 76ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0121 - accuracy: 0.9964\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0351 - accuracy: 0.9887\n",
      "\n",
      "Epoch:  332\n",
      "127/127 - 10s - loss: 0.0151 - accuracy: 0.9946 - val_loss: 0.0317 - val_accuracy: 0.9892 - 10s/epoch - 76ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0149 - accuracy: 0.9950\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0338 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  333\n",
      "127/127 - 10s - loss: 0.0225 - accuracy: 0.9914 - val_loss: 0.0464 - val_accuracy: 0.9855 - 10s/epoch - 77ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0300 - accuracy: 0.9894\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0490 - accuracy: 0.9853\n",
      "\n",
      "Epoch:  334\n",
      "127/127 - 10s - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0268 - val_accuracy: 0.9912 - 10s/epoch - 75ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0117 - accuracy: 0.9962\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0302 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  335\n",
      "127/127 - 12s - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.0326 - val_accuracy: 0.9904 - 12s/epoch - 91ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0150 - accuracy: 0.9952\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0336 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  336\n",
      "127/127 - 10s - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.0329 - val_accuracy: 0.9894 - 10s/epoch - 77ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0161 - accuracy: 0.9946\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0380 - accuracy: 0.9875\n",
      "\n",
      "Epoch:  337\n",
      "127/127 - 10s - loss: 0.0185 - accuracy: 0.9930 - val_loss: 0.0378 - val_accuracy: 0.9879 - 10s/epoch - 76ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0206 - accuracy: 0.9927\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0380 - accuracy: 0.9875\n",
      "\n",
      "Epoch:  338\n",
      "127/127 - 10s - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.0694 - val_accuracy: 0.9803 - 10s/epoch - 78ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0500 - accuracy: 0.9838\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0807 - accuracy: 0.9788\n",
      "\n",
      "Epoch:  339\n",
      "127/127 - 10s - loss: 0.0179 - accuracy: 0.9934 - val_loss: 0.0467 - val_accuracy: 0.9852 - 10s/epoch - 83ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0282 - accuracy: 0.9902\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0450 - accuracy: 0.9855\n",
      "\n",
      "Epoch:  340\n",
      "127/127 - 10s - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0312 - val_accuracy: 0.9902 - 10s/epoch - 78ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0158 - accuracy: 0.9947\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0403 - accuracy: 0.9867\n",
      "\n",
      "Epoch:  341\n",
      "127/127 - 10s - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.0304 - val_accuracy: 0.9912 - 10s/epoch - 79ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0133 - accuracy: 0.9960\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0300 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  342\n",
      "127/127 - 10s - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0508 - val_accuracy: 0.9856 - 10s/epoch - 80ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0301 - accuracy: 0.9897\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0569 - accuracy: 0.9831\n",
      "\n",
      "Epoch:  343\n",
      "127/127 - 10s - loss: 0.0186 - accuracy: 0.9932 - val_loss: 0.0256 - val_accuracy: 0.9917 - 10s/epoch - 79ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0118 - accuracy: 0.9962\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0301 - accuracy: 0.9902\n",
      "\n",
      "Epoch:  344\n",
      "127/127 - 10s - loss: 0.0109 - accuracy: 0.9958 - val_loss: 0.0282 - val_accuracy: 0.9912 - 10s/epoch - 79ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0135 - accuracy: 0.9955\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0348 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  345\n",
      "127/127 - 10s - loss: 0.0114 - accuracy: 0.9955 - val_loss: 0.0430 - val_accuracy: 0.9863 - 10s/epoch - 80ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0253 - accuracy: 0.9914\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0494 - accuracy: 0.9840\n",
      "\n",
      "Epoch:  346\n",
      "127/127 - 10s - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.0316 - val_accuracy: 0.9899 - 10s/epoch - 79ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0158 - accuracy: 0.9948\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0400 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  347\n",
      "127/127 - 10s - loss: 0.0143 - accuracy: 0.9948 - val_loss: 0.0284 - val_accuracy: 0.9916 - 10s/epoch - 80ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0134 - accuracy: 0.9959\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0335 - accuracy: 0.9892\n",
      "\n",
      "Epoch:  348\n",
      "127/127 - 10s - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0257 - val_accuracy: 0.9923 - 10s/epoch - 78ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0112 - accuracy: 0.9965\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0303 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  349\n",
      "127/127 - 10s - loss: 0.0387 - accuracy: 0.9862 - val_loss: 0.0432 - val_accuracy: 0.9864 - 10s/epoch - 78ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0266 - accuracy: 0.9908\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0464 - accuracy: 0.9850\n",
      "\n",
      "Epoch:  350\n",
      "127/127 - 10s - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0305 - val_accuracy: 0.9900 - 10s/epoch - 78ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0154 - accuracy: 0.9946\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0349 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  351\n",
      "127/127 - 10s - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.0477 - val_accuracy: 0.9855 - 10s/epoch - 79ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0236 - accuracy: 0.9921\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0527 - accuracy: 0.9852\n",
      "\n",
      "Epoch:  352\n",
      "127/127 - 10s - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0227 - val_accuracy: 0.9930 - 10s/epoch - 76ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0090 - accuracy: 0.9975\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0253 - accuracy: 0.9912\n",
      "\n",
      "Epoch:  353\n",
      "127/127 - 10s - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0269 - val_accuracy: 0.9915 - 10s/epoch - 77ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0119 - accuracy: 0.9962\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0360 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  354\n",
      "127/127 - 10s - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0297 - val_accuracy: 0.9918 - 10s/epoch - 81ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.0128 - accuracy: 0.9963\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0342 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  355\n",
      "127/127 - 10s - loss: 0.0072 - accuracy: 0.9972 - val_loss: 0.0486 - val_accuracy: 0.9848 - 10s/epoch - 77ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0282 - accuracy: 0.9904\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0553 - accuracy: 0.9835\n",
      "\n",
      "Epoch:  356\n",
      "127/127 - 10s - loss: 0.0110 - accuracy: 0.9959 - val_loss: 0.0492 - val_accuracy: 0.9855 - 10s/epoch - 77ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0292 - accuracy: 0.9904\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0503 - accuracy: 0.9856\n",
      "\n",
      "Epoch:  357\n",
      "127/127 - 10s - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.0431 - val_accuracy: 0.9878 - 10s/epoch - 77ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0252 - accuracy: 0.9917\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0476 - accuracy: 0.9849\n",
      "\n",
      "Epoch:  358\n",
      "127/127 - 10s - loss: 0.0148 - accuracy: 0.9942 - val_loss: 0.0312 - val_accuracy: 0.9909 - 10s/epoch - 77ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0148 - accuracy: 0.9955\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0394 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  359\n",
      "127/127 - 10s - loss: 0.0084 - accuracy: 0.9965 - val_loss: 0.0314 - val_accuracy: 0.9897 - 10s/epoch - 77ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0143 - accuracy: 0.9954\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0355 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  360\n",
      "127/127 - 10s - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.0312 - val_accuracy: 0.9902 - 10s/epoch - 78ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0140 - accuracy: 0.9955\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0380 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  361\n",
      "127/127 - 10s - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.0410 - val_accuracy: 0.9873 - 10s/epoch - 78ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0221 - accuracy: 0.9922\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0459 - accuracy: 0.9850\n",
      "\n",
      "Epoch:  362\n",
      "127/127 - 10s - loss: 0.0175 - accuracy: 0.9933 - val_loss: 0.0377 - val_accuracy: 0.9880 - 10s/epoch - 80ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0207 - accuracy: 0.9928\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0455 - accuracy: 0.9860\n",
      "\n",
      "Epoch:  363\n",
      "127/127 - 10s - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.0260 - val_accuracy: 0.9923 - 10s/epoch - 79ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0116 - accuracy: 0.9965\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0334 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  364\n",
      "127/127 - 10s - loss: 0.0250 - accuracy: 0.9920 - val_loss: 0.1397 - val_accuracy: 0.9617 - 10s/epoch - 77ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.1098 - accuracy: 0.9668\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1287 - accuracy: 0.9620\n",
      "\n",
      "Epoch:  365\n",
      "127/127 - 10s - loss: 0.0230 - accuracy: 0.9915 - val_loss: 0.0244 - val_accuracy: 0.9915 - 10s/epoch - 78ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0109 - accuracy: 0.9966\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0275 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  366\n",
      "127/127 - 9s - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.0241 - val_accuracy: 0.9919 - 9s/epoch - 73ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0100 - accuracy: 0.9969\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0291 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  367\n",
      "127/127 - 10s - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0364 - val_accuracy: 0.9894 - 10s/epoch - 75ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0190 - accuracy: 0.9939\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0385 - accuracy: 0.9865\n",
      "\n",
      "Epoch:  368\n",
      "127/127 - 10s - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.0338 - val_accuracy: 0.9890 - 10s/epoch - 78ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0174 - accuracy: 0.9942\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0368 - accuracy: 0.9869\n",
      "\n",
      "Epoch:  369\n",
      "127/127 - 10s - loss: 0.0134 - accuracy: 0.9950 - val_loss: 0.0310 - val_accuracy: 0.9891 - 10s/epoch - 76ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0139 - accuracy: 0.9951\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0389 - accuracy: 0.9871\n",
      "\n",
      "Epoch:  370\n",
      "127/127 - 10s - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0546 - val_accuracy: 0.9828 - 10s/epoch - 77ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0349 - accuracy: 0.9875\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0663 - accuracy: 0.9810\n",
      "\n",
      "Epoch:  371\n",
      "127/127 - 10s - loss: 0.0095 - accuracy: 0.9965 - val_loss: 0.0305 - val_accuracy: 0.9904 - 10s/epoch - 77ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0134 - accuracy: 0.9958\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0332 - accuracy: 0.9892\n",
      "\n",
      "Epoch:  372\n",
      "127/127 - 10s - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.0257 - val_accuracy: 0.9919 - 10s/epoch - 76ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0104 - accuracy: 0.9969\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0302 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  373\n",
      "127/127 - 10s - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0234 - val_accuracy: 0.9927 - 10s/epoch - 77ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0091 - accuracy: 0.9973\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0272 - accuracy: 0.9912\n",
      "\n",
      "Epoch:  374\n",
      "127/127 - 10s - loss: 0.0053 - accuracy: 0.9980 - val_loss: 0.0355 - val_accuracy: 0.9893 - 10s/epoch - 81ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0178 - accuracy: 0.9942\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0385 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  375\n",
      "127/127 - 12s - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.0290 - val_accuracy: 0.9912 - 12s/epoch - 95ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.0123 - accuracy: 0.9962\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.0342 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  376\n",
      "127/127 - 10s - loss: 0.0196 - accuracy: 0.9925 - val_loss: 0.0437 - val_accuracy: 0.9860 - 10s/epoch - 82ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0250 - accuracy: 0.9909\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0567 - accuracy: 0.9844\n",
      "\n",
      "Epoch:  377\n",
      "127/127 - 10s - loss: 0.0222 - accuracy: 0.9920 - val_loss: 0.0321 - val_accuracy: 0.9895 - 10s/epoch - 78ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0175 - accuracy: 0.9940\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0420 - accuracy: 0.9873\n",
      "\n",
      "Epoch:  378\n",
      "127/127 - 10s - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.0259 - val_accuracy: 0.9922 - 10s/epoch - 78ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0109 - accuracy: 0.9967\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0275 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  379\n",
      "127/127 - 10s - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0281 - val_accuracy: 0.9914 - 10s/epoch - 77ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0117 - accuracy: 0.9964\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0335 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  380\n",
      "127/127 - 10s - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.0391 - val_accuracy: 0.9886 - 10s/epoch - 77ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0205 - accuracy: 0.9932\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0472 - accuracy: 0.9866\n",
      "\n",
      "Epoch:  381\n",
      "127/127 - 10s - loss: 0.0093 - accuracy: 0.9965 - val_loss: 0.0343 - val_accuracy: 0.9891 - 10s/epoch - 77ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0165 - accuracy: 0.9944\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0442 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  382\n",
      "127/127 - 10s - loss: 0.0124 - accuracy: 0.9954 - val_loss: 0.0336 - val_accuracy: 0.9894 - 10s/epoch - 77ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0160 - accuracy: 0.9946\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0341 - accuracy: 0.9894\n",
      "\n",
      "Epoch:  383\n",
      "127/127 - 10s - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.0598 - val_accuracy: 0.9835 - 10s/epoch - 79ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0335 - accuracy: 0.9897\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0564 - accuracy: 0.9831\n",
      "\n",
      "Epoch:  384\n",
      "127/127 - 10s - loss: 0.0241 - accuracy: 0.9910 - val_loss: 0.0335 - val_accuracy: 0.9894 - 10s/epoch - 82ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.0149 - accuracy: 0.9954\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0334 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  385\n",
      "127/127 - 10s - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.0368 - val_accuracy: 0.9884 - 10s/epoch - 80ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0194 - accuracy: 0.9934\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0399 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  386\n",
      "127/127 - 10s - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0224 - val_accuracy: 0.9924 - 10s/epoch - 76ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0084 - accuracy: 0.9974\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0251 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  387\n",
      "127/127 - 10s - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0274 - val_accuracy: 0.9915 - 10s/epoch - 76ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0112 - accuracy: 0.9967\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.0320 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  388\n",
      "127/127 - 10s - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0290 - val_accuracy: 0.9919 - 10s/epoch - 79ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.0118 - accuracy: 0.9966\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.0381 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  389\n",
      "127/127 - 10s - loss: 0.0060 - accuracy: 0.9977 - val_loss: 0.0437 - val_accuracy: 0.9872 - 10s/epoch - 82ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.0238 - accuracy: 0.9920\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.0564 - accuracy: 0.9830\n",
      "\n",
      "Epoch:  390\n",
      "127/127 - 11s - loss: 0.0116 - accuracy: 0.9957 - val_loss: 0.0300 - val_accuracy: 0.9909 - 11s/epoch - 85ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0123 - accuracy: 0.9963\n",
      "for testing\n",
      "378/378 [==============================] - 4s 12ms/step - loss: 0.0351 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  391\n",
      "127/127 - 11s - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.0354 - val_accuracy: 0.9892 - 11s/epoch - 86ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.0155 - accuracy: 0.9949\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0408 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  392\n",
      "127/127 - 10s - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.0265 - val_accuracy: 0.9927 - 10s/epoch - 79ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0101 - accuracy: 0.9973\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0303 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  393\n",
      "127/127 - 10s - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.0508 - val_accuracy: 0.9865 - 10s/epoch - 77ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0244 - accuracy: 0.9932\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0537 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  394\n",
      "127/127 - 10s - loss: 0.0180 - accuracy: 0.9938 - val_loss: 0.0323 - val_accuracy: 0.9901 - 10s/epoch - 78ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0174 - accuracy: 0.9941\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0449 - accuracy: 0.9865\n",
      "\n",
      "Epoch:  395\n",
      "127/127 - 10s - loss: 0.0117 - accuracy: 0.9955 - val_loss: 0.0416 - val_accuracy: 0.9867 - 10s/epoch - 79ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0216 - accuracy: 0.9926\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0476 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  396\n",
      "127/127 - 10s - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.0259 - val_accuracy: 0.9910 - 10s/epoch - 80ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0111 - accuracy: 0.9963\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0302 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  397\n",
      "127/127 - 10s - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.0323 - val_accuracy: 0.9897 - 10s/epoch - 78ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0147 - accuracy: 0.9952\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0331 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  398\n",
      "127/127 - 10s - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0241 - val_accuracy: 0.9927 - 10s/epoch - 79ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0096 - accuracy: 0.9971\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0329 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  399\n",
      "127/127 - 10s - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.0294 - val_accuracy: 0.9902 - 10s/epoch - 79ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0133 - accuracy: 0.9955\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0352 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  400\n",
      "127/127 - 10s - loss: 0.0087 - accuracy: 0.9965 - val_loss: 0.0389 - val_accuracy: 0.9894 - 10s/epoch - 81ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0204 - accuracy: 0.9936\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0495 - accuracy: 0.9870\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for x in range(400):\n",
    "    print(\"\\nEpoch: \",x+1)\n",
    "    history = model.fit(X_train ,y_train ,batch_size=BATCH_SIZE ,epochs=1, verbose=2, shuffle=True, validation_split = 0.33)\n",
    "    if history_dataframe.size == 0:\n",
    "        history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    else:\n",
    "        history_dataframe = pd.concat([history_dataframe,pd.DataFrame.from_dict(history.history)],axis=0,ignore_index=True)\n",
    "    \n",
    "    print(\"for training\")\n",
    "    train_eva.append(model.evaluate(X_train,y_train))\n",
    "    print(\"for testing\")\n",
    "    test_eva.append(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ec37c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.637602</td>\n",
       "      <td>0.623593</td>\n",
       "      <td>0.637929</td>\n",
       "      <td>0.642701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.565123</td>\n",
       "      <td>0.713607</td>\n",
       "      <td>0.508909</td>\n",
       "      <td>0.757312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.465765</td>\n",
       "      <td>0.778789</td>\n",
       "      <td>0.379702</td>\n",
       "      <td>0.825327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.356911</td>\n",
       "      <td>0.843138</td>\n",
       "      <td>0.436299</td>\n",
       "      <td>0.783992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.305732</td>\n",
       "      <td>0.865503</td>\n",
       "      <td>0.398115</td>\n",
       "      <td>0.814806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.011241</td>\n",
       "      <td>0.995990</td>\n",
       "      <td>0.025941</td>\n",
       "      <td>0.991044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.007844</td>\n",
       "      <td>0.997131</td>\n",
       "      <td>0.032335</td>\n",
       "      <td>0.989729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.007574</td>\n",
       "      <td>0.997563</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>0.992672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.008305</td>\n",
       "      <td>0.996792</td>\n",
       "      <td>0.029363</td>\n",
       "      <td>0.990230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.008663</td>\n",
       "      <td>0.996514</td>\n",
       "      <td>0.038926</td>\n",
       "      <td>0.989353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    0.637602  0.623593  0.637929      0.642701\n",
       "1    0.565123  0.713607  0.508909      0.757312\n",
       "2    0.465765  0.778789  0.379702      0.825327\n",
       "3    0.356911  0.843138  0.436299      0.783992\n",
       "4    0.305732  0.865503  0.398115      0.814806\n",
       "..        ...       ...       ...           ...\n",
       "395  0.011241  0.995990  0.025941      0.991044\n",
       "396  0.007844  0.997131  0.032335      0.989729\n",
       "397  0.007574  0.997563  0.024096      0.992672\n",
       "398  0.008305  0.996792  0.029363      0.990230\n",
       "399  0.008663  0.996514  0.038926      0.989353\n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c8463e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva_df = pd.DataFrame(train_eva,columns=['loss','accuracy'])\n",
    "test_eva_df = pd.DataFrame(test_eva,columns=['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cc95506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(df,title,xlabel,ylabel,values=['loss'],legends=[]):\n",
    "    \n",
    "    for value in values:\n",
    "        epoch_count = range(1, len(df.index) + 1)\n",
    "        plt.plot(epoch_count, df[value].tolist())\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    if legends==[]:\n",
    "        legends = values\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35c781fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(train_eva_df,'Train','Epoch','Loss',['loss','accuracy'])\n",
    "plot_graph(test_eva_df,'Test','Epoch','Loss',['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2b80aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  401\n",
      "127/127 - 10s - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.0351 - val_accuracy: 0.9913 - 10s/epoch - 82ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.0163 - accuracy: 0.9954\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0463 - accuracy: 0.9875\n",
      "\n",
      "Epoch:  402\n",
      "127/127 - 10s - loss: 0.0162 - accuracy: 0.9938 - val_loss: 0.0439 - val_accuracy: 0.9861 - 10s/epoch - 82ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.0241 - accuracy: 0.9913\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0503 - accuracy: 0.9853\n",
      "\n",
      "Epoch:  403\n",
      "127/127 - 11s - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0219 - val_accuracy: 0.9928 - 11s/epoch - 87ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.0080 - accuracy: 0.9975\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0281 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  404\n",
      "127/127 - 11s - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0485 - val_accuracy: 0.9874 - 11s/epoch - 87ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.0241 - accuracy: 0.9929\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0640 - accuracy: 0.9841\n",
      "\n",
      "Epoch:  405\n",
      "127/127 - 11s - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.0291 - val_accuracy: 0.9914 - 11s/epoch - 83ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0116 - accuracy: 0.9965\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0325 - accuracy: 0.9902\n",
      "\n",
      "Epoch:  406\n",
      "127/127 - 11s - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.0410 - val_accuracy: 0.9890 - 11s/epoch - 83ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.9947\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0493 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  407\n",
      "127/127 - 10s - loss: 0.0132 - accuracy: 0.9948 - val_loss: 0.0460 - val_accuracy: 0.9874 - 10s/epoch - 82ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0248 - accuracy: 0.9921\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0609 - accuracy: 0.9843\n",
      "\n",
      "Epoch:  408\n",
      "127/127 - 11s - loss: 0.0206 - accuracy: 0.9925 - val_loss: 0.0257 - val_accuracy: 0.9917 - 11s/epoch - 85ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0111 - accuracy: 0.9966\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0291 - accuracy: 0.9902\n",
      "\n",
      "Epoch:  409\n",
      "127/127 - 10s - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0362 - val_accuracy: 0.9887 - 10s/epoch - 78ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0164 - accuracy: 0.9946\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0401 - accuracy: 0.9877\n",
      "\n",
      "Epoch:  410\n",
      "127/127 - 11s - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0276 - val_accuracy: 0.9917 - 11s/epoch - 85ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0113 - accuracy: 0.9965\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0368 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  411\n",
      "127/127 - 11s - loss: 0.0185 - accuracy: 0.9938 - val_loss: 0.0338 - val_accuracy: 0.9899 - 11s/epoch - 87ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0194 - accuracy: 0.9934\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0448 - accuracy: 0.9866\n",
      "\n",
      "Epoch:  412\n",
      "127/127 - 10s - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.0276 - val_accuracy: 0.9915 - 10s/epoch - 80ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0117 - accuracy: 0.9964\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0314 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  413\n",
      "127/127 - 10s - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0297 - val_accuracy: 0.9910 - 10s/epoch - 82ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0117 - accuracy: 0.9965\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0305 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  414\n",
      "127/127 - 12s - loss: 0.0077 - accuracy: 0.9970 - val_loss: 0.0550 - val_accuracy: 0.9847 - 12s/epoch - 95ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0327 - accuracy: 0.9890\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0673 - accuracy: 0.9816\n",
      "\n",
      "Epoch:  415\n",
      "127/127 - 11s - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.0330 - val_accuracy: 0.9901 - 11s/epoch - 90ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.0151 - accuracy: 0.9953\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0413 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  416\n",
      "127/127 - 14s - loss: 0.0270 - accuracy: 0.9913 - val_loss: 0.0389 - val_accuracy: 0.9886 - 14s/epoch - 108ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0211 - accuracy: 0.9934\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0505 - accuracy: 0.9867\n",
      "\n",
      "Epoch:  417\n",
      "127/127 - 11s - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.0330 - val_accuracy: 0.9902 - 11s/epoch - 89ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.0142 - accuracy: 0.9956\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.0409 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  418\n",
      "127/127 - 14s - loss: 0.0109 - accuracy: 0.9960 - val_loss: 0.0311 - val_accuracy: 0.9905 - 14s/epoch - 107ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.0138 - accuracy: 0.9958\n",
      "for testing\n",
      "378/378 [==============================] - 7s 17ms/step - loss: 0.0334 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  419\n",
      "127/127 - 14s - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0264 - val_accuracy: 0.9912 - 14s/epoch - 109ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.0106 - accuracy: 0.9966\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.0346 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  420\n",
      "127/127 - 12s - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.0760 - val_accuracy: 0.9771 - 12s/epoch - 96ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 12ms/step - loss: 0.0489 - accuracy: 0.9837\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.0811 - accuracy: 0.9787\n",
      "\n",
      "Epoch:  421\n",
      "127/127 - 12s - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0270 - val_accuracy: 0.9916 - 12s/epoch - 97ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 13ms/step - loss: 0.0113 - accuracy: 0.9965\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.0289 - accuracy: 0.9904\n",
      "\n",
      "Epoch:  422\n",
      "127/127 - 12s - loss: 0.0098 - accuracy: 0.9961 - val_loss: 0.0435 - val_accuracy: 0.9877 - 12s/epoch - 97ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.0242 - accuracy: 0.9919\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.0549 - accuracy: 0.9835\n",
      "\n",
      "Epoch:  423\n",
      "127/127 - 13s - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0259 - val_accuracy: 0.9927 - 13s/epoch - 99ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.0100 - accuracy: 0.9972\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.0319 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  424\n",
      "127/127 - 12s - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0250 - val_accuracy: 0.9925 - 12s/epoch - 98ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 13ms/step - loss: 0.0090 - accuracy: 0.9975\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.0289 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  425\n",
      "127/127 - 13s - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.0358 - val_accuracy: 0.9898 - 13s/epoch - 105ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.0171 - accuracy: 0.9945\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.0468 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  426\n",
      "127/127 - 13s - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.0429 - val_accuracy: 0.9876 - 13s/epoch - 98ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.0207 - accuracy: 0.9936\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0468 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  427\n",
      "127/127 - 16s - loss: 0.0156 - accuracy: 0.9946 - val_loss: 0.0422 - val_accuracy: 0.9879 - 16s/epoch - 125ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 15ms/step - loss: 0.0208 - accuracy: 0.9934\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.0431 - accuracy: 0.9871\n",
      "\n",
      "Epoch:  428\n",
      "127/127 - 12s - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0325 - val_accuracy: 0.9906 - 12s/epoch - 96ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.0143 - accuracy: 0.9957\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.0458 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  429\n",
      "127/127 - 14s - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.0577 - val_accuracy: 0.9847 - 14s/epoch - 107ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.0332 - accuracy: 0.9902\n",
      "for testing\n",
      "378/378 [==============================] - 8s 21ms/step - loss: 0.0609 - accuracy: 0.9845\n",
      "\n",
      "Epoch:  430\n",
      "127/127 - 14s - loss: 0.0215 - accuracy: 0.9925 - val_loss: 0.0263 - val_accuracy: 0.9915 - 14s/epoch - 111ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 14ms/step - loss: 0.0110 - accuracy: 0.9964\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.0278 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  431\n",
      "127/127 - 12s - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0258 - val_accuracy: 0.9919 - 12s/epoch - 98ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.0098 - accuracy: 0.9970\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.0326 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  432\n",
      "127/127 - 12s - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0221 - val_accuracy: 0.9929 - 12s/epoch - 91ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.0085 - accuracy: 0.9974\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.0302 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  433\n",
      "127/127 - 13s - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0217 - val_accuracy: 0.9932 - 13s/epoch - 99ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.0076 - accuracy: 0.9977\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.0267 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  434\n",
      "127/127 - 12s - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.0349 - val_accuracy: 0.9894 - 12s/epoch - 98ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.0152 - accuracy: 0.9953\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0385 - accuracy: 0.9886\n",
      "\n",
      "Epoch:  435\n",
      "127/127 - 12s - loss: 0.0070 - accuracy: 0.9975 - val_loss: 0.0457 - val_accuracy: 0.9858 - 12s/epoch - 93ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 13ms/step - loss: 0.0261 - accuracy: 0.9912\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.0574 - accuracy: 0.9840\n",
      "\n",
      "Epoch:  436\n",
      "127/127 - 12s - loss: 0.0106 - accuracy: 0.9959 - val_loss: 0.0369 - val_accuracy: 0.9898 - 12s/epoch - 96ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 12ms/step - loss: 0.0174 - accuracy: 0.9948\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.0507 - accuracy: 0.9859\n",
      "\n",
      "Epoch:  437\n",
      "127/127 - 12s - loss: 0.0171 - accuracy: 0.9934 - val_loss: 0.0379 - val_accuracy: 0.9892 - 12s/epoch - 95ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 13ms/step - loss: 0.0175 - accuracy: 0.9950\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.0388 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  438\n",
      "127/127 - 12s - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.0286 - val_accuracy: 0.9917 - 12s/epoch - 98ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 12ms/step - loss: 0.0126 - accuracy: 0.9962\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.0362 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  439\n",
      "127/127 - 13s - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0351 - val_accuracy: 0.9893 - 13s/epoch - 103ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.0175 - accuracy: 0.9943\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.0385 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  440\n",
      "127/127 - 12s - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0493 - val_accuracy: 0.9860 - 12s/epoch - 98ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 14ms/step - loss: 0.0257 - accuracy: 0.9917\n",
      "for testing\n",
      "378/378 [==============================] - 6s 16ms/step - loss: 0.0570 - accuracy: 0.9843\n",
      "\n",
      "Epoch:  441\n",
      "127/127 - 14s - loss: 0.0093 - accuracy: 0.9964 - val_loss: 0.0366 - val_accuracy: 0.9894 - 14s/epoch - 111ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.0181 - accuracy: 0.9944\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.0385 - accuracy: 0.9885\n",
      "\n",
      "Epoch:  442\n",
      "127/127 - 13s - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0297 - val_accuracy: 0.9916 - 13s/epoch - 102ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0114 - accuracy: 0.9969\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0334 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  443\n",
      "127/127 - 12s - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0325 - val_accuracy: 0.9904 - 12s/epoch - 91ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0147 - accuracy: 0.9951\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0407 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  444\n",
      "127/127 - 12s - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.0497 - val_accuracy: 0.9846 - 12s/epoch - 91ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0272 - accuracy: 0.9909\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0578 - accuracy: 0.9840\n",
      "\n",
      "Epoch:  445\n",
      "127/127 - 12s - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.0250 - val_accuracy: 0.9920 - 12s/epoch - 92ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0100 - accuracy: 0.9970\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0368 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  446\n",
      "127/127 - 12s - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.0229 - val_accuracy: 0.9923 - 12s/epoch - 91ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 12ms/step - loss: 0.0085 - accuracy: 0.9974\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0271 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  447\n",
      "127/127 - 12s - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0236 - val_accuracy: 0.9929 - 12s/epoch - 93ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0088 - accuracy: 0.9975\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0329 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  448\n",
      "127/127 - 12s - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0210 - val_accuracy: 0.9936 - 12s/epoch - 96ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0073 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 4s 12ms/step - loss: 0.0278 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  449\n",
      "127/127 - 12s - loss: 8.8741e-04 - accuracy: 0.9999 - val_loss: 0.0229 - val_accuracy: 0.9932 - 12s/epoch - 91ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0082 - accuracy: 0.9977\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0300 - accuracy: 0.9912\n",
      "\n",
      "Epoch:  450\n",
      "127/127 - 12s - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0255 - val_accuracy: 0.9921 - 12s/epoch - 92ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.0093 - accuracy: 0.9972\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0291 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  451\n",
      "127/127 - 12s - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0364 - val_accuracy: 0.9894 - 12s/epoch - 92ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0155 - accuracy: 0.9954\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0395 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  452\n",
      "127/127 - 12s - loss: 0.0149 - accuracy: 0.9948 - val_loss: 0.0511 - val_accuracy: 0.9845 - 12s/epoch - 92ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0303 - accuracy: 0.9900\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0528 - accuracy: 0.9854\n",
      "\n",
      "Epoch:  453\n",
      "127/127 - 12s - loss: 0.0147 - accuracy: 0.9946 - val_loss: 0.0610 - val_accuracy: 0.9831 - 12s/epoch - 92ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0344 - accuracy: 0.9889\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0705 - accuracy: 0.9826\n",
      "\n",
      "Epoch:  454\n",
      "127/127 - 12s - loss: 0.0100 - accuracy: 0.9964 - val_loss: 0.0250 - val_accuracy: 0.9922 - 12s/epoch - 95ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.0101 - accuracy: 0.9969\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0325 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  455\n",
      "127/127 - 12s - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0247 - val_accuracy: 0.9922 - 12s/epoch - 93ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0096 - accuracy: 0.9970\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0336 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  456\n",
      "127/127 - 12s - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0338 - val_accuracy: 0.9899 - 12s/epoch - 92ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0170 - accuracy: 0.9948\n",
      "for testing\n",
      "378/378 [==============================] - 4s 12ms/step - loss: 0.0522 - accuracy: 0.9877\n",
      "\n",
      "Epoch:  457\n",
      "127/127 - 12s - loss: 0.0229 - accuracy: 0.9922 - val_loss: 0.0633 - val_accuracy: 0.9803 - 12s/epoch - 92ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0407 - accuracy: 0.9856\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0699 - accuracy: 0.9791\n",
      "\n",
      "Epoch:  458\n",
      "127/127 - 12s - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.0305 - val_accuracy: 0.9909 - 12s/epoch - 92ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0146 - accuracy: 0.9956\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0378 - accuracy: 0.9879\n",
      "\n",
      "Epoch:  459\n",
      "127/127 - 12s - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0239 - val_accuracy: 0.9920 - 12s/epoch - 96ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.0090 - accuracy: 0.9971\n",
      "for testing\n",
      "378/378 [==============================] - 4s 12ms/step - loss: 0.0284 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  460\n",
      "127/127 - 14s - loss: 8.8135e-04 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9934 - 14s/epoch - 107ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0071 - accuracy: 0.9978\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  461\n",
      "127/127 - 9s - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0279 - val_accuracy: 0.9911 - 9s/epoch - 73ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0112 - accuracy: 0.9964\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0351 - accuracy: 0.9894\n",
      "\n",
      "Epoch:  462\n",
      "127/127 - 7s - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0297 - val_accuracy: 0.9919 - 7s/epoch - 56ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0113 - accuracy: 0.9970\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0329 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  463\n",
      "127/127 - 7s - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0272 - val_accuracy: 0.9921 - 7s/epoch - 56ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 6ms/step - loss: 0.0104 - accuracy: 0.9971\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0370 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  464\n",
      "127/127 - 7s - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.0447 - val_accuracy: 0.9884 - 7s/epoch - 55ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0217 - accuracy: 0.9938\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0498 - accuracy: 0.9877\n",
      "\n",
      "Epoch:  465\n",
      "127/127 - 7s - loss: 0.0188 - accuracy: 0.9932 - val_loss: 0.0317 - val_accuracy: 0.9899 - 7s/epoch - 55ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 6ms/step - loss: 0.0160 - accuracy: 0.9949\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0449 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  466\n",
      "127/127 - 7s - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.0285 - val_accuracy: 0.9911 - 7s/epoch - 58ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 6ms/step - loss: 0.0118 - accuracy: 0.9963\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0366 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  467\n",
      "127/127 - 7s - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0292 - val_accuracy: 0.9917 - 7s/epoch - 55ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 6ms/step - loss: 0.0114 - accuracy: 0.9966\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0338 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  468\n",
      "127/127 - 7s - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0281 - val_accuracy: 0.9919 - 7s/epoch - 54ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 6ms/step - loss: 0.0109 - accuracy: 0.9968\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0332 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  469\n",
      "127/127 - 7s - loss: 9.8804e-04 - accuracy: 0.9999 - val_loss: 0.0238 - val_accuracy: 0.9922 - 7s/epoch - 56ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0083 - accuracy: 0.9974\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0286 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  470\n",
      "127/127 - 7s - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.0555 - val_accuracy: 0.9843 - 7s/epoch - 58ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0365 - accuracy: 0.9884\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0695 - accuracy: 0.9815\n",
      "\n",
      "Epoch:  471\n",
      "127/127 - 7s - loss: 0.0191 - accuracy: 0.9928 - val_loss: 0.0440 - val_accuracy: 0.9869 - 7s/epoch - 57ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0269 - accuracy: 0.9911\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0576 - accuracy: 0.9847\n",
      "\n",
      "Epoch:  472\n",
      "127/127 - 7s - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.0379 - val_accuracy: 0.9884 - 7s/epoch - 58ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0202 - accuracy: 0.9931\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0461 - accuracy: 0.9859\n",
      "\n",
      "Epoch:  473\n",
      "127/127 - 8s - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0305 - val_accuracy: 0.9914 - 8s/epoch - 61ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0122 - accuracy: 0.9965\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0386 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  474\n",
      "127/127 - 7s - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0271 - val_accuracy: 0.9918 - 7s/epoch - 57ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0100 - accuracy: 0.9970\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0352 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  475\n",
      "127/127 - 7s - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0268 - val_accuracy: 0.9920 - 7s/epoch - 57ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0099 - accuracy: 0.9970\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0349 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  476\n",
      "127/127 - 7s - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0237 - val_accuracy: 0.9928 - 7s/epoch - 57ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0086 - accuracy: 0.9975\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0323 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  477\n",
      "127/127 - 7s - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0253 - val_accuracy: 0.9928 - 7s/epoch - 57ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0090 - accuracy: 0.9975\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0302 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  478\n",
      "127/127 - 7s - loss: 7.1124e-04 - accuracy: 0.9999 - val_loss: 0.0248 - val_accuracy: 0.9926 - 7s/epoch - 57ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0086 - accuracy: 0.9975\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0289 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  479\n",
      "127/127 - 7s - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0301 - val_accuracy: 0.9922 - 7s/epoch - 57ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0115 - accuracy: 0.9969\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0396 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  480\n",
      "127/127 - 7s - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.0408 - val_accuracy: 0.9878 - 7s/epoch - 58ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0198 - accuracy: 0.9936\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0463 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  481\n",
      "127/127 - 7s - loss: 0.0359 - accuracy: 0.9885 - val_loss: 0.0285 - val_accuracy: 0.9909 - 7s/epoch - 57ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0142 - accuracy: 0.9951\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0383 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  482\n",
      "127/127 - 7s - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0252 - val_accuracy: 0.9921 - 7s/epoch - 58ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0094 - accuracy: 0.9971\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0320 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  483\n",
      "127/127 - 7s - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0313 - val_accuracy: 0.9907 - 7s/epoch - 59ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0126 - accuracy: 0.9963\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0356 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  484\n",
      "127/127 - 8s - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0231 - val_accuracy: 0.9931 - 8s/epoch - 59ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0081 - accuracy: 0.9977\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0289 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  485\n",
      "127/127 - 7s - loss: 6.0143e-04 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 0.9936 - 7s/epoch - 58ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0077 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0276 - accuracy: 0.9918\n",
      "\n",
      "Epoch:  486\n",
      "127/127 - 8s - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0253 - val_accuracy: 0.9924 - 8s/epoch - 61ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0091 - accuracy: 0.9973\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0268 - accuracy: 0.9918\n",
      "\n",
      "Epoch:  487\n",
      "127/127 - 7s - loss: 9.2691e-04 - accuracy: 0.9999 - val_loss: 0.0226 - val_accuracy: 0.9932 - 7s/epoch - 59ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0077 - accuracy: 0.9977\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0255 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  488\n",
      "127/127 - 8s - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0307 - val_accuracy: 0.9916 - 8s/epoch - 60ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0113 - accuracy: 0.9969\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0329 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  489\n",
      "127/127 - 7s - loss: 0.0072 - accuracy: 0.9969 - val_loss: 0.0773 - val_accuracy: 0.9810 - 7s/epoch - 58ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0455 - accuracy: 0.9871\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0792 - accuracy: 0.9807\n",
      "\n",
      "Epoch:  490\n",
      "127/127 - 7s - loss: 0.0230 - accuracy: 0.9923 - val_loss: 0.0435 - val_accuracy: 0.9874 - 7s/epoch - 59ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0234 - accuracy: 0.9927\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0494 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  491\n",
      "127/127 - 7s - loss: 0.0140 - accuracy: 0.9946 - val_loss: 0.0389 - val_accuracy: 0.9887 - 7s/epoch - 59ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0211 - accuracy: 0.9931\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0475 - accuracy: 0.9850\n",
      "\n",
      "Epoch:  492\n",
      "127/127 - 7s - loss: 0.0104 - accuracy: 0.9962 - val_loss: 0.0544 - val_accuracy: 0.9841 - 7s/epoch - 58ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0272 - accuracy: 0.9910\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0580 - accuracy: 0.9826\n",
      "\n",
      "Epoch:  493\n",
      "127/127 - 7s - loss: 0.0090 - accuracy: 0.9964 - val_loss: 0.0290 - val_accuracy: 0.9911 - 7s/epoch - 58ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0123 - accuracy: 0.9962\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0368 - accuracy: 0.9889\n",
      "\n",
      "Epoch:  494\n",
      "127/127 - 7s - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0343 - val_accuracy: 0.9909 - 7s/epoch - 59ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0159 - accuracy: 0.9950\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0462 - accuracy: 0.9873\n",
      "\n",
      "Epoch:  495\n",
      "127/127 - 8s - loss: 0.0052 - accuracy: 0.9980 - val_loss: 0.0242 - val_accuracy: 0.9930 - 8s/epoch - 59ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0089 - accuracy: 0.9975\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0298 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  496\n",
      "127/127 - 7s - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0295 - val_accuracy: 0.9909 - 7s/epoch - 59ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0116 - accuracy: 0.9964\n",
      "for testing\n",
      "378/378 [==============================] - 4s 12ms/step - loss: 0.0348 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  497\n",
      "127/127 - 18s - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0282 - val_accuracy: 0.9920 - 18s/epoch - 144ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0101 - accuracy: 0.9972\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0372 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  498\n",
      "127/127 - 11s - loss: 6.3401e-04 - accuracy: 0.9999 - val_loss: 0.0227 - val_accuracy: 0.9930 - 11s/epoch - 85ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0077 - accuracy: 0.9977\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0278 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  499\n",
      "127/127 - 10s - loss: 2.9001e-04 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9935 - 10s/epoch - 78ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0079 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0297 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  500\n",
      "127/127 - 9s - loss: 4.4122e-04 - accuracy: 0.9999 - val_loss: 0.0248 - val_accuracy: 0.9933 - 9s/epoch - 68ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0085 - accuracy: 0.9978\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0309 - accuracy: 0.9912\n",
      "\n",
      "Epoch:  501\n",
      "127/127 - 9s - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.0966 - val_accuracy: 0.9721 - 9s/epoch - 69ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 8ms/step - loss: 0.0795 - accuracy: 0.9754\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1106 - accuracy: 0.9701\n",
      "\n",
      "Epoch:  502\n",
      "127/127 - 9s - loss: 0.0223 - accuracy: 0.9920 - val_loss: 0.0237 - val_accuracy: 0.9915 - 9s/epoch - 68ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0097 - accuracy: 0.9967\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0308 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  503\n",
      "127/127 - 8s - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0235 - val_accuracy: 0.9924 - 8s/epoch - 59ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0096 - accuracy: 0.9969\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0280 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  504\n",
      "127/127 - 8s - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.0256 - val_accuracy: 0.9920 - 8s/epoch - 59ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0097 - accuracy: 0.9970\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0311 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  505\n",
      "127/127 - 8s - loss: 9.3519e-04 - accuracy: 0.9999 - val_loss: 0.0222 - val_accuracy: 0.9931 - 8s/epoch - 59ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0076 - accuracy: 0.9977\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0298 - accuracy: 0.9912\n",
      "\n",
      "Epoch:  506\n",
      "127/127 - 8s - loss: 4.6097e-04 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9929 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0080 - accuracy: 0.9976\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0302 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  507\n",
      "127/127 - 12s - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0477 - val_accuracy: 0.9873 - 12s/epoch - 91ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0266 - accuracy: 0.9925\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0517 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  508\n",
      "127/127 - 12s - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.0311 - val_accuracy: 0.9907 - 12s/epoch - 96ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.0125 - accuracy: 0.9963\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0324 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  509\n",
      "127/127 - 10s - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0362 - val_accuracy: 0.9898 - 10s/epoch - 76ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0171 - accuracy: 0.9946\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0428 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  510\n",
      "127/127 - 10s - loss: 0.0241 - accuracy: 0.9924 - val_loss: 0.0305 - val_accuracy: 0.9913 - 10s/epoch - 81ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0147 - accuracy: 0.9954\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0359 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  511\n",
      "127/127 - 9s - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0240 - val_accuracy: 0.9932 - 9s/epoch - 73ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0085 - accuracy: 0.9977\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0307 - accuracy: 0.9918\n",
      "\n",
      "Epoch:  512\n",
      "127/127 - 9s - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0245 - val_accuracy: 0.9927 - 9s/epoch - 72ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0086 - accuracy: 0.9975\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0283 - accuracy: 0.9918\n",
      "\n",
      "Epoch:  513\n",
      "127/127 - 9s - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0350 - val_accuracy: 0.9902 - 9s/epoch - 74ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0149 - accuracy: 0.9956\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.0432 - accuracy: 0.9885\n",
      "\n",
      "Epoch:  514\n",
      "127/127 - 16s - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0264 - val_accuracy: 0.9924 - 16s/epoch - 129ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0094 - accuracy: 0.9973\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0307 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  515\n",
      "127/127 - 10s - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0282 - val_accuracy: 0.9923 - 10s/epoch - 76ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0111 - accuracy: 0.9969\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0369 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  516\n",
      "127/127 - 8s - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.0307 - val_accuracy: 0.9919 - 8s/epoch - 65ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0116 - accuracy: 0.9969\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0395 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  517\n",
      "127/127 - 9s - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.0393 - val_accuracy: 0.9884 - 9s/epoch - 70ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0202 - accuracy: 0.9932\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0557 - accuracy: 0.9852\n",
      "\n",
      "Epoch:  518\n",
      "127/127 - 9s - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.0271 - val_accuracy: 0.9924 - 9s/epoch - 72ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0103 - accuracy: 0.9971\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0342 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  519\n",
      "127/127 - 9s - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0276 - val_accuracy: 0.9910 - 9s/epoch - 70ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0115 - accuracy: 0.9962\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0362 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  520\n",
      "127/127 - 7s - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0330 - val_accuracy: 0.9900 - 7s/epoch - 59ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0128 - accuracy: 0.9961\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0382 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  521\n",
      "127/127 - 10s - loss: 0.0230 - accuracy: 0.9924 - val_loss: 0.0345 - val_accuracy: 0.9895 - 10s/epoch - 77ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0160 - accuracy: 0.9949\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0410 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  522\n",
      "127/127 - 8s - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.0236 - val_accuracy: 0.9925 - 8s/epoch - 60ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0086 - accuracy: 0.9974\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0303 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  523\n",
      "127/127 - 8s - loss: 7.9130e-04 - accuracy: 0.9999 - val_loss: 0.0232 - val_accuracy: 0.9933 - 8s/epoch - 59ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0079 - accuracy: 0.9978\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0315 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  524\n",
      "127/127 - 8s - loss: 6.9201e-04 - accuracy: 0.9998 - val_loss: 0.0241 - val_accuracy: 0.9930 - 8s/epoch - 59ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0085 - accuracy: 0.9976\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0302 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  525\n",
      "127/127 - 8s - loss: 6.1636e-04 - accuracy: 0.9999 - val_loss: 0.0218 - val_accuracy: 0.9940 - 8s/epoch - 60ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0074 - accuracy: 0.9980\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0299 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  526\n",
      "127/127 - 8s - loss: 4.0077e-04 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9929 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0088 - accuracy: 0.9976\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0332 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  527\n",
      "127/127 - 8s - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0990 - val_accuracy: 0.9758 - 8s/epoch - 59ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0672 - accuracy: 0.9806\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.1117 - accuracy: 0.9742\n",
      "\n",
      "Epoch:  528\n",
      "127/127 - 8s - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.0447 - val_accuracy: 0.9865 - 8s/epoch - 60ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0246 - accuracy: 0.9919\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0518 - accuracy: 0.9856\n",
      "\n",
      "Epoch:  529\n",
      "127/127 - 8s - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0295 - val_accuracy: 0.9922 - 8s/epoch - 59ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0108 - accuracy: 0.9971\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0342 - accuracy: 0.9912\n",
      "\n",
      "Epoch:  530\n",
      "127/127 - 8s - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0402 - val_accuracy: 0.9889 - 8s/epoch - 60ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0174 - accuracy: 0.9947\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0372 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  531\n",
      "127/127 - 8s - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0232 - val_accuracy: 0.9927 - 8s/epoch - 60ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0083 - accuracy: 0.9975\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0310 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  532\n",
      "127/127 - 8s - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0238 - val_accuracy: 0.9932 - 8s/epoch - 60ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0085 - accuracy: 0.9977\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0331 - accuracy: 0.9902\n",
      "\n",
      "Epoch:  533\n",
      "127/127 - 8s - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0316 - val_accuracy: 0.9917 - 8s/epoch - 60ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0125 - accuracy: 0.9965\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0355 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  534\n",
      "127/127 - 8s - loss: 0.0087 - accuracy: 0.9965 - val_loss: 0.0880 - val_accuracy: 0.9758 - 8s/epoch - 60ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0607 - accuracy: 0.9810\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0962 - accuracy: 0.9750\n",
      "\n",
      "Epoch:  535\n",
      "127/127 - 8s - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0306 - val_accuracy: 0.9905 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0130 - accuracy: 0.9958\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0431 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  536\n",
      "127/127 - 8s - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0284 - val_accuracy: 0.9920 - 8s/epoch - 60ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 8ms/step - loss: 0.0103 - accuracy: 0.9971\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0326 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  537\n",
      "127/127 - 11s - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.0246 - val_accuracy: 0.9925 - 11s/epoch - 85ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0088 - accuracy: 0.9974\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0349 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  538\n",
      "127/127 - 8s - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0299 - val_accuracy: 0.9917 - 8s/epoch - 60ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0121 - accuracy: 0.9965\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0369 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  539\n",
      "127/127 - 8s - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0268 - val_accuracy: 0.9917 - 8s/epoch - 60ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0101 - accuracy: 0.9969\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0366 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  540\n",
      "127/127 - 8s - loss: 7.3054e-04 - accuracy: 0.9999 - val_loss: 0.0234 - val_accuracy: 0.9936 - 8s/epoch - 60ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0079 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0306 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  541\n",
      "127/127 - 8s - loss: 3.6044e-04 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9935 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0083 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0316 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  542\n",
      "127/127 - 8s - loss: 2.2350e-04 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9937 - 8s/epoch - 60ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0077 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0291 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  543\n",
      "127/127 - 12s - loss: 1.3241e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9939 - 12s/epoch - 96ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0080 - accuracy: 0.9980\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.0299 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  544\n",
      "127/127 - 12s - loss: 1.3179e-04 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9937 - 12s/epoch - 98ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0081 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0313 - accuracy: 0.9912\n",
      "\n",
      "Epoch:  545\n",
      "127/127 - 12s - loss: 1.6306e-04 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9939 - 12s/epoch - 92ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0079 - accuracy: 0.9980\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0294 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  546\n",
      "127/127 - 11s - loss: 9.8426e-05 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9938 - 11s/epoch - 86ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0081 - accuracy: 0.9980\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0300 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  547\n",
      "127/127 - 11s - loss: 8.8675e-05 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9936 - 11s/epoch - 90ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 13ms/step - loss: 0.0080 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0300 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  548\n",
      "127/127 - 11s - loss: 8.8923e-05 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9938 - 11s/epoch - 85ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0082 - accuracy: 0.9980\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0309 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  549\n",
      "127/127 - 8s - loss: 3.3874e-04 - accuracy: 0.9999 - val_loss: 0.0313 - val_accuracy: 0.9918 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0115 - accuracy: 0.9969\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0484 - accuracy: 0.9889\n",
      "\n",
      "Epoch:  550\n",
      "127/127 - 8s - loss: 0.0603 - accuracy: 0.9808 - val_loss: 0.0823 - val_accuracy: 0.9752 - 8s/epoch - 60ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0686 - accuracy: 0.9776\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0975 - accuracy: 0.9726\n",
      "\n",
      "Epoch:  551\n",
      "127/127 - 8s - loss: 0.0142 - accuracy: 0.9948 - val_loss: 0.0232 - val_accuracy: 0.9919 - 8s/epoch - 60ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0095 - accuracy: 0.9970\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0293 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  552\n",
      "127/127 - 8s - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0276 - val_accuracy: 0.9910 - 8s/epoch - 61ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0110 - accuracy: 0.9966\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0322 - accuracy: 0.9912\n",
      "\n",
      "Epoch:  553\n",
      "127/127 - 8s - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0228 - val_accuracy: 0.9930 - 8s/epoch - 60ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0085 - accuracy: 0.9975\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0337 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  554\n",
      "127/127 - 8s - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0258 - val_accuracy: 0.9929 - 8s/epoch - 61ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0095 - accuracy: 0.9974\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0316 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  555\n",
      "127/127 - 8s - loss: 5.8590e-04 - accuracy: 0.9999 - val_loss: 0.0213 - val_accuracy: 0.9933 - 8s/epoch - 60ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0074 - accuracy: 0.9978\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0303 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  556\n",
      "127/127 - 8s - loss: 4.0810e-04 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9938 - 8s/epoch - 64ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0073 - accuracy: 0.9980\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0294 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  557\n",
      "127/127 - 8s - loss: 2.2159e-04 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9935 - 8s/epoch - 61ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0073 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0287 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  558\n",
      "127/127 - 8s - loss: 2.1503e-04 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9939 - 8s/epoch - 60ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0073 - accuracy: 0.9980\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0293 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  559\n",
      "127/127 - 7s - loss: 2.9630e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9930 - 7s/epoch - 56ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0081 - accuracy: 0.9977\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0302 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  560\n",
      "127/127 - 8s - loss: 3.0797e-04 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9932 - 8s/epoch - 65ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0083 - accuracy: 0.9977\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0328 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  561\n",
      "127/127 - 8s - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0357 - val_accuracy: 0.9902 - 8s/epoch - 65ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0153 - accuracy: 0.9953\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0437 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  562\n",
      "127/127 - 8s - loss: 0.0166 - accuracy: 0.9938 - val_loss: 0.0312 - val_accuracy: 0.9914 - 8s/epoch - 64ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0149 - accuracy: 0.9958\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0403 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  563\n",
      "127/127 - 8s - loss: 0.0262 - accuracy: 0.9906 - val_loss: 0.0315 - val_accuracy: 0.9904 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0138 - accuracy: 0.9959\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0352 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  564\n",
      "127/127 - 8s - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0277 - val_accuracy: 0.9920 - 8s/epoch - 61ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0104 - accuracy: 0.9970\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0327 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  565\n",
      "127/127 - 8s - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.0305 - val_accuracy: 0.9912 - 8s/epoch - 61ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0121 - accuracy: 0.9964\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0393 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  566\n",
      "127/127 - 8s - loss: 0.0050 - accuracy: 0.9980 - val_loss: 0.0292 - val_accuracy: 0.9917 - 8s/epoch - 61ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0112 - accuracy: 0.9968\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0350 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  567\n",
      "127/127 - 8s - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0274 - val_accuracy: 0.9929 - 8s/epoch - 61ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0100 - accuracy: 0.9974\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0331 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  568\n",
      "127/127 - 8s - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0404 - val_accuracy: 0.9900 - 8s/epoch - 61ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0182 - accuracy: 0.9951\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0427 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  569\n",
      "127/127 - 8s - loss: 9.5188e-04 - accuracy: 0.9998 - val_loss: 0.0235 - val_accuracy: 0.9932 - 8s/epoch - 61ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0079 - accuracy: 0.9977\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0296 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  570\n",
      "127/127 - 8s - loss: 2.5922e-04 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9937 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0079 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0302 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  571\n",
      "127/127 - 8s - loss: 5.7973e-04 - accuracy: 0.9998 - val_loss: 0.0355 - val_accuracy: 0.9908 - 8s/epoch - 61ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0155 - accuracy: 0.9954\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0433 - accuracy: 0.9885\n",
      "\n",
      "Epoch:  572\n",
      "127/127 - 8s - loss: 0.0171 - accuracy: 0.9938 - val_loss: 0.0559 - val_accuracy: 0.9809 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0398 - accuracy: 0.9855\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0697 - accuracy: 0.9778\n",
      "\n",
      "Epoch:  573\n",
      "127/127 - 8s - loss: 0.0182 - accuracy: 0.9934 - val_loss: 0.0234 - val_accuracy: 0.9924 - 8s/epoch - 61ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0095 - accuracy: 0.9970\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0361 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  574\n",
      "127/127 - 8s - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0229 - val_accuracy: 0.9933 - 8s/epoch - 61ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0082 - accuracy: 0.9977\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0291 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  575\n",
      "127/127 - 8s - loss: 9.4383e-04 - accuracy: 0.9998 - val_loss: 0.0237 - val_accuracy: 0.9933 - 8s/epoch - 64ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0086 - accuracy: 0.9975\n",
      "for testing\n",
      "378/378 [==============================] - 2s 7ms/step - loss: 0.0328 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  576\n",
      "127/127 - 8s - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0288 - val_accuracy: 0.9917 - 8s/epoch - 64ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0108 - accuracy: 0.9969\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0323 - accuracy: 0.9912\n",
      "\n",
      "Epoch:  577\n",
      "127/127 - 8s - loss: 0.0141 - accuracy: 0.9943 - val_loss: 0.0312 - val_accuracy: 0.9915 - 8s/epoch - 61ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0130 - accuracy: 0.9963\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.0427 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  578\n",
      "127/127 - 8s - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0355 - val_accuracy: 0.9905 - 8s/epoch - 63ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0151 - accuracy: 0.9957\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0386 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  579\n",
      "127/127 - 8s - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0233 - val_accuracy: 0.9930 - 8s/epoch - 61ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0080 - accuracy: 0.9977\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0332 - accuracy: 0.9902\n",
      "\n",
      "Epoch:  580\n",
      "127/127 - 8s - loss: 2.8035e-04 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9937 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0074 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0282 - accuracy: 0.9912\n",
      "\n",
      "Epoch:  581\n",
      "127/127 - 8s - loss: 1.4783e-04 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9937 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0077 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0293 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  582\n",
      "127/127 - 8s - loss: 1.2411e-04 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9935 - 8s/epoch - 61ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0079 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0296 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  583\n",
      "127/127 - 8s - loss: 1.1173e-04 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9937 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0075 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0297 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  584\n",
      "127/127 - 8s - loss: 9.3995e-05 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9936 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0078 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0299 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  585\n",
      "127/127 - 8s - loss: 8.3168e-05 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9935 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0079 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0291 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  586\n",
      "127/127 - 8s - loss: 7.2458e-05 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9936 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0079 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 2s 7ms/step - loss: 0.0293 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  587\n",
      "127/127 - 8s - loss: 6.7809e-05 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9935 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0080 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0296 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  588\n",
      "127/127 - 8s - loss: 6.1721e-05 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9937 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0080 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0302 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  589\n",
      "127/127 - 8s - loss: 6.4696e-05 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9935 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0083 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0296 - accuracy: 0.9912\n",
      "\n",
      "Epoch:  590\n",
      "127/127 - 8s - loss: 5.7676e-05 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 0.9935 - 8s/epoch - 63ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0084 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0310 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  591\n",
      "127/127 - 8s - loss: 4.9375e-05 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9934 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0084 - accuracy: 0.9978\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0304 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  592\n",
      "127/127 - 8s - loss: 5.0763e-05 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 0.9932 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 8ms/step - loss: 0.0086 - accuracy: 0.9978\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0306 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  593\n",
      "127/127 - 9s - loss: 1.9248e-04 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.9920 - 9s/epoch - 67ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0110 - accuracy: 0.9973\n",
      "for testing\n",
      "378/378 [==============================] - 2s 7ms/step - loss: 0.0341 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  594\n",
      "127/127 - 8s - loss: 0.0449 - accuracy: 0.9851 - val_loss: 0.0415 - val_accuracy: 0.9872 - 8s/epoch - 63ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0263 - accuracy: 0.9911\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0592 - accuracy: 0.9826\n",
      "\n",
      "Epoch:  595\n",
      "127/127 - 8s - loss: 0.0134 - accuracy: 0.9948 - val_loss: 0.0197 - val_accuracy: 0.9935 - 8s/epoch - 62ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0078 - accuracy: 0.9976\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0282 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  596\n",
      "127/127 - 8s - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0230 - val_accuracy: 0.9932 - 8s/epoch - 63ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0081 - accuracy: 0.9977\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0261 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  597\n",
      "127/127 - 10s - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0239 - val_accuracy: 0.9930 - 10s/epoch - 79ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0085 - accuracy: 0.9976\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0285 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  598\n",
      "127/127 - 8s - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.1028 - val_accuracy: 0.9730 - 8s/epoch - 64ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0816 - accuracy: 0.9762\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1114 - accuracy: 0.9721\n",
      "\n",
      "Epoch:  599\n",
      "127/127 - 8s - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0290 - val_accuracy: 0.9916 - 8s/epoch - 64ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0110 - accuracy: 0.9968\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0389 - accuracy: 0.9892\n",
      "\n",
      "Epoch:  600\n",
      "127/127 - 9s - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0227 - val_accuracy: 0.9934 - 9s/epoch - 68ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0082 - accuracy: 0.9976\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0320 - accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for x in range(200):\n",
    "    print(\"\\nEpoch: \",400+x+1)\n",
    "    history = model.fit(X_train ,y_train ,batch_size=BATCH_SIZE ,epochs=1, verbose=2, shuffle=True, validation_split = 0.33)\n",
    "    if history_dataframe.size == 0:\n",
    "        history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    else:\n",
    "        history_dataframe = pd.concat([history_dataframe,pd.DataFrame.from_dict(history.history)],axis=0,ignore_index=True)\n",
    "    \n",
    "    print(\"for training\")\n",
    "    train_eva.append(model.evaluate(X_train,y_train))\n",
    "    print(\"for testing\")\n",
    "    test_eva.append(model.evaluate(X_test, y_test))\n",
    "    \n",
    "#     clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8249e890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9914020895957947"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eva_df['accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5bbbeaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9974784851074219"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eva_df['accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138fa379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
