{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85c4fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e35daa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e6aebd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_initials = 'wheat_30_var_2_species'\n",
    "file_name = file_name_initials+\".csv\"\n",
    "\n",
    "def dir(file_name):\n",
    "    return '../data/'+file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "554bc6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class filter_method(Enum):\n",
    "    none = 0\n",
    "    snv = 1\n",
    "    msc = 2\n",
    "    savgol = 3\n",
    "\n",
    "FILT = 2\n",
    "FILTER = filter_method(FILT).name\n",
    "\n",
    "# to be set if filter chosen is savgol\n",
    "WINDOW = 7\n",
    "ORDER = 2\n",
    "DERIVATIVE = 1\n",
    "\n",
    "#will be used for test dataset in msc\n",
    "reference= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "99836770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_file_name(file_name):\n",
    "    name = \"./dataset/\"+str(file_name)\n",
    "    if FILT != 0:\n",
    "        name+=\"_FILTER_\"+str(FILTER)\n",
    "    if FILTER == \"savgol\":\n",
    "        name+=\"_WINDOW_\"+str(WINDOW)+\"_ORDER_\"+str(ORDER)+\"_DERIVATIVE_\"+str(DERIVATIVE)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0442d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_name):\n",
    "    DATASET_FILE_NAME = dataset_file_name(file_name)\n",
    "    X_train = np.load(DATASET_FILE_NAME+\"_train_dataset.npy\")\n",
    "    y_train = np.load(DATASET_FILE_NAME+\"_train_dataset_label.npy\")\n",
    "    X_test = np.load(DATASET_FILE_NAME+\"_test_dataset.npy\")\n",
    "    y_test = np.load(DATASET_FILE_NAME+\"_test_dataset_label.npy\")\n",
    "    \n",
    "    return (X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "435abfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train, X_test, y_test) = load_dataset(file_name_initials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "58535347",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_set = set(np.concatenate((y_train, y_test), axis =0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e8c8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_CLASSES = len(y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26a6b6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_OF_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1e1e570e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48384, 147, 1)\n",
      "(12096, 147, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ec820add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Input, Conv1D, Flatten, Dense, MaxPooling1D\n",
    "from keras.layers import LeakyReLU, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba682707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(input_shape,num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=5, input_shape=input_shape, activation='LeakyReLU'))\n",
    "    model.add(MaxPooling1D(pool_size=5))\n",
    "    model.add(Conv1D(filters=64, kernel_size=5, activation='LeakyReLU'))\n",
    "    model.add(MaxPooling1D(pool_size=5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(800, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(400, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d95ace51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(X_train.shape[1:],NUM_OF_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "33a0377c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 143, 32)           192       \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 28, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 24, 64)            10304     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 4, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1000)              257000    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 800)               800800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 400)               320400    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 802       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,389,498\n",
      "Trainable params: 1,389,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "20cd1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva = []\n",
    "test_eva = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7fd5eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dataframe = pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "863f63f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  1\n",
      "127/127 - 27s - loss: 0.6764 - accuracy: 0.5588 - val_loss: 0.6100 - val_accuracy: 0.6993 - 27s/epoch - 210ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 28s 18ms/step - loss: 0.6102 - accuracy: 0.6981\n",
      "for testing\n",
      "378/378 [==============================] - 9s 22ms/step - loss: 0.6072 - accuracy: 0.7020\n",
      "\n",
      "Epoch:  2\n",
      "127/127 - 18s - loss: 0.6150 - accuracy: 0.6677 - val_loss: 0.6028 - val_accuracy: 0.6802 - 18s/epoch - 143ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 24s 16ms/step - loss: 0.6034 - accuracy: 0.6775\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.5974 - accuracy: 0.6803\n",
      "\n",
      "Epoch:  3\n",
      "127/127 - 16s - loss: 0.5990 - accuracy: 0.6837 - val_loss: 0.5772 - val_accuracy: 0.7076 - 16s/epoch - 124ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.5770 - accuracy: 0.7071\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.5713 - accuracy: 0.7113\n",
      "\n",
      "Epoch:  4\n",
      "127/127 - 14s - loss: 0.5978 - accuracy: 0.6852 - val_loss: 0.5861 - val_accuracy: 0.6976 - 14s/epoch - 112ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.5860 - accuracy: 0.6978\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.5812 - accuracy: 0.7042\n",
      "\n",
      "Epoch:  5\n",
      "127/127 - 13s - loss: 0.5929 - accuracy: 0.6893 - val_loss: 0.5705 - val_accuracy: 0.7127 - 13s/epoch - 104ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.5709 - accuracy: 0.7121\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.5660 - accuracy: 0.7169\n",
      "\n",
      "Epoch:  6\n",
      "127/127 - 14s - loss: 0.5872 - accuracy: 0.6952 - val_loss: 0.5716 - val_accuracy: 0.7130 - 14s/epoch - 114ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.5715 - accuracy: 0.7128\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.5680 - accuracy: 0.7143\n",
      "\n",
      "Epoch:  7\n",
      "127/127 - 13s - loss: 0.5806 - accuracy: 0.6998 - val_loss: 0.5633 - val_accuracy: 0.7134 - 13s/epoch - 106ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.5638 - accuracy: 0.7119\n",
      "for testing\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.5585 - accuracy: 0.7154\n",
      "\n",
      "Epoch:  8\n",
      "127/127 - 22s - loss: 0.5760 - accuracy: 0.7033 - val_loss: 0.5651 - val_accuracy: 0.7127 - 22s/epoch - 172ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 27s 18ms/step - loss: 0.5651 - accuracy: 0.7116\n",
      "for testing\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.5603 - accuracy: 0.7144\n",
      "\n",
      "Epoch:  9\n",
      "127/127 - 18s - loss: 0.5702 - accuracy: 0.7065 - val_loss: 0.5327 - val_accuracy: 0.7475 - 18s/epoch - 141ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.5331 - accuracy: 0.7451\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.5295 - accuracy: 0.7460\n",
      "\n",
      "Epoch:  10\n",
      "127/127 - 14s - loss: 0.5534 - accuracy: 0.7203 - val_loss: 0.5246 - val_accuracy: 0.7337 - 14s/epoch - 109ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.5251 - accuracy: 0.7333\n",
      "for testing\n",
      "378/378 [==============================] - 6s 16ms/step - loss: 0.5240 - accuracy: 0.7363\n",
      "\n",
      "Epoch:  11\n",
      "127/127 - 14s - loss: 0.5439 - accuracy: 0.7286 - val_loss: 0.4935 - val_accuracy: 0.7709 - 14s/epoch - 113ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.4949 - accuracy: 0.7688\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.4940 - accuracy: 0.7675\n",
      "\n",
      "Epoch:  12\n",
      "127/127 - 14s - loss: 0.5261 - accuracy: 0.7420 - val_loss: 0.4624 - val_accuracy: 0.7929 - 14s/epoch - 110ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.4633 - accuracy: 0.7911\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.4628 - accuracy: 0.7875\n",
      "\n",
      "Epoch:  13\n",
      "127/127 - 14s - loss: 0.5218 - accuracy: 0.7442 - val_loss: 0.4668 - val_accuracy: 0.7871 - 14s/epoch - 109ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.4681 - accuracy: 0.7871\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.4679 - accuracy: 0.7846\n",
      "\n",
      "Epoch:  14\n",
      "127/127 - 14s - loss: 0.5001 - accuracy: 0.7625 - val_loss: 0.4935 - val_accuracy: 0.7506 - 14s/epoch - 111ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.4948 - accuracy: 0.7523\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.4970 - accuracy: 0.7511\n",
      "\n",
      "Epoch:  15\n",
      "127/127 - 20s - loss: 0.4907 - accuracy: 0.7642 - val_loss: 0.4212 - val_accuracy: 0.8072 - 20s/epoch - 155ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.4231 - accuracy: 0.8058\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.4206 - accuracy: 0.8056\n",
      "\n",
      "Epoch:  16\n",
      "127/127 - 14s - loss: 0.4807 - accuracy: 0.7725 - val_loss: 0.4256 - val_accuracy: 0.8104 - 14s/epoch - 110ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.4263 - accuracy: 0.8097\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.4294 - accuracy: 0.8070\n",
      "\n",
      "Epoch:  17\n",
      "127/127 - 14s - loss: 0.4620 - accuracy: 0.7849 - val_loss: 0.3927 - val_accuracy: 0.8248 - 14s/epoch - 110ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.3937 - accuracy: 0.8250\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.3956 - accuracy: 0.8253\n",
      "\n",
      "Epoch:  18\n",
      "127/127 - 14s - loss: 0.4766 - accuracy: 0.7756 - val_loss: 0.4380 - val_accuracy: 0.8124 - 14s/epoch - 108ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.4390 - accuracy: 0.8117\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.4401 - accuracy: 0.8113\n",
      "\n",
      "Epoch:  19\n",
      "127/127 - 14s - loss: 0.4552 - accuracy: 0.7888 - val_loss: 0.4493 - val_accuracy: 0.7882 - 14s/epoch - 109ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.4498 - accuracy: 0.7888\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.4537 - accuracy: 0.7851\n",
      "\n",
      "Epoch:  20\n",
      "127/127 - 14s - loss: 0.4426 - accuracy: 0.7954 - val_loss: 0.3869 - val_accuracy: 0.8286 - 14s/epoch - 111ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 13ms/step - loss: 0.3890 - accuracy: 0.8281\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.3912 - accuracy: 0.8283\n",
      "\n",
      "Epoch:  21\n",
      "127/127 - 13s - loss: 0.4465 - accuracy: 0.7929 - val_loss: 0.5463 - val_accuracy: 0.7725 - 13s/epoch - 105ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.5462 - accuracy: 0.7731\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.5454 - accuracy: 0.7713\n",
      "\n",
      "Epoch:  22\n",
      "127/127 - 13s - loss: 0.4514 - accuracy: 0.7919 - val_loss: 0.4106 - val_accuracy: 0.8082 - 13s/epoch - 106ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.4120 - accuracy: 0.8074\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.4114 - accuracy: 0.8068\n",
      "\n",
      "Epoch:  23\n",
      "127/127 - 13s - loss: 0.4287 - accuracy: 0.8030 - val_loss: 0.4253 - val_accuracy: 0.8091 - 13s/epoch - 106ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.4266 - accuracy: 0.8061\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.4285 - accuracy: 0.8031\n",
      "\n",
      "Epoch:  24\n",
      "127/127 - 13s - loss: 0.4267 - accuracy: 0.8041 - val_loss: 0.3650 - val_accuracy: 0.8389 - 13s/epoch - 105ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.3665 - accuracy: 0.8393\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.3677 - accuracy: 0.8376\n",
      "\n",
      "Epoch:  25\n",
      "127/127 - 13s - loss: 0.4264 - accuracy: 0.8033 - val_loss: 0.3900 - val_accuracy: 0.8219 - 13s/epoch - 106ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 19s 13ms/step - loss: 0.3917 - accuracy: 0.8235\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.3967 - accuracy: 0.8197\n",
      "\n",
      "Epoch:  26\n",
      "127/127 - 13s - loss: 0.4316 - accuracy: 0.8011 - val_loss: 0.3419 - val_accuracy: 0.8548 - 13s/epoch - 104ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.3436 - accuracy: 0.8535\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.3460 - accuracy: 0.8523\n",
      "\n",
      "Epoch:  27\n",
      "127/127 - 13s - loss: 0.3923 - accuracy: 0.8245 - val_loss: 0.3161 - val_accuracy: 0.8644 - 13s/epoch - 106ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.3174 - accuracy: 0.8624\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.3175 - accuracy: 0.8601\n",
      "\n",
      "Epoch:  28\n",
      "127/127 - 13s - loss: 0.4020 - accuracy: 0.8177 - val_loss: 0.4029 - val_accuracy: 0.8091 - 13s/epoch - 105ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.4044 - accuracy: 0.8110\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.4095 - accuracy: 0.8104\n",
      "\n",
      "Epoch:  29\n",
      "127/127 - 14s - loss: 0.3944 - accuracy: 0.8211 - val_loss: 0.3324 - val_accuracy: 0.8561 - 14s/epoch - 108ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.3330 - accuracy: 0.8566\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.3372 - accuracy: 0.8550\n",
      "\n",
      "Epoch:  30\n",
      "127/127 - 13s - loss: 0.3836 - accuracy: 0.8283 - val_loss: 0.3367 - val_accuracy: 0.8487 - 13s/epoch - 105ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.3374 - accuracy: 0.8510\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.3416 - accuracy: 0.8467\n",
      "\n",
      "Epoch:  31\n",
      "127/127 - 13s - loss: 0.3902 - accuracy: 0.8233 - val_loss: 0.3215 - val_accuracy: 0.8595 - 13s/epoch - 106ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 13ms/step - loss: 0.3218 - accuracy: 0.8602\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.3217 - accuracy: 0.8604\n",
      "\n",
      "Epoch:  32\n",
      "127/127 - 13s - loss: 0.3725 - accuracy: 0.8329 - val_loss: 0.3206 - val_accuracy: 0.8575 - 13s/epoch - 104ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.3213 - accuracy: 0.8584\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.3221 - accuracy: 0.8583\n",
      "\n",
      "Epoch:  33\n",
      "127/127 - 13s - loss: 0.3891 - accuracy: 0.8253 - val_loss: 0.3597 - val_accuracy: 0.8387 - 13s/epoch - 105ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.3597 - accuracy: 0.8406\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.3629 - accuracy: 0.8371\n",
      "\n",
      "Epoch:  34\n",
      "127/127 - 13s - loss: 0.3735 - accuracy: 0.8307 - val_loss: 0.3217 - val_accuracy: 0.8580 - 13s/epoch - 105ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.3220 - accuracy: 0.8586\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.3255 - accuracy: 0.8557\n",
      "\n",
      "Epoch:  35\n",
      "127/127 - 13s - loss: 0.3672 - accuracy: 0.8339 - val_loss: 0.3066 - val_accuracy: 0.8653 - 13s/epoch - 105ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.3072 - accuracy: 0.8652\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.3070 - accuracy: 0.8652\n",
      "\n",
      "Epoch:  36\n",
      "127/127 - 13s - loss: 0.3673 - accuracy: 0.8353 - val_loss: 0.3332 - val_accuracy: 0.8427 - 13s/epoch - 105ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.3356 - accuracy: 0.8432\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.3374 - accuracy: 0.8415\n",
      "\n",
      "Epoch:  37\n",
      "127/127 - 13s - loss: 0.3744 - accuracy: 0.8301 - val_loss: 0.3006 - val_accuracy: 0.8770 - 13s/epoch - 106ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.3009 - accuracy: 0.8769\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.3027 - accuracy: 0.8766\n",
      "\n",
      "Epoch:  38\n",
      "127/127 - 15s - loss: 0.3590 - accuracy: 0.8385 - val_loss: 0.2964 - val_accuracy: 0.8751 - 15s/epoch - 117ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.2969 - accuracy: 0.8744\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.3007 - accuracy: 0.8719\n",
      "\n",
      "Epoch:  39\n",
      "127/127 - 14s - loss: 0.3583 - accuracy: 0.8378 - val_loss: 0.3096 - val_accuracy: 0.8647 - 14s/epoch - 109ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 13ms/step - loss: 0.3097 - accuracy: 0.8665\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.3119 - accuracy: 0.8631\n",
      "\n",
      "Epoch:  40\n",
      "127/127 - 13s - loss: 0.3587 - accuracy: 0.8392 - val_loss: 0.2889 - val_accuracy: 0.8771 - 13s/epoch - 106ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 13ms/step - loss: 0.2902 - accuracy: 0.8752\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2894 - accuracy: 0.8745\n",
      "\n",
      "Epoch:  41\n",
      "127/127 - 13s - loss: 0.3542 - accuracy: 0.8418 - val_loss: 0.2824 - val_accuracy: 0.8813 - 13s/epoch - 105ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 13ms/step - loss: 0.2834 - accuracy: 0.8796\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2835 - accuracy: 0.8797\n",
      "\n",
      "Epoch:  42\n",
      "127/127 - 13s - loss: 0.3467 - accuracy: 0.8460 - val_loss: 0.2827 - val_accuracy: 0.8770 - 13s/epoch - 105ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 13ms/step - loss: 0.2836 - accuracy: 0.8760\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.2846 - accuracy: 0.8759\n",
      "\n",
      "Epoch:  43\n",
      "127/127 - 13s - loss: 0.3414 - accuracy: 0.8465 - val_loss: 0.3167 - val_accuracy: 0.8571 - 13s/epoch - 105ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.3170 - accuracy: 0.8563\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.3174 - accuracy: 0.8561\n",
      "\n",
      "Epoch:  44\n",
      "127/127 - 13s - loss: 0.3319 - accuracy: 0.8540 - val_loss: 0.2556 - val_accuracy: 0.8902 - 13s/epoch - 106ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2554 - accuracy: 0.8906\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2564 - accuracy: 0.8899\n",
      "\n",
      "Epoch:  45\n",
      "127/127 - 13s - loss: 0.3432 - accuracy: 0.8472 - val_loss: 0.3700 - val_accuracy: 0.8321 - 13s/epoch - 105ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.3710 - accuracy: 0.8308\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.3719 - accuracy: 0.8316\n",
      "\n",
      "Epoch:  46\n",
      "127/127 - 13s - loss: 0.3367 - accuracy: 0.8499 - val_loss: 0.2662 - val_accuracy: 0.8866 - 13s/epoch - 106ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2664 - accuracy: 0.8855\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2678 - accuracy: 0.8826\n",
      "\n",
      "Epoch:  47\n",
      "127/127 - 14s - loss: 0.3334 - accuracy: 0.8512 - val_loss: 0.2625 - val_accuracy: 0.8900 - 14s/epoch - 107ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2617 - accuracy: 0.8887\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2599 - accuracy: 0.8890\n",
      "\n",
      "Epoch:  48\n",
      "127/127 - 14s - loss: 0.3278 - accuracy: 0.8543 - val_loss: 0.2766 - val_accuracy: 0.8862 - 14s/epoch - 108ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2748 - accuracy: 0.8850\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2730 - accuracy: 0.8845\n",
      "\n",
      "Epoch:  49\n",
      "127/127 - 14s - loss: 0.3283 - accuracy: 0.8534 - val_loss: 0.2642 - val_accuracy: 0.8853 - 14s/epoch - 108ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2639 - accuracy: 0.8859\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2640 - accuracy: 0.8840\n",
      "\n",
      "Epoch:  50\n",
      "127/127 - 14s - loss: 0.3302 - accuracy: 0.8534 - val_loss: 0.2940 - val_accuracy: 0.8692 - 14s/epoch - 107ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2927 - accuracy: 0.8708\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2962 - accuracy: 0.8662\n",
      "\n",
      "Epoch:  51\n",
      "127/127 - 14s - loss: 0.3234 - accuracy: 0.8590 - val_loss: 0.2538 - val_accuracy: 0.8951 - 14s/epoch - 108ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2532 - accuracy: 0.8950\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2546 - accuracy: 0.8938\n",
      "\n",
      "Epoch:  52\n",
      "127/127 - 14s - loss: 0.3210 - accuracy: 0.8582 - val_loss: 0.2510 - val_accuracy: 0.9015 - 14s/epoch - 107ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2508 - accuracy: 0.9009\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2505 - accuracy: 0.9001\n",
      "\n",
      "Epoch:  53\n",
      "127/127 - 14s - loss: 0.3289 - accuracy: 0.8547 - val_loss: 0.2449 - val_accuracy: 0.8989 - 14s/epoch - 110ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2444 - accuracy: 0.8994\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.2450 - accuracy: 0.8988\n",
      "\n",
      "Epoch:  54\n",
      "127/127 - 14s - loss: 0.3110 - accuracy: 0.8634 - val_loss: 0.2417 - val_accuracy: 0.8960 - 14s/epoch - 108ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2410 - accuracy: 0.8965\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2386 - accuracy: 0.8971\n",
      "\n",
      "Epoch:  55\n",
      "127/127 - 14s - loss: 0.3044 - accuracy: 0.8665 - val_loss: 0.2568 - val_accuracy: 0.8925 - 14s/epoch - 108ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2567 - accuracy: 0.8930\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2565 - accuracy: 0.8906\n",
      "\n",
      "Epoch:  56\n",
      "127/127 - 14s - loss: 0.3092 - accuracy: 0.8655 - val_loss: 0.2409 - val_accuracy: 0.9027 - 14s/epoch - 108ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2398 - accuracy: 0.9033\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2396 - accuracy: 0.9030\n",
      "\n",
      "Epoch:  57\n",
      "127/127 - 14s - loss: 0.3017 - accuracy: 0.8677 - val_loss: 0.2391 - val_accuracy: 0.9002 - 14s/epoch - 107ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2390 - accuracy: 0.9016\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2393 - accuracy: 0.9020\n",
      "\n",
      "Epoch:  58\n",
      "127/127 - 14s - loss: 0.3135 - accuracy: 0.8627 - val_loss: 0.2521 - val_accuracy: 0.8950 - 14s/epoch - 107ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2512 - accuracy: 0.8956\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2488 - accuracy: 0.8961\n",
      "\n",
      "Epoch:  59\n",
      "127/127 - 14s - loss: 0.3037 - accuracy: 0.8655 - val_loss: 0.2481 - val_accuracy: 0.8971 - 14s/epoch - 109ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2481 - accuracy: 0.8966\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.2485 - accuracy: 0.8969\n",
      "\n",
      "Epoch:  60\n",
      "127/127 - 14s - loss: 0.3060 - accuracy: 0.8675 - val_loss: 0.2580 - val_accuracy: 0.8893 - 14s/epoch - 108ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2555 - accuracy: 0.8904\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.2556 - accuracy: 0.8901\n",
      "\n",
      "Epoch:  61\n",
      "127/127 - 15s - loss: 0.3001 - accuracy: 0.8678 - val_loss: 0.2584 - val_accuracy: 0.8851 - 15s/epoch - 119ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.2582 - accuracy: 0.8853\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.2578 - accuracy: 0.8861\n",
      "\n",
      "Epoch:  62\n",
      "127/127 - 16s - loss: 0.2996 - accuracy: 0.8688 - val_loss: 0.2455 - val_accuracy: 0.8911 - 16s/epoch - 125ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.2443 - accuracy: 0.8921\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2446 - accuracy: 0.8930\n",
      "\n",
      "Epoch:  63\n",
      "127/127 - 14s - loss: 0.2918 - accuracy: 0.8741 - val_loss: 0.2636 - val_accuracy: 0.8836 - 14s/epoch - 110ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2625 - accuracy: 0.8843\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.2635 - accuracy: 0.8822\n",
      "\n",
      "Epoch:  64\n",
      "127/127 - 14s - loss: 0.3023 - accuracy: 0.8673 - val_loss: 0.2281 - val_accuracy: 0.9086 - 14s/epoch - 111ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2271 - accuracy: 0.9087\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2241 - accuracy: 0.9124\n",
      "\n",
      "Epoch:  65\n",
      "127/127 - 14s - loss: 0.2865 - accuracy: 0.8746 - val_loss: 0.2362 - val_accuracy: 0.9017 - 14s/epoch - 108ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2361 - accuracy: 0.9026\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.2363 - accuracy: 0.9017\n",
      "\n",
      "Epoch:  66\n",
      "127/127 - 14s - loss: 0.2921 - accuracy: 0.8743 - val_loss: 0.2167 - val_accuracy: 0.9148 - 14s/epoch - 109ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2168 - accuracy: 0.9156\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2145 - accuracy: 0.9170\n",
      "\n",
      "Epoch:  67\n",
      "127/127 - 14s - loss: 0.2808 - accuracy: 0.8786 - val_loss: 0.2193 - val_accuracy: 0.9086 - 14s/epoch - 109ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2175 - accuracy: 0.9105\n",
      "for testing\n",
      "378/378 [==============================] - 6s 17ms/step - loss: 0.2160 - accuracy: 0.9094\n",
      "\n",
      "Epoch:  68\n",
      "127/127 - 17s - loss: 0.2801 - accuracy: 0.8781 - val_loss: 0.2299 - val_accuracy: 0.9030 - 17s/epoch - 135ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.2288 - accuracy: 0.9035\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.2287 - accuracy: 0.9048\n",
      "\n",
      "Epoch:  69\n",
      "127/127 - 15s - loss: 0.2898 - accuracy: 0.8732 - val_loss: 0.2171 - val_accuracy: 0.9096 - 15s/epoch - 118ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.2166 - accuracy: 0.9095\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.2159 - accuracy: 0.9077\n",
      "\n",
      "Epoch:  70\n",
      "127/127 - 14s - loss: 0.2876 - accuracy: 0.8756 - val_loss: 0.2140 - val_accuracy: 0.9105 - 14s/epoch - 109ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2128 - accuracy: 0.9099\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2127 - accuracy: 0.9082\n",
      "\n",
      "Epoch:  71\n",
      "127/127 - 14s - loss: 0.2817 - accuracy: 0.8773 - val_loss: 0.2324 - val_accuracy: 0.9128 - 14s/epoch - 108ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2316 - accuracy: 0.9126\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2307 - accuracy: 0.9144\n",
      "\n",
      "Epoch:  72\n",
      "127/127 - 14s - loss: 0.2774 - accuracy: 0.8803 - val_loss: 0.2038 - val_accuracy: 0.9160 - 14s/epoch - 110ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2023 - accuracy: 0.9171\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.2008 - accuracy: 0.9188\n",
      "\n",
      "Epoch:  73\n",
      "127/127 - 14s - loss: 0.2812 - accuracy: 0.8785 - val_loss: 0.2085 - val_accuracy: 0.9189 - 14s/epoch - 110ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.2087 - accuracy: 0.9195\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2064 - accuracy: 0.9214\n",
      "\n",
      "Epoch:  74\n",
      "127/127 - 14s - loss: 0.2716 - accuracy: 0.8814 - val_loss: 0.1912 - val_accuracy: 0.9234 - 14s/epoch - 110ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.1899 - accuracy: 0.9249\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.1874 - accuracy: 0.9272\n",
      "\n",
      "Epoch:  75\n",
      "127/127 - 14s - loss: 0.2785 - accuracy: 0.8777 - val_loss: 0.1906 - val_accuracy: 0.9213 - 14s/epoch - 113ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.1897 - accuracy: 0.9224\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.1865 - accuracy: 0.9253\n",
      "\n",
      "Epoch:  76\n",
      "127/127 - 14s - loss: 0.2712 - accuracy: 0.8807 - val_loss: 0.2091 - val_accuracy: 0.9151 - 14s/epoch - 110ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.2087 - accuracy: 0.9147\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2059 - accuracy: 0.9172\n",
      "\n",
      "Epoch:  77\n",
      "127/127 - 22s - loss: 0.2662 - accuracy: 0.8844 - val_loss: 0.2149 - val_accuracy: 0.9133 - 22s/epoch - 170ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.2141 - accuracy: 0.9135\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.2140 - accuracy: 0.9141\n",
      "\n",
      "Epoch:  78\n",
      "127/127 - 14s - loss: 0.2616 - accuracy: 0.8844 - val_loss: 0.1993 - val_accuracy: 0.9183 - 14s/epoch - 112ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 14ms/step - loss: 0.1980 - accuracy: 0.9187\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.1960 - accuracy: 0.9205\n",
      "\n",
      "Epoch:  79\n",
      "127/127 - 14s - loss: 0.2647 - accuracy: 0.8843 - val_loss: 0.1869 - val_accuracy: 0.9235 - 14s/epoch - 112ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.1863 - accuracy: 0.9247\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.1856 - accuracy: 0.9269\n",
      "\n",
      "Epoch:  80\n",
      "127/127 - 14s - loss: 0.2709 - accuracy: 0.8826 - val_loss: 0.2310 - val_accuracy: 0.9084 - 14s/epoch - 109ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.2295 - accuracy: 0.9078\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.2251 - accuracy: 0.9113\n",
      "\n",
      "Epoch:  81\n",
      "127/127 - 14s - loss: 0.2636 - accuracy: 0.8862 - val_loss: 0.2033 - val_accuracy: 0.9185 - 14s/epoch - 113ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.2019 - accuracy: 0.9189\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.1995 - accuracy: 0.9211\n",
      "\n",
      "Epoch:  82\n",
      "127/127 - 14s - loss: 0.2667 - accuracy: 0.8847 - val_loss: 0.1993 - val_accuracy: 0.9197 - 14s/epoch - 111ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.1984 - accuracy: 0.9198\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.1963 - accuracy: 0.9218\n",
      "\n",
      "Epoch:  83\n",
      "127/127 - 14s - loss: 0.2604 - accuracy: 0.8875 - val_loss: 0.2905 - val_accuracy: 0.8620 - 14s/epoch - 114ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 14ms/step - loss: 0.2909 - accuracy: 0.8601\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.2871 - accuracy: 0.8636\n",
      "\n",
      "Epoch:  84\n",
      "127/127 - 14s - loss: 0.2601 - accuracy: 0.8883 - val_loss: 0.1860 - val_accuracy: 0.9225 - 14s/epoch - 111ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.1849 - accuracy: 0.9234\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.1833 - accuracy: 0.9246\n",
      "\n",
      "Epoch:  85\n",
      "127/127 - 14s - loss: 0.2569 - accuracy: 0.8886 - val_loss: 0.1955 - val_accuracy: 0.9155 - 14s/epoch - 113ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.1937 - accuracy: 0.9167\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.1921 - accuracy: 0.9163\n",
      "\n",
      "Epoch:  86\n",
      "127/127 - 14s - loss: 0.2560 - accuracy: 0.8886 - val_loss: 0.1824 - val_accuracy: 0.9291 - 14s/epoch - 112ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 8ms/step - loss: 0.1813 - accuracy: 0.9294\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1803 - accuracy: 0.9301\n",
      "\n",
      "Epoch:  87\n",
      "127/127 - 9s - loss: 0.2559 - accuracy: 0.8895 - val_loss: 0.1898 - val_accuracy: 0.9211 - 9s/epoch - 74ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.1874 - accuracy: 0.9228\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1865 - accuracy: 0.9253\n",
      "\n",
      "Epoch:  88\n",
      "127/127 - 11s - loss: 0.2582 - accuracy: 0.8864 - val_loss: 0.1893 - val_accuracy: 0.9218 - 11s/epoch - 86ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1873 - accuracy: 0.9234\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1830 - accuracy: 0.9270\n",
      "\n",
      "Epoch:  89\n",
      "127/127 - 10s - loss: 0.2527 - accuracy: 0.8910 - val_loss: 0.1877 - val_accuracy: 0.9211 - 10s/epoch - 82ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.1865 - accuracy: 0.9235\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1848 - accuracy: 0.9253\n",
      "\n",
      "Epoch:  90\n",
      "127/127 - 12s - loss: 0.2505 - accuracy: 0.8935 - val_loss: 0.2071 - val_accuracy: 0.9213 - 12s/epoch - 91ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.2045 - accuracy: 0.9226\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.2027 - accuracy: 0.9265\n",
      "\n",
      "Epoch:  91\n",
      "127/127 - 10s - loss: 0.2519 - accuracy: 0.8898 - val_loss: 0.1906 - val_accuracy: 0.9235 - 10s/epoch - 80ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.1891 - accuracy: 0.9262\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1880 - accuracy: 0.9292\n",
      "\n",
      "Epoch:  92\n",
      "127/127 - 16s - loss: 0.2533 - accuracy: 0.8910 - val_loss: 0.1797 - val_accuracy: 0.9297 - 16s/epoch - 123ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 12ms/step - loss: 0.1784 - accuracy: 0.9299\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1757 - accuracy: 0.9326\n",
      "\n",
      "Epoch:  93\n",
      "127/127 - 10s - loss: 0.2450 - accuracy: 0.8952 - val_loss: 0.2054 - val_accuracy: 0.9134 - 10s/epoch - 82ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.2032 - accuracy: 0.9145\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.2023 - accuracy: 0.9148\n",
      "\n",
      "Epoch:  94\n",
      "127/127 - 11s - loss: 0.2516 - accuracy: 0.8908 - val_loss: 0.1974 - val_accuracy: 0.9260 - 11s/epoch - 83ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1949 - accuracy: 0.9268\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1936 - accuracy: 0.9288\n",
      "\n",
      "Epoch:  95\n",
      "127/127 - 10s - loss: 0.2471 - accuracy: 0.8941 - val_loss: 0.1833 - val_accuracy: 0.9283 - 10s/epoch - 81ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1818 - accuracy: 0.9292\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1792 - accuracy: 0.9311\n",
      "\n",
      "Epoch:  96\n",
      "127/127 - 10s - loss: 0.2531 - accuracy: 0.8896 - val_loss: 0.1858 - val_accuracy: 0.9276 - 10s/epoch - 81ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1848 - accuracy: 0.9284\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1825 - accuracy: 0.9314\n",
      "\n",
      "Epoch:  97\n",
      "127/127 - 11s - loss: 0.2477 - accuracy: 0.8943 - val_loss: 0.1861 - val_accuracy: 0.9222 - 11s/epoch - 83ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1836 - accuracy: 0.9241\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1843 - accuracy: 0.9234\n",
      "\n",
      "Epoch:  98\n",
      "127/127 - 11s - loss: 0.2464 - accuracy: 0.8953 - val_loss: 0.1773 - val_accuracy: 0.9279 - 11s/epoch - 84ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1749 - accuracy: 0.9297\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1727 - accuracy: 0.9326\n",
      "\n",
      "Epoch:  99\n",
      "127/127 - 10s - loss: 0.2529 - accuracy: 0.8910 - val_loss: 0.1863 - val_accuracy: 0.9223 - 10s/epoch - 82ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1850 - accuracy: 0.9235\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1814 - accuracy: 0.9272\n",
      "\n",
      "Epoch:  100\n",
      "127/127 - 11s - loss: 0.2416 - accuracy: 0.8953 - val_loss: 0.1794 - val_accuracy: 0.9262 - 11s/epoch - 84ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1781 - accuracy: 0.9268\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1773 - accuracy: 0.9277\n",
      "\n",
      "Epoch:  101\n",
      "127/127 - 11s - loss: 0.2406 - accuracy: 0.8962 - val_loss: 0.1685 - val_accuracy: 0.9322 - 11s/epoch - 84ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1665 - accuracy: 0.9330\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1632 - accuracy: 0.9351\n",
      "\n",
      "Epoch:  102\n",
      "127/127 - 11s - loss: 0.2407 - accuracy: 0.8978 - val_loss: 0.1740 - val_accuracy: 0.9306 - 11s/epoch - 83ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1719 - accuracy: 0.9322\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1711 - accuracy: 0.9328\n",
      "\n",
      "Epoch:  103\n",
      "127/127 - 11s - loss: 0.2411 - accuracy: 0.8977 - val_loss: 0.1748 - val_accuracy: 0.9243 - 11s/epoch - 83ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1724 - accuracy: 0.9263\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1717 - accuracy: 0.9285\n",
      "\n",
      "Epoch:  104\n",
      "127/127 - 10s - loss: 0.2334 - accuracy: 0.9006 - val_loss: 0.1726 - val_accuracy: 0.9275 - 10s/epoch - 82ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1719 - accuracy: 0.9293\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1703 - accuracy: 0.9308\n",
      "\n",
      "Epoch:  105\n",
      "127/127 - 10s - loss: 0.2474 - accuracy: 0.8941 - val_loss: 0.1654 - val_accuracy: 0.9344 - 10s/epoch - 81ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.1643 - accuracy: 0.9356\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1639 - accuracy: 0.9362\n",
      "\n",
      "Epoch:  106\n",
      "127/127 - 10s - loss: 0.2343 - accuracy: 0.8999 - val_loss: 0.1733 - val_accuracy: 0.9254 - 10s/epoch - 81ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1710 - accuracy: 0.9271\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1703 - accuracy: 0.9293\n",
      "\n",
      "Epoch:  107\n",
      "127/127 - 10s - loss: 0.2360 - accuracy: 0.8984 - val_loss: 0.1704 - val_accuracy: 0.9299 - 10s/epoch - 82ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1687 - accuracy: 0.9312\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1677 - accuracy: 0.9327\n",
      "\n",
      "Epoch:  108\n",
      "127/127 - 11s - loss: 0.2350 - accuracy: 0.9000 - val_loss: 0.1946 - val_accuracy: 0.9169 - 11s/epoch - 83ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.1914 - accuracy: 0.9188\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1920 - accuracy: 0.9187\n",
      "\n",
      "Epoch:  109\n",
      "127/127 - 11s - loss: 0.2352 - accuracy: 0.8993 - val_loss: 0.1622 - val_accuracy: 0.9384 - 11s/epoch - 84ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1605 - accuracy: 0.9395\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1583 - accuracy: 0.9429\n",
      "\n",
      "Epoch:  110\n",
      "127/127 - 11s - loss: 0.2314 - accuracy: 0.9011 - val_loss: 0.1725 - val_accuracy: 0.9284 - 11s/epoch - 88ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1703 - accuracy: 0.9295\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1670 - accuracy: 0.9311\n",
      "\n",
      "Epoch:  111\n",
      "127/127 - 11s - loss: 0.2341 - accuracy: 0.8989 - val_loss: 0.1702 - val_accuracy: 0.9349 - 11s/epoch - 83ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.1697 - accuracy: 0.9368\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1686 - accuracy: 0.9397\n",
      "\n",
      "Epoch:  112\n",
      "127/127 - 11s - loss: 0.2270 - accuracy: 0.9036 - val_loss: 0.1698 - val_accuracy: 0.9285 - 11s/epoch - 84ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1684 - accuracy: 0.9296\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1691 - accuracy: 0.9294\n",
      "\n",
      "Epoch:  113\n",
      "127/127 - 10s - loss: 0.2264 - accuracy: 0.9035 - val_loss: 0.1639 - val_accuracy: 0.9319 - 10s/epoch - 82ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1616 - accuracy: 0.9339\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1616 - accuracy: 0.9350\n",
      "\n",
      "Epoch:  114\n",
      "127/127 - 11s - loss: 0.2252 - accuracy: 0.9042 - val_loss: 0.1779 - val_accuracy: 0.9257 - 11s/epoch - 84ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.1775 - accuracy: 0.9264\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1769 - accuracy: 0.9268\n",
      "\n",
      "Epoch:  115\n",
      "127/127 - 11s - loss: 0.2275 - accuracy: 0.9043 - val_loss: 0.1555 - val_accuracy: 0.9356 - 11s/epoch - 89ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1541 - accuracy: 0.9365\n",
      "for testing\n",
      "378/378 [==============================] - 4s 12ms/step - loss: 0.1526 - accuracy: 0.9387\n",
      "\n",
      "Epoch:  116\n",
      "127/127 - 12s - loss: 0.2297 - accuracy: 0.9016 - val_loss: 0.2135 - val_accuracy: 0.9044 - 12s/epoch - 97ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.2096 - accuracy: 0.9067\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.2119 - accuracy: 0.9072\n",
      "\n",
      "Epoch:  117\n",
      "127/127 - 11s - loss: 0.2321 - accuracy: 0.8999 - val_loss: 0.1641 - val_accuracy: 0.9352 - 11s/epoch - 84ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.1617 - accuracy: 0.9360\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1618 - accuracy: 0.9359\n",
      "\n",
      "Epoch:  118\n",
      "127/127 - 11s - loss: 0.2234 - accuracy: 0.9038 - val_loss: 0.1692 - val_accuracy: 0.9295 - 11s/epoch - 84ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.1663 - accuracy: 0.9320\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1660 - accuracy: 0.9341\n",
      "\n",
      "Epoch:  119\n",
      "127/127 - 11s - loss: 0.2238 - accuracy: 0.9046 - val_loss: 0.1600 - val_accuracy: 0.9367 - 11s/epoch - 84ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.1583 - accuracy: 0.9377\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1560 - accuracy: 0.9391\n",
      "\n",
      "Epoch:  120\n",
      "127/127 - 11s - loss: 0.2271 - accuracy: 0.9026 - val_loss: 0.1595 - val_accuracy: 0.9376 - 11s/epoch - 86ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.1568 - accuracy: 0.9403\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1555 - accuracy: 0.9440\n",
      "\n",
      "Epoch:  121\n",
      "127/127 - 11s - loss: 0.2225 - accuracy: 0.9067 - val_loss: 0.1627 - val_accuracy: 0.9347 - 11s/epoch - 86ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1613 - accuracy: 0.9363\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1620 - accuracy: 0.9361\n",
      "\n",
      "Epoch:  122\n",
      "127/127 - 11s - loss: 0.2192 - accuracy: 0.9079 - val_loss: 0.1663 - val_accuracy: 0.9319 - 11s/epoch - 85ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1639 - accuracy: 0.9326\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1647 - accuracy: 0.9332\n",
      "\n",
      "Epoch:  123\n",
      "127/127 - 11s - loss: 0.2239 - accuracy: 0.9026 - val_loss: 0.1538 - val_accuracy: 0.9359 - 11s/epoch - 86ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.1512 - accuracy: 0.9380\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1511 - accuracy: 0.9380\n",
      "\n",
      "Epoch:  124\n",
      "127/127 - 11s - loss: 0.2220 - accuracy: 0.9052 - val_loss: 0.1688 - val_accuracy: 0.9304 - 11s/epoch - 85ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1654 - accuracy: 0.9330\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1649 - accuracy: 0.9351\n",
      "\n",
      "Epoch:  125\n",
      "127/127 - 11s - loss: 0.2169 - accuracy: 0.9087 - val_loss: 0.1564 - val_accuracy: 0.9344 - 11s/epoch - 85ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1534 - accuracy: 0.9368\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1527 - accuracy: 0.9383\n",
      "\n",
      "Epoch:  126\n",
      "127/127 - 11s - loss: 0.2157 - accuracy: 0.9063 - val_loss: 0.1479 - val_accuracy: 0.9425 - 11s/epoch - 84ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.1455 - accuracy: 0.9445\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1454 - accuracy: 0.9462\n",
      "\n",
      "Epoch:  127\n",
      "127/127 - 11s - loss: 0.2197 - accuracy: 0.9063 - val_loss: 0.1577 - val_accuracy: 0.9367 - 11s/epoch - 88ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.1544 - accuracy: 0.9400\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1527 - accuracy: 0.9430\n",
      "\n",
      "Epoch:  128\n",
      "127/127 - 11s - loss: 0.2189 - accuracy: 0.9086 - val_loss: 0.1527 - val_accuracy: 0.9432 - 11s/epoch - 87ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 10ms/step - loss: 0.1509 - accuracy: 0.9447\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1518 - accuracy: 0.9454\n",
      "\n",
      "Epoch:  129\n",
      "127/127 - 11s - loss: 0.2114 - accuracy: 0.9100 - val_loss: 0.1540 - val_accuracy: 0.9370 - 11s/epoch - 86ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.1514 - accuracy: 0.9388\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1518 - accuracy: 0.9390\n",
      "\n",
      "Epoch:  130\n",
      "127/127 - 11s - loss: 0.2203 - accuracy: 0.9077 - val_loss: 0.1633 - val_accuracy: 0.9349 - 11s/epoch - 85ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.1615 - accuracy: 0.9343\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1601 - accuracy: 0.9368\n",
      "\n",
      "Epoch:  131\n",
      "127/127 - 19s - loss: 0.2181 - accuracy: 0.9069 - val_loss: 0.1604 - val_accuracy: 0.9324 - 19s/epoch - 149ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.1600 - accuracy: 0.9321\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1604 - accuracy: 0.9327\n",
      "\n",
      "Epoch:  132\n",
      "127/127 - 13s - loss: 0.2184 - accuracy: 0.9071 - val_loss: 0.1574 - val_accuracy: 0.9391 - 13s/epoch - 99ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1559 - accuracy: 0.9398\n",
      "for testing\n",
      "378/378 [==============================] - 6s 16ms/step - loss: 0.1551 - accuracy: 0.9397\n",
      "\n",
      "Epoch:  133\n",
      "127/127 - 13s - loss: 0.2256 - accuracy: 0.9042 - val_loss: 0.1738 - val_accuracy: 0.9329 - 13s/epoch - 103ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 14ms/step - loss: 0.1719 - accuracy: 0.9331\n",
      "for testing\n",
      "378/378 [==============================] - 6s 14ms/step - loss: 0.1733 - accuracy: 0.9342\n",
      "\n",
      "Epoch:  134\n",
      "127/127 - 14s - loss: 0.2089 - accuracy: 0.9124 - val_loss: 0.1692 - val_accuracy: 0.9303 - 14s/epoch - 111ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.1663 - accuracy: 0.9325\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1695 - accuracy: 0.9327\n",
      "\n",
      "Epoch:  135\n",
      "127/127 - 11s - loss: 0.2138 - accuracy: 0.9104 - val_loss: 0.1644 - val_accuracy: 0.9368 - 11s/epoch - 86ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.1624 - accuracy: 0.9369\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1609 - accuracy: 0.9391\n",
      "\n",
      "Epoch:  136\n",
      "127/127 - 11s - loss: 0.2069 - accuracy: 0.9125 - val_loss: 0.1736 - val_accuracy: 0.9280 - 11s/epoch - 85ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.1704 - accuracy: 0.9304\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1726 - accuracy: 0.9327\n",
      "\n",
      "Epoch:  137\n",
      "127/127 - 11s - loss: 0.2109 - accuracy: 0.9107 - val_loss: 0.1773 - val_accuracy: 0.9258 - 11s/epoch - 86ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.1751 - accuracy: 0.9268\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.1772 - accuracy: 0.9269\n",
      "\n",
      "Epoch:  138\n",
      "127/127 - 15s - loss: 0.2148 - accuracy: 0.9084 - val_loss: 0.1460 - val_accuracy: 0.9424 - 15s/epoch - 115ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.1434 - accuracy: 0.9446\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.1438 - accuracy: 0.9462\n",
      "\n",
      "Epoch:  139\n",
      "127/127 - 15s - loss: 0.2140 - accuracy: 0.9078 - val_loss: 0.1414 - val_accuracy: 0.9458 - 15s/epoch - 116ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.1392 - accuracy: 0.9474\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.1393 - accuracy: 0.9482\n",
      "\n",
      "Epoch:  140\n",
      "127/127 - 15s - loss: 0.2126 - accuracy: 0.9084 - val_loss: 0.2070 - val_accuracy: 0.9141 - 15s/epoch - 120ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 2740s 2s/step - loss: 0.2028 - accuracy: 0.9151\n",
      "for testing\n",
      "378/378 [==============================] - 9s 24ms/step - loss: 0.2061 - accuracy: 0.9155\n",
      "\n",
      "Epoch:  141\n",
      "127/127 - 25s - loss: 0.2049 - accuracy: 0.9144 - val_loss: 0.1381 - val_accuracy: 0.9446 - 25s/epoch - 194ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 32s 21ms/step - loss: 0.1365 - accuracy: 0.9452\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.1348 - accuracy: 0.9477\n",
      "\n",
      "Epoch:  142\n",
      "127/127 - 15s - loss: 0.2190 - accuracy: 0.9084 - val_loss: 0.1580 - val_accuracy: 0.9336 - 15s/epoch - 119ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.1560 - accuracy: 0.9352\n",
      "for testing\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.1566 - accuracy: 0.9361\n",
      "\n",
      "Epoch:  143\n",
      "127/127 - 16s - loss: 0.2007 - accuracy: 0.9154 - val_loss: 0.1348 - val_accuracy: 0.9485 - 16s/epoch - 129ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.1334 - accuracy: 0.9500\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.1335 - accuracy: 0.9507\n",
      "\n",
      "Epoch:  144\n",
      "127/127 - 15s - loss: 0.2019 - accuracy: 0.9143 - val_loss: 0.1524 - val_accuracy: 0.9377 - 15s/epoch - 122ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.1513 - accuracy: 0.9400\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.1507 - accuracy: 0.9383\n",
      "\n",
      "Epoch:  145\n",
      "127/127 - 15s - loss: 0.2154 - accuracy: 0.9075 - val_loss: 0.1655 - val_accuracy: 0.9332 - 15s/epoch - 121ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 25s 17ms/step - loss: 0.1654 - accuracy: 0.9343\n",
      "for testing\n",
      "378/378 [==============================] - 7s 19ms/step - loss: 0.1661 - accuracy: 0.9344\n",
      "\n",
      "Epoch:  146\n",
      "127/127 - 17s - loss: 0.2103 - accuracy: 0.9083 - val_loss: 0.1686 - val_accuracy: 0.9339 - 17s/epoch - 136ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 15ms/step - loss: 0.1670 - accuracy: 0.9334\n",
      "for testing\n",
      "378/378 [==============================] - 7s 19ms/step - loss: 0.1647 - accuracy: 0.9375\n",
      "\n",
      "Epoch:  147\n",
      "127/127 - 16s - loss: 0.2021 - accuracy: 0.9148 - val_loss: 0.1678 - val_accuracy: 0.9297 - 16s/epoch - 124ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 14ms/step - loss: 0.1660 - accuracy: 0.9296\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 5s 14ms/step - loss: 0.1681 - accuracy: 0.9296\n",
      "\n",
      "Epoch:  148\n",
      "127/127 - 15s - loss: 0.2062 - accuracy: 0.9133 - val_loss: 0.1351 - val_accuracy: 0.9461 - 15s/epoch - 121ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 14ms/step - loss: 0.1334 - accuracy: 0.9486\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.1320 - accuracy: 0.9491\n",
      "\n",
      "Epoch:  149\n",
      "127/127 - 16s - loss: 0.2055 - accuracy: 0.9141 - val_loss: 0.1678 - val_accuracy: 0.9324 - 16s/epoch - 126ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.1654 - accuracy: 0.9344\n",
      "for testing\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.1665 - accuracy: 0.9344\n",
      "\n",
      "Epoch:  150\n",
      "127/127 - 15s - loss: 0.2060 - accuracy: 0.9128 - val_loss: 0.1443 - val_accuracy: 0.9409 - 15s/epoch - 120ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 15ms/step - loss: 0.1416 - accuracy: 0.9432\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.1436 - accuracy: 0.9421\n",
      "\n",
      "Epoch:  151\n",
      "127/127 - 16s - loss: 0.1958 - accuracy: 0.9181 - val_loss: 0.1302 - val_accuracy: 0.9501 - 16s/epoch - 127ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.1278 - accuracy: 0.9510\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.1281 - accuracy: 0.9509\n",
      "\n",
      "Epoch:  152\n",
      "127/127 - 18s - loss: 0.1985 - accuracy: 0.9179 - val_loss: 0.1392 - val_accuracy: 0.9455 - 18s/epoch - 144ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 27s 18ms/step - loss: 0.1366 - accuracy: 0.9468\n",
      "for testing\n",
      "378/378 [==============================] - 7s 17ms/step - loss: 0.1383 - accuracy: 0.9475\n",
      "\n",
      "Epoch:  153\n",
      "127/127 - 17s - loss: 0.1977 - accuracy: 0.9168 - val_loss: 0.1259 - val_accuracy: 0.9501 - 17s/epoch - 131ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 24s 16ms/step - loss: 0.1231 - accuracy: 0.9535\n",
      "for testing\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.1237 - accuracy: 0.9544\n",
      "\n",
      "Epoch:  154\n",
      "127/127 - 17s - loss: 0.1999 - accuracy: 0.9157 - val_loss: 0.1744 - val_accuracy: 0.9247 - 17s/epoch - 136ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 27s 18ms/step - loss: 0.1718 - accuracy: 0.9250\n",
      "for testing\n",
      "378/378 [==============================] - 6s 16ms/step - loss: 0.1754 - accuracy: 0.9246\n",
      "\n",
      "Epoch:  155\n",
      "127/127 - 16s - loss: 0.2086 - accuracy: 0.9122 - val_loss: 0.1517 - val_accuracy: 0.9387 - 16s/epoch - 129ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 15ms/step - loss: 0.1489 - accuracy: 0.9402\n",
      "for testing\n",
      "378/378 [==============================] - 7s 17ms/step - loss: 0.1494 - accuracy: 0.9406\n",
      "\n",
      "Epoch:  156\n",
      "127/127 - 15s - loss: 0.1947 - accuracy: 0.9177 - val_loss: 0.1425 - val_accuracy: 0.9450 - 15s/epoch - 121ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.1398 - accuracy: 0.9470\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.1402 - accuracy: 0.9474\n",
      "\n",
      "Epoch:  157\n",
      "127/127 - 16s - loss: 0.2001 - accuracy: 0.9164 - val_loss: 0.1568 - val_accuracy: 0.9347 - 16s/epoch - 124ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 15ms/step - loss: 0.1536 - accuracy: 0.9361\n",
      "for testing\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.1563 - accuracy: 0.9353\n",
      "\n",
      "Epoch:  158\n",
      "127/127 - 19s - loss: 0.1914 - accuracy: 0.9199 - val_loss: 0.1479 - val_accuracy: 0.9374 - 19s/epoch - 150ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 26s 17ms/step - loss: 0.1453 - accuracy: 0.9387\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.1478 - accuracy: 0.9392\n",
      "\n",
      "Epoch:  159\n",
      "127/127 - 16s - loss: 0.2021 - accuracy: 0.9134 - val_loss: 0.1694 - val_accuracy: 0.9277 - 16s/epoch - 127ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 15ms/step - loss: 0.1647 - accuracy: 0.9305\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.1711 - accuracy: 0.9292\n",
      "\n",
      "Epoch:  160\n",
      "127/127 - 18s - loss: 0.1935 - accuracy: 0.9187 - val_loss: 0.1293 - val_accuracy: 0.9505 - 18s/epoch - 143ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 15ms/step - loss: 0.1268 - accuracy: 0.9524\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.1296 - accuracy: 0.9511\n",
      "\n",
      "Epoch:  161\n",
      "127/127 - 16s - loss: 0.1965 - accuracy: 0.9170 - val_loss: 0.1284 - val_accuracy: 0.9503 - 16s/epoch - 127ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 15ms/step - loss: 0.1255 - accuracy: 0.9525\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.1266 - accuracy: 0.9532\n",
      "\n",
      "Epoch:  162\n",
      "127/127 - 17s - loss: 0.1944 - accuracy: 0.9189 - val_loss: 0.1456 - val_accuracy: 0.9443 - 17s/epoch - 131ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 29s 19ms/step - loss: 0.1426 - accuracy: 0.9475\n",
      "for testing\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.1423 - accuracy: 0.9483\n",
      "\n",
      "Epoch:  163\n",
      "127/127 - 18s - loss: 0.1964 - accuracy: 0.9171 - val_loss: 0.1662 - val_accuracy: 0.9299 - 18s/epoch - 144ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 27s 18ms/step - loss: 0.1639 - accuracy: 0.9303\n",
      "for testing\n",
      "378/378 [==============================] - 7s 19ms/step - loss: 0.1635 - accuracy: 0.9304\n",
      "\n",
      "Epoch:  164\n",
      "127/127 - 20s - loss: 0.1884 - accuracy: 0.9212 - val_loss: 0.1375 - val_accuracy: 0.9478 - 20s/epoch - 154ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 25s 17ms/step - loss: 0.1340 - accuracy: 0.9516\n",
      "for testing\n",
      "378/378 [==============================] - 6s 16ms/step - loss: 0.1353 - accuracy: 0.9524\n",
      "\n",
      "Epoch:  165\n",
      "127/127 - 16s - loss: 0.1958 - accuracy: 0.9165 - val_loss: 0.1354 - val_accuracy: 0.9466 - 16s/epoch - 130ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.1328 - accuracy: 0.9493\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.1327 - accuracy: 0.9498\n",
      "\n",
      "Epoch:  166\n",
      "127/127 - 18s - loss: 0.1927 - accuracy: 0.9191 - val_loss: 0.1459 - val_accuracy: 0.9424 - 18s/epoch - 144ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 24s 16ms/step - loss: 0.1415 - accuracy: 0.9454\n",
      "for testing\n",
      "378/378 [==============================] - 6s 17ms/step - loss: 0.1432 - accuracy: 0.9460\n",
      "\n",
      "Epoch:  167\n",
      "127/127 - 17s - loss: 0.1949 - accuracy: 0.9194 - val_loss: 0.1415 - val_accuracy: 0.9483 - 17s/epoch - 132ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.1375 - accuracy: 0.9514\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.1394 - accuracy: 0.9496\n",
      "\n",
      "Epoch:  168\n",
      "127/127 - 17s - loss: 0.1954 - accuracy: 0.9179 - val_loss: 0.1308 - val_accuracy: 0.9449 - 17s/epoch - 131ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 27s 18ms/step - loss: 0.1270 - accuracy: 0.9479\n",
      "for testing\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.1290 - accuracy: 0.9483\n",
      "\n",
      "Epoch:  169\n",
      "127/127 - 18s - loss: 0.1912 - accuracy: 0.9207 - val_loss: 0.1430 - val_accuracy: 0.9400 - 18s/epoch - 143ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 28s 18ms/step - loss: 0.1416 - accuracy: 0.9422\n",
      "for testing\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.1426 - accuracy: 0.9430\n",
      "\n",
      "Epoch:  170\n",
      "127/127 - 18s - loss: 0.1933 - accuracy: 0.9180 - val_loss: 0.1464 - val_accuracy: 0.9445 - 18s/epoch - 140ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 26s 17ms/step - loss: 0.1424 - accuracy: 0.9473\n",
      "for testing\n",
      "378/378 [==============================] - 6s 16ms/step - loss: 0.1430 - accuracy: 0.9486\n",
      "\n",
      "Epoch:  171\n",
      "127/127 - 18s - loss: 0.1918 - accuracy: 0.9199 - val_loss: 0.1345 - val_accuracy: 0.9449 - 18s/epoch - 143ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 25s 16ms/step - loss: 0.1308 - accuracy: 0.9468\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.1318 - accuracy: 0.9466\n",
      "\n",
      "Epoch:  172\n",
      "127/127 - 19s - loss: 0.1934 - accuracy: 0.9186 - val_loss: 0.1461 - val_accuracy: 0.9404 - 19s/epoch - 149ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 26s 17ms/step - loss: 0.1420 - accuracy: 0.9418\n",
      "for testing\n",
      "378/378 [==============================] - 6s 17ms/step - loss: 0.1441 - accuracy: 0.9439\n",
      "\n",
      "Epoch:  173\n",
      "127/127 - 18s - loss: 0.1904 - accuracy: 0.9204 - val_loss: 0.1410 - val_accuracy: 0.9440 - 18s/epoch - 140ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 25s 16ms/step - loss: 0.1374 - accuracy: 0.9453\n",
      "for testing\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.1388 - accuracy: 0.9468\n",
      "\n",
      "Epoch:  174\n",
      "127/127 - 18s - loss: 0.1871 - accuracy: 0.9212 - val_loss: 0.1298 - val_accuracy: 0.9543 - 18s/epoch - 141ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 25s 17ms/step - loss: 0.1259 - accuracy: 0.9563\n",
      "for testing\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.1281 - accuracy: 0.9547\n",
      "\n",
      "Epoch:  175\n",
      "127/127 - 17s - loss: 0.1930 - accuracy: 0.9201 - val_loss: 0.1566 - val_accuracy: 0.9383 - 17s/epoch - 137ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 24s 16ms/step - loss: 0.1534 - accuracy: 0.9404\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.1527 - accuracy: 0.9422\n",
      "\n",
      "Epoch:  176\n",
      "127/127 - 16s - loss: 0.1902 - accuracy: 0.9201 - val_loss: 0.1368 - val_accuracy: 0.9474 - 16s/epoch - 125ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 15ms/step - loss: 0.1338 - accuracy: 0.9485\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.1338 - accuracy: 0.9487\n",
      "\n",
      "Epoch:  177\n",
      "127/127 - 16s - loss: 0.1897 - accuracy: 0.9181 - val_loss: 0.1447 - val_accuracy: 0.9387 - 16s/epoch - 127ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 15ms/step - loss: 0.1413 - accuracy: 0.9412\n",
      "for testing\n",
      "378/378 [==============================] - 6s 16ms/step - loss: 0.1442 - accuracy: 0.9413\n",
      "\n",
      "Epoch:  178\n",
      "127/127 - 16s - loss: 0.1890 - accuracy: 0.9212 - val_loss: 0.1445 - val_accuracy: 0.9383 - 16s/epoch - 127ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 15ms/step - loss: 0.1428 - accuracy: 0.9386\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.1430 - accuracy: 0.9400\n",
      "\n",
      "Epoch:  179\n",
      "127/127 - 16s - loss: 0.1880 - accuracy: 0.9213 - val_loss: 0.1344 - val_accuracy: 0.9471 - 16s/epoch - 127ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 15ms/step - loss: 0.1303 - accuracy: 0.9495\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.1338 - accuracy: 0.9479\n",
      "\n",
      "Epoch:  180\n",
      "127/127 - 16s - loss: 0.1846 - accuracy: 0.9227 - val_loss: 0.1143 - val_accuracy: 0.9558 - 16s/epoch - 129ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.1110 - accuracy: 0.9579\n",
      "for testing\n",
      "378/378 [==============================] - 8s 20ms/step - loss: 0.1122 - accuracy: 0.9569\n",
      "\n",
      "Epoch:  181\n",
      "127/127 - 21s - loss: 0.1833 - accuracy: 0.9242 - val_loss: 0.1231 - val_accuracy: 0.9533 - 21s/epoch - 162ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.1197 - accuracy: 0.9560\n",
      "for testing\n",
      "378/378 [==============================] - 6s 17ms/step - loss: 0.1220 - accuracy: 0.9570\n",
      "\n",
      "Epoch:  182\n",
      "127/127 - 17s - loss: 0.1754 - accuracy: 0.9275 - val_loss: 0.1310 - val_accuracy: 0.9465 - 17s/epoch - 130ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 24s 16ms/step - loss: 0.1276 - accuracy: 0.9476\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.1302 - accuracy: 0.9470\n",
      "\n",
      "Epoch:  183\n",
      "127/127 - 12s - loss: 0.1852 - accuracy: 0.9214 - val_loss: 0.1222 - val_accuracy: 0.9515 - 12s/epoch - 91ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1188 - accuracy: 0.9530\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1209 - accuracy: 0.9517\n",
      "\n",
      "Epoch:  184\n",
      "127/127 - 12s - loss: 0.1840 - accuracy: 0.9244 - val_loss: 0.1200 - val_accuracy: 0.9545 - 12s/epoch - 98ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.1170 - accuracy: 0.9562\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1208 - accuracy: 0.9540\n",
      "\n",
      "Epoch:  185\n",
      "127/127 - 13s - loss: 0.1834 - accuracy: 0.9213 - val_loss: 0.1199 - val_accuracy: 0.9565 - 13s/epoch - 104ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1162 - accuracy: 0.9596\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1177 - accuracy: 0.9586\n",
      "\n",
      "Epoch:  186\n",
      "127/127 - 13s - loss: 0.1798 - accuracy: 0.9249 - val_loss: 0.1285 - val_accuracy: 0.9523 - 13s/epoch - 100ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1243 - accuracy: 0.9556\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1263 - accuracy: 0.9550\n",
      "\n",
      "Epoch:  187\n",
      "127/127 - 13s - loss: 0.1824 - accuracy: 0.9236 - val_loss: 0.1242 - val_accuracy: 0.9543 - 13s/epoch - 101ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 10ms/step - loss: 0.1189 - accuracy: 0.9579\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1206 - accuracy: 0.9566\n",
      "\n",
      "Epoch:  188\n",
      "127/127 - 12s - loss: 0.1796 - accuracy: 0.9250 - val_loss: 0.1179 - val_accuracy: 0.9553 - 12s/epoch - 98ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.1150 - accuracy: 0.9586\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1170 - accuracy: 0.9584\n",
      "\n",
      "Epoch:  189\n",
      "127/127 - 11s - loss: 0.1866 - accuracy: 0.9214 - val_loss: 0.1332 - val_accuracy: 0.9513 - 11s/epoch - 87ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.1287 - accuracy: 0.9545\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1309 - accuracy: 0.9518\n",
      "\n",
      "Epoch:  190\n",
      "127/127 - 11s - loss: 0.1849 - accuracy: 0.9234 - val_loss: 0.1544 - val_accuracy: 0.9387 - 11s/epoch - 86ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.1473 - accuracy: 0.9401\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1512 - accuracy: 0.9392\n",
      "\n",
      "Epoch:  191\n",
      "127/127 - 12s - loss: 0.1874 - accuracy: 0.9217 - val_loss: 0.1489 - val_accuracy: 0.9424 - 12s/epoch - 91ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1445 - accuracy: 0.9446\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1491 - accuracy: 0.9431\n",
      "\n",
      "Epoch:  192\n",
      "127/127 - 12s - loss: 0.1801 - accuracy: 0.9251 - val_loss: 0.1191 - val_accuracy: 0.9527 - 12s/epoch - 92ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1144 - accuracy: 0.9565\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1156 - accuracy: 0.9583\n",
      "\n",
      "Epoch:  193\n",
      "127/127 - 12s - loss: 0.1830 - accuracy: 0.9238 - val_loss: 0.1239 - val_accuracy: 0.9543 - 12s/epoch - 94ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1200 - accuracy: 0.9561\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1239 - accuracy: 0.9533\n",
      "\n",
      "Epoch:  194\n",
      "127/127 - 12s - loss: 0.1781 - accuracy: 0.9259 - val_loss: 0.1327 - val_accuracy: 0.9465 - 12s/epoch - 95ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.1289 - accuracy: 0.9488\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1328 - accuracy: 0.9490\n",
      "\n",
      "Epoch:  195\n",
      "127/127 - 12s - loss: 0.1837 - accuracy: 0.9241 - val_loss: 0.1360 - val_accuracy: 0.9449 - 12s/epoch - 95ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1325 - accuracy: 0.9475\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1342 - accuracy: 0.9476\n",
      "\n",
      "Epoch:  196\n",
      "127/127 - 13s - loss: 0.1765 - accuracy: 0.9260 - val_loss: 0.1134 - val_accuracy: 0.9593 - 13s/epoch - 100ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 24s 16ms/step - loss: 0.1098 - accuracy: 0.9615\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 4s 12ms/step - loss: 0.1121 - accuracy: 0.9604\n",
      "\n",
      "Epoch:  197\n",
      "127/127 - 13s - loss: 0.1826 - accuracy: 0.9232 - val_loss: 0.1170 - val_accuracy: 0.9564 - 13s/epoch - 100ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1143 - accuracy: 0.9581\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1164 - accuracy: 0.9576\n",
      "\n",
      "Epoch:  198\n",
      "127/127 - 12s - loss: 0.1769 - accuracy: 0.9260 - val_loss: 0.1210 - val_accuracy: 0.9525 - 12s/epoch - 91ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1160 - accuracy: 0.9566\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.1202 - accuracy: 0.9552\n",
      "\n",
      "Epoch:  199\n",
      "127/127 - 13s - loss: 0.1769 - accuracy: 0.9253 - val_loss: 0.1239 - val_accuracy: 0.9507 - 13s/epoch - 105ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1206 - accuracy: 0.9523\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1217 - accuracy: 0.9527\n",
      "\n",
      "Epoch:  200\n",
      "127/127 - 13s - loss: 0.1794 - accuracy: 0.9252 - val_loss: 0.1460 - val_accuracy: 0.9381 - 13s/epoch - 99ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.1410 - accuracy: 0.9398\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1441 - accuracy: 0.9406\n",
      "\n",
      "Epoch:  201\n",
      "127/127 - 12s - loss: 0.1824 - accuracy: 0.9248 - val_loss: 0.1199 - val_accuracy: 0.9541 - 12s/epoch - 93ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1168 - accuracy: 0.9562\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1201 - accuracy: 0.9560\n",
      "\n",
      "Epoch:  202\n",
      "127/127 - 14s - loss: 0.1845 - accuracy: 0.9223 - val_loss: 0.1394 - val_accuracy: 0.9409 - 14s/epoch - 112ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1336 - accuracy: 0.9453\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1346 - accuracy: 0.9458\n",
      "\n",
      "Epoch:  203\n",
      "127/127 - 12s - loss: 0.1757 - accuracy: 0.9267 - val_loss: 0.1211 - val_accuracy: 0.9579 - 12s/epoch - 93ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1166 - accuracy: 0.9609\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1194 - accuracy: 0.9575\n",
      "\n",
      "Epoch:  204\n",
      "127/127 - 12s - loss: 0.1764 - accuracy: 0.9274 - val_loss: 0.1208 - val_accuracy: 0.9537 - 12s/epoch - 93ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1161 - accuracy: 0.9572\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1224 - accuracy: 0.9556\n",
      "\n",
      "Epoch:  205\n",
      "127/127 - 13s - loss: 0.1802 - accuracy: 0.9239 - val_loss: 0.1212 - val_accuracy: 0.9522 - 13s/epoch - 99ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 10ms/step - loss: 0.1173 - accuracy: 0.9549\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1221 - accuracy: 0.9532\n",
      "\n",
      "Epoch:  206\n",
      "127/127 - 12s - loss: 0.1662 - accuracy: 0.9317 - val_loss: 0.1292 - val_accuracy: 0.9457 - 12s/epoch - 92ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1239 - accuracy: 0.9496\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1268 - accuracy: 0.9475\n",
      "\n",
      "Epoch:  207\n",
      "127/127 - 12s - loss: 0.1733 - accuracy: 0.9291 - val_loss: 0.1172 - val_accuracy: 0.9529 - 12s/epoch - 94ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1140 - accuracy: 0.9551\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1156 - accuracy: 0.9554\n",
      "\n",
      "Epoch:  208\n",
      "127/127 - 12s - loss: 0.1789 - accuracy: 0.9251 - val_loss: 0.1215 - val_accuracy: 0.9535 - 12s/epoch - 92ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1174 - accuracy: 0.9567\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.1197 - accuracy: 0.9540\n",
      "\n",
      "Epoch:  209\n",
      "127/127 - 14s - loss: 0.1806 - accuracy: 0.9254 - val_loss: 0.1205 - val_accuracy: 0.9518 - 14s/epoch - 110ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 12ms/step - loss: 0.1168 - accuracy: 0.9530\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1196 - accuracy: 0.9525\n",
      "\n",
      "Epoch:  210\n",
      "127/127 - 13s - loss: 0.1731 - accuracy: 0.9286 - val_loss: 0.1104 - val_accuracy: 0.9592 - 13s/epoch - 103ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1065 - accuracy: 0.9630\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1092 - accuracy: 0.9609\n",
      "\n",
      "Epoch:  211\n",
      "127/127 - 12s - loss: 0.1696 - accuracy: 0.9297 - val_loss: 0.1335 - val_accuracy: 0.9459 - 12s/epoch - 96ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1283 - accuracy: 0.9491\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1323 - accuracy: 0.9479\n",
      "\n",
      "Epoch:  212\n",
      "127/127 - 12s - loss: 0.1751 - accuracy: 0.9266 - val_loss: 0.1148 - val_accuracy: 0.9537 - 12s/epoch - 93ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.1112 - accuracy: 0.9562\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1138 - accuracy: 0.9555\n",
      "\n",
      "Epoch:  213\n",
      "127/127 - 12s - loss: 0.1742 - accuracy: 0.9274 - val_loss: 0.1107 - val_accuracy: 0.9602 - 12s/epoch - 94ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1065 - accuracy: 0.9619\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1101 - accuracy: 0.9602\n",
      "\n",
      "Epoch:  214\n",
      "127/127 - 12s - loss: 0.1686 - accuracy: 0.9317 - val_loss: 0.1238 - val_accuracy: 0.9534 - 12s/epoch - 94ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1197 - accuracy: 0.9554\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1263 - accuracy: 0.9525\n",
      "\n",
      "Epoch:  215\n",
      "127/127 - 12s - loss: 0.1717 - accuracy: 0.9283 - val_loss: 0.1306 - val_accuracy: 0.9498 - 12s/epoch - 96ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1251 - accuracy: 0.9532\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1278 - accuracy: 0.9531\n",
      "\n",
      "Epoch:  216\n",
      "127/127 - 12s - loss: 0.1721 - accuracy: 0.9270 - val_loss: 0.1355 - val_accuracy: 0.9468 - 12s/epoch - 95ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.1297 - accuracy: 0.9503\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1342 - accuracy: 0.9491\n",
      "\n",
      "Epoch:  217\n",
      "127/127 - 12s - loss: 0.1694 - accuracy: 0.9300 - val_loss: 0.1160 - val_accuracy: 0.9527 - 12s/epoch - 94ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1116 - accuracy: 0.9553\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1162 - accuracy: 0.9534\n",
      "\n",
      "Epoch:  218\n",
      "127/127 - 12s - loss: 0.1723 - accuracy: 0.9284 - val_loss: 0.1233 - val_accuracy: 0.9474 - 12s/epoch - 95ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1189 - accuracy: 0.9501\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1196 - accuracy: 0.9508\n",
      "\n",
      "Epoch:  219\n",
      "127/127 - 12s - loss: 0.1716 - accuracy: 0.9289 - val_loss: 0.1162 - val_accuracy: 0.9524 - 12s/epoch - 95ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.1124 - accuracy: 0.9563\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.1139 - accuracy: 0.9564\n",
      "\n",
      "Epoch:  220\n",
      "127/127 - 13s - loss: 0.1673 - accuracy: 0.9290 - val_loss: 0.1033 - val_accuracy: 0.9600 - 13s/epoch - 100ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0988 - accuracy: 0.9624\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1037 - accuracy: 0.9605\n",
      "\n",
      "Epoch:  221\n",
      "127/127 - 12s - loss: 0.1757 - accuracy: 0.9277 - val_loss: 0.1353 - val_accuracy: 0.9434 - 12s/epoch - 96ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1324 - accuracy: 0.9448\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1355 - accuracy: 0.9438\n",
      "\n",
      "Epoch:  222\n",
      "127/127 - 12s - loss: 0.1684 - accuracy: 0.9298 - val_loss: 0.1207 - val_accuracy: 0.9567 - 12s/epoch - 96ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.1162 - accuracy: 0.9604\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1179 - accuracy: 0.9611\n",
      "\n",
      "Epoch:  223\n",
      "127/127 - 12s - loss: 0.1751 - accuracy: 0.9270 - val_loss: 0.1244 - val_accuracy: 0.9546 - 12s/epoch - 97ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.1199 - accuracy: 0.9567\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1225 - accuracy: 0.9537\n",
      "\n",
      "Epoch:  224\n",
      "127/127 - 15s - loss: 0.1732 - accuracy: 0.9287 - val_loss: 0.1098 - val_accuracy: 0.9542 - 15s/epoch - 118ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.1054 - accuracy: 0.9571\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1083 - accuracy: 0.9562\n",
      "\n",
      "Epoch:  225\n",
      "127/127 - 12s - loss: 0.1702 - accuracy: 0.9315 - val_loss: 0.1158 - val_accuracy: 0.9552 - 12s/epoch - 97ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 10ms/step - loss: 0.1103 - accuracy: 0.9602\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1142 - accuracy: 0.9592\n",
      "\n",
      "Epoch:  226\n",
      "127/127 - 12s - loss: 0.1688 - accuracy: 0.9288 - val_loss: 0.1344 - val_accuracy: 0.9438 - 12s/epoch - 97ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1302 - accuracy: 0.9465\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1324 - accuracy: 0.9482\n",
      "\n",
      "Epoch:  227\n",
      "127/127 - 12s - loss: 0.1675 - accuracy: 0.9294 - val_loss: 0.1154 - val_accuracy: 0.9538 - 12s/epoch - 96ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1107 - accuracy: 0.9560\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1143 - accuracy: 0.9553\n",
      "\n",
      "Epoch:  228\n",
      "127/127 - 12s - loss: 0.1705 - accuracy: 0.9282 - val_loss: 0.1366 - val_accuracy: 0.9465 - 12s/epoch - 96ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1313 - accuracy: 0.9503\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1349 - accuracy: 0.9478\n",
      "\n",
      "Epoch:  229\n",
      "127/127 - 12s - loss: 0.1664 - accuracy: 0.9316 - val_loss: 0.1063 - val_accuracy: 0.9621 - 12s/epoch - 98ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.1037 - accuracy: 0.9635\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1062 - accuracy: 0.9625\n",
      "\n",
      "Epoch:  230\n",
      "127/127 - 13s - loss: 0.1679 - accuracy: 0.9307 - val_loss: 0.1217 - val_accuracy: 0.9538 - 13s/epoch - 103ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.1158 - accuracy: 0.9569\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1202 - accuracy: 0.9551\n",
      "\n",
      "Epoch:  231\n",
      "127/127 - 12s - loss: 0.1710 - accuracy: 0.9313 - val_loss: 0.1060 - val_accuracy: 0.9585 - 12s/epoch - 98ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.1008 - accuracy: 0.9626\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1048 - accuracy: 0.9612\n",
      "\n",
      "Epoch:  232\n",
      "127/127 - 13s - loss: 0.1665 - accuracy: 0.9314 - val_loss: 0.1290 - val_accuracy: 0.9495 - 13s/epoch - 100ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1237 - accuracy: 0.9516\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1292 - accuracy: 0.9486\n",
      "\n",
      "Epoch:  233\n",
      "127/127 - 13s - loss: 0.1639 - accuracy: 0.9305 - val_loss: 0.1149 - val_accuracy: 0.9599 - 13s/epoch - 99ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1106 - accuracy: 0.9619\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1145 - accuracy: 0.9606\n",
      "\n",
      "Epoch:  234\n",
      "127/127 - 12s - loss: 0.1610 - accuracy: 0.9332 - val_loss: 0.1211 - val_accuracy: 0.9547 - 12s/epoch - 97ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.1157 - accuracy: 0.9569\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1215 - accuracy: 0.9546\n",
      "\n",
      "Epoch:  235\n",
      "127/127 - 12s - loss: 0.1661 - accuracy: 0.9313 - val_loss: 0.1049 - val_accuracy: 0.9578 - 12s/epoch - 98ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0994 - accuracy: 0.9630\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1028 - accuracy: 0.9619\n",
      "\n",
      "Epoch:  236\n",
      "127/127 - 12s - loss: 0.1604 - accuracy: 0.9336 - val_loss: 0.1108 - val_accuracy: 0.9571 - 12s/epoch - 97ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.1054 - accuracy: 0.9610\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1097 - accuracy: 0.9614\n",
      "\n",
      "Epoch:  237\n",
      "127/127 - 13s - loss: 0.1619 - accuracy: 0.9322 - val_loss: 0.1040 - val_accuracy: 0.9594 - 13s/epoch - 102ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0974 - accuracy: 0.9642\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.1011 - accuracy: 0.9626\n",
      "\n",
      "Epoch:  238\n",
      "127/127 - 13s - loss: 0.1599 - accuracy: 0.9346 - val_loss: 0.1090 - val_accuracy: 0.9594 - 13s/epoch - 102ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.1037 - accuracy: 0.9615\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1090 - accuracy: 0.9615\n",
      "\n",
      "Epoch:  239\n",
      "127/127 - 13s - loss: 0.1631 - accuracy: 0.9331 - val_loss: 0.1036 - val_accuracy: 0.9635 - 13s/epoch - 101ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0988 - accuracy: 0.9661\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1025 - accuracy: 0.9641\n",
      "\n",
      "Epoch:  240\n",
      "127/127 - 12s - loss: 0.1636 - accuracy: 0.9326 - val_loss: 0.1065 - val_accuracy: 0.9580 - 12s/epoch - 98ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 10ms/step - loss: 0.0997 - accuracy: 0.9631\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1035 - accuracy: 0.9607\n",
      "\n",
      "Epoch:  241\n",
      "127/127 - 12s - loss: 0.1577 - accuracy: 0.9346 - val_loss: 0.1071 - val_accuracy: 0.9582 - 12s/epoch - 97ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.1015 - accuracy: 0.9620\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1047 - accuracy: 0.9601\n",
      "\n",
      "Epoch:  242\n",
      "127/127 - 12s - loss: 0.1653 - accuracy: 0.9311 - val_loss: 0.1018 - val_accuracy: 0.9614 - 12s/epoch - 98ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0965 - accuracy: 0.9645\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1026 - accuracy: 0.9619\n",
      "\n",
      "Epoch:  243\n",
      "127/127 - 12s - loss: 0.1572 - accuracy: 0.9360 - val_loss: 0.1321 - val_accuracy: 0.9439 - 12s/epoch - 98ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.1253 - accuracy: 0.9487\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1304 - accuracy: 0.9478\n",
      "\n",
      "Epoch:  244\n",
      "127/127 - 13s - loss: 0.1649 - accuracy: 0.9316 - val_loss: 0.1179 - val_accuracy: 0.9515 - 13s/epoch - 99ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 10ms/step - loss: 0.1128 - accuracy: 0.9549\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1149 - accuracy: 0.9553\n",
      "\n",
      "Epoch:  245\n",
      "127/127 - 12s - loss: 0.1645 - accuracy: 0.9315 - val_loss: 0.1021 - val_accuracy: 0.9597 - 12s/epoch - 97ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0976 - accuracy: 0.9624\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1024 - accuracy: 0.9598\n",
      "\n",
      "Epoch:  246\n",
      "127/127 - 13s - loss: 0.1535 - accuracy: 0.9384 - val_loss: 0.1112 - val_accuracy: 0.9572 - 13s/epoch - 105ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.1032 - accuracy: 0.9615\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1075 - accuracy: 0.9597\n",
      "\n",
      "Epoch:  247\n",
      "127/127 - 5471s - loss: 0.1639 - accuracy: 0.9327 - val_loss: 0.1038 - val_accuracy: 0.9597 - 5471s/epoch - 43s/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 12ms/step - loss: 0.0975 - accuracy: 0.9643\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1004 - accuracy: 0.9638\n",
      "\n",
      "Epoch:  248\n",
      "127/127 - 11s - loss: 0.1576 - accuracy: 0.9350 - val_loss: 0.1120 - val_accuracy: 0.9577 - 11s/epoch - 90ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.1056 - accuracy: 0.9596\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1111 - accuracy: 0.9570\n",
      "\n",
      "Epoch:  249\n",
      "127/127 - 12s - loss: 0.1590 - accuracy: 0.9333 - val_loss: 0.1089 - val_accuracy: 0.9595 - 12s/epoch - 98ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1040 - accuracy: 0.9616\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1091 - accuracy: 0.9594\n",
      "\n",
      "Epoch:  250\n",
      "127/127 - 12s - loss: 0.1593 - accuracy: 0.9340 - val_loss: 0.1143 - val_accuracy: 0.9559 - 12s/epoch - 94ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1072 - accuracy: 0.9606\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1120 - accuracy: 0.9593\n",
      "\n",
      "Epoch:  251\n",
      "127/127 - 12s - loss: 0.1580 - accuracy: 0.9343 - val_loss: 0.1157 - val_accuracy: 0.9568 - 12s/epoch - 98ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1097 - accuracy: 0.9599\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1157 - accuracy: 0.9572\n",
      "\n",
      "Epoch:  252\n",
      "127/127 - 11s - loss: 0.1549 - accuracy: 0.9360 - val_loss: 0.1042 - val_accuracy: 0.9593 - 11s/epoch - 88ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0975 - accuracy: 0.9639\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1043 - accuracy: 0.9620\n",
      "\n",
      "Epoch:  253\n",
      "127/127 - 11s - loss: 0.1611 - accuracy: 0.9332 - val_loss: 0.1121 - val_accuracy: 0.9570 - 11s/epoch - 88ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1054 - accuracy: 0.9599\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1108 - accuracy: 0.9599\n",
      "\n",
      "Epoch:  254\n",
      "127/127 - 11s - loss: 0.1517 - accuracy: 0.9380 - val_loss: 0.1311 - val_accuracy: 0.9466 - 11s/epoch - 87ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1256 - accuracy: 0.9498\n",
      "for testing\n",
      "378/378 [==============================] - 4s 12ms/step - loss: 0.1271 - accuracy: 0.9496\n",
      "\n",
      "Epoch:  255\n",
      "127/127 - 16s - loss: 0.1605 - accuracy: 0.9320 - val_loss: 0.1125 - val_accuracy: 0.9560 - 16s/epoch - 128ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 30s 20ms/step - loss: 0.1065 - accuracy: 0.9587\n",
      "for testing\n",
      "378/378 [==============================] - 7s 20ms/step - loss: 0.1106 - accuracy: 0.9570\n",
      "\n",
      "Epoch:  256\n",
      "127/127 - 19s - loss: 0.1560 - accuracy: 0.9357 - val_loss: 0.1085 - val_accuracy: 0.9608 - 19s/epoch - 152ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 31s 20ms/step - loss: 0.1026 - accuracy: 0.9639\n",
      "for testing\n",
      "378/378 [==============================] - 8s 22ms/step - loss: 0.1059 - accuracy: 0.9611\n",
      "\n",
      "Epoch:  257\n",
      "127/127 - 22s - loss: 0.1575 - accuracy: 0.9354 - val_loss: 0.1054 - val_accuracy: 0.9604 - 22s/epoch - 176ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 31s 20ms/step - loss: 0.0987 - accuracy: 0.9642\n",
      "for testing\n",
      "378/378 [==============================] - 7s 19ms/step - loss: 0.1031 - accuracy: 0.9605\n",
      "\n",
      "Epoch:  258\n",
      "127/127 - 18s - loss: 0.1545 - accuracy: 0.9357 - val_loss: 0.0996 - val_accuracy: 0.9627 - 18s/epoch - 141ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 25s 16ms/step - loss: 0.0942 - accuracy: 0.9655\n",
      "for testing\n",
      "378/378 [==============================] - 6s 17ms/step - loss: 0.0998 - accuracy: 0.9635\n",
      "\n",
      "Epoch:  259\n",
      "127/127 - 18s - loss: 0.1527 - accuracy: 0.9379 - val_loss: 0.1058 - val_accuracy: 0.9597 - 18s/epoch - 139ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 25s 17ms/step - loss: 0.1006 - accuracy: 0.9623\n",
      "for testing\n",
      "378/378 [==============================] - 6s 16ms/step - loss: 0.1060 - accuracy: 0.9606\n",
      "\n",
      "Epoch:  260\n",
      "127/127 - 18s - loss: 0.1593 - accuracy: 0.9337 - val_loss: 0.1063 - val_accuracy: 0.9598 - 18s/epoch - 139ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 25s 16ms/step - loss: 0.1006 - accuracy: 0.9624\n",
      "for testing\n",
      "378/378 [==============================] - 6s 16ms/step - loss: 0.1062 - accuracy: 0.9596\n",
      "\n",
      "Epoch:  261\n",
      "127/127 - 18s - loss: 0.1557 - accuracy: 0.9368 - val_loss: 0.1043 - val_accuracy: 0.9575 - 18s/epoch - 141ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 25s 16ms/step - loss: 0.0996 - accuracy: 0.9605\n",
      "for testing\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.1052 - accuracy: 0.9570\n",
      "\n",
      "Epoch:  262\n",
      "127/127 - 31s - loss: 0.1511 - accuracy: 0.9384 - val_loss: 0.1068 - val_accuracy: 0.9616 - 31s/epoch - 245ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 27s 18ms/step - loss: 0.1007 - accuracy: 0.9645\n",
      "for testing\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.1047 - accuracy: 0.9616\n",
      "\n",
      "Epoch:  263\n",
      "127/127 - 20s - loss: 0.1517 - accuracy: 0.9378 - val_loss: 0.1012 - val_accuracy: 0.9605 - 20s/epoch - 159ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 27s 18ms/step - loss: 0.0949 - accuracy: 0.9642\n",
      "for testing\n",
      "378/378 [==============================] - 7s 17ms/step - loss: 0.1005 - accuracy: 0.9611\n",
      "\n",
      "Epoch:  264\n",
      "127/127 - 19s - loss: 0.1538 - accuracy: 0.9363 - val_loss: 0.1109 - val_accuracy: 0.9587 - 19s/epoch - 150ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 27s 18ms/step - loss: 0.1051 - accuracy: 0.9601\n",
      "for testing\n",
      "378/378 [==============================] - 3755s 10s/step - loss: 0.1096 - accuracy: 0.9588\n",
      "\n",
      "Epoch:  265\n",
      "127/127 - 33s - loss: 0.1560 - accuracy: 0.9352 - val_loss: 0.1109 - val_accuracy: 0.9560 - 33s/epoch - 263ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 38s 25ms/step - loss: 0.1048 - accuracy: 0.9602\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.1087 - accuracy: 0.9587\n",
      "\n",
      "Epoch:  266\n",
      "127/127 - 21s - loss: 0.1501 - accuracy: 0.9380 - val_loss: 0.1035 - val_accuracy: 0.9614 - 21s/epoch - 162ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.0972 - accuracy: 0.9641\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.1025 - accuracy: 0.9625\n",
      "\n",
      "Epoch:  267\n",
      "127/127 - 14s - loss: 0.1595 - accuracy: 0.9337 - val_loss: 0.1092 - val_accuracy: 0.9587 - 14s/epoch - 106ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.1030 - accuracy: 0.9611\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1093 - accuracy: 0.9589\n",
      "\n",
      "Epoch:  268\n",
      "127/127 - 13s - loss: 0.1534 - accuracy: 0.9365 - val_loss: 0.1098 - val_accuracy: 0.9562 - 13s/epoch - 105ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.1047 - accuracy: 0.9579\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.1117 - accuracy: 0.9573\n",
      "\n",
      "Epoch:  269\n",
      "127/127 - 15s - loss: 0.1597 - accuracy: 0.9344 - val_loss: 0.1144 - val_accuracy: 0.9547 - 15s/epoch - 117ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.1088 - accuracy: 0.9577\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1160 - accuracy: 0.9542\n",
      "\n",
      "Epoch:  270\n",
      "127/127 - 13s - loss: 0.1558 - accuracy: 0.9365 - val_loss: 0.1039 - val_accuracy: 0.9585 - 13s/epoch - 102ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0974 - accuracy: 0.9626\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1014 - accuracy: 0.9618\n",
      "\n",
      "Epoch:  271\n",
      "127/127 - 14s - loss: 0.1587 - accuracy: 0.9353 - val_loss: 0.1094 - val_accuracy: 0.9570 - 14s/epoch - 107ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.1007 - accuracy: 0.9626\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.1041 - accuracy: 0.9600\n",
      "\n",
      "Epoch:  272\n",
      "127/127 - 15s - loss: 0.1489 - accuracy: 0.9391 - val_loss: 0.0945 - val_accuracy: 0.9644 - 15s/epoch - 115ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0886 - accuracy: 0.9679\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0916 - accuracy: 0.9667\n",
      "\n",
      "Epoch:  273\n",
      "127/127 - 13s - loss: 0.1530 - accuracy: 0.9356 - val_loss: 0.1022 - val_accuracy: 0.9637 - 13s/epoch - 104ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0952 - accuracy: 0.9673\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0990 - accuracy: 0.9661\n",
      "\n",
      "Epoch:  274\n",
      "127/127 - 13s - loss: 0.1508 - accuracy: 0.9381 - val_loss: 0.1114 - val_accuracy: 0.9555 - 13s/epoch - 104ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.1047 - accuracy: 0.9588\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1120 - accuracy: 0.9558\n",
      "\n",
      "Epoch:  275\n",
      "127/127 - 13s - loss: 0.1516 - accuracy: 0.9370 - val_loss: 0.1095 - val_accuracy: 0.9568 - 13s/epoch - 105ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.1037 - accuracy: 0.9598\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.1085 - accuracy: 0.9600\n",
      "\n",
      "Epoch:  276\n",
      "127/127 - 13s - loss: 0.1541 - accuracy: 0.9357 - val_loss: 0.1152 - val_accuracy: 0.9558 - 13s/epoch - 103ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.1088 - accuracy: 0.9585\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.1119 - accuracy: 0.9572\n",
      "\n",
      "Epoch:  277\n",
      "127/127 - 13s - loss: 0.1469 - accuracy: 0.9409 - val_loss: 0.1154 - val_accuracy: 0.9552 - 13s/epoch - 104ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.1074 - accuracy: 0.9595\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.1151 - accuracy: 0.9573\n",
      "\n",
      "Epoch:  278\n",
      "127/127 - 13s - loss: 0.1506 - accuracy: 0.9389 - val_loss: 0.1032 - val_accuracy: 0.9605 - 13s/epoch - 104ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0970 - accuracy: 0.9635\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0987 - accuracy: 0.9625\n",
      "\n",
      "Epoch:  279\n",
      "127/127 - 13s - loss: 0.1483 - accuracy: 0.9383 - val_loss: 0.1308 - val_accuracy: 0.9447 - 13s/epoch - 105ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.1230 - accuracy: 0.9478\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1306 - accuracy: 0.9458\n",
      "\n",
      "Epoch:  280\n",
      "127/127 - 14s - loss: 0.1517 - accuracy: 0.9375 - val_loss: 0.1036 - val_accuracy: 0.9603 - 14s/epoch - 107ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0963 - accuracy: 0.9654\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.1030 - accuracy: 0.9633\n",
      "\n",
      "Epoch:  281\n",
      "127/127 - 16s - loss: 0.1458 - accuracy: 0.9399 - val_loss: 0.1282 - val_accuracy: 0.9513 - 16s/epoch - 129ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 12ms/step - loss: 0.1216 - accuracy: 0.9517\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.1301 - accuracy: 0.9485\n",
      "\n",
      "Epoch:  282\n",
      "127/127 - 14s - loss: 0.1503 - accuracy: 0.9375 - val_loss: 0.0914 - val_accuracy: 0.9665 - 14s/epoch - 108ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.0872 - accuracy: 0.9683\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0916 - accuracy: 0.9664\n",
      "\n",
      "Epoch:  283\n",
      "127/127 - 14s - loss: 0.1501 - accuracy: 0.9384 - val_loss: 0.0976 - val_accuracy: 0.9614 - 14s/epoch - 114ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0906 - accuracy: 0.9654\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0965 - accuracy: 0.9630\n",
      "\n",
      "Epoch:  284\n",
      "127/127 - 17s - loss: 0.1538 - accuracy: 0.9347 - val_loss: 0.1184 - val_accuracy: 0.9563 - 17s/epoch - 132ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.1107 - accuracy: 0.9604\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.1153 - accuracy: 0.9577\n",
      "\n",
      "Epoch:  285\n",
      "127/127 - 14s - loss: 0.1445 - accuracy: 0.9412 - val_loss: 0.0899 - val_accuracy: 0.9677 - 14s/epoch - 113ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.0835 - accuracy: 0.9715\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0901 - accuracy: 0.9675\n",
      "\n",
      "Epoch:  286\n",
      "127/127 - 14s - loss: 0.1461 - accuracy: 0.9404 - val_loss: 0.1070 - val_accuracy: 0.9567 - 14s/epoch - 108ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0977 - accuracy: 0.9625\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.1035 - accuracy: 0.9602\n",
      "\n",
      "Epoch:  287\n",
      "127/127 - 14s - loss: 0.1499 - accuracy: 0.9389 - val_loss: 0.0996 - val_accuracy: 0.9648 - 14s/epoch - 110ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0922 - accuracy: 0.9693\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0975 - accuracy: 0.9676\n",
      "\n",
      "Epoch:  288\n",
      "127/127 - 14s - loss: 0.1457 - accuracy: 0.9394 - val_loss: 0.1030 - val_accuracy: 0.9604 - 14s/epoch - 112ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.0950 - accuracy: 0.9646\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.1013 - accuracy: 0.9627\n",
      "\n",
      "Epoch:  289\n",
      "127/127 - 20s - loss: 0.1466 - accuracy: 0.9405 - val_loss: 0.0854 - val_accuracy: 0.9690 - 20s/epoch - 158ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 34s 22ms/step - loss: 0.0786 - accuracy: 0.9721\n",
      "for testing\n",
      "378/378 [==============================] - 9s 23ms/step - loss: 0.0841 - accuracy: 0.9702\n",
      "\n",
      "Epoch:  290\n",
      "127/127 - 26s - loss: 0.1423 - accuracy: 0.9416 - val_loss: 0.1089 - val_accuracy: 0.9565 - 26s/epoch - 202ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 30s 20ms/step - loss: 0.0995 - accuracy: 0.9613\n",
      "for testing\n",
      "378/378 [==============================] - 10s 26ms/step - loss: 0.1066 - accuracy: 0.9583\n",
      "\n",
      "Epoch:  291\n",
      "127/127 - 35s - loss: 0.1390 - accuracy: 0.9418 - val_loss: 0.0952 - val_accuracy: 0.9636 - 35s/epoch - 272ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 42s 28ms/step - loss: 0.0867 - accuracy: 0.9682\n",
      "for testing\n",
      "378/378 [==============================] - 9s 23ms/step - loss: 0.0935 - accuracy: 0.9638\n",
      "\n",
      "Epoch:  292\n",
      "127/127 - 27s - loss: 0.1460 - accuracy: 0.9393 - val_loss: 0.0943 - val_accuracy: 0.9646 - 27s/epoch - 209ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 31s 20ms/step - loss: 0.0872 - accuracy: 0.9679\n",
      "for testing\n",
      "378/378 [==============================] - 11s 28ms/step - loss: 0.0943 - accuracy: 0.9663\n",
      "\n",
      "Epoch:  293\n",
      "127/127 - 29s - loss: 0.1477 - accuracy: 0.9403 - val_loss: 0.1211 - val_accuracy: 0.9506 - 29s/epoch - 230ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 37s 24ms/step - loss: 0.1136 - accuracy: 0.9539\n",
      "for testing\n",
      "378/378 [==============================] - 12s 32ms/step - loss: 0.1219 - accuracy: 0.9514\n",
      "\n",
      "Epoch:  294\n",
      "127/127 - 36s - loss: 0.1448 - accuracy: 0.9415 - val_loss: 0.1009 - val_accuracy: 0.9619 - 36s/epoch - 280ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 47s 31ms/step - loss: 0.0920 - accuracy: 0.9671\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 12s 32ms/step - loss: 0.0969 - accuracy: 0.9653\n",
      "\n",
      "Epoch:  295\n",
      "127/127 - 32s - loss: 0.1447 - accuracy: 0.9410 - val_loss: 0.0939 - val_accuracy: 0.9633 - 32s/epoch - 254ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 43s 28ms/step - loss: 0.0868 - accuracy: 0.9671\n",
      "for testing\n",
      "378/378 [==============================] - 10s 27ms/step - loss: 0.0942 - accuracy: 0.9641\n",
      "\n",
      "Epoch:  296\n",
      "127/127 - 34s - loss: 0.1471 - accuracy: 0.9393 - val_loss: 0.1031 - val_accuracy: 0.9605 - 34s/epoch - 264ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 41s 27ms/step - loss: 0.0959 - accuracy: 0.9651\n",
      "for testing\n",
      "378/378 [==============================] - 10s 25ms/step - loss: 0.0991 - accuracy: 0.9638\n",
      "\n",
      "Epoch:  297\n",
      "127/127 - 27s - loss: 0.1419 - accuracy: 0.9414 - val_loss: 0.0953 - val_accuracy: 0.9652 - 27s/epoch - 209ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 34s 23ms/step - loss: 0.0881 - accuracy: 0.9691\n",
      "for testing\n",
      "378/378 [==============================] - 10s 25ms/step - loss: 0.0927 - accuracy: 0.9670\n",
      "\n",
      "Epoch:  298\n",
      "127/127 - 32s - loss: 0.1435 - accuracy: 0.9416 - val_loss: 0.0962 - val_accuracy: 0.9654 - 32s/epoch - 255ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 39s 25ms/step - loss: 0.0881 - accuracy: 0.9696\n",
      "for testing\n",
      "378/378 [==============================] - 10s 26ms/step - loss: 0.0949 - accuracy: 0.9660\n",
      "\n",
      "Epoch:  299\n",
      "127/127 - 30s - loss: 0.1435 - accuracy: 0.9402 - val_loss: 0.0929 - val_accuracy: 0.9670 - 30s/epoch - 235ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 42s 28ms/step - loss: 0.0859 - accuracy: 0.9707\n",
      "for testing\n",
      "378/378 [==============================] - 9s 24ms/step - loss: 0.0914 - accuracy: 0.9667\n",
      "\n",
      "Epoch:  300\n",
      "127/127 - 33s - loss: 0.1494 - accuracy: 0.9384 - val_loss: 0.1050 - val_accuracy: 0.9598 - 33s/epoch - 260ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 36s 24ms/step - loss: 0.0979 - accuracy: 0.9646\n",
      "for testing\n",
      "378/378 [==============================] - 8s 21ms/step - loss: 0.1035 - accuracy: 0.9634\n",
      "\n",
      "Epoch:  301\n",
      "127/127 - 27s - loss: 0.1492 - accuracy: 0.9374 - val_loss: 0.0932 - val_accuracy: 0.9655 - 27s/epoch - 210ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 36s 24ms/step - loss: 0.0853 - accuracy: 0.9701\n",
      "for testing\n",
      "378/378 [==============================] - 8s 22ms/step - loss: 0.0902 - accuracy: 0.9668\n",
      "\n",
      "Epoch:  302\n",
      "127/127 - 27s - loss: 0.1405 - accuracy: 0.9435 - val_loss: 0.1121 - val_accuracy: 0.9567 - 27s/epoch - 215ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 37s 25ms/step - loss: 0.1041 - accuracy: 0.9592\n",
      "for testing\n",
      "378/378 [==============================] - 10s 26ms/step - loss: 0.1130 - accuracy: 0.9555\n",
      "\n",
      "Epoch:  303\n",
      "127/127 - 28s - loss: 0.1411 - accuracy: 0.9417 - val_loss: 0.0854 - val_accuracy: 0.9690 - 28s/epoch - 219ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 34s 23ms/step - loss: 0.0782 - accuracy: 0.9726\n",
      "for testing\n",
      "378/378 [==============================] - 8s 22ms/step - loss: 0.0852 - accuracy: 0.9687\n",
      "\n",
      "Epoch:  304\n",
      "127/127 - 28s - loss: 0.1440 - accuracy: 0.9410 - val_loss: 0.0941 - val_accuracy: 0.9638 - 28s/epoch - 223ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 34s 23ms/step - loss: 0.0854 - accuracy: 0.9693\n",
      "for testing\n",
      "378/378 [==============================] - 8s 22ms/step - loss: 0.0910 - accuracy: 0.9668\n",
      "\n",
      "Epoch:  305\n",
      "127/127 - 28s - loss: 0.1375 - accuracy: 0.9431 - val_loss: 0.1082 - val_accuracy: 0.9567 - 28s/epoch - 220ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 34s 23ms/step - loss: 0.0979 - accuracy: 0.9613\n",
      "for testing\n",
      "378/378 [==============================] - 8s 22ms/step - loss: 0.1054 - accuracy: 0.9578\n",
      "\n",
      "Epoch:  306\n",
      "127/127 - 27s - loss: 0.1478 - accuracy: 0.9385 - val_loss: 0.0954 - val_accuracy: 0.9644 - 27s/epoch - 211ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 31s 21ms/step - loss: 0.0886 - accuracy: 0.9678\n",
      "for testing\n",
      "378/378 [==============================] - 8s 21ms/step - loss: 0.0956 - accuracy: 0.9642\n",
      "\n",
      "Epoch:  307\n",
      "127/127 - 24s - loss: 0.1450 - accuracy: 0.9425 - val_loss: 0.0954 - val_accuracy: 0.9627 - 24s/epoch - 191ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 32s 21ms/step - loss: 0.0871 - accuracy: 0.9672\n",
      "for testing\n",
      "378/378 [==============================] - 8s 21ms/step - loss: 0.0921 - accuracy: 0.9644\n",
      "\n",
      "Epoch:  308\n",
      "127/127 - 25s - loss: 0.1405 - accuracy: 0.9422 - val_loss: 0.1102 - val_accuracy: 0.9612 - 25s/epoch - 194ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 32s 21ms/step - loss: 0.1015 - accuracy: 0.9649\n",
      "for testing\n",
      "378/378 [==============================] - 8s 21ms/step - loss: 0.1062 - accuracy: 0.9617\n",
      "\n",
      "Epoch:  309\n",
      "127/127 - 25s - loss: 0.1419 - accuracy: 0.9428 - val_loss: 0.1030 - val_accuracy: 0.9600 - 25s/epoch - 194ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 32s 21ms/step - loss: 0.0938 - accuracy: 0.9650\n",
      "for testing\n",
      "378/378 [==============================] - 8s 21ms/step - loss: 0.0983 - accuracy: 0.9633\n",
      "\n",
      "Epoch:  310\n",
      "127/127 - 25s - loss: 0.1478 - accuracy: 0.9398 - val_loss: 0.0962 - val_accuracy: 0.9647 - 25s/epoch - 196ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 33s 22ms/step - loss: 0.0908 - accuracy: 0.9674\n",
      "for testing\n",
      "378/378 [==============================] - 9s 23ms/step - loss: 0.0982 - accuracy: 0.9632\n",
      "\n",
      "Epoch:  311\n",
      "127/127 - 25s - loss: 0.1392 - accuracy: 0.9427 - val_loss: 0.1053 - val_accuracy: 0.9607 - 25s/epoch - 199ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 32s 21ms/step - loss: 0.0986 - accuracy: 0.9645\n",
      "for testing\n",
      "378/378 [==============================] - 8s 21ms/step - loss: 0.1044 - accuracy: 0.9613\n",
      "\n",
      "Epoch:  312\n",
      "127/127 - 32188s - loss: 0.1395 - accuracy: 0.9431 - val_loss: 0.0890 - val_accuracy: 0.9658 - 32188s/epoch - 253s/step\n",
      "for training\n",
      "1512/1512 [==============================] - 27s 18ms/step - loss: 0.0802 - accuracy: 0.9711\n",
      "for testing\n",
      "378/378 [==============================] - 10s 27ms/step - loss: 0.0853 - accuracy: 0.9689\n",
      "\n",
      "Epoch:  313\n",
      "127/127 - 23s - loss: 0.1414 - accuracy: 0.9419 - val_loss: 0.0896 - val_accuracy: 0.9657 - 23s/epoch - 184ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 12ms/step - loss: 0.0838 - accuracy: 0.9684\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.0888 - accuracy: 0.9683\n",
      "\n",
      "Epoch:  314\n",
      "127/127 - 16s - loss: 0.1361 - accuracy: 0.9440 - val_loss: 0.0919 - val_accuracy: 0.9647 - 16s/epoch - 124ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.0840 - accuracy: 0.9690\n",
      "for testing\n",
      "378/378 [==============================] - 4s 12ms/step - loss: 0.0885 - accuracy: 0.9671\n",
      "\n",
      "Epoch:  315\n",
      "127/127 - 14s - loss: 0.1458 - accuracy: 0.9404 - val_loss: 0.0916 - val_accuracy: 0.9659 - 14s/epoch - 111ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 15ms/step - loss: 0.0851 - accuracy: 0.9691\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.0932 - accuracy: 0.9644\n",
      "\n",
      "Epoch:  316\n",
      "127/127 - 20s - loss: 0.1402 - accuracy: 0.9440 - val_loss: 0.0972 - val_accuracy: 0.9646 - 20s/epoch - 154ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.0916 - accuracy: 0.9676\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.0956 - accuracy: 0.9659\n",
      "\n",
      "Epoch:  317\n",
      "127/127 - 15s - loss: 0.1428 - accuracy: 0.9420 - val_loss: 0.0969 - val_accuracy: 0.9634 - 15s/epoch - 121ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 12ms/step - loss: 0.0900 - accuracy: 0.9666\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0936 - accuracy: 0.9639\n",
      "\n",
      "Epoch:  318\n",
      "127/127 - 14s - loss: 0.1389 - accuracy: 0.9430 - val_loss: 0.1078 - val_accuracy: 0.9563 - 14s/epoch - 114ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.0987 - accuracy: 0.9599\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.1080 - accuracy: 0.9568\n",
      "\n",
      "Epoch:  319\n",
      "127/127 - 16s - loss: 0.1444 - accuracy: 0.9406 - val_loss: 0.0913 - val_accuracy: 0.9653 - 16s/epoch - 124ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 22s 14ms/step - loss: 0.0831 - accuracy: 0.9693\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0882 - accuracy: 0.9673\n",
      "\n",
      "Epoch:  320\n",
      "127/127 - 17s - loss: 0.1458 - accuracy: 0.9419 - val_loss: 0.1084 - val_accuracy: 0.9574 - 17s/epoch - 133ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.1014 - accuracy: 0.9605\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.1082 - accuracy: 0.9581\n",
      "\n",
      "Epoch:  321\n",
      "127/127 - 17s - loss: 0.1425 - accuracy: 0.9419 - val_loss: 0.0930 - val_accuracy: 0.9637 - 17s/epoch - 130ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 15ms/step - loss: 0.0863 - accuracy: 0.9678\n",
      "for testing\n",
      "378/378 [==============================] - 9s 23ms/step - loss: 0.0913 - accuracy: 0.9667\n",
      "\n",
      "Epoch:  322\n",
      "127/127 - 19s - loss: 0.1379 - accuracy: 0.9429 - val_loss: 0.0946 - val_accuracy: 0.9643 - 19s/epoch - 151ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.0861 - accuracy: 0.9685\n",
      "for testing\n",
      "378/378 [==============================] - 4s 12ms/step - loss: 0.0950 - accuracy: 0.9648\n",
      "\n",
      "Epoch:  323\n",
      "127/127 - 16s - loss: 0.1388 - accuracy: 0.9427 - val_loss: 0.1409 - val_accuracy: 0.9418 - 16s/epoch - 122ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 12ms/step - loss: 0.1288 - accuracy: 0.9462\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.1419 - accuracy: 0.9411\n",
      "\n",
      "Epoch:  324\n",
      "127/127 - 18s - loss: 0.1378 - accuracy: 0.9431 - val_loss: 0.0935 - val_accuracy: 0.9659 - 18s/epoch - 143ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.0849 - accuracy: 0.9695\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.0910 - accuracy: 0.9672\n",
      "\n",
      "Epoch:  325\n",
      "127/127 - 17s - loss: 0.1384 - accuracy: 0.9437 - val_loss: 0.1054 - val_accuracy: 0.9603 - 17s/epoch - 133ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.0988 - accuracy: 0.9628\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.1035 - accuracy: 0.9622\n",
      "\n",
      "Epoch:  326\n",
      "127/127 - 20s - loss: 0.1384 - accuracy: 0.9438 - val_loss: 0.0854 - val_accuracy: 0.9689 - 20s/epoch - 157ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.0773 - accuracy: 0.9729\n",
      "for testing\n",
      "378/378 [==============================] - 4s 12ms/step - loss: 0.0833 - accuracy: 0.9701\n",
      "\n",
      "Epoch:  327\n",
      "127/127 - 16s - loss: 0.1451 - accuracy: 0.9407 - val_loss: 0.1016 - val_accuracy: 0.9624 - 16s/epoch - 128ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.0933 - accuracy: 0.9670\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.0983 - accuracy: 0.9652\n",
      "\n",
      "Epoch:  328\n",
      "127/127 - 17s - loss: 0.1360 - accuracy: 0.9438 - val_loss: 0.0861 - val_accuracy: 0.9676 - 17s/epoch - 136ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 13ms/step - loss: 0.0784 - accuracy: 0.9715\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.0858 - accuracy: 0.9672\n",
      "\n",
      "Epoch:  329\n",
      "127/127 - 18s - loss: 0.1324 - accuracy: 0.9457 - val_loss: 0.1025 - val_accuracy: 0.9614 - 18s/epoch - 142ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.0950 - accuracy: 0.9645\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.1019 - accuracy: 0.9592\n",
      "\n",
      "Epoch:  330\n",
      "127/127 - 18s - loss: 0.1373 - accuracy: 0.9438 - val_loss: 0.0899 - val_accuracy: 0.9672 - 18s/epoch - 146ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.0796 - accuracy: 0.9720\n",
      "for testing\n",
      "378/378 [==============================] - 4s 12ms/step - loss: 0.0873 - accuracy: 0.9678\n",
      "\n",
      "Epoch:  331\n",
      "127/127 - 17s - loss: 0.1309 - accuracy: 0.9471 - val_loss: 0.0818 - val_accuracy: 0.9692 - 17s/epoch - 132ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 13ms/step - loss: 0.0737 - accuracy: 0.9736\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.0805 - accuracy: 0.9711\n",
      "\n",
      "Epoch:  332\n",
      "127/127 - 18s - loss: 0.1383 - accuracy: 0.9438 - val_loss: 0.1100 - val_accuracy: 0.9575 - 18s/epoch - 140ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.1022 - accuracy: 0.9598\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.1101 - accuracy: 0.9571\n",
      "\n",
      "Epoch:  333\n",
      "127/127 - 18s - loss: 0.1346 - accuracy: 0.9455 - val_loss: 0.0845 - val_accuracy: 0.9684 - 18s/epoch - 139ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.0759 - accuracy: 0.9727\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.0812 - accuracy: 0.9694\n",
      "\n",
      "Epoch:  334\n",
      "127/127 - 22s - loss: 0.1329 - accuracy: 0.9450 - val_loss: 0.0812 - val_accuracy: 0.9708 - 22s/epoch - 175ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.0734 - accuracy: 0.9750\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.0798 - accuracy: 0.9711\n",
      "\n",
      "Epoch:  335\n",
      "127/127 - 16s - loss: 0.1393 - accuracy: 0.9434 - val_loss: 0.0904 - val_accuracy: 0.9682 - 16s/epoch - 126ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.0834 - accuracy: 0.9710\n",
      "for testing\n",
      "378/378 [==============================] - 4s 12ms/step - loss: 0.0904 - accuracy: 0.9677\n",
      "\n",
      "Epoch:  336\n",
      "127/127 - 15s - loss: 0.1388 - accuracy: 0.9436 - val_loss: 0.1126 - val_accuracy: 0.9550 - 15s/epoch - 122ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.1042 - accuracy: 0.9591\n",
      "for testing\n",
      "378/378 [==============================] - 6s 17ms/step - loss: 0.1159 - accuracy: 0.9535\n",
      "\n",
      "Epoch:  337\n",
      "127/127 - 18s - loss: 0.1381 - accuracy: 0.9439 - val_loss: 0.0946 - val_accuracy: 0.9662 - 18s/epoch - 144ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.0875 - accuracy: 0.9684\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.0944 - accuracy: 0.9640\n",
      "\n",
      "Epoch:  338\n",
      "127/127 - 17s - loss: 0.1386 - accuracy: 0.9441 - val_loss: 0.0933 - val_accuracy: 0.9625 - 17s/epoch - 138ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.0854 - accuracy: 0.9673\n",
      "for testing\n",
      "378/378 [==============================] - 6s 16ms/step - loss: 0.0917 - accuracy: 0.9654\n",
      "\n",
      "Epoch:  339\n",
      "127/127 - 20s - loss: 0.1349 - accuracy: 0.9462 - val_loss: 0.0958 - val_accuracy: 0.9616 - 20s/epoch - 156ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.0872 - accuracy: 0.9668\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.0921 - accuracy: 0.9637\n",
      "\n",
      "Epoch:  340\n",
      "127/127 - 23s - loss: 0.1362 - accuracy: 0.9441 - val_loss: 0.0881 - val_accuracy: 0.9679 - 23s/epoch - 179ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.0815 - accuracy: 0.9697\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.0880 - accuracy: 0.9687\n",
      "\n",
      "Epoch:  341\n",
      "127/127 - 18s - loss: 0.1308 - accuracy: 0.9471 - val_loss: 0.1109 - val_accuracy: 0.9567 - 18s/epoch - 142ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 25s 17ms/step - loss: 0.1003 - accuracy: 0.9607\n",
      "for testing\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.1106 - accuracy: 0.9554\n",
      "\n",
      "Epoch:  342\n",
      "127/127 - 20s - loss: 0.1325 - accuracy: 0.9470 - val_loss: 0.0923 - val_accuracy: 0.9640 - 20s/epoch - 155ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.0839 - accuracy: 0.9674\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.0906 - accuracy: 0.9664\n",
      "\n",
      "Epoch:  343\n",
      "127/127 - 18s - loss: 0.1363 - accuracy: 0.9444 - val_loss: 0.0859 - val_accuracy: 0.9681 - 18s/epoch - 142ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 25s 16ms/step - loss: 0.0780 - accuracy: 0.9716\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 5s 14ms/step - loss: 0.0861 - accuracy: 0.9696\n",
      "\n",
      "Epoch:  344\n",
      "127/127 - 19s - loss: 0.1364 - accuracy: 0.9438 - val_loss: 0.0846 - val_accuracy: 0.9681 - 19s/epoch - 147ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.0770 - accuracy: 0.9721\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.0837 - accuracy: 0.9698\n",
      "\n",
      "Epoch:  345\n",
      "127/127 - 17s - loss: 0.1340 - accuracy: 0.9462 - val_loss: 0.0826 - val_accuracy: 0.9688 - 17s/epoch - 134ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 13ms/step - loss: 0.0747 - accuracy: 0.9732\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.0820 - accuracy: 0.9701\n",
      "\n",
      "Epoch:  346\n",
      "127/127 - 19s - loss: 0.1372 - accuracy: 0.9446 - val_loss: 0.1252 - val_accuracy: 0.9503 - 19s/epoch - 147ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 20s 13ms/step - loss: 0.1160 - accuracy: 0.9547\n",
      "for testing\n",
      "378/378 [==============================] - 5s 14ms/step - loss: 0.1244 - accuracy: 0.9511\n",
      "\n",
      "Epoch:  347\n",
      "127/127 - 19s - loss: 0.1344 - accuracy: 0.9456 - val_loss: 0.0953 - val_accuracy: 0.9630 - 19s/epoch - 151ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 29s 19ms/step - loss: 0.0875 - accuracy: 0.9662\n",
      "for testing\n",
      "378/378 [==============================] - 10s 25ms/step - loss: 0.0957 - accuracy: 0.9625\n",
      "\n",
      "Epoch:  348\n",
      "127/127 - 40s - loss: 0.1354 - accuracy: 0.9439 - val_loss: 0.0917 - val_accuracy: 0.9672 - 40s/epoch - 317ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 34s 23ms/step - loss: 0.0832 - accuracy: 0.9720\n",
      "for testing\n",
      "378/378 [==============================] - 11s 28ms/step - loss: 0.0910 - accuracy: 0.9677\n",
      "\n",
      "Epoch:  349\n",
      "127/127 - 36s - loss: 0.1339 - accuracy: 0.9446 - val_loss: 0.0882 - val_accuracy: 0.9676 - 36s/epoch - 282ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 43s 28ms/step - loss: 0.0788 - accuracy: 0.9718\n",
      "for testing\n",
      "378/378 [==============================] - 9s 22ms/step - loss: 0.0862 - accuracy: 0.9680\n",
      "\n",
      "Epoch:  350\n",
      "127/127 - 27s - loss: 0.1321 - accuracy: 0.9453 - val_loss: 0.0983 - val_accuracy: 0.9622 - 27s/epoch - 215ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 37s 25ms/step - loss: 0.0889 - accuracy: 0.9666\n",
      "for testing\n",
      "378/378 [==============================] - 8s 21ms/step - loss: 0.0983 - accuracy: 0.9634\n",
      "\n",
      "Epoch:  351\n",
      "127/127 - 29s - loss: 0.1342 - accuracy: 0.9449 - val_loss: 0.1478 - val_accuracy: 0.9370 - 29s/epoch - 232ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 33s 22ms/step - loss: 0.1386 - accuracy: 0.9393\n",
      "for testing\n",
      "378/378 [==============================] - 8s 21ms/step - loss: 0.1449 - accuracy: 0.9387\n",
      "\n",
      "Epoch:  352\n",
      "127/127 - 29s - loss: 0.1363 - accuracy: 0.9439 - val_loss: 0.0961 - val_accuracy: 0.9639 - 29s/epoch - 225ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 33s 22ms/step - loss: 0.0883 - accuracy: 0.9667\n",
      "for testing\n",
      "378/378 [==============================] - 10s 26ms/step - loss: 0.0952 - accuracy: 0.9654\n",
      "\n",
      "Epoch:  353\n",
      "127/127 - 32s - loss: 0.1361 - accuracy: 0.9449 - val_loss: 0.1172 - val_accuracy: 0.9547 - 32s/epoch - 255ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 43s 28ms/step - loss: 0.1086 - accuracy: 0.9581\n",
      "for testing\n",
      "378/378 [==============================] - 8s 21ms/step - loss: 0.1180 - accuracy: 0.9526\n",
      "\n",
      "Epoch:  354\n",
      "127/127 - 27s - loss: 0.1321 - accuracy: 0.9461 - val_loss: 0.0826 - val_accuracy: 0.9699 - 27s/epoch - 213ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 35s 23ms/step - loss: 0.0749 - accuracy: 0.9740\n",
      "for testing\n",
      "378/378 [==============================] - 9s 23ms/step - loss: 0.0829 - accuracy: 0.9706\n",
      "\n",
      "Epoch:  355\n",
      "127/127 - 30s - loss: 0.1269 - accuracy: 0.9476 - val_loss: 0.0792 - val_accuracy: 0.9697 - 30s/epoch - 237ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 42s 28ms/step - loss: 0.0697 - accuracy: 0.9750\n",
      "for testing\n",
      "378/378 [==============================] - 10s 26ms/step - loss: 0.0761 - accuracy: 0.9721\n",
      "\n",
      "Epoch:  356\n",
      "127/127 - 31s - loss: 0.1306 - accuracy: 0.9464 - val_loss: 0.0917 - val_accuracy: 0.9633 - 31s/epoch - 246ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 36s 24ms/step - loss: 0.0820 - accuracy: 0.9687\n",
      "for testing\n",
      "378/378 [==============================] - 9s 22ms/step - loss: 0.0915 - accuracy: 0.9657\n",
      "\n",
      "Epoch:  357\n",
      "127/127 - 33s - loss: 0.1335 - accuracy: 0.9451 - val_loss: 0.0845 - val_accuracy: 0.9695 - 33s/epoch - 257ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 38s 25ms/step - loss: 0.0767 - accuracy: 0.9730\n",
      "for testing\n",
      "378/378 [==============================] - 10s 27ms/step - loss: 0.0825 - accuracy: 0.9714\n",
      "\n",
      "Epoch:  358\n",
      "127/127 - 31s - loss: 0.1298 - accuracy: 0.9477 - val_loss: 0.0847 - val_accuracy: 0.9690 - 31s/epoch - 246ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 45s 29ms/step - loss: 0.0766 - accuracy: 0.9736\n",
      "for testing\n",
      "378/378 [==============================] - 12s 30ms/step - loss: 0.0833 - accuracy: 0.9702\n",
      "\n",
      "Epoch:  359\n",
      "127/127 - 29s - loss: 0.1277 - accuracy: 0.9479 - val_loss: 0.0924 - val_accuracy: 0.9664 - 29s/epoch - 224ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 34s 22ms/step - loss: 0.0834 - accuracy: 0.9705\n",
      "for testing\n",
      "378/378 [==============================] - 9s 24ms/step - loss: 0.0905 - accuracy: 0.9664\n",
      "\n",
      "Epoch:  360\n",
      "127/127 - 29s - loss: 0.1315 - accuracy: 0.9448 - val_loss: 0.1102 - val_accuracy: 0.9546 - 29s/epoch - 226ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 44s 29ms/step - loss: 0.1002 - accuracy: 0.9604\n",
      "for testing\n",
      "378/378 [==============================] - 8s 21ms/step - loss: 0.1039 - accuracy: 0.9587\n",
      "\n",
      "Epoch:  361\n",
      "127/127 - 32s - loss: 0.1261 - accuracy: 0.9486 - val_loss: 0.0839 - val_accuracy: 0.9682 - 32s/epoch - 250ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 37s 25ms/step - loss: 0.0751 - accuracy: 0.9723\n",
      "for testing\n",
      "378/378 [==============================] - 10s 25ms/step - loss: 0.0826 - accuracy: 0.9694\n",
      "\n",
      "Epoch:  362\n",
      "127/127 - 34s - loss: 0.1297 - accuracy: 0.9475 - val_loss: 0.0971 - val_accuracy: 0.9617 - 34s/epoch - 266ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 41s 27ms/step - loss: 0.0882 - accuracy: 0.9659\n",
      "for testing\n",
      "378/378 [==============================] - 10s 27ms/step - loss: 0.0987 - accuracy: 0.9623\n",
      "\n",
      "Epoch:  363\n",
      "127/127 - 32s - loss: 0.1344 - accuracy: 0.9460 - val_loss: 0.0916 - val_accuracy: 0.9662 - 32s/epoch - 252ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 38s 25ms/step - loss: 0.0831 - accuracy: 0.9707\n",
      "for testing\n",
      "378/378 [==============================] - 10s 25ms/step - loss: 0.0886 - accuracy: 0.9696\n",
      "\n",
      "Epoch:  364\n",
      "127/127 - 27s - loss: 0.1291 - accuracy: 0.9476 - val_loss: 0.0825 - val_accuracy: 0.9683 - 27s/epoch - 216ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 34s 23ms/step - loss: 0.0749 - accuracy: 0.9728\n",
      "for testing\n",
      "378/378 [==============================] - 9s 24ms/step - loss: 0.0824 - accuracy: 0.9687\n",
      "\n",
      "Epoch:  365\n",
      "127/127 - 28s - loss: 0.1246 - accuracy: 0.9490 - val_loss: 0.0763 - val_accuracy: 0.9717 - 28s/epoch - 224ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 39s 26ms/step - loss: 0.0687 - accuracy: 0.9755\n",
      "for testing\n",
      "378/378 [==============================] - 11s 29ms/step - loss: 0.0762 - accuracy: 0.9728\n",
      "\n",
      "Epoch:  366\n",
      "127/127 - 30s - loss: 0.1319 - accuracy: 0.9457 - val_loss: 0.0874 - val_accuracy: 0.9670 - 30s/epoch - 236ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 44s 29ms/step - loss: 0.0795 - accuracy: 0.9704\n",
      "for testing\n",
      "378/378 [==============================] - 10s 26ms/step - loss: 0.0856 - accuracy: 0.9681\n",
      "\n",
      "Epoch:  367\n",
      "127/127 - 32s - loss: 0.1283 - accuracy: 0.9481 - val_loss: 0.0867 - val_accuracy: 0.9696 - 32s/epoch - 252ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 47s 31ms/step - loss: 0.0780 - accuracy: 0.9736\n",
      "for testing\n",
      "378/378 [==============================] - 9s 24ms/step - loss: 0.0860 - accuracy: 0.9699\n",
      "\n",
      "Epoch:  368\n",
      "127/127 - 32s - loss: 0.1301 - accuracy: 0.9466 - val_loss: 0.0833 - val_accuracy: 0.9693 - 32s/epoch - 249ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 44s 29ms/step - loss: 0.0755 - accuracy: 0.9732\n",
      "for testing\n",
      "378/378 [==============================] - 11s 28ms/step - loss: 0.0871 - accuracy: 0.9674\n",
      "\n",
      "Epoch:  369\n",
      "127/127 - 31s - loss: 0.1221 - accuracy: 0.9496 - val_loss: 0.0876 - val_accuracy: 0.9670 - 31s/epoch - 242ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 43s 28ms/step - loss: 0.0774 - accuracy: 0.9716\n",
      "for testing\n",
      "378/378 [==============================] - 12s 33ms/step - loss: 0.0865 - accuracy: 0.9684\n",
      "\n",
      "Epoch:  370\n",
      "127/127 - 33s - loss: 0.1254 - accuracy: 0.9494 - val_loss: 0.0768 - val_accuracy: 0.9707 - 33s/epoch - 260ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 43s 28ms/step - loss: 0.0677 - accuracy: 0.9759\n",
      "for testing\n",
      "378/378 [==============================] - 11s 28ms/step - loss: 0.0742 - accuracy: 0.9736\n",
      "\n",
      "Epoch:  371\n",
      "127/127 - 35s - loss: 0.1252 - accuracy: 0.9489 - val_loss: 0.1089 - val_accuracy: 0.9552 - 35s/epoch - 274ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 49s 33ms/step - loss: 0.0977 - accuracy: 0.9612\n",
      "for testing\n",
      "378/378 [==============================] - 9s 24ms/step - loss: 0.1100 - accuracy: 0.9559\n",
      "\n",
      "Epoch:  372\n",
      "127/127 - 31s - loss: 0.1306 - accuracy: 0.9458 - val_loss: 0.0947 - val_accuracy: 0.9641 - 31s/epoch - 246ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 43s 28ms/step - loss: 0.0860 - accuracy: 0.9701\n",
      "for testing\n",
      "378/378 [==============================] - 10s 27ms/step - loss: 0.0926 - accuracy: 0.9668\n",
      "\n",
      "Epoch:  373\n",
      "127/127 - 33s - loss: 0.1263 - accuracy: 0.9480 - val_loss: 0.0798 - val_accuracy: 0.9716 - 33s/epoch - 257ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 37s 24ms/step - loss: 0.0724 - accuracy: 0.9744\n",
      "for testing\n",
      "378/378 [==============================] - 9s 23ms/step - loss: 0.0805 - accuracy: 0.9702\n",
      "\n",
      "Epoch:  374\n",
      "127/127 - 30s - loss: 0.1269 - accuracy: 0.9482 - val_loss: 0.0857 - val_accuracy: 0.9685 - 30s/epoch - 239ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 39s 26ms/step - loss: 0.0787 - accuracy: 0.9713\n",
      "for testing\n",
      "378/378 [==============================] - 10s 26ms/step - loss: 0.0896 - accuracy: 0.9661\n",
      "\n",
      "Epoch:  375\n",
      "127/127 - 30s - loss: 0.1239 - accuracy: 0.9488 - val_loss: 0.0982 - val_accuracy: 0.9607 - 30s/epoch - 240ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 39s 25ms/step - loss: 0.0875 - accuracy: 0.9667\n",
      "for testing\n",
      "378/378 [==============================] - 10s 26ms/step - loss: 0.0954 - accuracy: 0.9635\n",
      "\n",
      "Epoch:  376\n",
      "127/127 - 30s - loss: 0.1263 - accuracy: 0.9472 - val_loss: 0.0893 - val_accuracy: 0.9651 - 30s/epoch - 233ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 41s 27ms/step - loss: 0.0804 - accuracy: 0.9706\n",
      "for testing\n",
      "378/378 [==============================] - 10s 26ms/step - loss: 0.0883 - accuracy: 0.9652\n",
      "\n",
      "Epoch:  377\n",
      "127/127 - 33s - loss: 0.1239 - accuracy: 0.9484 - val_loss: 0.0860 - val_accuracy: 0.9681 - 33s/epoch - 260ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 40s 26ms/step - loss: 0.0758 - accuracy: 0.9732\n",
      "for testing\n",
      "378/378 [==============================] - 11s 28ms/step - loss: 0.0847 - accuracy: 0.9687\n",
      "\n",
      "Epoch:  378\n",
      "127/127 - 31s - loss: 0.1268 - accuracy: 0.9485 - val_loss: 0.0784 - val_accuracy: 0.9719 - 31s/epoch - 247ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 42s 27ms/step - loss: 0.0692 - accuracy: 0.9761\n",
      "for testing\n",
      "378/378 [==============================] - 10s 27ms/step - loss: 0.0784 - accuracy: 0.9720\n",
      "\n",
      "Epoch:  379\n",
      "127/127 - 31s - loss: 0.1295 - accuracy: 0.9472 - val_loss: 0.0844 - val_accuracy: 0.9686 - 31s/epoch - 242ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 43s 28ms/step - loss: 0.0747 - accuracy: 0.9745\n",
      "for testing\n",
      "378/378 [==============================] - 10s 25ms/step - loss: 0.0814 - accuracy: 0.9709\n",
      "\n",
      "Epoch:  380\n",
      "127/127 - 28s - loss: 0.1271 - accuracy: 0.9484 - val_loss: 0.0729 - val_accuracy: 0.9738 - 28s/epoch - 220ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 44s 29ms/step - loss: 0.0653 - accuracy: 0.9772\n",
      "for testing\n",
      "378/378 [==============================] - 11s 29ms/step - loss: 0.0738 - accuracy: 0.9734\n",
      "\n",
      "Epoch:  381\n",
      "127/127 - 34s - loss: 0.1273 - accuracy: 0.9473 - val_loss: 0.1128 - val_accuracy: 0.9576 - 34s/epoch - 269ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 41s 27ms/step - loss: 0.1050 - accuracy: 0.9610\n",
      "for testing\n",
      "378/378 [==============================] - 11s 28ms/step - loss: 0.1141 - accuracy: 0.9554\n",
      "\n",
      "Epoch:  382\n",
      "127/127 - 38s - loss: 0.1217 - accuracy: 0.9511 - val_loss: 0.1007 - val_accuracy: 0.9620 - 38s/epoch - 300ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 37s 24ms/step - loss: 0.0902 - accuracy: 0.9666\n",
      "for testing\n",
      "378/378 [==============================] - 11s 28ms/step - loss: 0.1003 - accuracy: 0.9634\n",
      "\n",
      "Epoch:  383\n",
      "127/127 - 31s - loss: 0.1257 - accuracy: 0.9495 - val_loss: 0.1028 - val_accuracy: 0.9600 - 31s/epoch - 245ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 39s 26ms/step - loss: 0.0920 - accuracy: 0.9651\n",
      "for testing\n",
      "378/378 [==============================] - 9s 23ms/step - loss: 0.1021 - accuracy: 0.9617\n",
      "\n",
      "Epoch:  384\n",
      "127/127 - 30s - loss: 0.1278 - accuracy: 0.9474 - val_loss: 0.0886 - val_accuracy: 0.9690 - 30s/epoch - 234ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 39s 26ms/step - loss: 0.0777 - accuracy: 0.9725\n",
      "for testing\n",
      "378/378 [==============================] - 9s 24ms/step - loss: 0.0871 - accuracy: 0.9690\n",
      "\n",
      "Epoch:  385\n",
      "127/127 - 41s - loss: 0.1226 - accuracy: 0.9489 - val_loss: 0.0844 - val_accuracy: 0.9678 - 41s/epoch - 326ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 39s 26ms/step - loss: 0.0741 - accuracy: 0.9717\n",
      "for testing\n",
      "378/378 [==============================] - 9s 24ms/step - loss: 0.0819 - accuracy: 0.9673\n",
      "\n",
      "Epoch:  386\n",
      "127/127 - 30s - loss: 0.1243 - accuracy: 0.9489 - val_loss: 0.0857 - val_accuracy: 0.9675 - 30s/epoch - 235ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 41s 27ms/step - loss: 0.0752 - accuracy: 0.9730\n",
      "for testing\n",
      "378/378 [==============================] - 10s 26ms/step - loss: 0.0829 - accuracy: 0.9692\n",
      "\n",
      "Epoch:  387\n",
      "127/127 - 30s - loss: 0.1244 - accuracy: 0.9501 - val_loss: 0.0840 - val_accuracy: 0.9691 - 30s/epoch - 236ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 35s 23ms/step - loss: 0.0728 - accuracy: 0.9735\n",
      "for testing\n",
      "378/378 [==============================] - 9s 23ms/step - loss: 0.0825 - accuracy: 0.9709\n",
      "\n",
      "Epoch:  388\n",
      "127/127 - 28s - loss: 0.1221 - accuracy: 0.9497 - val_loss: 0.0904 - val_accuracy: 0.9645 - 28s/epoch - 221ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 43s 29ms/step - loss: 0.0792 - accuracy: 0.9692\n",
      "for testing\n",
      "378/378 [==============================] - 11s 28ms/step - loss: 0.0897 - accuracy: 0.9634\n",
      "\n",
      "Epoch:  389\n",
      "127/127 - 34s - loss: 0.1281 - accuracy: 0.9480 - val_loss: 0.0814 - val_accuracy: 0.9708 - 34s/epoch - 264ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 43s 28ms/step - loss: 0.0720 - accuracy: 0.9743\n",
      "for testing\n",
      "378/378 [==============================] - 6s 16ms/step - loss: 0.0813 - accuracy: 0.9699\n",
      "\n",
      "Epoch:  390\n",
      "127/127 - 22s - loss: 0.1228 - accuracy: 0.9499 - val_loss: 0.0828 - val_accuracy: 0.9694 - 22s/epoch - 174ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 15ms/step - loss: 0.0739 - accuracy: 0.9738\n",
      "for testing\n",
      "378/378 [==============================] - 6s 16ms/step - loss: 0.0823 - accuracy: 0.9712\n",
      "\n",
      "Epoch:  391\n",
      "127/127 - 20s - loss: 0.1217 - accuracy: 0.9507 - val_loss: 0.0802 - val_accuracy: 0.9715 - 20s/epoch - 159ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 25s 17ms/step - loss: 0.0703 - accuracy: 0.9760\n",
      "for testing\n",
      "378/378 [==============================] - 6s 17ms/step - loss: 0.0771 - accuracy: 0.9730\n",
      "\n",
      "Epoch:  392\n",
      "127/127 - 20s - loss: 0.1231 - accuracy: 0.9509 - val_loss: 0.0847 - val_accuracy: 0.9672 - 20s/epoch - 158ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.0754 - accuracy: 0.9716\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 6s 15ms/step - loss: 0.0841 - accuracy: 0.9692\n",
      "\n",
      "Epoch:  393\n",
      "127/127 - 22s - loss: 0.1228 - accuracy: 0.9496 - val_loss: 0.0891 - val_accuracy: 0.9644 - 22s/epoch - 175ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 29s 19ms/step - loss: 0.0767 - accuracy: 0.9701\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.0843 - accuracy: 0.9659\n",
      "\n",
      "Epoch:  394\n",
      "127/127 - 26s - loss: 0.1216 - accuracy: 0.9500 - val_loss: 0.0963 - val_accuracy: 0.9641 - 26s/epoch - 205ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 26s 17ms/step - loss: 0.0857 - accuracy: 0.9692\n",
      "for testing\n",
      "378/378 [==============================] - 11s 28ms/step - loss: 0.0969 - accuracy: 0.9651\n",
      "\n",
      "Epoch:  395\n",
      "127/127 - 24s - loss: 0.1306 - accuracy: 0.9466 - val_loss: 0.0842 - val_accuracy: 0.9704 - 24s/epoch - 188ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 21s 14ms/step - loss: 0.0749 - accuracy: 0.9743\n",
      "for testing\n",
      "378/378 [==============================] - 6s 16ms/step - loss: 0.0854 - accuracy: 0.9678\n",
      "\n",
      "Epoch:  396\n",
      "127/127 - 21s - loss: 0.1216 - accuracy: 0.9497 - val_loss: 0.0812 - val_accuracy: 0.9696 - 21s/epoch - 166ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 29s 19ms/step - loss: 0.0710 - accuracy: 0.9736\n",
      "for testing\n",
      "378/378 [==============================] - 7s 19ms/step - loss: 0.0817 - accuracy: 0.9697\n",
      "\n",
      "Epoch:  397\n",
      "127/127 - 21s - loss: 0.1253 - accuracy: 0.9506 - val_loss: 0.0946 - val_accuracy: 0.9650 - 21s/epoch - 165ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 32s 21ms/step - loss: 0.0848 - accuracy: 0.9674\n",
      "for testing\n",
      "378/378 [==============================] - 7s 20ms/step - loss: 0.0958 - accuracy: 0.9639\n",
      "\n",
      "Epoch:  398\n",
      "127/127 - 21s - loss: 0.1243 - accuracy: 0.9495 - val_loss: 0.0870 - val_accuracy: 0.9653 - 21s/epoch - 164ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 22s 15ms/step - loss: 0.0769 - accuracy: 0.9707\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.0888 - accuracy: 0.9640\n",
      "\n",
      "Epoch:  399\n",
      "127/127 - 20s - loss: 0.1159 - accuracy: 0.9529 - val_loss: 0.0858 - val_accuracy: 0.9675 - 20s/epoch - 159ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.0763 - accuracy: 0.9721\n",
      "for testing\n",
      "378/378 [==============================] - 6s 16ms/step - loss: 0.0826 - accuracy: 0.9704\n",
      "\n",
      "Epoch:  400\n",
      "127/127 - 23s - loss: 0.1203 - accuracy: 0.9511 - val_loss: 0.0771 - val_accuracy: 0.9726 - 23s/epoch - 183ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 23s 15ms/step - loss: 0.0667 - accuracy: 0.9775\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.0763 - accuracy: 0.9730\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for x in range(400):\n",
    "    print(\"\\nEpoch: \",x+1)\n",
    "    history = model.fit(X_train ,y_train ,batch_size=BATCH_SIZE ,epochs=1, verbose=2, shuffle=True, validation_split = 0.33)\n",
    "    if history_dataframe.size == 0:\n",
    "        history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    else:\n",
    "        history_dataframe = pd.concat([history_dataframe,pd.DataFrame.from_dict(history.history)],axis=0,ignore_index=True)\n",
    "    \n",
    "    print(\"for training\")\n",
    "    train_eva.append(model.evaluate(X_train,y_train))\n",
    "    print(\"for testing\")\n",
    "    test_eva.append(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ec37c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.637602</td>\n",
       "      <td>0.623593</td>\n",
       "      <td>0.637929</td>\n",
       "      <td>0.642701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.565123</td>\n",
       "      <td>0.713607</td>\n",
       "      <td>0.508909</td>\n",
       "      <td>0.757312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.465765</td>\n",
       "      <td>0.778789</td>\n",
       "      <td>0.379702</td>\n",
       "      <td>0.825327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.356911</td>\n",
       "      <td>0.843138</td>\n",
       "      <td>0.436299</td>\n",
       "      <td>0.783992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.305732</td>\n",
       "      <td>0.865503</td>\n",
       "      <td>0.398115</td>\n",
       "      <td>0.814806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.011241</td>\n",
       "      <td>0.995990</td>\n",
       "      <td>0.025941</td>\n",
       "      <td>0.991044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.007844</td>\n",
       "      <td>0.997131</td>\n",
       "      <td>0.032335</td>\n",
       "      <td>0.989729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.007574</td>\n",
       "      <td>0.997563</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>0.992672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.008305</td>\n",
       "      <td>0.996792</td>\n",
       "      <td>0.029363</td>\n",
       "      <td>0.990230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.008663</td>\n",
       "      <td>0.996514</td>\n",
       "      <td>0.038926</td>\n",
       "      <td>0.989353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    0.637602  0.623593  0.637929      0.642701\n",
       "1    0.565123  0.713607  0.508909      0.757312\n",
       "2    0.465765  0.778789  0.379702      0.825327\n",
       "3    0.356911  0.843138  0.436299      0.783992\n",
       "4    0.305732  0.865503  0.398115      0.814806\n",
       "..        ...       ...       ...           ...\n",
       "395  0.011241  0.995990  0.025941      0.991044\n",
       "396  0.007844  0.997131  0.032335      0.989729\n",
       "397  0.007574  0.997563  0.024096      0.992672\n",
       "398  0.008305  0.996792  0.029363      0.990230\n",
       "399  0.008663  0.996514  0.038926      0.989353\n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c8463e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva_df = pd.DataFrame(train_eva,columns=['loss','accuracy'])\n",
    "test_eva_df = pd.DataFrame(test_eva,columns=['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cc95506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(df,title,xlabel,ylabel,values=['loss'],legends=[]):\n",
    "    \n",
    "    for value in values:\n",
    "        epoch_count = range(1, len(df.index) + 1)\n",
    "        plt.plot(epoch_count, df[value].tolist())\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    if legends==[]:\n",
    "        legends = values\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35c781fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB9TUlEQVR4nO3dd3hT1RsH8G/atOnedJdS9l5l7yUCDhQUFBVQUFFAECcuFAcucCGIIuJAQBT8oSBS9pJVyi5QoNCWLrp30ib398dpVpOWUpKmLd/P8/Qhvbm5OTcpuW/e855zZJIkSSAiIiJqIOxs3QAiIiIiS2JwQ0RERA0KgxsiIiJqUBjcEBERUYPC4IaIiIgaFAY3RERE1KAwuCEiIqIGhcENERERNSgMboiIiKhBYXBDRDYlk8mq9bNr165bep63334bMpnMMo0mojpNxuUXiMiWDh48aPT7u+++i507d2LHjh1G29u2bQsPD48aP09SUhKSkpLQq1evGh+DiOoHua0bQES3t4rBRqNGjWBnZ3fDIKSoqAguLi7Vfp7Q0FCEhobWqI1EVL+wW4qI6rxBgwahffv22LNnD/r06QMXFxc88cQTAIC1a9di+PDhCAoKgrOzM9q0aYNXX30VhYWFRscw1y3VpEkT3H333diyZQu6du0KZ2dntG7dGitWrKi1cyMiy2PmhojqhZSUFDz66KN4+eWX8cEHH8DOTnw3i4uLw6hRozB79my4urri3Llz+Oijj3D48GGTri1zTpw4gRdeeAGvvvoqAgICsHz5ckyZMgXNmzfHgAEDrH1aRGQFDG6IqF7IysrCunXrMGTIEKPtb7zxhu62JEno27cv2rRpg4EDB+LkyZPo2LFjlcfNyMjA/v370bhxYwDAgAEDsH37dvz6668MbojqKXZLEVG94O3tbRLYAMDly5cxYcIEBAYGwt7eHg4ODhg4cCAAIDY29obH7dy5sy6wAQAnJye0bNkSV69etVzjiahWMXNDRPVCUFCQybaCggL0798fTk5OeO+999CyZUu4uLggMTERY8aMQXFx8Q2P6+vra7JNoVBU67FEVDcxuCGiesHcHDU7duxAcnIydu3apcvWAEBOTk4ttoyI6hp2SxFRvaUNeBQKhdH2ZcuW2aI5RFRHMHNDRPVWnz594O3tjWnTpmHevHlwcHDAqlWrcOLECVs3jYhsiJkbIqq3fH19sWnTJri4uODRRx/FE088ATc3N6xdu9bWTSMiG+LyC0RERNSgMHNDREREDQqDGyIiImpQGNwQERFRg8LghoiIiBoUBjdERETUoDC4ISIiogbltpvET6PRIDk5Ge7u7mancyciIqK6R5Ik5OfnIzg4GHZ2VedmbrvgJjk5GWFhYbZuBhEREdVAYmIiQkNDq9zntgtu3N3dAYgXx8PDw8atISIiourIy8tDWFiY7jpeldsuuNF2RXl4eDC4ISIiqmeqU1LCgmIiIiJqUBjcEBERUYPC4IaIiIgalNuu5qa61Go1SktLbd0MugkODg6wt7e3dTOIiMjGGNxUIEkSUlNTkZOTY+umUA14eXkhMDCQcxgREd3GGNxUoA1s/P394eLiwotkPSFJEoqKipCeng4ACAoKsnGLiIjIVhjcGFCr1brAxtfX19bNoZvk7OwMAEhPT4e/vz+7qIiIblMsKDagrbFxcXGxcUuoprTvHeuliIhuXwxuzGBXVP3F946IiGwa3OzZswf33HMPgoODIZPJ8Oeff97wMbt370ZkZCScnJzQtGlTfPPNN9ZvKBEREdUbNg1uCgsL0alTJyxevLha+8fHx2PUqFHo378/YmJi8Nprr+G5557DH3/8YeWW1n2DBg3C7Nmzbd0MIiIim7NpQfHIkSMxcuTIau//zTffoHHjxvj8888BAG3atMHRo0fx6aefYuzYsVZqJREREdUn9arm5r///sPw4cONtt155504evRopQWkSqUSeXl5Rj9EREQ2pywAJMk6x5YkQKOp2WM1aqBMVflxrdVmC6pXQ8FTU1MREBBgtC0gIABlZWXIyMgwO7fJggUL8M4779RWE+uE7OxszJo1C3/99ReUSiUGDhyIL7/8Ei1atAAAXL16FTNmzMC+ffugUqnQpEkTfPLJJxg1ahSys7MxY8YMbN26FQUFBQgNDcVrr72Gxx9/3MZnRXSb06gBdSng4GSd4ysLALkCsHe4ucflpQDKPECtAnxbmG+f9tjF2UBuEuAZCrj56+/PSQTi9wCtRgIuPmJb9lXgwhagTAl0ehhwayQuqrF/AWfWA0GdgH7PGz9PaQlwaTvgFgD4twUcnMXvcduA0G5A86FAXBTg4gtEDNCfq0YDnP4duHYMGPAicGYDkB4L5CQA3uFAz2eA7Ctie3hvILQH4NcC0A5gKM4BTq0DSouBpgOB/74GfJsD3aaI1+bMeiDpKODqB9y1SJzTpe3AusmAdxPAOwJoOQLo+ZQ4XlEWcPZ/Yj97B6D13eKxO94DNGVASFdg5wJA0gBDXgdajgSSYwDfZkDqKWDvIuBatHjN+8wQr2W3JwCfpsA/LwNpZ4CgzsCID8RrplYCnmHA5Z2Agwuw8Tkg6xLg1Vi8p72nAydWAx4hwLGfgLAewIMrRdsubBX3OXsBp/8Amg0BBr8B+DW/ub8jC6tXwQ1gOhpGKo8gKxslM3fuXMyZM0f3e15eHsLCwqr9fJIkobhUXYOW3jpnB/sajf6ZPHky4uLisHHjRnh4eOCVV17BqFGjcPbsWTg4OGD69OlQqVTYs2cPXF1dcfbsWbi5uQEA3nzzTZw9exb//PMP/Pz8cPHiRRQXF1v61IhuXpkSkNkD9nKgMENcJIM7V++xkiQuBGc2iAtAcBexPTdJXMSaDhIf1MXZwNmNQGh3IKBt1ccDRMCx+0NxjNGLAWdvID8VWDMBkDuJ/Zw8ge5TgRbDjI+hLgVOrxcXz8a9gHObgOiVQHgfwD0YaHmnuGBon2/NI8ClHeJiZa8QF7nWdxm/BifXAbH/A3pNFxdhQ5d2iotvSS4QuxHoNweI2wq0uRtw8gKWDxPBwJStgHsgcP28uFA2Hwbs/hhoNUIEBJIEHPsRuPAvUJQJJB7SP0ezIcC9iwFNqbhoAyIYWfsYAINv+/aOQORkoN0YIOZn4Pgqsb3DOCCiv7gwn/wNKC0S23d/BDy5Azj+K7D/c7HtzAbRhib9gAEvi3b8NUtclLXC+wJpp8U5H4J43dRKcV+nh4GyEvF+lRYBKSf07c1LMn7tTqwVf3fF2cDxX8S2Jv3Fe+7oBnw7CMhNFNsdXIHSQnH7+K/ib0xj0LNw7CfjY2ddFj+Xdoj3zCMEWHEnkHFBv8/2+UBQRxEAAmKfvGvi9rrJ4v+FpBbBS+41/TmWFYuACBDHd3QDMs6L39NO688FAML7AVf3mW9b3L/G28/9DbzrJ95HdYUMz5kN4v9Ql0eAO97V/w3XMpkk1Y38kkwmw4YNG3DfffdVus+AAQPQpUsXfPHFF7ptGzZswLhx41BUVAQHhxt/48jLy4Onpydyc3Ph4eFhdF9JSQni4+MREREBJyfx7aNIVYa2b/1r7lBWd3b+nXBxrF78OWjQIHTu3BnTp09Hy5YtsX//fvTp0wcAkJmZibCwMPz444948MEH0bFjR4wdOxbz5s0zOc69994LPz8/rFixwqLnUlvMvYdkQQmHgItRQJ/nAKfy/z+XdohvnmqV+AbbuKd+/4Lr4tuvfxvA0UUEA5IkLhRaaWfEt15XfxF4ZF8VH8oyO/EBP+g14OQaYOcHQIvhwH1LgCV9xIf7hN/EN9aujwEewYCqCIAEbH5JXMx9mwEhkcDhb8U3U+0Hu1dj8Xxpp8UFzruJCAi2vS0uTJ6NgVnHATszE0HmJgHfDRHn6+Civ8iE9hDbHN1MLxIA8NCv4tv/3kWijZIEFGeJY7xwDlgxEkg/o9/fIwQY/4v4lh77F7D2UfPvyZ0fiG/WBenAF530AcHkzUCTvuL2uU0i4DJHe2HUatRaBGkJ/4nfDS9gL14Ets3TByOAeJ+cPEUAIWn02zo9LN73+L0GF0eZyJoUZZhvS0VBnQFVIZAZBwR0ANJOmd8voL14LwHAxU8Ewqp8430c3Y23GQY62jZr2w+IwCuiP3BkhfHzhnYXgZBaJYInBxfxf6Iiw+M17m0cQGl5hALD3ga2v6MPjpx9xN+FW6B4/64dA7LjzZ+3Xyv937Qh/3bAAyuA6B+AQxVGFLsHi2xP1FsiODVH4QE8+IP4/7zxOX2w5tNU/H2nnjTe38FVBMkRA8Tf6oUt4v/QzKMie2QhVV2/K6pXmZvevXvjr7/+Mtq2detWdOvWrVqBze0gNjYWcrkcPXvqLzC+vr5o1aoVYmNjAQDPPfccnnnmGWzduhXDhg3D2LFj0bFjRwDAM888g7Fjx+LYsWMYPnw47rvvPl2QRDYgSUD6WfEhFN7X9GJ7ZoPIAHQcBxxfDez6AGg6WHxgHl0hLlQ+TcXFTVMqUtPugeKx8XvFbb8Wxse8Fg1smSuOcWmn+GbcdKC4YKybDOQnA3s+AZoNFfdtf0c8R3G2+Gk3BrhrIXBxG/Dns+J5Q3sA434Efh0HZF4Guj8BdHwI2PC0/qJUmQtbgYJUcfvc38DyOP0367WPigvU3k8Bv5YiUDLMEOQnA1f2itsZ58WFWqMWAVdOgtgudxZBxz8v6R+XmwD8MUVcAP3biOAhI05c1C/vAgrSxH7F2frHJB02bnezoeJ9ubhNBG+VBRelRcCxn4Hr4v8nQruLQCXnKvC/6cDU7cDWN8R97kFAYEfAPUBkr85vBvZ8CiQcFNkYQwe+EkFet8eBbVV0zWsDGwcX8fpcP2d8v+E388/alv8uE+cW2BFodz/gGSLaGlOeCZA0xgEQADz6BxAxUGTILu8Gdi0Q2aHwPkDf2eK91L7PANDjaWD4uyLTsflFfYAR+Tgw8iPxel7cJrZp/4YiHwfueEdcnP9+XlzcAaDPTKDXs2L/xr2Bxd2MA5vBr4u/2yW9xN+rnRwY9Sng6ivej2UDxDmN/hro8ihw/QKwpCdwdb94vNwJePwfYN0k8Xc14GWRDfz9cZGBu+sz0YX1/XDx/6vtveL/7aC5IiMT1gP4uocItIuzRPA94Tfxt1dwHdjyighCT/1m/JpOKn/PNWrg0FLxngNAjycB/9bidRr+HnBlH/DreKBRS3Fcj2DxXiQfE58Xf80SXWfeEcCYb0W3nne4OJZrI/HlYNCrQGAHse3qARHM5qeK/wt9Z+u7I7s8Kv4eVQUWDWxulk0zNwUFBbh48SIAoEuXLli0aBEGDx4MHx8fNG7cGHPnzsW1a9fw008ijRcfH4/27dvj6aefxpNPPon//vsP06ZNw+rVq6s9WupmMzf1pVtKm7kZPHgwHnjgAZSUlBgtP9C5c2eMHTsWb775JgAgMTERmzZtwtatW/H3339j4cKFmDlzJgDg+vXr2LRpE7Zt24Y//vgD06dPx6effmr5E7QCi2ZutP81qts1mHkJ+PMZoNUo0Q2hKTPuVihIF/UEmjLgn1fEt+Nhb4v7T/8hApWhbwGNWoljFWeLwEGbim7UGnhsg/iw0aa2N5V3uT68Blj3uMh4AOJbU26CaRsdXIGHy1Pl/5sutkVOFhf4xEPiQzd+r6gHkDuL47n4As8cAHa8q794WYKjm/gAtJOLeoOSXECZLwIuB2fxAaoNIm6W3Am4Y76oBUiOAVrcKYK4dmPEhSPrMlCYLrpjgjoBP90r9gvqDAS2Nz3P4K7iW7dhhmPER+LC5NvC4KJv4PU08YFfpgJWDBfHt1eI97zpIJGRuLRdXOS13INEFqcoC1jUVrz+Id2Aa0fFN+4ZhwGFu9hXXQp8FGGaoWg3RlyoKvIMA/q/IIK0poNE19LAV0RXVfxucdH3aVpe61EigpcVI/QZBS23QJEV0GaFtDLigKV9RGBxxzsiQ6XtInL2Bl66DNhVMYZl3eP6dj93HPCJELcTDonXT2vcT0Db0frfj/4g2jzgRRFsa2VfBb4QX9owbZ/+wixJwMcR+sC008PA/eXZjV/GigCoxXDgkXX6Y8X8IgKxoW/p63R+Gi0CXUC8rkPfEt14F/4Fes8Q770kGX9+KAvEFxVt4GAo9bQI0twCRAbEXNbwj6kiUAbE/5s30vX75SQAi7uLv/3nT+v/TrSKssTfu7n3oCRX1Am1va/q7lgbu5nMjU2Dm127dmHw4MEm2ydNmoSVK1di8uTJuHLlCnbt2qW7b/fu3Xj++edx5swZBAcH45VXXsG0adOq/Zw3G9zUF9Xplvrpp5/wwAMPmDx27ty52LRpE06ePGly37Jly/DSSy/Vm1FmN/UeFqSLD4qukwCFm377pR3iW3FOgujrn7pNXAAN5SaJfdyDxIdhs8HAV9306VuvcPHhOeE3cTH98xlxAVF4iA+vzDix34gPxUXzxGrxe/ep4lvQV5H6b5b2jiLQUOaKb6D2jsDehTf3wrQcKS7m16Jv7nHmtB0tPqQvbTe9r9Vd4ty09QKNe4s2r3kEgCRer4iBopsJEKn7GUdF95E5ax8TGYmQSGDUJ6I7CAA6P2KcGRj6lijgDO0h3jcXHxHMqMtEBqSy42uV5AKxf4uC1pwE4NuBYntYLyDxoH4//7Yik9b6buAhg+c/t7m8Xqa3qI/o/6JI/WspC8Rr4tfS+G+t4DqwqI2+JqPVXSL4BIANzwAnftXv+8jvQIs7jNu95hGRzQJEsHjvV+J1WNbf9Bwrtrk69n0uuqEMDXlTBBLmZFwU5+ceKM55QYjYHtgRmLa36udKihZBTLsxwNjv9NtVhcAHIdBl5ObEisxDdZzbJALmTg8Zb/9+uL5WaNjb+sLkxCPAv68BIz8Uf3NVOfkbsP5JcfuVKyKAs7aot4D95WUZno2B5yt006XHis+HG/2911P1pltq0KBBqCq2Wrlypcm2gQMH4tixY1ZsVf3WokULjB49Gk8++SSWLVsGd3d3vPrqqwgJCcHo0eLbzuzZszFy5Ei0bNkS2dnZ2LFjB9q0aQMAeOuttxAZGYl27dpBqVTi77//1t1Xp0ga8eGpcBMXyIqyE4Bzf4hvYKGVfEhteFoEMrlJwIjyb8+lxeKCoa1bAMSohAlr9L9f3Ab8NknsG9xFfKu2czAuGsy5Kv79ZYzIxCTHiN+VeeJHa8urxm26Fi0+dLWBjXuQuKhlxokuoQNfAagkkyR3BqYfFN+281PEtuHvibRzYHvRrfTLWH03jV8r8W329O/mj1eRe5AIVu5bIjIr/7wqUuGG+s8R9Q/n/gZSjos6Fo8gcWFTFYqLnKQBLvwjAopWo6r+IL5rocgmdHtCfNsd97N4z8P7Aqd+F69T67vFN2ctD4NRk/by6n3QO3mKAkhABEZjvxfbWtwhuoxO/SbqjFrcIbqw3CtcXFuPEj+A6BpRVPjgVbiJ2pmK3BqJ541eKX4P6aK/r/tUEQTK7EWgVDGwAUQGRhvcTPpLPEdlQ3gD2lXxAlSiz0wRJCoLgA3lI3m6VFL7AxiPkFG4ib+/rW/oM5RVCY0EXjgvXndDjq6iDRkXRI1KdQMbQBRcm21nS31w08jg8y2sOzDVTP2MOe0fEN0yIV1rJ7ABxPlreYaY3u9fBz+rbaRe1dxQ9fzwww+YNWsW7r77bqhUKgwYMACbN2/W1SWp1WpMnz4dSUlJ8PDwwIgRI/DZZ58BABwdHTF37lxcuXIFzs7O6N+/P9asWVPV01mOdkSLYTpW0ogMi1olPvS0H3zZCUBJtsiCKAtE9492aKkkAZteAJL2iJEsw98XhYEnfxOp3BbDRSByaYfYP2YVMOQN8SGacNA4sAFEWllVKIpV7R2AtRP1GZprR8W/2sDGcKQEII6VHANAJi7wahVwZb8Ylnp8FXCi/OI1bJ74xph6Gkg6Ih7b+RExbNTBSWR/dAWKEtBxvLjAO3mIoAcQ/ezeTYA29wKHl4nCyl7P6l9PuUKk2k/+JmpTuj0ujnn6D/Hv9MPAz/eL7qwm/UUQ1PEhkalwL++KMEx1D5snahIiBolvsG7+4tuuTAZ0eED8aGm7BLSGzhOjXga+UvXfhJu/6OLQanuv/nZod1G423yY6eNulWHbuz4mfrS0o4Aqc7OjQ/q/qA9uggyCm9BI4Knd4sLpVckIz7ajRbdWQDv9CDC5o/l9/WvQ3WBnLwIEdanIPAa009dsVUefmaJ2prI2VeTqZ357YEcR3IR1r/5zV6VRK/O3b4adHdD3Ocu0p7oMA5qbCfJuQ3VmtFRtaajdUvWORiO6SRxd9RfMzMuifsC/rSiQy7smUsqGBaLeTUSfcsWiRwBwC0CJshTxSSmI2D4VTgWJpvtU5t6vRHfJgS+BI8tN79dmZuzkombGnPB+ongwStQ1of+L5d1HEtDmHjHypaLSYpFRcfIEPmkuRpEoPER2554vRD2M1lfd9N1ZL10WgQUAHFomRlTcvUi8ntcvAKvGAj2eEheXG7m0QwRYTQeKLNa5TSL7kJ8sRuxUZ96Tm61PsoTrF8RQ5p7TjEdf1Ucn1wGpJ4Bh75ivtahKaYl4jOH7tKitfhSX1oyjpsXj9UX8XmDjDDHMPMJMl9vNurAV+PVBke187drNv+a2khwjhp0DIpM4/F2bNqe21ZtuKbqNSJJI4aoKRIBSlKnvOnH2Fml+Za74vSRXFL8ZZkAcXEQWJDtBDCk2pyANKJOAkvJunzHLRdGkthumzT3iOHFbxXOE9xXf2o4sB6J/FKMrKgtctJkZ7f0tR4jhjoCoxwmJFEWEyvLiTjsHoO+s8pEwPwEDXjI9JiC6dxycxe2QSDFkVtttVTHbcecHwJ/TgJEf6wMbAOj5tPF+jVoCsysZMmtOsyH6256h+uPdKENhyBarsTdqKX4ago4Pip+aMDdp3vhfRLG5dxNRqC53Et179VVEf2DWiRvvV12Ne4lC8Ij+9SewAYy7pTzMdEuRDoMbsgxVoRhh4egqsi52DqIw09lTjLbJitdftAuvi+BFSzuEWKskVx/YKDzE6CCFuxitUFYsAqQqSSJYaj9GdP/887LIqHSfKu42nOn1/BYR3Gi7l7QatTbNDsmdxDkCYqhn8nExdLXrRP2xJQm4c4FI3Tt5iIDkzg+qd/EP7WY8WVbFboSWw4GXL9/4OEQhXYGndoli9TN/iot5fbqIW5uTh5iDpb5xNZg4z1zNDekwuKHqKS0WNScuPsYX6jIlkJcMlOSYf5wqXzzWsIhWO7zXTi7mVci6ZDx5lnZftwDjfmVnLyC/WP9YSTIemmuo3f3iw9wnwnhIJyC2az/ozaXpB70GdJ8i0vrLBui3T/ob+GGEGAkV3AW4831RzNlhnH4fmQzo/azx79XVdaIYnaUpK5/G3rn6jyUyJ6iTCHI8Q2+4K9UDMpn44pV6UvxLlWJwQ6Y0ahE0SBD9+EWZ+rku1Cp9QWFJrhgVpA1M5AoR7FSknQXTu4mYe0JbQ+PiJ0ZUOLoZBz9a8grpdicPfVeWwkOMlFEVVniMswh8Wt1XvXP1amxcR3PnAn1wUrG4May7mC9DO1dExaLZW+UeCMw6KYYSG87jQXQrqrtEBdUPD60SWfH6Wj9VSxjckKBWiXoRtQrIT4MuAJE7GU9OVpAqfgynZHdwBbxCRT2LJInj5CXrJ5QDxH3O3iKLU5AmAhttkKRwNx/cVCxklTvrn9fJUzxGVVg+D4xC3K/wBXIBuFRzaKa9g8geaQt1K46cuP9bMQR2XPmkedYeaukZAoxZZt3nIKL6y6ux+KEqMbi5HUgakVGprJujJE/M3WGui0dbY2InF7OramthtIGNayPRdaSda0YmExkWJw/x7UKbtdGuQ+QepO831lJ4AKgwsgMQdTuGZDKR/VEVieBGUovjK9z1/9lLSqp4ISrh18IguKmQ6u00XtTu3OxKyUREZDMMbhqyMlV5AJAhZtP1biKyJ+oyUXMik5Wvs3NV7GevEN0tLr4is5KbaBCceIpMS1GW6EYqKxGjlhwqGbkElN9X/njtpGYymXFgA4isi3bhPUPmAgpHV/EDiAXmZHJA4Xqzr4wx3/KJxxzdzc8dwcCGiKheYXDTUEiSGEXk6KrPomReNF4cLvuq6Lq5fk7Ujfg0EcGLpkwEHP6tjWf7dfYxDm7sHQ26kgymkK+M4T5VBUEymRimqirUT9svs7/x6A6ZTIzGulV+5cOJG7WyzZBmIiKyKAY3DUVRhpiAzdFNjGiydzQObAAAUvmQa0mMYtIu5giIkUkVlzFwdBUZF02ZyGrcLLmTCBxk9tULGuzk5m9bW9t7xeq+HWo4zwgREdUpDG7qA0kSWQ0HF/MruhoGKaqCqueBKUgV/2rKROGvplQENS4+pvvKZLe+AJvjTXQZGQU3tTgnh5OnflVgIiKq96pYf55sRqMRtTBauUmi4FU7P4whSRK1KoYjmsyRmQkWtMdTeJhffLK2GQU07B4iIqKaqQNXNDIiSaImJv2sKNpVFYouJ0Bf/2IoPwXIjhe3nX3KhypX7F5yEysqV6TN8FRchddCSktLb7xTZVj7QkRENcTgpi6QJLGytUYtghm1UnQbpccCGXH6/cxd8LUjjOwV2HLgFPoNGgavNv3h224w7p74HC6lFYihzgp3JCWn4aFnXoVPu0Fwbd4H3UY+gkPHTulGMm3cuBHdunWDk5MT/Pz8MGbMGIOnluHPP/80emovLy+sXLkSAHDlyhXIZDL89ttvGDRoEJycnPDLL78gMzMTDz/8MEJDQ+Hi4oIOHTpg9erVRsfRaDT46KOP0Lx5cygieqJx91F4f9FSAMCQIUMwY8YMo/0zMzOhUCiwY8eOGrzYRETU0LHm5kYkSSx+aLXja4CcRLF8gYu3qDspLZ/8Tu4kemfkzmJCPLVKBEDZV0TBsGeofkZg32YoLInFnDlz0KGxDwqzUvHWp0tx/2NP4/jJ0ygqKsLAB55ESGAjbPzhMwQ28sWxU+egcXAB7OXYtGkTxowZg9dffx0///wzVCoVNm3adNOn88orr2DhwoX44YcfoFAoUFJSgsjISLzyyivw8PDApk2b8Nhjj6Fp06bo2bMnAGDu3Ln47rvv8Nlnn6Ffx6ZIuRqHcyniNZ86dSpmzJiBhQsXQqFQAABWrVqF4OBgDB48+BZffCIiaogY3NxIaRHwgZm5T2rDCxdEl5FcIdYSkTSicFg7m6+rL8RMwmLumLFjx4rt+alAvie+XzgP/h2H4uzZszhw4ACuZ2bjyKaf4eMtuqGaRzQGfETB8Pvvv4+HHnoI77zzju7pO3XqdNNNnj17tlHGBwBefPFF3e2ZM2diy5YtWLduHXr27In8/Hx88cUXWLx4MSZNmgRIEpp17I1+9uJPc+zYsZg5cyb+97//Ydw4sYbTDz/8gMmTJ0PGrisiIjKD3VJ1mcJNrFwtk4kJ9gD9aCdAzCwMlGd4ZLh06RImTJiAph17waNVf0T0uhsAkJCQgOPHj6NLl87w8fEWswTbycWyCQoxxPv48eMYOnToLTe5W7duRr+r1Wq8//776NixI3x9feHm5oatW7ciISEBABAbGwulUql/bpkMsNfH3AqFAo8++ihWrFiha+eJEycwefLkW24rERE1TMzc3IiDC/BasnWOXZInioFl9iLY0M5L4+gmhmAbTnwndzReqwnQZ3DKF5i85557EBYWhu+Wfo1g5xJoNBLaD3kQKpUKzs7O4nmCyrMxbv7i3/Lsh7Nz1StQy2QySJJktM1cwbCrq/HQ74ULF+Kzzz7D559/jg4dOsDV1RWzZ8+GSqWq1vMComuqc+fOSEpKwooVKzB06FCEh5spkCYiIgIzNzcmk+mn/Lfkj6pAZGEcnMViiW6NxG3t746uxgXE2syNIe2K2A4KZGZmIjY2Fm+88QaGDh+JNi2bIztPv2J2x44dcfz4cWRlZZWfl53R8O+OHTti+/btlb4MjRo1QkpKiu73uLg4FBXduBZp7969GD16NB599FF06tQJTZs2RVycvki6RYsWcHZ2rvK5O3TogG7duuG7777Dr7/+iieeeOKGz0tERLcvBje2oC4F8soDBUc3MTuw3CB4cfIyfYzhopcV75c7wdvbG76+vvj2229x8fJl7DidjjnvL9bt8vDDDyMwMBD33Xcf9u/fj8uXL+OPP/7Af//9BwCYN28eVq9ejXnz5iE2NhanTp3Cxx9/rHv8kCFDsHjxYhw7dgxHjx7FtGnT4OBw4zWXmjdvjqioKBw4cACxsbF4+umnkZqq71pzcnLCK6+8gpdffhk//fQTLl26hIMHD+L77783Os7UqVPx4YcfQq1W4/7777/h8xIR0e2LwY0tFF4HIImaF78WYmFGZ1/RDeUeZH52XmcvcZ9fK9N1nRxcYGdnhzVr1iA6Ohrt27fH8y++iE8++VS3i6OjI7Zu3Qp/f3+MGjUKHTp0wIcffgh7e/FcgwYNwrp167Bx40Z07twZQ4YMwaFDh3SPX7hwIcLCwjBgwABMmDABL774Ilxcqlgvqtybb76Jrl274s4778SgQYN0AVbFfV544QW89dZbaNOmDcaPH4/09HSjfR5++GHI5XJMmDABTk5ON3xeIiK6fcmkioUUDVxeXh48PT2Rm5sLDw8Po/tKSkoQHx+PiIgI611AJQlIOy3msfGOEEHLzSrJA7Iuidtyp/KJ+xq2xMRENGnSBEeOHEHXrl0r3a9W3kMiIqp1VV2/K2JBcW0rK5+gDzLAqeo3p1L2jvrbihoeo54oLS1FSkoKXn31VfTq1avKwIaIiAhgt5T1Gc4+DACl2iJgl5qv52QU3NRgte56ZP/+/QgPD0d0dDS++YaLWxIR0Y0xc2NthRlAXpLIsPg2049wupnVsiuyswPcA0VhcgMPbgYNGmQyBJ2IiKgqDG6srei6+Fc7J40lghtAFBcTERGRCXZLmWHRTIGdQfyo0YiVvoFbD27ILGZ5iIiIwY0B7bwt1ZmcrtoMgxuprPyGzHg7WYz2vavOHDxERNQw8QprwN7eHl5eXro5VlxcXG59ccYySfwAQGF++W07QKm8teOSEUmSUFRUhPT0dHh5eenm7yEiotsPg5sKAgMDAcBkErkaK8rU19lkqYHiLJG1KXSs+nFUI15eXrr3kIiIbk8MbiqQyWQICgqCv7+/2YUhb9qWb4GLUeJ2h3HAqd8A35bAw7/e+rHJiIODAzM2RETE4KYy9vb2lrlQFiUDBYnidsphcdsnDODsuURERFbBgmJrKy3W306PFf828LlpiIiIbInBjbUZBjdFGeLfmi67QERERDfE4MbayopNtzFzQ0REZDUMbqytlMENERFRbWJwY22lJabbGvhK3kRERLbE4MbaSs3MdszghoiIyGoY3FhbmbnMDbuliIiIrIXBjTVJkj5zI3fWb+doKSIiIqthcGNNZQbrR3mH628zc0NERGQ1DG6sybDexovBDRERUW1gcGNN2nobOzngGaLfzoJiIiIiq2FwY03aOW4cXAAXP/12BjdERERWw+DGmrTdUg7OgKOrfju7pYiIiKyGwY01aSfwkzuJAEfLgSuCExERWQuDG2vSZW5cANdGtm0LERHRbUJu6wY0aNqCYgcnoM09QOu7gdButm0TERFRA8fgxpoMMzf2DsBDq2zbHiIiotsAu6WsybDmhoiIiGoFgxtrMhwtRURERLWC3VLWoCoCCtMNam4Y3BAREdUWBjfWsHwYkH4GaDdG/M7ghoiIqNawW8oa0s+If8+sF//KGdwQERHVFgY3tYGZGyIiolrD4KY2OHEtKSIiotpi8+BmyZIliIiIgJOTEyIjI7F3794q91+1ahU6deoEFxcXBAUF4fHHH0dmZmYttbYaylSm29yDa78dREREtymbBjdr167F7Nmz8frrryMmJgb9+/fHyJEjkZCQYHb/ffv2YeLEiZgyZQrOnDmDdevW4ciRI5g6dWott7wKqgLTbe6Btd8OIiKi25RNg5tFixZhypQpmDp1Ktq0aYPPP/8cYWFhWLp0qdn9Dx48iCZNmuC5555DREQE+vXrh6effhpHjx6t5ZZXwVxw48HMDRERUW2xWXCjUqkQHR2N4cOHG20fPnw4Dhw4YPYxffr0QVJSEjZv3gxJkpCWlobff/8dd911V6XPo1QqkZeXZ/RjVUpzmZsg6z4nERER6dgsuMnIyIBarUZAQIDR9oCAAKSmppp9TJ8+fbBq1SqMHz8ejo6OCAwMhJeXF7766qtKn2fBggXw9PTU/YSFhVn0PExUzNw4uAIKd+s+JxEREenYvKBYJpMZ/S5Jksk2rbNnz+K5557DW2+9hejoaGzZsgXx8fGYNm1apcefO3cucnNzdT+JiYkWbb8JZb7x727+QCXnQ0RERJZnsxmK/fz8YG9vb5KlSU9PN8nmaC1YsAB9+/bFSy+9BADo2LEjXF1d0b9/f7z33nsICjLt/lEoFFAoFJY/gcqoCo1/56KZREREtcpmmRtHR0dERkYiKirKaHtUVBT69Olj9jFFRUWwszNusr29PQCR8akTKnZL2XGFCyIiotpk026pOXPmYPny5VixYgViY2Px/PPPIyEhQdfNNHfuXEycOFG3/z333IP169dj6dKluHz5Mvbv34/nnnsOPXr0QHBwHRmRVLGg2J7BDRERUW2y6ZV3/PjxyMzMxPz585GSkoL27dtj8+bNCA8PBwCkpKQYzXkzefJk5OfnY/HixXjhhRfg5eWFIUOG4KOPPrLVKZhSVai5cfG1TTuIiIhuUzKpzvTn1I68vDx4enoiNzcXHh5WWBZh+3xg70LA3lEMAX/0D8CvheWfh4iI6DZyM9dv9plYmrZbqs9MYOhbtm0LERHRbcjmQ8EbHG1BsaObbdtBRER0m2JwY2naeW44cR8REZFNMLixNO08N8zcEBER2QSDG0vTdUu52rYdREREtykGN5amLShWMHNDRERkCwxuLE07z40ja26IiIhsgcGNpWlrbpi5ISIisgkGN5amDW4cXGzbDiIiotsUgxtLkiSgrETcdnC2bVuIiIhuUwxuLEmt0t+WK2zXDiIiotsYgxtLKlPqb9szuCEiIrIFBjeWZBjcMHNDRERkEwxuLEldHtzYOwIymW3bQkREdJticGNJ2syN3Mm27SAiIrqNMbixpDKDzA0RERHZBIMbS9IOA2fmhoiIyGYY3FiSdii4nJkbIiIiW2FwY0nM3BAREdkcgxtLYs0NERGRzTG4sSSOliIiIrI5BjeWpAtuOIEfERGRrTC4sSQ1gxsiIiJbY3BjSbqCYgY3REREtsLgxpLKyoeCc9FMIiIim2FwY0kcCk5ERGRzDG4siZP4ERER2RyDG0ti5oaIiMjmGNxYkq7mhpkbIiIiW2FwY0nM3BAREdkcgxtL4iR+RERENsfgxpI4iR8REZHNMbixJE7iR0REZHMMbiyJk/gRERHZHIMbS2JBMRERkc0xuLEkTuJHRERkcwxuLImZGyIiIptjcGNJnMSPiIjI5hjcWBIzN0RERDbH4MaSWHNDRERkcwxuLImZGyIiIptjcGNJuuUXGNwQERHZCoMbS9IGNywoJiIishkGN5YiSQZrSzFzQ0REZCsMbixFW0wMsKCYiIjIhhjcWIq2mBhg5oaIiMiGGNxYSHpOnv4X1twQERHZjNzWDWgo7CUNrkuekEGCLwCZrRtERER0m2JwYyFyr2B0Ui4FAFxQS3CUM7whIiKyBXZLWYhCrn8pVWqNDVtCRER0e2NwYyEO9vqXsrSMwQ0REZGtMLixEHs7GeztRFcUMzdERES2w+DGghzLszcqZm6IiIhshsGNBTnYM3NDRERkawxuLMhRbg+AmRsiIiJbYnBjQY7lmZtSZm6IiIhshsGNBTnKWXNDRERkazYPbpYsWYKIiAg4OTkhMjISe/furXJ/pVKJ119/HeHh4VAoFGjWrBlWrFhRS62tGoMbIiIi27PpDMVr167F7NmzsWTJEvTt2xfLli3DyJEjcfbsWTRu3NjsY8aNG4e0tDR8//33aN68OdLT01FWVlbLLTdPO9cNC4qJiIhsx6bBzaJFizBlyhRMnToVAPD555/j33//xdKlS7FgwQKT/bds2YLdu3fj8uXL8PHxAQA0adKkNptcJWZuiIiIbM9m3VIqlQrR0dEYPny40fbhw4fjwIEDZh+zceNGdOvWDR9//DFCQkLQsmVLvPjiiyguLq70eZRKJfLy8ox+rEU7z02pWrLacxAREVHVbJa5ycjIgFqtRkBAgNH2gIAApKammn3M5cuXsW/fPjg5OWHDhg3IyMjAs88+i6ysrErrbhYsWIB33nnH4u03R5e5Uatr5fmIiIjIlM0LimUy49WzJUky2aal0Wggk8mwatUq9OjRA6NGjcKiRYuwcuXKSrM3c+fORW5uru4nMTHR4uegxRmKiYiIbM9mmRs/Pz/Y29ubZGnS09NNsjlaQUFBCAkJgaenp25bmzZtIEkSkpKS0KJFC5PHKBQKKBQKyza+EvqCYnZLERER2YrNMjeOjo6IjIxEVFSU0faoqCj06dPH7GP69u2L5ORkFBQU6LZduHABdnZ2CA0NtWp7q4MFxURERLZn026pOXPmYPny5VixYgViY2Px/PPPIyEhAdOmTQMgupQmTpyo23/ChAnw9fXF448/jrNnz2LPnj146aWX8MQTT8DZ2dlWp6HD4IaIiMj2bDoUfPz48cjMzMT8+fORkpKC9u3bY/PmzQgPDwcApKSkICEhQbe/m5sboqKiMHPmTHTr1g2+vr4YN24c3nvvPVudghEH3WgpBjdERES2IpMk6bYqEMnLy4Onpydyc3Ph4eFh0WO/vfEMVh64ghmDm+PFO1tZ9NhERES3s5u5ftt8tFRD4sCFM4mIiGyOwY0FaWtulKy5ISIishkGNxbkaG8PgGtLERER2RKDGwtykJd3SzFzQ0REZDMMbizIkauCExER2RyDGwtScJ4bIiIim2NwY0Gc54aIiMj2GNxYEEdLERER2R6DGwti5oaIiMj2GNxYENeWIiIisj0GNxakC26YuSEiIrIZBjcWpB0KXlp2Wy3XRUREVKcwuLEgZm6IiIhsj8GNBekm8WPNDRERkc3UKLhJTExEUlKS7vfDhw9j9uzZ+Pbbby3WsPrIgTMUExER2VyNgpsJEyZg586dAIDU1FTccccdOHz4MF577TXMnz/fog2sTzhaioiIyPZqFNycPn0aPXr0AAD89ttvaN++PQ4cOIBff/0VK1eutGT76hVHznNDRERkczUKbkpLS6FQKAAA27Ztw7333gsAaN26NVJSUizXunqGmRsiIiLbq1Fw065dO3zzzTfYu3cvoqKiMGLECABAcnIyfH19LdrA+kQb3JRpJGg0HA5ORERkCzUKbj766CMsW7YMgwYNwsMPP4xOnToBADZu3KjrrrodOdjLdLdZVExERGQb8po8aNCgQcjIyEBeXh68vb1125966im4uLhYrHH1jTZzA4jgxsnB3oatISIiuj3VKHNTXFwMpVKpC2yuXr2Kzz//HOfPn4e/v79FG1ifaAuKAdbdEBER2UqNgpvRo0fjp59+AgDk5OSgZ8+eWLhwIe677z4sXbrUog2sT2Qyma5riiOmiIiIbKNGwc2xY8fQv39/AMDvv/+OgIAAXL16FT/99BO+/PJLizawvuEsxURERLZVo+CmqKgI7u7uAICtW7dizJgxsLOzQ69evXD16lWLNrC+cZBzrhsiIiJbqlFw07x5c/z5559ITEzEv//+i+HDhwMA0tPT4eHhYdEG1jfazI2SmRsiIiKbqFFw89Zbb+HFF19EkyZN0KNHD/Tu3RuAyOJ06dLFog2sbziRHxERkW3VaCj4Aw88gH79+iElJUU3xw0ADB06FPfff7/FGlcf6Zdg4CR+REREtlCj4AYAAgMDERgYiKSkJMhkMoSEhNzWE/hpMXNDRERkWzXqltJoNJg/fz48PT0RHh6Oxo0bw8vLC++++y40mtv7oq4LbtRqG7eEiIjo9lSjzM3rr7+O77//Hh9++CH69u0LSZKwf/9+vP322ygpKcH7779v6XbWGw66oeDsliIiIrKFGgU3P/74I5YvX65bDRwAOnXqhJCQEDz77LO3dXCjm+eGQ8GJiIhsokbdUllZWWjdurXJ9tatWyMrK+uWG1Wf6ea5Yc0NERGRTdQouOnUqRMWL15ssn3x4sXo2LHjLTeqPmPmhoiIyLZq1C318ccf46677sK2bdvQu3dvyGQyHDhwAImJidi8ebOl21ivKDhaioiIyKZqlLkZOHAgLly4gPvvvx85OTnIysrCmDFjcObMGfzwww+WbmO9woUziYiIbKvG89wEBwebFA6fOHECP/74I1asWHHLDauvtEPBufwCERGRbdQoc0OV4yR+REREtsXgxsIc7LkqOBERkS0xuLEwZm6IiIhs66ZqbsaMGVPl/Tk5ObfSlgbBkZkbIiIim7qp4MbT0/OG90+cOPGWGlTfcZ4bIiIi27qp4OZ2H+ZdHRwtRUREZFusubEwfUExF84kIiKyBQY3FqYvKFbbuCVERES3JwY3FmY4WqpYxQCHiIiotjG4sTBtQfHO89fRbt4WxCRk27hFREREtxcGNxamzdwAgEYC3v37rA1bQ0REdPthcGNh2oJiLQ4JJyIiql0MbizMMHMDAKVlHDVFRERUmxjcWJhjhcwNZyomIiKqXQxuLMxRLjP6nZP5ERER1S4GNxbmaG9v9DszN0RERLWLwY2FVay5YeaGiIiodjG4sTAHe+NuqbySUqg1LComIiKqLQxuLKxi5kaSgJwilY1aQ0REdPthcGNhFUdLAUBWIYMbIiKi2mLz4GbJkiWIiIiAk5MTIiMjsXfv3mo9bv/+/ZDL5ejcubN1G3iTKmZuACCTwQ0REVGtsWlws3btWsyePRuvv/46YmJi0L9/f4wcORIJCQlVPi43NxcTJ07E0KFDa6ml1WcuuGHmhoiIqPbYNLhZtGgRpkyZgqlTp6JNmzb4/PPPERYWhqVLl1b5uKeffhoTJkxA7969a6ml1Vdx+QWAmRsiIqLaZLPgRqVSITo6GsOHDzfaPnz4cBw4cKDSx/3www+4dOkS5s2bV63nUSqVyMvLM/qxJrmdzGRbNoMbIiKiWmOz4CYjIwNqtRoBAQFG2wMCApCammr2MXFxcXj11VexatUqyOXyaj3PggUL4OnpqfsJCwu75bZXRSYzDW5KStVWfU4iIiLSs3lBccVgQJIkswGCWq3GhAkT8M4776Bly5bVPv7cuXORm5ur+0lMTLzlNt+sMs5zQ0REVGuql/6wAj8/P9jb25tkadLT002yOQCQn5+Po0ePIiYmBjNmzAAAaDQaSJIEuVyOrVu3YsiQISaPUygUUCgU1jmJauISDERERLXHZpkbR0dHREZGIioqymh7VFQU+vTpY7K/h4cHTp06hePHj+t+pk2bhlatWuH48ePo2bNnbTX9ppWpmbkhIiKqLTbL3ADAnDlz8Nhjj6Fbt27o3bs3vv32WyQkJGDatGkARJfStWvX8NNPP8HOzg7t27c3ery/vz+cnJxMttc1ZRpmboiIiGqLTYOb8ePHIzMzE/Pnz0dKSgrat2+PzZs3Izw8HACQkpJywzlv6rLWge44l5qPUmZuiIiIao1MkqTb6sqbl5cHT09P5ObmwsPDwyrPcTg+C9FXsyG3k+H9zbG4r3MwPn+oi1Wei4iI6HZwM9dvm4+Waoh6RPjgmUHNdCuEl3K0FBERUa1hcGNF8vLZiss4WoqIiKjWMLixIm3mhqOliIiIag+DGyuS25VnbtgtRUREVGsY3FiRXJu54VBwIiKiWsPgxoq0K4RzKDgREVHtYXBjRdoVwllQTEREVHsY3FiRNnOjrbnRsPaGiIjI6hjcWJG25qZULaFQWYb+H+/EnLXHbdsoIiKiBo7BjRXpRkupNdh8KgXXcoqxPuaajVtFRETUsDG4sSL9aCmJRcVERES1hMGNFWkLikvVGqg5HJyIiKhWMLixIl1BsVoymsjvNlurlIiIqFYxuLEiw0n81AbBjYpDw4mIiKyGwY0VaQuKSytkbpRlDG6IiIishcGNFekXztQYTeSnYnBDRERkNQxurEiuXX5BI6G4VK3bzuCGiIjIehjcWJGDwfILhUp9cMNuKSIiIuthcGNF2syNRgIKlWW67czcEBERWQ+DGyvSjpYCgPwSBjdERES1gcGNFTnY6V/e3OJS3W1lmdrc7kRERGQBDG6syDBzk1eiD26YuSEiIrIeBjdWpF1+ATAObpScxI+IiMhqGNxYkUwm0wU4ecX6mhtlKYMbIiIia2FwY2XarimjbilmboiIiKyGwY2VaYuKDdfKVJayoJiIiMhaGNxYmb1BUbEWMzdERETWw+DGyuR2pi8xR0sRERFZD4MbK3Mwk7nh8gtERETWw+DGyuTmuqUY3BAREVkNgxsrc2C3FBERUa1icGNl5jI3XH6BiIjIehjcWBkLiomIiGoXgxsrM1dQzKHgRERE1sPgxsrk9qYvMZdfICIish4GN1ZmuHimFhfOJCIish4GN1bmwMwNERFRrWJwY2WGo6XcneQAWHNDRERkTQxurMxwtFQjdwUAQMWh4ERERFbD4MbKDEdL+ZcHN1x+gYiIyHoY3FiZ4Wgpf3cnAJznhoiIyJoY3FiZg8FoKX23FIMbIiIia2FwY2X2duyWIiIiqk0MbqzMsFuKmRsiIiLrY3BjZXKjzE15zQ2HghMREVkNgxsrM1wB3N+jvFuqlEPBiYiIrIXBjZUVqvSBDCfxIyIisj4GN1ZWqCzT3VbI7QEApWoJGo1kqyYRERE1aAxurKxIqc/cuDja624XqMrM7U5ERES3iMGNlRUaBDFODvbwKO+aSsstsVWTiIiIGjQGN1ZWpDIuHg70FCOmUvMY3BAREVkDgxsre6h7GACgX3M/AECAhwhu0vKUt3TcOWuPY9yy/1DG4mQiIiIjcls3oKGb2r8pOoV5oWOoJwDD4KbmmRuNRsL6mGsAgJjEHHRv4nPrDSUiImogGNxYmb2dDL2a+up+DywPblJvoeamyGCenLzi0po3joiIqAFit1QtC7BAzY3h8PKcIgY3REREhhjc1LJAC3RL5Zfog5u0fBYmExERGWJwU8ss0S1lmLlJv8XCZCIioobG5sHNkiVLEBERAScnJ0RGRmLv3r2V7rt+/XrccccdaNSoETw8PNC7d2/8+++/tdjaWxfgKdaXyihQ1nikU4FBcHMrGSAiIqKGyKbBzdq1azF79my8/vrriImJQf/+/TFy5EgkJCSY3X/Pnj244447sHnzZkRHR2Pw4MG45557EBMTU8strzk/VwXkdjJoJCA9v2ZZF8NuKc6XQ0REZMymwc2iRYswZcoUTJ06FW3atMHnn3+OsLAwLF261Oz+n3/+OV5++WV0794dLVq0wAcffIAWLVrgr7/+quWW15ydnQzhvi4AgLPJeTU6BruliIiIKmez4EalUiE6OhrDhw832j58+HAcOHCgWsfQaDTIz8+Hj0/l87wolUrk5eUZ/dhat3DR3iNXs2r0eMNuqfT8Ei7CSUREZMBmwU1GRgbUajUCAgKMtgcEBCA1NbVax1i4cCEKCwsxbty4SvdZsGABPD09dT9hYWG31G5L6B5RHtzE33pwU6qWkFWkski7iIiIGgKbFxTLZDKj3yVJMtlmzurVq/H2229j7dq18Pf3r3S/uXPnIjc3V/eTmJh4y22+Vd2beAMATl3LRYnBhHyXrhcgr+TG89YYBjfArY28IiIiamhsFtz4+fnB3t7eJEuTnp5uks2paO3atZgyZQp+++03DBs2rMp9FQoFPDw8jH5srbGPC/zdFShVS1h1SBRPX0jLx9CFu/HId4fMPiYltxjDFu3GLwevGtXcAEBWITM3REREWjYLbhwdHREZGYmoqCij7VFRUejTp0+lj1u9ejUmT56MX3/9FXfddZe1m2kVMpkMk/o0AQC8+/dZ/HcpE1vPiCDv1LVcs8HKin3xuJhegDf+PG00WgoAstktRUREpGPTbqk5c+Zg+fLlWLFiBWJjY/H8888jISEB06ZNAyC6lCZOnKjbf/Xq1Zg4cSIWLlyIXr16ITU1FampqcjNzbXVKdTYs4OaYVSHQADArgvpUJXp57zZG3fdZH8XR/0yYEcrFCLnmllf6kJaPi6mF1iquURERPWGTYOb8ePH4/PPP8f8+fPRuXNn7NmzB5s3b0Z4eDgAICUlxWjOm2XLlqGsrAzTp09HUFCQ7mfWrFm2OoUak8lk6NvcDwAQm5KPxOxi3X27L5gGNyVl+tqcxCyxr6ujPQDT9aUKlWUY/tkeDFu0u8YTBRIREdVXNl8V/Nlnn8Wzzz5r9r6VK1ca/b5r1y7rN6gWtQkS9T/nUvLQ2MdFt33/xQyTfXPNLJAZ6u2C82n5Jt1ShpMDFirV8HSxed04ERFRreFVz4ZaBbhDJhPByImkHN32tDwlilVqo33Nrf4d6u0MwDTwMSw4zleaH31VUqrm/DhERNQgMbixIVeFHOHlGZtStXGgkZxbbPR7TrFp0bA2uKmYuckzqMEpVBoHSaoyDQqVZej30Q5MWH6w5o0nIiKqoxjc2Ji2awoAXBzt0cLfDQCQnFMhuKmkWwoAcioUFBsWGBvOiRN9NRvt3/4XM349howCFQ5ezjIZVk5ERFTfMbixsZ4R+qUjytQSQsqzMRWDG202pk8zX902beamYuCTY5S50Qcvr/xxEqoyDXae1xcsx3FEFRERNTAMbmzs0V7haFK+kObQNv4I9hIBy7Uc41mHtQFLt3Bv3bYQXXBj3C2VW0lwYzgbstaFtPxbaT4REVGdw+DGxuT2dtg4sx9eHtEKL97ZCiHlwc2R+Cz8dykTGo0EZZkaReUFxkPb6GdvDvRwAiCCGcPiYMNMjmG3lOFcOlpxDG6IiKiBsflQcAI8nBzw7KDmAIBgLxGw/Hc5E/9dzkTnMC8sGNMBACCTAR1CPLF8Yje4KuTwdHEAAGgkIL+kTPd7ZZkblZk5by6k1a1uqfXHkvDzwav45tFIBJQHb0RERDeDmZs6JtjT2ej344k5mLUmBgDg6ewAOzsZhrUNQO9mvlDI7eGincjPYDSV0WgpgyHl9SFzM+e3E4hJyMH7m2Jt3RQiIqqnGNzUMdqaGwAY2LIR7O1kuuyKl7ODyf7eLo4AgGyDrijDQMdwHSpzwU1ybonJKuN1AdfLIiKimmJwU8cEejpBbicDALw7uj0m9g7X3edZHsgY8iwPeL7cHqcLUsx1SxUqy1BWyaR917KLzW63JYnzCxIRUQ0xuKljHOztsHFGP2yc0ReNfV0wvnuY7j6Zmf29XUVws+NcOlbujwdgPri5brAkQ0XXcoos0HLLUnP2ZCIiqiEGN3VQ22APdAz1AgC0DtRP8nc8Mcdk38l9InS3zyTnATA/Wiq9quCmDmZuNEzdEBFRDTG4qQeeH9YSAPDKiNYm993RNgArH+8OALiYXgC1RjKqszlwKRPf7L6E1LwSk8e2LZ8dOSmn7gU3jG2IiKimOBS8HnhuaHMMbxeAZo3czN7fIsAdgJht+I7PdhvdV6Asw4f/nMPgVo1MHtc22ANnU/KYuSEiogaFmZt6QCaToU2QBxzl5t+uYE8n3ZDwy9cLze5zOD7LZJt2XatrdSRzY1hnw+CGiIhqisFNAyCTySrN6mhp57txsNeXJWu7pSquY2UrhstDsJ6YiIhqisFNA/TLlJ74dWpPs/d1CxcLddrbydAyQARE6flKs3Pg1LZig+CGo6WIiKimGNw0EP1a+AEAAjwU6NfCD838zWdyujcRC296OjvAx9URTg52kKTKszfq8rWtaoNh5qbYzCKfRERE1cGC4gbiuSEt4O4kx5guoQAAV4XpW+vuJNcVH3s4ySGTyRDh54bYlDycT8tHEz9Xo/0lScKYJftxPV+JHS8OgpODvVXPwTC4KarFWZMlScLRq9loGeCumxSRiIjqL2ZuGghnR3s8O6g5Aj3FYpMuZgKRFv5uaF6e0dHW6HQM8QQAnEzKMdk/s1CFE0m5SM4tQWxK3k23qUytwdQfj+DTf89Xa/9ilb5rzHBNLGv773ImHvzmP7zx5+lae04iIrIeBjcNlJ2d6XzGLfzd0SbIA//M6o/PHuoMAOgYpg1uck32v5iuXzE8zcw8OTfy3+VMbItNx+KdF6GpRg1NiUH3V5Gq9jI3VzLEDM3xGXVrhXQiIqoZdks1YO/e1x6XrxcgMasI22LT0aK8gFg7BBwAOpXPhHwyKReSJKFMI8HBXsS8l67rL/YJWTe/REOxQfYlo0AJfw+nau9fqpagKtNUOvzdkrTLVRjO7ExERPUXg5sG7LFeYtHNk0k5CPR0wtiuoSb7tAp0h6PcDrnFpfhsWxwW74jDu/e1xyM9w40yNzUJbgxX9k7MLq4yuMkpUpk8R7FKXSvBTV6JCGpyGdwQUR135EoWYlPy8FivcMhk5lYcJIDdUreFjqFeeO++DvB2NV1V3MHeTld38+X2OGgk4PUNpyFJUoXgphh5JaX460QyilVqXM0sRKm66uHjhot1JmVXHhxJkoQe7283qXkpvEHXlLJMjf8dv4aMgsrXzaqOvPLMTb6y7IbnRERkS6+tP4W3/ncG51Lzbd2UOo3BDeGVkaZrVp26lotLBsFNYlYRFv57HjNXx2DgJzsx8JNdmPDdQZRVEQwYLtZZ1SzIGQUqqMwc50Z1N3+fSMGsNcexcGv1CpYrY7iKuuFtIqK6JruI3ejVweCG0L2JD5Y9FomeET5oVT5UfMySA0jO1RcRJ2UX4ffoJAD6oOXIlWws3nmx0uMaZ24qD24SK8nqFCpNR0wlZBZh65lUSJKke1xi1q3NsJxnsNAoPzCIqC5Tlk+ZUVJL84/VVwxuCABwZ7tArH26N94Z3Q4AUFY+uqlHEx842MtQqpZ0w7M7hHiif/mkgUt3XUJWocrsMSsLbirOPpxYST2PuW6pOb8dx1M/R+N4Yo4uEKns+avLOHNjfKxDlzNx7+J9OJ6Yc0vPQURkCcry2eSVpexCrwqDGzLSq6kvjrw+DHtfHoyjbwzD2qd7oamffrbj3k198dfMfvjpiR7oEOIJZZkGvxy8anKcS9cLjLqitDU3P/13Be3n/Ystp1MN7jOfeSkyk7k5nyb6mePSCpBTXrCcU6TCltMpOFHDACTfILjJLjTO3Dz6/SGcTMrFo8sP1ejYRESWotZIui782po5vr5icEMmGrkrEObjAj83BWQyGd64u43uvkGtGgEQi3VO7R8BAPhhfzwSs4qw+8J1PP3zUSzaeh5DF+5GikG31rXsYkiShE//PY/iUjWm/RKN9PK5c6qbucktKkV+eRdSUnYRcsqDkuTcEkz75RhGf70fPx+8irnrT97U2lSGmZucCjU3pWpxnIJanDGZiMgcw4CGmZuqMbihG+rfohFWTO6GMV1D8FCPxrrtozoEoXWgO7KLSvHo94fwwm8n8O+ZNHy5w7QOR1mmwbGEbKOZh5ftuQyg8pqbogqzFBvul5RdrCusM/Te32ex+nAiTpiZcdkcSZJ0Q8EB6LJBtlKoLMOiqAuIvppt03YQUd1jGNCw5qZqDG6oWoa0DsCicZ2N1l5ysLfDj0/0QJiPM65mFlU6JPueTsEAgI/+OW+UUdFewCsrCC6skC0x7L5Kyi5GrplARNsffSWjsDqnheJStS47A9h2tJQkSXjo24P4cnsc5v991mbtoIZDkiRsj02rNDtK9YthQFPCxYWrxOCGbkmAhxN+fqIn/NwUAIDx3cIQ4uVstM/9XURwc/hKFgCgsY8LAOBsSh5KStWVrkhesVA4yShzU2Q2c6NV3eAmr9g4gMquEDAZTiJYsasrp0iFYwmWy7BEnU3DqWtiGYya1g8RGTp1LRdTfjyKF9edsHVTyAJKDDI37JaqGoMbumVN/Fzx18y++GVKT3z0QEfsf3UIdr80CP7uCkwb2Az9WzTSBT8AcG+nYHg6O0BVpsG66CTdyCyt9iFieQjthV7LMHOTnFtSZZblSmb1vqlWPMYf0ddw4GKG7neFvf6/SEJWEe7+ai/mrj8JAHjhtxMYs+QAYiwU4Jw1WJzUw4mTh9Ot0/6fSc69tekSqG4wrLlht1TVGNyQRQR5OqNf+fBwAAj3dcWh14bi1ZGt4WBvh68ndIGbQlywezX1RcdQMSvym+WzEmt/B8SILAA4nphjtOBmVXPlVHQlU5+5Sc4prnSyQcN6G0B0U01YfgiXrxcg6mwaCgyKmpfvvYzT1/Kw+nAiytQaXTBiqZlCsw0yVXklZVVOkEhUlYvpBZi5OkbX9VsxQ0n1EzM31cfghqzGcN2Tnk19seOFgfh5Sg/0be6rW7BT7Ae8eXdb3e9tgz3g5GCH/JIyDF64C/87fg1A1Us4VBSfUQhJknDgUgb6fLgD8zaeMbtfXiXZn0eWH8KTPx2FZJBUOhyfpbudmF2sWyndcFTYrciq0M1WceQWUXVN/fEI/jqRjO/3xQMA8ktKIUnVH0HY0Gk0Et7fdBZ/n0y2dVNuimGdDTM3VWNwQ7XG38MJ/Vs0gkwmw4j2gXCU28HeTobH+0QgsrG3bj9VmQatA0XX1NXMIsxacxy5xaW6bEyYj7PZ4xvKLylDdlEpvt8rPtxXHUowyoxoabulDLvNAPMBS5zBchSH4zOhTSqlVKgZSs8rMckIVUfF9tl65BbVXxW7ZTUSjEYq1jd7466j/8c7sC8u48Y7V8OZ5Dx8tzceCzafs8jxaot2wARgnMUhUwxuyCbah3ji1NvDceG9kXjrnraws9NneUrVEtoGexjt//LvJ1BSqkGzRq64p2Nwlce2Lz9WfEYhrhuM4NoQIzJAhcoyxKXlI6tQpcvc9IzwwScPdISzg3212r//YqbudmqePhDKLS7F4E93YeySAwDEHEBDFu6qtGjaUMUC6ooF0xfTCzBl5RFcSOOCeXTz8msQcNcV286mITGrGFFnU2+8czXkFOsnAK1PDDM3hoEOmWLVItmMQm4cSEzpF4Ed59Jxb+dg9G3uh8SsIly+XohrOcX490waAGBSnyZo4uuKJbsumRzP311kX1oEuGH/xUzsPp+OM8n6It35f5/FXyeTcfpaLkrVEuztZOgZ4QMA8HF1xIPdwnDwchb+OJZ0w7YfuKQPbq5lFyP6ahY6hXrhYnoBClVqxKUXILe4FO/8JYZ0f7EtDh890LHKY2pHasntZCjTSCbBzoxfj+Fcaj72X8rAuXdH3rCNRIbyissQ5Hnj/eoi7fpvlpqqQTsZaKFKDbVG0n0hquuMuqU4FLxKzNxQnfHm3W2x88VB8HByQISfK36e0hOLxnXS3e/l4oAxXUMRGe5t9vFRzw9E1PMDcVcHkdn5csdFqDUS3J3kaOEvlpCIScjRzWuj1ki6IKVdeaYoxMvJ5LjBnk5oGeBmtM1wTp/LGYUYu/Q/LNtz2WjJiVNJ+tFeBTdY4RzQBzdNG7kCMP1WGV8+vJ3paKqJ+py50bbdUsFNgcFiuYa36zrDbA0zN1VjcEN1Ws+mvvh6Qld8OKYD/prRD24KOVwVpgnHJr4u8HRxgKeLA+5sF2B034AWjfDTlB5oG+SB7k288ffMfvjg/g5G+3QoH60V7GVaz9M22BNbZg3A3zP7YdljkZW2dVtsmlH306ZT+mLFjHzzExxqFavUuqBFu5ZXxW6pRu76uqC0vMqLmDMKlHhi5RH8e8YyKfy6KqNAiW1n04xG1FHl8uvRRbwii2duDCYIzVfWn6BPycxNtTG4oTrvro5BeKhHY4SVT/4HAJP7NAEAvD6qDf6c3hd/Tu+ru8/XTaFbtRwQXVlBns7YPKs/1k3rg/YhnkbZH4XcDi0D3AGYD248nOSws5OhfYin0Sivik4l5eKSQdHx3ydSdLcvGmzXis8o1E3Wl1WepXGU2yHEW7ShYoFxrkGwY7g8w+H4LKw+nKAbDbPldCp2nEvHd+XLW9zIV9vj8M1u0c23+VQKRn2xF1czqzcJoi3N23gGU386il0X0m3dlFu2/2IGlu2+VKMRTRtikqq1XEdNity1ilRlGLZot26Op9qWb/FuqVKD2/Un6DMeCs7gpiqsuaF66fW72mB052B0DPUy21/+wf0dsC46CWO7hiDc19Xk/hb+bnB3kiO/pAxtgz3gUD5Zn7ngRmUw30yAhwIdQjxNJhgEgDKNhE2n9AGN4bfDzEIVsgpV8HF1BCC6xB785j9kFCjx1t1t0UNb++PiqNvHcLbk3OJSo+MdvZKNUR2CAADjlv0HQIz4uqNtgG525srW7DJ0LacYC6MuiON0C8Ozq44BAN748zTu7xKCfs39sOvCdQR6OGFAy0aVHufS9QI4O9ibff2sJf66OM+L6QUY0jrgBnvXXZIk4ZHyVec7hHqiTzN9YL7pZAoi/FxNCuy1Tibl4Pm1YvbhKx/epdtuJwMqJrTybuEivj02HRfTC3AxvQAf3N/BaJqH2qAt/M+10Hw9hl1R9Sm4MVo4k91SVWLmhuolB3s7dGnsXWkhYJiPC+bc0dJsYAMAdnYydC0fft4xRF9lGWym5sZwjSuZTIYPx3Yw2Uer4mKfhi6mF0CSJJxLzcOBSxm6up35f5/F79GiiNnb1RHeLtrgRv/t8lqFCQwPXMrAhbR8nEnWB1l7LlwHoB8GnJanNJu6LlNrEJeWj1K1BmcNCq5PGwRse+MyMOe3E5j0wxG8/PtJTFxxuNKV0XOLSnH3l/swdumBamce9ly4jsk/HNatDF8T2tfPUvMM2cpVg2HbhkXkxxKyMf3XYxj15d5KX9d4g2VGisv/9kpK1SaBDVD5nE7VYXi4TDNTKlibvuZGZZH5evKNgpuavy6puSW12j1kmLlht1TVmLmh29aT/Zsiu0iFCT3DddtcHOVoHeiOa9nFukyJXYVvqe2CPbF8YjckZhch1NsFi3fEoUeED74rn1PHUIiXMyL8XLHvYgY2n0rBp1vPG00GqLXywBUAgI+rA7xdxOKkF8qHq/u4OuoKlUO8nJGcW4xzqfkY/tkeo2McLe+aMOxSupZTjGaN9MXQJ5Ny8Mwvx3AtpxjTBzeDo71+xNr/jptOaBZrsCTE9tg0jO4covs9OacY036JRrtgTxSXqlGcq8b1AiX83U0DxIoW77iIw1ey8NvRRMwY0uKG+1ek0Ui6i2xV9Uf1wVGDLiXDi+7FNH1XZlx6ga7r1JBhMJ2UXYQWAe6Vdj/dSobCMAC4ll1sMi+UNWk0ki6wLlVLKC5Vw8Xx1i5dhoF6TV+X+IxCDP50F3pE+OC3p3vfUnuqi0PBq4+ZG7pt9Wvhh40z+qFVoPFF449n+mDXS4Pw7uh2CPJ0wisjW5s8dljbADzeNwJ3tA3A/2b0w7SBzcw+xzODmmFYG38AIoCpGNg8N6S50UKj3i6O8C7vlrqaWYThn+1BbnEprpV3MXUM9UT7YPPjeWNT8pCWV4KrBitAV1wNev5fZ3WB0j+nU42ClxsNgf9063mjQGLexjM4mZSL1YcTdNuuVmNNL7VGwunyjFNsStVz9pSpNdh5Pt3kW2pOcaluIdNUK2durucrseOcKFy+dL0AnedvxZfb4yx2fMN6mUyDUXjp+frz2lvJ5HWG567thqzsYn0rNTeZBfpszc0sg3ImORev/nHylgLQQlWZUSbKEnU3RgXFNXxdtDOnH47PqrXZn40n8WPmpioMbogqcFXI4eumwGO9m+C/uUPNfmOuyNdNgWaN9F1gj/UKx10dgjC+exgm9m6Cke0DAYhaH8PRXANb+eO9+9vrfvdxdTQqnM4oUGLl/iu6C0qIl3OlQ+EBYPXhBKgMPgDj0gp0H4LnUvOMsgSXrxfeVDFuYlYx+n+8EynlizCaK5LW1vsUKMsQdTZNVyOQW1yq+7Z8+XqBLuNguFioOSsPXMHjPxzBVztEMHE9X4mcIpXRUPy0vKpHot0stUbCrDUxeH+TmKPohXUn8MTKo/hs2wW89b/TyCkqxaLyOiVzlGXqm7rYHTN4TzIqCSL2xV03+1jDoCExS+xfWfdTTTMUhcoyo+6yaznVXwbl3sX7seZIIt79++wN91VrJPx2NFH3N6RVsd0WCW4MC4or6W69EQeDRXXTbzAa0lKM57lh5qYq7JYispCX7myFab8cQ5fGXnj3vvZG9335cBccuJSJyHBvZBYo8e+ZNPi4OqJDiCcc5Xa4p1Mw/jqRjGaN3BDi5SyyR+fT8dWOi/h610VdliLc1wWdwrzw039XjL7Nhno7Iym7GEsrTG74/uZY/Ho4AX8+2xff7RHdZqM6BCIhqwinr+VV+wOydaA7zqXmQ1WmwX+XMnFf5xCjAEPramYR0vNK8Nj3h3E+LR8v3dkK93cJwfDP9qCkVI1He4WjvUGN05XMQhQoy3SLqlZ08LLIdO2Ly8BTA0oxbNFueDjLMX+0/vVNyyuBRiMZzXJ9K2JT8nRddMPaBOhqmb7acdFoP3PPeehyJh7+7iDmjmyDJwc0veFzFavUuJCuz14Z1rMYBjcHL2ehWKWGs6PxxJeGwU3SDTI3NclQ7DqfjsdXHjFaY+1mMjfav9vYGwSxALD+WBJe/v0kFHI7nH9PP0mlSXBTdHPnIUmSSQF0ZQXFOUUqbD6Virs6BsHT2aHK4xr+/V+6XoAAjxt3x96qEqN5btRmz40EZm6ILGRE+yCseaoXvp7Q1eQ+B3s7DGzZCG4KOcJ9XfHPrP74fVpvOMrFf8GFD3bCz1N64KEeYQCAyHBvzB7WEq0D3aEq00CtkRDgocC9nULQMdQLW2YPwHcTu+mO/1x53Yq5fvj4jEJ0mr9V1+00pV8EekX46u43XKtLO2qrol+m9sTUfhEAxNIT3+69bPYieiEtH0/8eATny5eIWH8sCZtPpaBAWYYyjYSVB65gjUE3liQB51Mrv/BpC6bPJOfhcHwWcotLkZhVjJX7r+j2KdNIyCjUX2hOJOYYFUpXV0mpuFgYdq099XN0pfsn55pe5Kf/GgONJILK6riSWWgUOGQZnIfhQrHFpWpsi00zeXyqQdbqu73xWBR1odLup5oUFO++cB0Vk1AVi9srY9hl5ut64xqd/RdF11vFv+GK53MzC8pO/fEoRn+9H6Vq42MWVNIt9d3ey3htwyms2GdaP1eR4ZxWl6/XztQJhsO/NRJ0E5Jqlao1uoDydsfghsiCejX1rdZw6DZBHmhqUOjrKLdD/xaNjJaksLeT4acneqBNkAcc7e3w8QOd4FlebNwywN1oLp+RHQLR1E/fLdYp1HxdzpP9IxAZ7oPBrUUdUCN3Bb56uCveuKsNHogMxQ+Tu5s8xsfVEX5uCnRu7AVA1OZ8+I/5BQe3nk3D6Wt50CY0Ll0vxHd7jefb0XaNyct3qmyOlswCpW4kVJlGwrqjibr7dl8w7qZ5fu1xvPf3Waw7mojRX+/HuGX/Ib+kFKoyTbXW4tp4Ihmt39yCtUcSdQu0AvoukPHdwkwecyVDH3wcT8zBm3+eNpvNEvsWYkNMEsoqXGQrdsFoa1vUGklXGzWmiyjiNlfwXbGW5cvtcbogoaKadEuZ63qsLHMjSRIW74jDhhgRRJ9IytHdl12NNZwM//YNZ+eumHGqbrdUdqEK22LTcDIpF+dTjf8G8ivJ3GjP19x5V2Q4Sq+2gpuSCoGf8dBwNYYu3I37vt5/0zVAJaVqfBZ1ARfTG866deyWIqrD/D2c8PfMfsgpUsG3wggVJwd77H5pEMo0EtydHDBzaHO893csxncPw+S+TXD/1wfQM8IH47qH4Z9TKXBRyDF7mMjw9G3uhz+e6YNmjVzh5eKIzmFeuuM+3KMxVh9OQO+mvjh1LVdXL9SlsWmtj0JuZzZb9N3Eblh54Ar2xmXoamLmj26Ht/53BkD5Wl6RoVi25zI+2nIeXi6OaBXgjvOp+Qj1dkZWkQqf/nve6Jhbz5pmLrT2X8w0Wsy0QFmGXeevY1tsGv53PBmLJ3TB3ZUsuCpJEp5bHQMAeHX9KTwQGWp0v6O9HZ4Z1AzHErKNVoaPzyxEv/IA87Hlh0xqNwy722aujsGpa7n460QKlj7aVXchv1we3Gi7/bQ1N+n5JShVS5DbyfDkgKZYH3MNuy+kI6+kFB5OIsBVlqlN1h8DgEMVitb93BTIKFAaZUDS80uw8XgyHukZbtLVlVWoQkpuMdoFe5oNDJOyi8x2yZ1IysWnW0Ut0vC2gThePkElILIcN+pC0S5mCYigODJcFNZXDMoqZqAupOXj4OVMPNIz3GhqiIvX9e9Vam6JrjvUcPRVxeNrA7eKc0RdTM9Hep4SfZrrv1Ak5+iDm0vlz5WSW4yjV7Jxd8egGnUX5ZeUokwt6QYVVFRx4r6SUg20gxPj0gqQUD6AoLqjFrXWHknEF9vjcDIpBz883uOm210XMbghquPs7WQmgY2W4Tw+93cJxf1d9Bfmfa8MBiDm5unV1NfksZUVJr9xVxv0a+6HQa0awdnBHtrP6GBP/YdluK8L/nimD7bHpuGVP06VP4/oZprSLwJD2wSgTCPpRvm0DnTHhB6N8e2ey0jJLcHiCV0QGe6N9HwlNsRcw8u/3/rMt419XHQf7gDw2bYLum/Ui3dchNxOhj7N/XTBQZlaAzuZzGhxVQA4FC+CpE8e6IgOoZ7wcnZEoKcTVj7RAwv/PY+0/BLsv5iJ+OuFkCQJao1ktij1SkYh2od4IjGrSDfp445z6VgUdQGv3Nka+y5m4OBl8Vzdm/jgXGo+sgqV0Ggk3UU2yMsJbYI8dOd2IjEH/VuIyRTTDbqkXB3tUVhepK095/4t/JCUXYwHIkPxyb/nkVGgwh/RSUjNK8HZlDxsOpmC/JIyDG7tj7c3nsHAlo3w5ICmGLNkP65kFmHJI13NFmsXqtT441gSHqyQzTIMhB7+7qBR12ChSo28krIq61gMg4XL1wt0f58VJx/UZm60r/30VccQl14AGYDHejfR7WeYfTH8u6i4zluBueDGYH9JkjBskZh24Z9Z/dEmyAPKMnWF9eXEc72+4TR2nEuHg70MI9oHmZxjfkkpsgpVJvNvSZKEF9adwMbjyXCwt8OqJ3vq5uEyVDFzY1hgfMkgmLuUXnhTwc3JJH33b0PB4IaogappoaGrQo67Opp+MMtkMjwzqBl+PZSApY9Ews9NgTFdQ3H6Wh56NfXFpesFuJZdjFdGiKHzd7YLxJ/T+2JHbBqGtwuE3N4O65/pg3xlmW7unUXjOsHH1RHf74uHg70M3Zv44OjVbKMRX4/1CsfPB6/qfp8+uBm+3ikKp0O8nHEtpxgP92iMd+5th58PXoWqTIOPtpwz6io4l5qPab8cQwt/N7gq5DiZlAONBET4uZpM3KgdddQmyAOtA/UzA4d4OWPR+M5Ydegq9l/MxIr98VgXnYg2QeZnD44vD24qrvG1bPdlRJ1J02VtABFo/nzwKjSSqCnRFjGH+4iLYMdQTyRkFeFkUq4uuEkt75Jq7OOCbx6NxPpjSVhuUCvSOcwLP0/pCQD460QyzqXm44V1J4za8sX2OHxRPqz9eGIOkrKLdZNAamerNvTSna3wyb/n8eE/5zCyQ5BRIfg5g2H92otl76a++K88gEvJLTYKbkpK1cguUiHIU3TjGtWwGLw2FTM1OUWl0Ggk3Pv1Ppy+pr8Y/3DgCh7pGa7LKFUa3FTMBJVntPJLSnWBU3ZRKfJLSuHu5GDUDXc8MQdtgjyQlmsc9CVmFSOjQIkjV0TWLCYhB5HhPpi9NgZju4ZiTFfxpWPm6hjsi8vAn9P7Qm4vQ0t/d9jZyZCYVYz1x8TQ8jKNGk//HI0ts/qbfKmpmLkxzJoanu+l6wXo3Uz/haZYpcY7f53BsDYBGNbWdDZvbW1ber4SmQVKo+dVlqlx+louujb21n2mbDubBheFvdFs2nUNgxsiqrZXRrTGy3e20n3IOdjbmYwMM9Q5zMuoy8vfwwn+BvfLZDK8cVcbDGsTgDAfZ4R6uyA9rwS5xaVwdrRH1Nk0jO8ehtS8EkSVd0s93KOxLriZMaQ5Wvi7ITJcfPBO6RcBjUbC+mNJiEsvgJeLA1oHuutGXcVVqKWIzyhEfEYh5HYyDGntb9T11cTP+Nu1VoTB9vySMrOTMgIiAzSgZSNsPCFqZd6+py3+u5yJfysENgDQIsANXi4OyCkqxWvrT2FLeUD0SM/GAIBOoV74+2QKTiTm4FxqHgpKyrCqPOBrUr48g0YKMQpu3J30H++jOgThXOqN6ym0ReeGmSBDT/Zvit+jkxCfUYhfD13FfV1CdBmCcxUKw0e2D8TSRyNx15d7cSY5D8k5xbpg8UxyLp76KRrJucWY1LsJnh/W0mik2NJdl3AxvQDfPBqp6zayt5NBrZGQUaDEhfR8o8AGEBmrbeWBNGB8sU/KLoIkSUZTEmhdyylGck6xSeFyYlYx2gY74FiC4fQJ4pjaYvImvi5wcrDHudR8rDmcoGvr2ZQ8fL3zoq67dHTnEJSqNdh1XgStd3+1D4Doqp3YuwliEsVzhHg5w9nRHhfTC7Ah5hqm9m+KIlUZ3tl4Fl4uDkZBGlB55qZiDdCGmGtYcyQR/5xOxf5Xh8BNIUdJqRqZhSr4uTkavVbnU/PRp7k+uPn03/P4bm883r+/PR7pGY7knGJM/ekoAJHdzChQ4ekBTY26KbedTUOvZr6VjoKsDQxuiOimWHroqUwmM/qW6e/hBP/yYbWP9xUjtD4c0wElpWoMaNEIod4uaOrnissZhejX3M9oXiBALK2xYXpfpOWVIMzbBcoyNf6MuYaYxBzdt+P1z/ZBIzcFJq44jPiMQrx1T1uMaB9oFNxU9sHcvYkPHowMRYi3M0rVGl2g9UjPxmjayA2ZBUos2XUJvxxMwC8HxcgwhdwOIzsE4f4uoejSOAFqjYQTiTm652vi64rS8m/h2sAmMtwbI8rrnTqWF4hvPZtmUnv03JDmAIDm/m5G27s10Y98G9UhsMq5eTqGeuqyLd3CvfFor3DMXnvcZD9HuR2eGtAUc9efwgebz+GDzecw7562mNyniclw7+eGivquIE9nnEnOw7GrORjQohGyi0rxyPJDyCkf0r3ywBWjpT+0os6mYdf5dF1Bca+mPth/MRN74zJMulQjw70RfTUbr204hU5hXgjwcDLJ3CzecRELoy7goe7G3Wn5JWUY8PFO3UhFrcTsIrQN9kBMQo5um3bSSW0RfJCnM9qHeOBcaj6+2a0vnD+Xmm8URB28nAknB+PaJgD4YHMsJvZuoqtPuqNtAJr4uuDtv85i65k0TO3fFKsPJ2KtQTG9oaTsIqw6lIDuTbyNgldtoFOq1uBkUo6uyDy3uBSrDyXgyQFNMePXY9h+Lh1P9m+KMoMRVhOWH8Kzg5rh5RGtIUkSNp8Sf4+bTqbgkZ7hRsH8S+XdyU0bueLO8qDyamYhnvr5KNydHLDzxUG6tfJqG4MbIqrzfN0Uui4WANgwvS/yiktNAhstN4UcbuVdX45yOzzWuwnGRpbBy9kR/Vr46uoZNj3XD1czi3RdS1tm98e0n6PN1ktoOdjb4ZMHOwEQXRna4GZAy0a4s12gLsNkaOG4Trp5ULSzWecUqXBxyQFE+LnCVSFHpzAvHLgkunCe6BuByX2a6AJJw7mBAMDbxQHZRaWY0LOxLohxcrCHv7sC6flKDGsTYFSz0dzfHU8PaIp8ZRnOpeThWEKOLiAY0LIRRrYPxMkkUTs1uksI7usSAm9XR/x66CraBHng821xCPcVr/X9XUKwcOsFXc3JO3+dxcKtF1CgLIOdDPjh8R6wk0H3moaUd/st3nkRvx1N1E141ybIA9MGNsWL607oRtCFeDnDTSHXTSWw8sAVXZHw4Fb+SMwqRkJWkW6ofY8mPhgbGYLRnUNw/5IDiE3Jw5glB9A+xEM32gwALqQV4MvyiSDXHBGBgp+bo66Au0wj6QJRLW3djWHm5vCVLCzbfQlfbBPHuqdTMIK9nPDd3nijYOZ6vhLXDSb2+z06yeQ9BMTSLhqNpAtuOod5oUeED97+6yyOXM3CicQcXYbO+HFiKPgHm88hIavIaJZwQB/cfBZ1AUsqzH21fN9lDGnjj22xYgLPb/cYj2YEgCW7LmFy3ybIKy7TvY4HLmXi+33xZkfj/Xs6Fe2CPRDq7YJley5DIwFdGnvZLLABAJlUW/NG1xF5eXnw9PREbm4uPDzM95UTEVXXwcuZiL6ajWcGNoOdnQylag2+23tZFJ6WquHkYI9BrfzNPtZwBFH01WxsOZ2CaQObmS0gv3fxPpxMysVro1pjar+mSMgqQmMfF6PugAMXM7A77jqeG9ICrpVknrIKVTiXkofIJt74+0QKhrcLQE5RKfp/vBMAEPPmHUajdSRJws7z6Wgf7KnLqMUkZGNfXAZOXcs1yiS1CnDHv88PMHq+LadTMe0X4/mC7GTAn9P7omOoF9YfS8Kc30Qt0KBWjbDy8R5IzCrCgE926ubYkcmAP5/ti13nr+OzbfoM1I9P9MDA8tXq4zMKcc9X+4yCjFYB7rpAqaJ+zf3gYC+DBKBMLWFfhYu2g70Mzw5qjq92xJldiPSOtgH49rFIlJRqEPleVJWL5gKVd/XNu6ct3vlLzOC868VBaOLnitGL9+FEkj6b5aaQY1SHQPx2VHQbarswKyOTAYfmDkWPD7YbbQ/0cEJqXgncneQmo9AqvlYLxnRAXFoBVuw3P+ePh5McKrXGaCLQh3uE4Y/oa1CpNfjt6d6VzptVUzdz/bZ5cLNkyRJ88sknSElJQbt27fD555+jf//+le6/e/duzJkzB2fOnEFwcDBefvllTJs2rdrPx+CGiOqjxKwixGcUon8LP6vMSrv1TCrcFHKj4c43IkmSrp7mRFIOhrQOMDsKL7eoFI5yO+yNu46TSbloG+yBUR302bGvd17EJ/+ex0t3tsL0waKbbfGOOCyMugBJEl1vc4a3Qnp+CYYu3K27MJ+YN9yoSHnL6VQ8tzoGHUM9MWd4S3Rt7I2hC3frsg9v39MWi6IuoFOYF14d2Rrtytdpu56vRPf3twEQ2aDDV4zrqMZ0DcHeuAxdNubd0e0wrnuYbkj/trNpeP634yhQlqF1oIeui272sBZwdrDHp1vP6ybcmz+6HfJLyrA9Ng3HDLq8/NwcceT1YZDJZNh1Ph0f/nMO13KKkV9ShtnDWmBYmwBdrU4TXxdd4XeotzMWPtgJT/8Sjf4tGuFkUo7ZNd4iw70xsn0g3tukn2By0bhOCPZyRmaBCn2b++Ldv2MRk5BtUhPm4SQ3GbV25PVh8HF1RLPXNps8V/cm3lg3rY/J9ltVb4KbtWvX4rHHHsOSJUvQt29fLFu2DMuXL8fZs2fRuHFjk/3j4+PRvn17PPnkk3j66aexf/9+PPvss1i9ejXGjh1bredkcENEVPdkFCjh6+poFLidTMrBxfQCjO4couueis8oxPRVx9A+xAMfP9DJ5DgVl6nYcjoVh+IzMX1w8ypXMz+RmIM/j1/D83e0RExCDnaeS0dSdjF6RvhgSr8IrI+5hv8dv4a3722nG+1nKKtQhev5SqjKNPhi+wUMaR2Acd1CIbe3w5nkXLzyx0kUKdXY9Fx/ODvaY+HW87olPe7tFIyJvcON6qS0VGUaOMrtIEkS3vrfGRSXquHl7KArHp9zR0s8N7QFVGUaONjLcCGtAI99f0jX/fdAZCg8nR0wrlsYQr2dcefne5CcU4y+zf3w3cRuJrVAZ5PzMOrLvQDEHE9dGnvhrXva4o/oa3CU2+Gb3ZfQOtAdW2aLDN1X2+Pw7Z7LugVO/d0VWP9sH4R6m+8yvhX1Jrjp2bMnunbtiqVLl+q2tWnTBvfddx8WLFhgsv8rr7yCjRs3IjZWH3lOmzYNJ06cwH///Vet52RwQ0REtmDYDXktpxjz/ncG93cJMTv1wo2OcyIpF1czCzGyfZBuGRet9PwS/HooAVczi/DGXW2MujlLStUo00iVFsxLkoQnf4pGRoESXzzU2WROnv8uZSLU29mo3k2jkVCoKsNvR5NwR5sANPa1fGAD1JPgRqVSwcXFBevWrcP999+v2z5r1iwcP34cu3fvNnnMgAED0KVLF3zxxRe6bRs2bMC4ceNQVFQEB4eqFzoDGNwQERHVRzdz/bbZaKmMjAyo1WoEBBhPKBQQEIDU1FSzj0lNTTW7f1lZGTIyMhAUZBr9KpVKKJX6qvW8vIYzAyMRERGZsvnCmRUL4260/oi5/c1t11qwYAE8PT11P2FhpgvgERERUcNhs+DGz88P9vb2Jlma9PR0k+yMVmBgoNn95XI5fH1N184BgLlz5yI3N1f3k5hofjIkIiIiahhsFtw4OjoiMjISUVFRRtujoqLQp4/5IWS9e/c22X/r1q3o1q1bpfU2CoUCHh4eRj9ERETUcNm0W2rOnDlYvnw5VqxYgdjYWDz//PNISEjQzVszd+5cTJw4Ubf/tGnTcPXqVcyZMwexsbFYsWIFvv/+e7z44ou2OgUiIiKqY2y6/ML48eORmZmJ+fPnIyUlBe3bt8fmzZsRHh4OAEhJSUFCgn5a6YiICGzevBnPP/88vv76awQHB+PLL7+s9hw3RERE1PDZfIbi2sah4ERERPXPzVy/bT5aioiIiMiSGNwQERFRg8LghoiIiBoUBjdERETUoDC4ISIiogaFwQ0RERE1KAxuiIiIqEGx6SR+tqCd1oergxMREdUf2ut2dabnu+2Cm/z8fADg6uBERET1UH5+Pjw9Pavc57aboVij0SA5ORnu7u6QyWQWO25eXh7CwsKQmJjYIGc+bujnBzT8c2zo5wc0/HNs6OcHNPxzbOjnB1jvHCVJQn5+PoKDg2FnV3VVzW2XubGzs0NoaKjVjt/QVx5v6OcHNPxzbOjnBzT8c2zo5wc0/HNs6OcHWOccb5Sx0WJBMRERETUoDG6IiIioQWFwYyEKhQLz5s2DQqGwdVOsoqGfH9Dwz7Ghnx/Q8M+xoZ8f0PDPsaGfH1A3zvG2KygmIiKiho2ZGyIiImpQGNwQERFRg8LghoiIiBoUBjdERETUoDC4sYAlS5YgIiICTk5OiIyMxN69e23dpBp7++23IZPJjH4CAwN190uShLfffhvBwcFwdnbGoEGDcObMGRu2uGp79uzBPffcg+DgYMhkMvz5559G91fnfJRKJWbOnAk/Pz+4urri3nvvRVJSUi2eRdVudI6TJ082eU979epltE9dPscFCxage/fucHd3h7+/P+677z6cP3/eaJ/6/D5W5/zq+3u4dOlSdOzYUTepW+/evfHPP//o7q/P7x9w4/Or7+9fRQsWLIBMJsPs2bN12+rae8jg5hatXbsWs2fPxuuvv46YmBj0798fI0eOREJCgq2bVmPt2rVDSkqK7ufUqVO6+z7++GMsWrQIixcvxpEjRxAYGIg77rhDt2ZXXVNYWIhOnTph8eLFZu+vzvnMnj0bGzZswJo1a7Bv3z4UFBTg7rvvhlqtrq3TqNKNzhEARowYYfSebt682ej+unyOu3fvxvTp03Hw4EFERUWhrKwMw4cPR2FhoW6f+vw+Vuf8gPr9HoaGhuLDDz/E0aNHcfToUQwZMgSjR4/WXfzq8/sH3Pj8gPr9/hk6cuQIvv32W3Ts2NFoe517DyW6JT169JCmTZtmtK1169bSq6++aqMW3Zp58+ZJnTp1MnufRqORAgMDpQ8//FC3raSkRPL09JS++eabWmphzQGQNmzYoPu9OueTk5MjOTg4SGvWrNHtc+3aNcnOzk7asmVLrbW9uiqeoyRJ0qRJk6TRo0dX+pj6do7p6ekSAGn37t2SJDW897Hi+UlSw3sPJUmSvL29peXLlze4909Le36S1HDev/z8fKlFixZSVFSUNHDgQGnWrFmSJNXN/4PM3NwClUqF6OhoDB8+3Gj78OHDceDAARu16tbFxcUhODgYEREReOihh3D58mUAQHx8PFJTU43OV6FQYODAgfXyfKtzPtHR0SgtLTXaJzg4GO3bt69X57xr1y74+/ujZcuWePLJJ5Genq67r76dY25uLgDAx8cHQMN7Hyuen1ZDeQ/VajXWrFmDwsJC9O7du8G9fxXPT6shvH/Tp0/HXXfdhWHDhhltr4vv4W23cKYlZWRkQK1WIyAgwGh7QEAAUlNTbdSqW9OzZ0/89NNPaNmyJdLS0vDee++hT58+OHPmjO6czJ3v1atXbdHcW1Kd80lNTYWjoyO8vb1N9qkv7/HIkSPx4IMPIjw8HPHx8XjzzTcxZMgQREdHQ6FQ1KtzlCQJc+bMQb9+/dC+fXsADet9NHd+QMN4D0+dOoXevXujpKQEbm5u2LBhA9q2bau7sNX396+y8wMaxvu3Zs0aREdH4+jRoyb31cX/gwxuLEAmkxn9LkmSybb6YuTIkbrbHTp0QO/evdGsWTP8+OOPugK4hnS+QM3Opz6d8/jx43W327dvj27duiE8PBybNm3CmDFjKn1cXTzHGTNm4OTJk9i3b5/JfQ3hfazs/BrCe9iqVSscP34cOTk5+OOPPzBp0iTs3r1bd399f/8qO7+2bdvW+/cvMTERs2bNwtatW+Hk5FTpfnXpPWS31C3w8/ODvb29SdSZnp5uEsHWV66urujQoQPi4uJ0o6YayvlW53wCAwOhUqmQnZ1d6T71TVBQEMLDwxEXFweg/pzjzJkzsXHjRuzcuROhoaG67Q3lfazs/Mypj++ho6Mjmjdvjm7dumHBggXo1KkTvvjiiwbz/lV2fubUt/cvOjoa6enpiIyMhFwuh1wux+7du/Hll19CLpfr2liX3kMGN7fA0dERkZGRiIqKMtoeFRWFPn362KhVlqVUKhEbG4ugoCBEREQgMDDQ6HxVKhV2795dL8+3OucTGRkJBwcHo31SUlJw+vTpennOAJCZmYnExEQEBQUBqPvnKEkSZsyYgfXr12PHjh2IiIgwur++v483Oj9z6tt7aI4kSVAqlfX+/auM9vzMqW/v39ChQ3Hq1CkcP35c99OtWzc88sgjOH78OJo2bVr33kOLlyjfZtasWSM5ODhI33//vXT27Flp9uzZkqurq3TlyhVbN61GXnjhBWnXrl3S5cuXpYMHD0p333235O7urjufDz/8UPL09JTWr18vnTp1Snr44YeloKAgKS8vz8YtNy8/P1+KiYmRYmJiJADSokWLpJiYGOnq1auSJFXvfKZNmyaFhoZK27Ztk44dOyYNGTJE6tSpk1RWVmar0zJS1Tnm5+dLL7zwgnTgwAEpPj5e2rlzp9S7d28pJCSk3pzjM888I3l6ekq7du2SUlJSdD9FRUW6ferz+3ij82sI7+HcuXOlPXv2SPHx8dLJkyel1157TbKzs5O2bt0qSVL9fv8kqerzawjvnzmGo6Ukqe69hwxuLODrr7+WwsPDJUdHR6lr165GQzjrm/Hjx0tBQUGSg4ODFBwcLI0ZM0Y6c+aM7n6NRiPNmzdPCgwMlBQKhTRgwADp1KlTNmxx1Xbu3CkBMPmZNGmSJEnVO5/i4mJpxowZko+Pj+Ts7CzdfffdUkJCgg3OxryqzrGoqEgaPny41KhRI8nBwUFq3LixNGnSJJP21+VzNHduAKQffvhBt099fh9vdH4N4T184okndJ+RjRo1koYOHaoLbCSpfr9/klT1+TWE98+cisFNXXsPZZIkSZbPBxERERHZBmtuiIiIqEFhcENEREQNCoMbIiIialAY3BAREVGDwuCGiIiIGhQGN0RERNSgMLghIiKiBoXBDRERxKJ/f/75p62bQUQWwOCGiGxu8uTJkMlkJj8jRoywddOIqB6S27oBREQAMGLECPzwww9G2xQKhY1aQ0T1GTM3RFQnKBQKBAYGGv14e3sDEF1GS5cuxciRI+Hs7IyIiAisW7fO6PGnTp3CkCFD4OzsDF9fXzz11FMoKCgw2mfFihVo164dFAoFgoKCMGPGDKP7MzIycP/998PFxQUtWrTAxo0brXvSRGQVDG6IqF548803MXbsWJw4cQKPPvooHn74YcTGxgIAioqKMGLECHh7e+PIkSNYt24dtm3bZhS8LF26FNOnT8dTTz2FU6dOYePGjWjevLnRc7zzzjsYN24cTp48iVGjRuGRRx5BVlZWrZ4nEVmAVZbjJCK6CZMmTZLs7e0lV1dXo5/58+dLkiRWzp42bZrRY3r27Ck988wzkiRJ0rfffit5e3tLBQUFuvs3bdok2dnZSampqZIkSVJwcLD0+uuvV9oGANIbb7yh+72goECSyWTSP//8Y7HzJKLawZobIqoTBg8ejKVLlxpt8/Hx0d3u3bu30X29e/fG8ePHAQCxsbHo1KkTXF1ddff37dsXGo0G58+fh0wmQ3JyMoYOHVplGzp27Ki77erqCnd3d6Snp9f0lIjIRhjcEFGd4OrqatJNdCMymQwAIEmS7ra5fZydnat1PAcHB5PHajSam2oTEdkea26IqF44ePCgye+tW7cGALRt2xbHjx9HYWGh7v79+/fDzs4OLVu2hLu7O5o0aYLt27fXapuJyDaYuSGiOkGpVCI1NdVom1wuh5+fHwBg3bp16NatG/r164dVq1bh8OHD+P777wEAjzzyCObNm4dJkybh7bffxvXr1zFz5kw89thjCAgIAAC8/fbbmDZtGvz9/TFy5Ejk5+dj//79mDlzZu2eKBFZHYMbIqoTtmzZgqCgIKNtrVq1wrlz5wCIkUxr1qzBs88+i8DAQKxatQpt27YFALi4uODff//FrFmz0L17d7i4uGDs2LFYtGiR7liTJk1CSUkJPvvsM7z44ovw8/PDAw88UHsnSES1RiZJkmTrRhARVUUmk2HDhg247777bN0UIqoHWHNDREREDQqDGyIiImpQWHNDRHUee8+J6GYwc0NEREQNCoMbIiIialAY3BAREVGDwuCGiIiIGhQGN0RERNSgMLghIiKiBoXBDRERETUoDG6IiIioQWFwQ0RERA3K/wHcPgd2nDJv4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(train_eva_df,'Train','Epoch','Loss',['loss','accuracy'])\n",
    "plot_graph(test_eva_df,'Test','Epoch','Loss',['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d02ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
