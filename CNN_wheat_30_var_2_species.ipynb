{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c4fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35daa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6aebd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'wheat_30_var_2_species.csv'\n",
    "\n",
    "def dir(file_name):\n",
    "    return '../data/'+file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a19daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_X_Y(dataframe):\n",
    "    return (dataframe.drop('classes', axis =1), dataframe.loc[:,'classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "554bc6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class filter_method(Enum):\n",
    "    none = 0\n",
    "    snv = 1\n",
    "    msc = 2\n",
    "    savgol = 3\n",
    "\n",
    "FILT = 2\n",
    "FILTER = filter_method(FILT).name\n",
    "\n",
    "# to be set if filter chosen is savgol\n",
    "WINDOW = 7\n",
    "ORDER = 2\n",
    "DERIVATIVE = 1\n",
    "\n",
    "#will be used for test dataset in msc\n",
    "reference= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c20231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def create_test_train(X, y, test_size = 0.2, shuffle = True):\n",
    "    return train_test_split(X,y, test_size = test_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e9301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Normal Variate\n",
    "def snv(input_data):\n",
    "  \n",
    "    # Define a new array and populate it with the corrected data  \n",
    "    output_data = np.zeros_like(input_data)\n",
    "    for i in range(input_data.shape[0]):\n",
    " \n",
    "        # Apply correction\n",
    "        output_data[i,:] = (input_data[i,:] - np.mean(input_data[i,:])) / np.std(input_data[i,:])\n",
    " \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d925acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicative scatter correction\n",
    "def msc(input_data, reference=None):\n",
    "#     print(reference)\n",
    "    ''' Perform Multiplicative scatter correction'''\n",
    "\n",
    "    # Baseline correction\n",
    "    for i in range(input_data.shape[0]):\n",
    "        input_data[i,:] -= input_data[i,:].mean()\n",
    "\n",
    "    # Get the reference spectrum. If not given, estimate from the mean    \n",
    "    if reference is None:    \n",
    "        # Calculate mean\n",
    "        matm = np.mean(input_data, axis=0)\n",
    "    else:\n",
    "        matm = reference\n",
    "\n",
    "    # Define a new data matrix and populate it with the corrected data    \n",
    "    output_data = np.zeros_like(input_data)\n",
    "    for i in range(input_data.shape[0]):\n",
    "        # Run regression\n",
    "        fit = np.polyfit(matm, input_data[i,:], 1, full=True)\n",
    "        # Apply correction\n",
    "        output_data[i,:] = (input_data[i,:] - fit[0][1]) / fit[0][0] \n",
    "\n",
    "    return (output_data, matm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b5090be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter, general_gaussian\n",
    "def savgol(input_data):\n",
    "    w = WINDOW\n",
    "    p = ORDER\n",
    "    d = DERIVATIVE\n",
    "    \n",
    "    output_data = savgol_filter(np.array(input_data), w, polyorder = p, deriv=d)\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b68affd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X,y, type=\"train\"):\n",
    "    if FILTER == \"snv\":\n",
    "        return {\"X\": snv(np.array(X)), \"y\": y}\n",
    "    elif FILTER == \"msc\":\n",
    "        msc_output = msc(np.array(X), reference = reference if type==\"test\" else None)\n",
    "        X = msc_output[0]\n",
    "        ref = msc_output[1]\n",
    "        return {\n",
    "            \"X\": X,\n",
    "            \"y\": y,\n",
    "            \"ref\": ref\n",
    "        }\n",
    "    elif FILTER == \"savgol\":\n",
    "        return {\n",
    "            \"X\": savgol(X),\n",
    "            \"y\": y\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"X\":X,\n",
    "            \"y\":y\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8dec1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(dir(file_name))\n",
    "X,y = seperate_X_Y(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58535347",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_set = set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e8c8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_CLASSES = len(y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd357e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = create_test_train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f79eb839",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_results = preprocess_data(X_train_raw,y_train_raw)\n",
    "X_train, y_train = preprocessed_results[\"X\"], preprocessed_results[\"y\"]\n",
    "\n",
    "if FILTER == \"msc\":\n",
    "    reference = preprocessed_results[\"ref\"]\n",
    "    \n",
    "preprocessed_results_test = preprocess_data(X_test_raw, y_test_raw, type=\"test\")\n",
    "X_test, y_test = preprocessed_results_test[\"X\"], preprocessed_results_test[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e1e570e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48384, 147, 1)\n",
      "(12096, 147, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec820add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Input, Conv1D, Flatten, Dense, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba682707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(input_shape,num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=5, input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=5))\n",
    "    model.add(Conv1D(filters=64, kernel_size=5))\n",
    "    model.add(MaxPooling1D(pool_size=5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(800, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d95ace51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(X_train.shape[1:],NUM_OF_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33a0377c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 143, 32)           192       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 28, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 24, 64)            10304     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 4, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              257000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 800)               800800    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 1602      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069,898\n",
      "Trainable params: 1,069,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20cd1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva = []\n",
    "test_eva = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fd5eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dataframe = pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "863f63f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  1\n",
      "378/378 - 16s - loss: 0.6238 - accuracy: 0.6460 - 16s/epoch - 43ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.5882 - accuracy: 0.6911\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.5872 - accuracy: 0.6953\n",
      "\n",
      "Epoch:  2\n",
      "378/378 - 14s - loss: 0.5537 - accuracy: 0.7193 - 14s/epoch - 38ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.4111 - accuracy: 0.8385\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.4095 - accuracy: 0.8425\n",
      "\n",
      "Epoch:  3\n",
      "378/378 - 12s - loss: 0.3337 - accuracy: 0.8521 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.2809 - accuracy: 0.8780\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.2804 - accuracy: 0.8777\n",
      "\n",
      "Epoch:  4\n",
      "378/378 - 12s - loss: 0.2887 - accuracy: 0.8737 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.2451 - accuracy: 0.8949\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.2451 - accuracy: 0.8953\n",
      "\n",
      "Epoch:  5\n",
      "378/378 - 12s - loss: 0.2638 - accuracy: 0.8846 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.2716 - accuracy: 0.8805\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.2741 - accuracy: 0.8792\n",
      "\n",
      "Epoch:  6\n",
      "378/378 - 12s - loss: 0.2440 - accuracy: 0.8952 - 12s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.2237 - accuracy: 0.9043\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.2242 - accuracy: 0.9041\n",
      "\n",
      "Epoch:  7\n",
      "378/378 - 12s - loss: 0.2302 - accuracy: 0.9009 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.2042 - accuracy: 0.9140\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.2030 - accuracy: 0.9144\n",
      "\n",
      "Epoch:  8\n",
      "378/378 - 13s - loss: 0.2198 - accuracy: 0.9067 - 13s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.1937 - accuracy: 0.9187\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1931 - accuracy: 0.9196\n",
      "\n",
      "Epoch:  9\n",
      "378/378 - 12s - loss: 0.2132 - accuracy: 0.9102 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.2416 - accuracy: 0.8956\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.2384 - accuracy: 0.8953\n",
      "\n",
      "Epoch:  10\n",
      "378/378 - 18s - loss: 0.1974 - accuracy: 0.9170 - 18s/epoch - 47ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.2202 - accuracy: 0.9026\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.2152 - accuracy: 0.9057\n",
      "\n",
      "Epoch:  11\n",
      "378/378 - 15s - loss: 0.1931 - accuracy: 0.9193 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.1888 - accuracy: 0.9179\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1849 - accuracy: 0.9203\n",
      "\n",
      "Epoch:  12\n",
      "378/378 - 14s - loss: 0.1879 - accuracy: 0.9214 - 14s/epoch - 38ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1798 - accuracy: 0.9232\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1768 - accuracy: 0.9247\n",
      "\n",
      "Epoch:  13\n",
      "378/378 - 13s - loss: 0.1861 - accuracy: 0.9211 - 13s/epoch - 35ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.1622 - accuracy: 0.9321\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1629 - accuracy: 0.9340\n",
      "\n",
      "Epoch:  14\n",
      "378/378 - 13s - loss: 0.1788 - accuracy: 0.9227 - 13s/epoch - 34ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1608 - accuracy: 0.9324\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1610 - accuracy: 0.9346\n",
      "\n",
      "Epoch:  15\n",
      "378/378 - 14s - loss: 0.1791 - accuracy: 0.9257 - 14s/epoch - 37ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.1647 - accuracy: 0.9303\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1660 - accuracy: 0.9318\n",
      "\n",
      "Epoch:  16\n",
      "378/378 - 16s - loss: 0.1749 - accuracy: 0.9267 - 16s/epoch - 43ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1548 - accuracy: 0.9361\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1554 - accuracy: 0.9377\n",
      "\n",
      "Epoch:  17\n",
      "378/378 - 13s - loss: 0.1716 - accuracy: 0.9275 - 13s/epoch - 34ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1654 - accuracy: 0.9319\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1673 - accuracy: 0.9317\n",
      "\n",
      "Epoch:  18\n",
      "378/378 - 12s - loss: 0.1701 - accuracy: 0.9273 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.1468 - accuracy: 0.9392\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1471 - accuracy: 0.9396\n",
      "\n",
      "Epoch:  19\n",
      "378/378 - 12s - loss: 0.1625 - accuracy: 0.9308 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.1595 - accuracy: 0.9331\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1600 - accuracy: 0.9336\n",
      "\n",
      "Epoch:  20\n",
      "378/378 - 12s - loss: 0.1627 - accuracy: 0.9316 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.1414 - accuracy: 0.9402\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1424 - accuracy: 0.9409\n",
      "\n",
      "Epoch:  21\n",
      "378/378 - 12s - loss: 0.1610 - accuracy: 0.9325 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1524 - accuracy: 0.9368\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1505 - accuracy: 0.9392\n",
      "\n",
      "Epoch:  22\n",
      "378/378 - 12s - loss: 0.1501 - accuracy: 0.9373 - 12s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1504 - accuracy: 0.9370\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1515 - accuracy: 0.9371\n",
      "\n",
      "Epoch:  23\n",
      "378/378 - 13s - loss: 0.1568 - accuracy: 0.9343 - 13s/epoch - 34ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1293 - accuracy: 0.9461\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1303 - accuracy: 0.9475\n",
      "\n",
      "Epoch:  24\n",
      "378/378 - 12s - loss: 0.1497 - accuracy: 0.9371 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.1507 - accuracy: 0.9372\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1529 - accuracy: 0.9364\n",
      "\n",
      "Epoch:  25\n",
      "378/378 - 13s - loss: 0.1481 - accuracy: 0.9389 - 13s/epoch - 35ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1902 - accuracy: 0.9187\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1896 - accuracy: 0.9195\n",
      "\n",
      "Epoch:  26\n",
      "378/378 - 12s - loss: 0.1443 - accuracy: 0.9406 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1232 - accuracy: 0.9493\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1263 - accuracy: 0.9498\n",
      "\n",
      "Epoch:  27\n",
      "378/378 - 12s - loss: 0.1455 - accuracy: 0.9377 - 12s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1276 - accuracy: 0.9473\n",
      "for testing\n",
      "378/378 [==============================] - 5s 13ms/step - loss: 0.1296 - accuracy: 0.9484\n",
      "\n",
      "Epoch:  28\n",
      "378/378 - 14s - loss: 0.1414 - accuracy: 0.9411 - 14s/epoch - 37ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.1447 - accuracy: 0.9385\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1448 - accuracy: 0.9392\n",
      "\n",
      "Epoch:  29\n",
      "378/378 - 12s - loss: 0.1393 - accuracy: 0.9426 - 12s/epoch - 31ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.1292 - accuracy: 0.9473\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1277 - accuracy: 0.9472\n",
      "\n",
      "Epoch:  30\n",
      "378/378 - 13s - loss: 0.1311 - accuracy: 0.9460 - 13s/epoch - 35ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.1287 - accuracy: 0.9472\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1281 - accuracy: 0.9513\n",
      "\n",
      "Epoch:  31\n",
      "378/378 - 12s - loss: 0.1354 - accuracy: 0.9443 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1211 - accuracy: 0.9500\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1234 - accuracy: 0.9502\n",
      "\n",
      "Epoch:  32\n",
      "378/378 - 12s - loss: 0.1350 - accuracy: 0.9449 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1423 - accuracy: 0.9412\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1425 - accuracy: 0.9434\n",
      "\n",
      "Epoch:  33\n",
      "378/378 - 12s - loss: 0.1325 - accuracy: 0.9461 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1186 - accuracy: 0.9515\n",
      "for testing\n",
      "378/378 [==============================] - 2s 7ms/step - loss: 0.1208 - accuracy: 0.9502\n",
      "\n",
      "Epoch:  34\n",
      "378/378 - 12s - loss: 0.1305 - accuracy: 0.9466 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1136 - accuracy: 0.9543\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1147 - accuracy: 0.9544\n",
      "\n",
      "Epoch:  35\n",
      "378/378 - 12s - loss: 0.1304 - accuracy: 0.9456 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1178 - accuracy: 0.9513\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1184 - accuracy: 0.9534\n",
      "\n",
      "Epoch:  36\n",
      "378/378 - 12s - loss: 0.1290 - accuracy: 0.9468 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1171 - accuracy: 0.9518\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1170 - accuracy: 0.9532\n",
      "\n",
      "Epoch:  37\n",
      "378/378 - 12s - loss: 0.1241 - accuracy: 0.9482 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.1083 - accuracy: 0.9565\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1081 - accuracy: 0.9570\n",
      "\n",
      "Epoch:  38\n",
      "378/378 - 12s - loss: 0.1254 - accuracy: 0.9487 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1707 - accuracy: 0.9273\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1700 - accuracy: 0.9288\n",
      "\n",
      "Epoch:  39\n",
      "378/378 - 12s - loss: 0.1243 - accuracy: 0.9488 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1172 - accuracy: 0.9520\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1199 - accuracy: 0.9521\n",
      "\n",
      "Epoch:  40\n",
      "378/378 - 12s - loss: 0.1207 - accuracy: 0.9514 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.1047 - accuracy: 0.9572\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1064 - accuracy: 0.9587\n",
      "\n",
      "Epoch:  41\n",
      "378/378 - 13s - loss: 0.1163 - accuracy: 0.9525 - 13s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1133 - accuracy: 0.9535\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1166 - accuracy: 0.9527\n",
      "\n",
      "Epoch:  42\n",
      "378/378 - 15s - loss: 0.1143 - accuracy: 0.9531 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0986 - accuracy: 0.9622\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0985 - accuracy: 0.9625\n",
      "\n",
      "Epoch:  43\n",
      "378/378 - 12s - loss: 0.1141 - accuracy: 0.9535 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1088 - accuracy: 0.9554\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1127 - accuracy: 0.9547\n",
      "\n",
      "Epoch:  44\n",
      "378/378 - 12s - loss: 0.1160 - accuracy: 0.9515 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.1276 - accuracy: 0.9476\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1311 - accuracy: 0.9487\n",
      "\n",
      "Epoch:  45\n",
      "378/378 - 12s - loss: 0.1183 - accuracy: 0.9526 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1030 - accuracy: 0.9586\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1049 - accuracy: 0.9592\n",
      "\n",
      "Epoch:  46\n",
      "378/378 - 12s - loss: 0.1098 - accuracy: 0.9557 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0948 - accuracy: 0.9628\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0987 - accuracy: 0.9632\n",
      "\n",
      "Epoch:  47\n",
      "378/378 - 12s - loss: 0.1164 - accuracy: 0.9524 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1101 - accuracy: 0.9550\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1128 - accuracy: 0.9540\n",
      "\n",
      "Epoch:  48\n",
      "378/378 - 12s - loss: 0.1124 - accuracy: 0.9543 - 12s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1008 - accuracy: 0.9600\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1064 - accuracy: 0.9579\n",
      "\n",
      "Epoch:  49\n",
      "378/378 - 12s - loss: 0.1093 - accuracy: 0.9561 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0951 - accuracy: 0.9615\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0981 - accuracy: 0.9605\n",
      "\n",
      "Epoch:  50\n",
      "378/378 - 12s - loss: 0.1041 - accuracy: 0.9583 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0953 - accuracy: 0.9626\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0988 - accuracy: 0.9625\n",
      "\n",
      "Epoch:  51\n",
      "378/378 - 12s - loss: 0.1108 - accuracy: 0.9557 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0965 - accuracy: 0.9612\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0999 - accuracy: 0.9607\n",
      "\n",
      "Epoch:  52\n",
      "378/378 - 12s - loss: 0.1042 - accuracy: 0.9579 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0888 - accuracy: 0.9648\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0936 - accuracy: 0.9653\n",
      "\n",
      "Epoch:  53\n",
      "378/378 - 12s - loss: 0.1057 - accuracy: 0.9564 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0885 - accuracy: 0.9649\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0933 - accuracy: 0.9643\n",
      "\n",
      "Epoch:  54\n",
      "378/378 - 12s - loss: 0.1009 - accuracy: 0.9598 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1073 - accuracy: 0.9573\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1142 - accuracy: 0.9544\n",
      "\n",
      "Epoch:  55\n",
      "378/378 - 12s - loss: 0.1011 - accuracy: 0.9594 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1004 - accuracy: 0.9589\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1028 - accuracy: 0.9614\n",
      "\n",
      "Epoch:  56\n",
      "378/378 - 12s - loss: 0.0998 - accuracy: 0.9603 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0961 - accuracy: 0.9618\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1021 - accuracy: 0.9590\n",
      "\n",
      "Epoch:  57\n",
      "378/378 - 12s - loss: 0.0955 - accuracy: 0.9618 - 12s/epoch - 31ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1138 - accuracy: 0.9541\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1179 - accuracy: 0.9542\n",
      "\n",
      "Epoch:  58\n",
      "378/378 - 12s - loss: 0.0951 - accuracy: 0.9623 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0771 - accuracy: 0.9703\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0810 - accuracy: 0.9702\n",
      "\n",
      "Epoch:  59\n",
      "378/378 - 12s - loss: 0.0964 - accuracy: 0.9610 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0804 - accuracy: 0.9685\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0846 - accuracy: 0.9683\n",
      "\n",
      "Epoch:  60\n",
      "378/378 - 12s - loss: 0.0935 - accuracy: 0.9627 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0880 - accuracy: 0.9642\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0928 - accuracy: 0.9645\n",
      "\n",
      "Epoch:  61\n",
      "378/378 - 12s - loss: 0.0931 - accuracy: 0.9637 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0751 - accuracy: 0.9714\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0788 - accuracy: 0.9718\n",
      "\n",
      "Epoch:  62\n",
      "378/378 - 12s - loss: 0.0897 - accuracy: 0.9641 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0935 - accuracy: 0.9641\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0981 - accuracy: 0.9644\n",
      "\n",
      "Epoch:  63\n",
      "378/378 - 12s - loss: 0.0910 - accuracy: 0.9643 - 12s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0907 - accuracy: 0.9639\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0951 - accuracy: 0.9626\n",
      "\n",
      "Epoch:  64\n",
      "378/378 - 12s - loss: 0.0953 - accuracy: 0.9619 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0769 - accuracy: 0.9700\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0824 - accuracy: 0.9692\n",
      "\n",
      "Epoch:  65\n",
      "378/378 - 12s - loss: 0.0883 - accuracy: 0.9657 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0940 - accuracy: 0.9622\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0993 - accuracy: 0.9619\n",
      "\n",
      "Epoch:  66\n",
      "378/378 - 12s - loss: 0.0860 - accuracy: 0.9665 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0936 - accuracy: 0.9621\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0990 - accuracy: 0.9623\n",
      "\n",
      "Epoch:  67\n",
      "378/378 - 12s - loss: 0.0840 - accuracy: 0.9662 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0719 - accuracy: 0.9722\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0783 - accuracy: 0.9692\n",
      "\n",
      "Epoch:  68\n",
      "378/378 - 12s - loss: 0.0867 - accuracy: 0.9659 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0912 - accuracy: 0.9636\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0974 - accuracy: 0.9615\n",
      "\n",
      "Epoch:  69\n",
      "378/378 - 12s - loss: 0.0896 - accuracy: 0.9651 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0764 - accuracy: 0.9700\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0851 - accuracy: 0.9680\n",
      "\n",
      "Epoch:  70\n",
      "378/378 - 12s - loss: 0.0828 - accuracy: 0.9671 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0881 - accuracy: 0.9646\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0948 - accuracy: 0.9640\n",
      "\n",
      "Epoch:  71\n",
      "378/378 - 12s - loss: 0.0822 - accuracy: 0.9679 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0713 - accuracy: 0.9727\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0767 - accuracy: 0.9707\n",
      "\n",
      "Epoch:  72\n",
      "378/378 - 12s - loss: 0.0818 - accuracy: 0.9683 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0711 - accuracy: 0.9727\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0775 - accuracy: 0.9721\n",
      "\n",
      "Epoch:  73\n",
      "378/378 - 12s - loss: 0.0830 - accuracy: 0.9680 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0812 - accuracy: 0.9683\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0919 - accuracy: 0.9637\n",
      "\n",
      "Epoch:  74\n",
      "378/378 - 12s - loss: 0.0793 - accuracy: 0.9695 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0778 - accuracy: 0.9696\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0849 - accuracy: 0.9662\n",
      "\n",
      "Epoch:  75\n",
      "378/378 - 12s - loss: 0.0852 - accuracy: 0.9664 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0768 - accuracy: 0.9704\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0831 - accuracy: 0.9696\n",
      "\n",
      "Epoch:  76\n",
      "378/378 - 12s - loss: 0.0795 - accuracy: 0.9690 - 12s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0697 - accuracy: 0.9734\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0773 - accuracy: 0.9710\n",
      "\n",
      "Epoch:  77\n",
      "378/378 - 15s - loss: 0.0801 - accuracy: 0.9692 - 15s/epoch - 39ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1139 - accuracy: 0.9548\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1202 - accuracy: 0.9521\n",
      "\n",
      "Epoch:  78\n",
      "378/378 - 12s - loss: 0.0767 - accuracy: 0.9708 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0627 - accuracy: 0.9766\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0701 - accuracy: 0.9746\n",
      "\n",
      "Epoch:  79\n",
      "378/378 - 12s - loss: 0.0784 - accuracy: 0.9700 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0651 - accuracy: 0.9748\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0714 - accuracy: 0.9735\n",
      "\n",
      "Epoch:  80\n",
      "378/378 - 12s - loss: 0.0722 - accuracy: 0.9712 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0604 - accuracy: 0.9771\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0667 - accuracy: 0.9761\n",
      "\n",
      "Epoch:  81\n",
      "378/378 - 12s - loss: 0.0734 - accuracy: 0.9716 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0821 - accuracy: 0.9665\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0898 - accuracy: 0.9645\n",
      "\n",
      "Epoch:  82\n",
      "378/378 - 12s - loss: 0.0742 - accuracy: 0.9710 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0666 - accuracy: 0.9739\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0710 - accuracy: 0.9735\n",
      "\n",
      "Epoch:  83\n",
      "378/378 - 12s - loss: 0.0778 - accuracy: 0.9699 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0644 - accuracy: 0.9755\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0693 - accuracy: 0.9744\n",
      "\n",
      "Epoch:  84\n",
      "378/378 - 12s - loss: 0.0730 - accuracy: 0.9720 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0608 - accuracy: 0.9766\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0717 - accuracy: 0.9727\n",
      "\n",
      "Epoch:  85\n",
      "378/378 - 12s - loss: 0.0662 - accuracy: 0.9745 - 12s/epoch - 31ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0991 - accuracy: 0.9609\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1086 - accuracy: 0.9575\n",
      "\n",
      "Epoch:  86\n",
      "378/378 - 12s - loss: 0.0726 - accuracy: 0.9718 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0817 - accuracy: 0.9680\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0929 - accuracy: 0.9638\n",
      "\n",
      "Epoch:  87\n",
      "378/378 - 12s - loss: 0.0656 - accuracy: 0.9754 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0647 - accuracy: 0.9754\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0715 - accuracy: 0.9734\n",
      "\n",
      "Epoch:  88\n",
      "378/378 - 12s - loss: 0.0728 - accuracy: 0.9713 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0727 - accuracy: 0.9714\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0815 - accuracy: 0.9696\n",
      "\n",
      "Epoch:  89\n",
      "378/378 - 12s - loss: 0.0706 - accuracy: 0.9727 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0628 - accuracy: 0.9758\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0703 - accuracy: 0.9730\n",
      "\n",
      "Epoch:  90\n",
      "378/378 - 12s - loss: 0.0695 - accuracy: 0.9733 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0591 - accuracy: 0.9774\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0700 - accuracy: 0.9744\n",
      "\n",
      "Epoch:  91\n",
      "378/378 - 12s - loss: 0.0630 - accuracy: 0.9759 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0616 - accuracy: 0.9763\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0684 - accuracy: 0.9740\n",
      "\n",
      "Epoch:  92\n",
      "378/378 - 12s - loss: 0.0655 - accuracy: 0.9745 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0497 - accuracy: 0.9827\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0588 - accuracy: 0.9786\n",
      "\n",
      "Epoch:  93\n",
      "378/378 - 12s - loss: 0.0652 - accuracy: 0.9754 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0522 - accuracy: 0.9806\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0581 - accuracy: 0.9801\n",
      "\n",
      "Epoch:  94\n",
      "378/378 - 12s - loss: 0.0662 - accuracy: 0.9742 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0499 - accuracy: 0.9812\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0584 - accuracy: 0.9788\n",
      "\n",
      "Epoch:  95\n",
      "378/378 - 12s - loss: 0.0663 - accuracy: 0.9748 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0579 - accuracy: 0.9773\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0682 - accuracy: 0.9737\n",
      "\n",
      "Epoch:  96\n",
      "378/378 - 12s - loss: 0.0629 - accuracy: 0.9757 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0517 - accuracy: 0.9810\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0587 - accuracy: 0.9796\n",
      "\n",
      "Epoch:  97\n",
      "378/378 - 12s - loss: 0.0678 - accuracy: 0.9744 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0547 - accuracy: 0.9782\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0657 - accuracy: 0.9755\n",
      "\n",
      "Epoch:  98\n",
      "378/378 - 12s - loss: 0.0602 - accuracy: 0.9769 - 12s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0577 - accuracy: 0.9784\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0653 - accuracy: 0.9763\n",
      "\n",
      "Epoch:  99\n",
      "378/378 - 12s - loss: 0.0681 - accuracy: 0.9743 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0701 - accuracy: 0.9720\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0809 - accuracy: 0.9693\n",
      "\n",
      "Epoch:  100\n",
      "378/378 - 12s - loss: 0.0637 - accuracy: 0.9755 - 12s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0547 - accuracy: 0.9786\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0640 - accuracy: 0.9769\n",
      "\n",
      "Epoch:  101\n",
      "378/378 - 12s - loss: 0.0624 - accuracy: 0.9757 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0515 - accuracy: 0.9817\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0568 - accuracy: 0.9803\n",
      "\n",
      "Epoch:  102\n",
      "378/378 - 12s - loss: 0.0583 - accuracy: 0.9774 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0535 - accuracy: 0.9794\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0638 - accuracy: 0.9766\n",
      "\n",
      "Epoch:  103\n",
      "378/378 - 12s - loss: 0.0607 - accuracy: 0.9774 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0563 - accuracy: 0.9791\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0633 - accuracy: 0.9782\n",
      "\n",
      "Epoch:  104\n",
      "378/378 - 12s - loss: 0.0609 - accuracy: 0.9769 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0680 - accuracy: 0.9742\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0744 - accuracy: 0.9728\n",
      "\n",
      "Epoch:  105\n",
      "378/378 - 12s - loss: 0.0591 - accuracy: 0.9776 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0630 - accuracy: 0.9759\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0734 - accuracy: 0.9735\n",
      "\n",
      "Epoch:  106\n",
      "378/378 - 12s - loss: 0.0565 - accuracy: 0.9786 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0471 - accuracy: 0.9827\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0573 - accuracy: 0.9786\n",
      "\n",
      "Epoch:  107\n",
      "378/378 - 12s - loss: 0.0601 - accuracy: 0.9770 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0525 - accuracy: 0.9803\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0638 - accuracy: 0.9770\n",
      "\n",
      "Epoch:  108\n",
      "378/378 - 12s - loss: 0.0555 - accuracy: 0.9791 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0511 - accuracy: 0.9807\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0584 - accuracy: 0.9789\n",
      "\n",
      "Epoch:  109\n",
      "378/378 - 12s - loss: 0.0570 - accuracy: 0.9780 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0447 - accuracy: 0.9830\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0547 - accuracy: 0.9806\n",
      "\n",
      "Epoch:  110\n",
      "378/378 - 12s - loss: 0.0565 - accuracy: 0.9787 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0730 - accuracy: 0.9721\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0810 - accuracy: 0.9688\n",
      "\n",
      "Epoch:  111\n",
      "378/378 - 12s - loss: 0.0579 - accuracy: 0.9786 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0434 - accuracy: 0.9839\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0516 - accuracy: 0.9810\n",
      "\n",
      "Epoch:  112\n",
      "378/378 - 13s - loss: 0.0605 - accuracy: 0.9767 - 13s/epoch - 35ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0521 - accuracy: 0.9800\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0632 - accuracy: 0.9755\n",
      "\n",
      "Epoch:  113\n",
      "378/378 - 18s - loss: 0.0552 - accuracy: 0.9788 - 18s/epoch - 47ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0426 - accuracy: 0.9847\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0509 - accuracy: 0.9812\n",
      "\n",
      "Epoch:  114\n",
      "378/378 - 12s - loss: 0.0513 - accuracy: 0.9805 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0674 - accuracy: 0.9745\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0796 - accuracy: 0.9701\n",
      "\n",
      "Epoch:  115\n",
      "378/378 - 12s - loss: 0.0546 - accuracy: 0.9799 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0424 - accuracy: 0.9850\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0492 - accuracy: 0.9817\n",
      "\n",
      "Epoch:  116\n",
      "378/378 - 12s - loss: 0.0525 - accuracy: 0.9804 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0400 - accuracy: 0.9858\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0498 - accuracy: 0.9811\n",
      "\n",
      "Epoch:  117\n",
      "378/378 - 10s - loss: 0.0531 - accuracy: 0.9804 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0485 - accuracy: 0.9809\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0572 - accuracy: 0.9794\n",
      "\n",
      "Epoch:  118\n",
      "378/378 - 11s - loss: 0.0524 - accuracy: 0.9800 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0626 - accuracy: 0.9760\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0768 - accuracy: 0.9715\n",
      "\n",
      "Epoch:  119\n",
      "378/378 - 11s - loss: 0.0572 - accuracy: 0.9788 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0630 - accuracy: 0.9750\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0676 - accuracy: 0.9730\n",
      "\n",
      "Epoch:  120\n",
      "378/378 - 11s - loss: 0.0501 - accuracy: 0.9807 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0399 - accuracy: 0.9859\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0475 - accuracy: 0.9833\n",
      "\n",
      "Epoch:  121\n",
      "378/378 - 11s - loss: 0.0532 - accuracy: 0.9799 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0499 - accuracy: 0.9809\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0593 - accuracy: 0.9773\n",
      "\n",
      "Epoch:  122\n",
      "378/378 - 11s - loss: 0.0513 - accuracy: 0.9803 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0485 - accuracy: 0.9816\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0547 - accuracy: 0.9796\n",
      "\n",
      "Epoch:  123\n",
      "378/378 - 10s - loss: 0.0562 - accuracy: 0.9781 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0515 - accuracy: 0.9800\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0630 - accuracy: 0.9763\n",
      "\n",
      "Epoch:  124\n",
      "378/378 - 11s - loss: 0.0504 - accuracy: 0.9813 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0498 - accuracy: 0.9815\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0596 - accuracy: 0.9780\n",
      "\n",
      "Epoch:  125\n",
      "378/378 - 11s - loss: 0.0471 - accuracy: 0.9823 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0455 - accuracy: 0.9825\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0552 - accuracy: 0.9804\n",
      "\n",
      "Epoch:  126\n",
      "378/378 - 11s - loss: 0.0451 - accuracy: 0.9833 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0357 - accuracy: 0.9871\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0452 - accuracy: 0.9836\n",
      "\n",
      "Epoch:  127\n",
      "378/378 - 11s - loss: 0.0486 - accuracy: 0.9815 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0485 - accuracy: 0.9810\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0609 - accuracy: 0.9790\n",
      "\n",
      "Epoch:  128\n",
      "378/378 - 11s - loss: 0.0468 - accuracy: 0.9824 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0424 - accuracy: 0.9841\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0492 - accuracy: 0.9814\n",
      "\n",
      "Epoch:  129\n",
      "378/378 - 11s - loss: 0.0495 - accuracy: 0.9804 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0481 - accuracy: 0.9818\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0614 - accuracy: 0.9776\n",
      "\n",
      "Epoch:  130\n",
      "378/378 - 11s - loss: 0.0507 - accuracy: 0.9802 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0428 - accuracy: 0.9841\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0547 - accuracy: 0.9793\n",
      "\n",
      "Epoch:  131\n",
      "378/378 - 10s - loss: 0.0472 - accuracy: 0.9818 - 10s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0585 - accuracy: 0.9774\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0649 - accuracy: 0.9764\n",
      "\n",
      "Epoch:  132\n",
      "378/378 - 11s - loss: 0.0474 - accuracy: 0.9824 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0424 - accuracy: 0.9833\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0526 - accuracy: 0.9804\n",
      "\n",
      "Epoch:  133\n",
      "378/378 - 13s - loss: 0.0472 - accuracy: 0.9820 - 13s/epoch - 35ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0417 - accuracy: 0.9841\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0505 - accuracy: 0.9815\n",
      "\n",
      "Epoch:  134\n",
      "378/378 - 11s - loss: 0.0476 - accuracy: 0.9823 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0409 - accuracy: 0.9850\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0503 - accuracy: 0.9815\n",
      "\n",
      "Epoch:  135\n",
      "378/378 - 11s - loss: 0.0457 - accuracy: 0.9829 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0536 - accuracy: 0.9791\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0601 - accuracy: 0.9762\n",
      "\n",
      "Epoch:  136\n",
      "378/378 - 11s - loss: 0.0519 - accuracy: 0.9806 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0364 - accuracy: 0.9864\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0473 - accuracy: 0.9829\n",
      "\n",
      "Epoch:  137\n",
      "378/378 - 11s - loss: 0.0450 - accuracy: 0.9833 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0377 - accuracy: 0.9861\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0466 - accuracy: 0.9826\n",
      "\n",
      "Epoch:  138\n",
      "378/378 - 11s - loss: 0.0463 - accuracy: 0.9827 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0341 - accuracy: 0.9874\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0429 - accuracy: 0.9848\n",
      "\n",
      "Epoch:  139\n",
      "378/378 - 10s - loss: 0.0462 - accuracy: 0.9824 - 10s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0488 - accuracy: 0.9807\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0594 - accuracy: 0.9775\n",
      "\n",
      "Epoch:  140\n",
      "378/378 - 10s - loss: 0.0414 - accuracy: 0.9841 - 10s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0342 - accuracy: 0.9869\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0447 - accuracy: 0.9840\n",
      "\n",
      "Epoch:  141\n",
      "378/378 - 10s - loss: 0.0467 - accuracy: 0.9824 - 10s/epoch - 27ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0355 - accuracy: 0.9869\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0443 - accuracy: 0.9837\n",
      "\n",
      "Epoch:  142\n",
      "378/378 - 10s - loss: 0.0434 - accuracy: 0.9839 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0350 - accuracy: 0.9873\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0451 - accuracy: 0.9835\n",
      "\n",
      "Epoch:  143\n",
      "378/378 - 11s - loss: 0.0428 - accuracy: 0.9843 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0323 - accuracy: 0.9887\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0395 - accuracy: 0.9857\n",
      "\n",
      "Epoch:  144\n",
      "378/378 - 11s - loss: 0.0404 - accuracy: 0.9853 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0503 - accuracy: 0.9804\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0586 - accuracy: 0.9784\n",
      "\n",
      "Epoch:  145\n",
      "378/378 - 12s - loss: 0.0489 - accuracy: 0.9811 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0391 - accuracy: 0.9857\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0470 - accuracy: 0.9826\n",
      "\n",
      "Epoch:  146\n",
      "378/378 - 12s - loss: 0.0416 - accuracy: 0.9846 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0470 - accuracy: 0.9818\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0622 - accuracy: 0.9769\n",
      "\n",
      "Epoch:  147\n",
      "378/378 - 11s - loss: 0.0423 - accuracy: 0.9837 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0503 - accuracy: 0.9810\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0581 - accuracy: 0.9792\n",
      "\n",
      "Epoch:  148\n",
      "378/378 - 12s - loss: 0.0391 - accuracy: 0.9850 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0325 - accuracy: 0.9883\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0404 - accuracy: 0.9851\n",
      "\n",
      "Epoch:  149\n",
      "378/378 - 12s - loss: 0.0489 - accuracy: 0.9816 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0424 - accuracy: 0.9838\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0509 - accuracy: 0.9814\n",
      "\n",
      "Epoch:  150\n",
      "378/378 - 12s - loss: 0.0403 - accuracy: 0.9851 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0327 - accuracy: 0.9878\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0398 - accuracy: 0.9850\n",
      "\n",
      "Epoch:  151\n",
      "378/378 - 12s - loss: 0.0397 - accuracy: 0.9854 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0357 - accuracy: 0.9870\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0470 - accuracy: 0.9834\n",
      "\n",
      "Epoch:  152\n",
      "378/378 - 13s - loss: 0.0386 - accuracy: 0.9861 - 13s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0457 - accuracy: 0.9823\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0554 - accuracy: 0.9788\n",
      "\n",
      "Epoch:  153\n",
      "378/378 - 13s - loss: 0.0433 - accuracy: 0.9837 - 13s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0322 - accuracy: 0.9875\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0442 - accuracy: 0.9850\n",
      "\n",
      "Epoch:  154\n",
      "378/378 - 11s - loss: 0.0376 - accuracy: 0.9854 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0453 - accuracy: 0.9825\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0590 - accuracy: 0.9786\n",
      "\n",
      "Epoch:  155\n",
      "378/378 - 13s - loss: 0.0439 - accuracy: 0.9834 - 13s/epoch - 34ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0499 - accuracy: 0.9800\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0574 - accuracy: 0.9788\n",
      "\n",
      "Epoch:  156\n",
      "378/378 - 10s - loss: 0.0391 - accuracy: 0.9855 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0307 - accuracy: 0.9887\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0404 - accuracy: 0.9847\n",
      "\n",
      "Epoch:  157\n",
      "378/378 - 10s - loss: 0.0377 - accuracy: 0.9856 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0482 - accuracy: 0.9810\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0629 - accuracy: 0.9762\n",
      "\n",
      "Epoch:  158\n",
      "378/378 - 11s - loss: 0.0388 - accuracy: 0.9853 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0360 - accuracy: 0.9867\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0460 - accuracy: 0.9830\n",
      "\n",
      "Epoch:  159\n",
      "378/378 - 11s - loss: 0.0407 - accuracy: 0.9847 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0307 - accuracy: 0.9885\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0425 - accuracy: 0.9848\n",
      "\n",
      "Epoch:  160\n",
      "378/378 - 12s - loss: 0.0374 - accuracy: 0.9859 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0294 - accuracy: 0.9891\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0399 - accuracy: 0.9851\n",
      "\n",
      "Epoch:  161\n",
      "378/378 - 11s - loss: 0.0370 - accuracy: 0.9861 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0346 - accuracy: 0.9866\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0476 - accuracy: 0.9819\n",
      "\n",
      "Epoch:  162\n",
      "378/378 - 12s - loss: 0.0392 - accuracy: 0.9856 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0271 - accuracy: 0.9900\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0381 - accuracy: 0.9857\n",
      "\n",
      "Epoch:  163\n",
      "378/378 - 11s - loss: 0.0350 - accuracy: 0.9865 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0325 - accuracy: 0.9872\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0464 - accuracy: 0.9836\n",
      "\n",
      "Epoch:  164\n",
      "378/378 - 12s - loss: 0.0371 - accuracy: 0.9863 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0826 - accuracy: 0.9701\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0914 - accuracy: 0.9679\n",
      "\n",
      "Epoch:  165\n",
      "378/378 - 11s - loss: 0.0352 - accuracy: 0.9868 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0366 - accuracy: 0.9858\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0506 - accuracy: 0.9812\n",
      "\n",
      "Epoch:  166\n",
      "378/378 - 10s - loss: 0.0337 - accuracy: 0.9876 - 10s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0255 - accuracy: 0.9906\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0366 - accuracy: 0.9870\n",
      "\n",
      "Epoch:  167\n",
      "378/378 - 12s - loss: 0.0370 - accuracy: 0.9864 - 12s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0297 - accuracy: 0.9895\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0411 - accuracy: 0.9853\n",
      "\n",
      "Epoch:  168\n",
      "378/378 - 11s - loss: 0.0355 - accuracy: 0.9867 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0305 - accuracy: 0.9890\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0441 - accuracy: 0.9848\n",
      "\n",
      "Epoch:  169\n",
      "378/378 - 11s - loss: 0.0374 - accuracy: 0.9857 - 11s/epoch - 28ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0620 - accuracy: 0.9758\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0804 - accuracy: 0.9720\n",
      "\n",
      "Epoch:  170\n",
      "378/378 - 10s - loss: 0.0346 - accuracy: 0.9869 - 10s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0292 - accuracy: 0.9888\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0454 - accuracy: 0.9859\n",
      "\n",
      "Epoch:  171\n",
      "378/378 - 12s - loss: 0.0354 - accuracy: 0.9869 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0299 - accuracy: 0.9883\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0463 - accuracy: 0.9840\n",
      "\n",
      "Epoch:  172\n",
      "378/378 - 11s - loss: 0.0356 - accuracy: 0.9863 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0325 - accuracy: 0.9876\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0449 - accuracy: 0.9836\n",
      "\n",
      "Epoch:  173\n",
      "378/378 - 11s - loss: 0.0339 - accuracy: 0.9871 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0351 - accuracy: 0.9859\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0461 - accuracy: 0.9838\n",
      "\n",
      "Epoch:  174\n",
      "378/378 - 11s - loss: 0.0351 - accuracy: 0.9864 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0418 - accuracy: 0.9834\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0541 - accuracy: 0.9802\n",
      "\n",
      "Epoch:  175\n",
      "378/378 - 11s - loss: 0.0331 - accuracy: 0.9879 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0307 - accuracy: 0.9880\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0452 - accuracy: 0.9836\n",
      "\n",
      "Epoch:  176\n",
      "378/378 - 10s - loss: 0.0366 - accuracy: 0.9858 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0292 - accuracy: 0.9890\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0394 - accuracy: 0.9854\n",
      "\n",
      "Epoch:  177\n",
      "378/378 - 10s - loss: 0.0334 - accuracy: 0.9871 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0249 - accuracy: 0.9905\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0358 - accuracy: 0.9875\n",
      "\n",
      "Epoch:  178\n",
      "378/378 - 10s - loss: 0.0309 - accuracy: 0.9885 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0460 - accuracy: 0.9825\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0551 - accuracy: 0.9797\n",
      "\n",
      "Epoch:  179\n",
      "378/378 - 11s - loss: 0.0322 - accuracy: 0.9877 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0399 - accuracy: 0.9849\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0531 - accuracy: 0.9816\n",
      "\n",
      "Epoch:  180\n",
      "378/378 - 10s - loss: 0.0357 - accuracy: 0.9867 - 10s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0265 - accuracy: 0.9901\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0396 - accuracy: 0.9857\n",
      "\n",
      "Epoch:  181\n",
      "378/378 - 11s - loss: 0.0332 - accuracy: 0.9877 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0364 - accuracy: 0.9860\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0446 - accuracy: 0.9845\n",
      "\n",
      "Epoch:  182\n",
      "378/378 - 10s - loss: 0.0329 - accuracy: 0.9868 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0343 - accuracy: 0.9865\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0484 - accuracy: 0.9828\n",
      "\n",
      "Epoch:  183\n",
      "378/378 - 10s - loss: 0.0325 - accuracy: 0.9879 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0255 - accuracy: 0.9907\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0362 - accuracy: 0.9862\n",
      "\n",
      "Epoch:  184\n",
      "378/378 - 11s - loss: 0.0322 - accuracy: 0.9878 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0274 - accuracy: 0.9892\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0405 - accuracy: 0.9860\n",
      "\n",
      "Epoch:  185\n",
      "378/378 - 11s - loss: 0.0352 - accuracy: 0.9864 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0316 - accuracy: 0.9876\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0444 - accuracy: 0.9826\n",
      "\n",
      "Epoch:  186\n",
      "378/378 - 11s - loss: 0.0300 - accuracy: 0.9888 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0287 - accuracy: 0.9893\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0404 - accuracy: 0.9846\n",
      "\n",
      "Epoch:  187\n",
      "378/378 - 11s - loss: 0.0313 - accuracy: 0.9882 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 6ms/step - loss: 0.0255 - accuracy: 0.9906\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0425 - accuracy: 0.9850\n",
      "\n",
      "Epoch:  188\n",
      "378/378 - 14s - loss: 0.0322 - accuracy: 0.9878 - 14s/epoch - 36ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0343 - accuracy: 0.9865\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0446 - accuracy: 0.9831\n",
      "\n",
      "Epoch:  189\n",
      "378/378 - 11s - loss: 0.0315 - accuracy: 0.9879 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0234 - accuracy: 0.9918\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0354 - accuracy: 0.9869\n",
      "\n",
      "Epoch:  190\n",
      "378/378 - 13s - loss: 0.0307 - accuracy: 0.9884 - 13s/epoch - 35ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0247 - accuracy: 0.9912\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0399 - accuracy: 0.9852\n",
      "\n",
      "Epoch:  191\n",
      "378/378 - 15s - loss: 0.0327 - accuracy: 0.9871 - 15s/epoch - 41ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0208 - accuracy: 0.9927\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0325 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  192\n",
      "378/378 - 14s - loss: 0.0306 - accuracy: 0.9888 - 14s/epoch - 36ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0279 - accuracy: 0.9895\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0417 - accuracy: 0.9860\n",
      "\n",
      "Epoch:  193\n",
      "378/378 - 16s - loss: 0.0285 - accuracy: 0.9894 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0239 - accuracy: 0.9916\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0362 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  194\n",
      "378/378 - 14s - loss: 0.0307 - accuracy: 0.9888 - 14s/epoch - 37ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0552 - accuracy: 0.9782\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0673 - accuracy: 0.9731\n",
      "\n",
      "Epoch:  195\n",
      "378/378 - 12s - loss: 0.0289 - accuracy: 0.9887 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0236 - accuracy: 0.9907\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0399 - accuracy: 0.9862\n",
      "\n",
      "Epoch:  196\n",
      "378/378 - 13s - loss: 0.0270 - accuracy: 0.9896 - 13s/epoch - 34ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0306 - accuracy: 0.9878\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0458 - accuracy: 0.9837\n",
      "\n",
      "Epoch:  197\n",
      "378/378 - 14s - loss: 0.0314 - accuracy: 0.9878 - 14s/epoch - 37ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0354 - accuracy: 0.9867\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0499 - accuracy: 0.9807\n",
      "\n",
      "Epoch:  198\n",
      "378/378 - 16s - loss: 0.0295 - accuracy: 0.9889 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0184 - accuracy: 0.9936\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0320 - accuracy: 0.9886\n",
      "\n",
      "Epoch:  199\n",
      "378/378 - 15s - loss: 0.0281 - accuracy: 0.9896 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0224 - accuracy: 0.9917\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0361 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  200\n",
      "378/378 - 14s - loss: 0.0294 - accuracy: 0.9890 - 14s/epoch - 37ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0343 - accuracy: 0.9861\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0522 - accuracy: 0.9816\n",
      "\n",
      "Epoch:  201\n",
      "378/378 - 16s - loss: 0.0291 - accuracy: 0.9888 - 16s/epoch - 43ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0237 - accuracy: 0.9911\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0367 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  202\n",
      "378/378 - 15s - loss: 0.0281 - accuracy: 0.9898 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0205 - accuracy: 0.9922\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0350 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  203\n",
      "378/378 - 15s - loss: 0.0279 - accuracy: 0.9897 - 15s/epoch - 39ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0198 - accuracy: 0.9928\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0323 - accuracy: 0.9887\n",
      "\n",
      "Epoch:  204\n",
      "378/378 - 14s - loss: 0.0299 - accuracy: 0.9885 - 14s/epoch - 38ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0203 - accuracy: 0.9932\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0317 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  205\n",
      "378/378 - 12s - loss: 0.0306 - accuracy: 0.9886 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0223 - accuracy: 0.9919\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0343 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  206\n",
      "378/378 - 11s - loss: 0.0286 - accuracy: 0.9895 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0233 - accuracy: 0.9913\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0354 - accuracy: 0.9879\n",
      "\n",
      "Epoch:  207\n",
      "378/378 - 11s - loss: 0.0266 - accuracy: 0.9896 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0275 - accuracy: 0.9892\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0364 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  208\n",
      "378/378 - 12s - loss: 0.0312 - accuracy: 0.9881 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0417 - accuracy: 0.9844\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0578 - accuracy: 0.9797\n",
      "\n",
      "Epoch:  209\n",
      "378/378 - 12s - loss: 0.0249 - accuracy: 0.9908 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0219 - accuracy: 0.9918\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0373 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  210\n",
      "378/378 - 13s - loss: 0.0280 - accuracy: 0.9897 - 13s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0229 - accuracy: 0.9910\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0374 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  211\n",
      "378/378 - 12s - loss: 0.0261 - accuracy: 0.9906 - 12s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0188 - accuracy: 0.9932\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0317 - accuracy: 0.9887\n",
      "\n",
      "Epoch:  212\n",
      "378/378 - 12s - loss: 0.0269 - accuracy: 0.9896 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0228 - accuracy: 0.9915\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0377 - accuracy: 0.9865\n",
      "\n",
      "Epoch:  213\n",
      "378/378 - 13s - loss: 0.0269 - accuracy: 0.9898 - 13s/epoch - 35ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0371 - accuracy: 0.9856\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0607 - accuracy: 0.9807\n",
      "\n",
      "Epoch:  214\n",
      "378/378 - 15s - loss: 0.0265 - accuracy: 0.9897 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0195 - accuracy: 0.9928\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0335 - accuracy: 0.9892\n",
      "\n",
      "Epoch:  215\n",
      "378/378 - 10s - loss: 0.0298 - accuracy: 0.9888 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0175 - accuracy: 0.9935\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0326 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  216\n",
      "378/378 - 11s - loss: 0.0263 - accuracy: 0.9899 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0211 - accuracy: 0.9922\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0343 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  217\n",
      "378/378 - 12s - loss: 0.0272 - accuracy: 0.9897 - 12s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0305 - accuracy: 0.9882\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0428 - accuracy: 0.9849\n",
      "\n",
      "Epoch:  218\n",
      "378/378 - 12s - loss: 0.0239 - accuracy: 0.9911 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0171 - accuracy: 0.9939\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0289 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  219\n",
      "378/378 - 11s - loss: 0.0241 - accuracy: 0.9911 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0225 - accuracy: 0.9915\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0344 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  220\n",
      "378/378 - 12s - loss: 0.0253 - accuracy: 0.9908 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0184 - accuracy: 0.9932\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0319 - accuracy: 0.9889\n",
      "\n",
      "Epoch:  221\n",
      "378/378 - 11s - loss: 0.0269 - accuracy: 0.9896 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0299 - accuracy: 0.9880\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0489 - accuracy: 0.9834\n",
      "\n",
      "Epoch:  222\n",
      "378/378 - 10s - loss: 0.0228 - accuracy: 0.9913 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0274 - accuracy: 0.9895\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0400 - accuracy: 0.9851\n",
      "\n",
      "Epoch:  223\n",
      "378/378 - 10s - loss: 0.0252 - accuracy: 0.9902 - 10s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0350 - accuracy: 0.9862\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0495 - accuracy: 0.9827\n",
      "\n",
      "Epoch:  224\n",
      "378/378 - 10s - loss: 0.0239 - accuracy: 0.9909 - 10s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0195 - accuracy: 0.9925\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0382 - accuracy: 0.9863\n",
      "\n",
      "Epoch:  225\n",
      "378/378 - 11s - loss: 0.0277 - accuracy: 0.9895 - 11s/epoch - 30ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0174 - accuracy: 0.9937\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0319 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  226\n",
      "378/378 - 11s - loss: 0.0241 - accuracy: 0.9907 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0299 - accuracy: 0.9878\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0477 - accuracy: 0.9830\n",
      "\n",
      "Epoch:  227\n",
      "378/378 - 11s - loss: 0.0229 - accuracy: 0.9914 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0292 - accuracy: 0.9887\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0444 - accuracy: 0.9847\n",
      "\n",
      "Epoch:  228\n",
      "378/378 - 11s - loss: 0.0230 - accuracy: 0.9912 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0139 - accuracy: 0.9954\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0281 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  229\n",
      "378/378 - 11s - loss: 0.0246 - accuracy: 0.9910 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0166 - accuracy: 0.9938\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0318 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  230\n",
      "378/378 - 11s - loss: 0.0206 - accuracy: 0.9919 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0188 - accuracy: 0.9930\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0313 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  231\n",
      "378/378 - 10s - loss: 0.0267 - accuracy: 0.9900 - 10s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0288 - accuracy: 0.9892\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0426 - accuracy: 0.9845\n",
      "\n",
      "Epoch:  232\n",
      "378/378 - 10s - loss: 0.0255 - accuracy: 0.9902 - 10s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0411 - accuracy: 0.9841\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0590 - accuracy: 0.9798\n",
      "\n",
      "Epoch:  233\n",
      "378/378 - 11s - loss: 0.0216 - accuracy: 0.9919 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0173 - accuracy: 0.9936\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0323 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  234\n",
      "378/378 - 10s - loss: 0.0267 - accuracy: 0.9898 - 10s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0192 - accuracy: 0.9927\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0377 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  235\n",
      "378/378 - 11s - loss: 0.0212 - accuracy: 0.9918 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0181 - accuracy: 0.9930\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0357 - accuracy: 0.9875\n",
      "\n",
      "Epoch:  236\n",
      "378/378 - 11s - loss: 0.0253 - accuracy: 0.9908 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0197 - accuracy: 0.9926\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0354 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  237\n",
      "378/378 - 16s - loss: 0.0240 - accuracy: 0.9907 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0168 - accuracy: 0.9936\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0318 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  238\n",
      "378/378 - 13s - loss: 0.0215 - accuracy: 0.9916 - 13s/epoch - 34ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0237 - accuracy: 0.9908\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0346 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  239\n",
      "378/378 - 11s - loss: 0.0222 - accuracy: 0.9916 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0430 - accuracy: 0.9829\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0609 - accuracy: 0.9789\n",
      "\n",
      "Epoch:  240\n",
      "378/378 - 11s - loss: 0.0246 - accuracy: 0.9908 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0245 - accuracy: 0.9906\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0395 - accuracy: 0.9869\n",
      "\n",
      "Epoch:  241\n",
      "378/378 - 11s - loss: 0.0202 - accuracy: 0.9926 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0212 - accuracy: 0.9917\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0369 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  242\n",
      "378/378 - 13s - loss: 0.0214 - accuracy: 0.9919 - 13s/epoch - 34ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0204 - accuracy: 0.9918\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0361 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  243\n",
      "378/378 - 11s - loss: 0.0196 - accuracy: 0.9929 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0146 - accuracy: 0.9948\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0269 - accuracy: 0.9894\n",
      "\n",
      "Epoch:  244\n",
      "378/378 - 11s - loss: 0.0273 - accuracy: 0.9898 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0218 - accuracy: 0.9916\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0383 - accuracy: 0.9877\n",
      "\n",
      "Epoch:  245\n",
      "378/378 - 13s - loss: 0.0218 - accuracy: 0.9919 - 13s/epoch - 35ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0146 - accuracy: 0.9945\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0279 - accuracy: 0.9904\n",
      "\n",
      "Epoch:  246\n",
      "378/378 - 13s - loss: 0.0208 - accuracy: 0.9919 - 13s/epoch - 34ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 6ms/step - loss: 0.0204 - accuracy: 0.9918\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0388 - accuracy: 0.9862\n",
      "\n",
      "Epoch:  247\n",
      "378/378 - 13s - loss: 0.0217 - accuracy: 0.9919 - 13s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0147 - accuracy: 0.9945\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0304 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  248\n",
      "378/378 - 12s - loss: 0.0238 - accuracy: 0.9912 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0118 - accuracy: 0.9958\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0261 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  249\n",
      "378/378 - 11s - loss: 0.0169 - accuracy: 0.9937 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0228 - accuracy: 0.9914\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0362 - accuracy: 0.9862\n",
      "\n",
      "Epoch:  250\n",
      "378/378 - 11s - loss: 0.0209 - accuracy: 0.9921 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0172 - accuracy: 0.9937\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0314 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  251\n",
      "378/378 - 11s - loss: 0.0220 - accuracy: 0.9919 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0194 - accuracy: 0.9928\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0340 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  252\n",
      "378/378 - 11s - loss: 0.0232 - accuracy: 0.9910 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0120 - accuracy: 0.9960\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0257 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  253\n",
      "378/378 - 11s - loss: 0.0246 - accuracy: 0.9905 - 11s/epoch - 29ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0370 - accuracy: 0.9857\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0582 - accuracy: 0.9812\n",
      "\n",
      "Epoch:  254\n",
      "378/378 - 13s - loss: 0.0218 - accuracy: 0.9918 - 13s/epoch - 35ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0169 - accuracy: 0.9939\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0300 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  255\n",
      "378/378 - 11s - loss: 0.0202 - accuracy: 0.9921 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0114 - accuracy: 0.9960\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0251 - accuracy: 0.9912\n",
      "\n",
      "Epoch:  256\n",
      "378/378 - 11s - loss: 0.0154 - accuracy: 0.9946 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0157 - accuracy: 0.9942\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0288 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  257\n",
      "378/378 - 11s - loss: 0.0194 - accuracy: 0.9932 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0117 - accuracy: 0.9960\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0254 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  258\n",
      "378/378 - 11s - loss: 0.0248 - accuracy: 0.9907 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0420 - accuracy: 0.9832\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0574 - accuracy: 0.9811\n",
      "\n",
      "Epoch:  259\n",
      "378/378 - 12s - loss: 0.0234 - accuracy: 0.9912 - 12s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0154 - accuracy: 0.9948\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0304 - accuracy: 0.9894\n",
      "\n",
      "Epoch:  260\n",
      "378/378 - 12s - loss: 0.0159 - accuracy: 0.9942 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0194 - accuracy: 0.9925\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0350 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  261\n",
      "378/378 - 12s - loss: 0.0210 - accuracy: 0.9920 - 12s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0161 - accuracy: 0.9939\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0321 - accuracy: 0.9889\n",
      "\n",
      "Epoch:  262\n",
      "378/378 - 13s - loss: 0.0232 - accuracy: 0.9909 - 13s/epoch - 34ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0119 - accuracy: 0.9958\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0271 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  263\n",
      "378/378 - 13s - loss: 0.0166 - accuracy: 0.9940 - 13s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0149 - accuracy: 0.9942\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0298 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  264\n",
      "378/378 - 11s - loss: 0.0186 - accuracy: 0.9928 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0181 - accuracy: 0.9928\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0321 - accuracy: 0.9887\n",
      "\n",
      "Epoch:  265\n",
      "378/378 - 12s - loss: 0.0184 - accuracy: 0.9930 - 12s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0108 - accuracy: 0.9964\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0256 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  266\n",
      "378/378 - 11s - loss: 0.0193 - accuracy: 0.9927 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0118 - accuracy: 0.9957\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0268 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  267\n",
      "378/378 - 11s - loss: 0.0178 - accuracy: 0.9933 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0205 - accuracy: 0.9923\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0361 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  268\n",
      "378/378 - 12s - loss: 0.0165 - accuracy: 0.9940 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0130 - accuracy: 0.9954\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0288 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  269\n",
      "378/378 - 11s - loss: 0.0187 - accuracy: 0.9930 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0114 - accuracy: 0.9961\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0260 - accuracy: 0.9912\n",
      "\n",
      "Epoch:  270\n",
      "378/378 - 12s - loss: 0.0241 - accuracy: 0.9909 - 12s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0190 - accuracy: 0.9923\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0373 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  271\n",
      "378/378 - 11s - loss: 0.0174 - accuracy: 0.9936 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0178 - accuracy: 0.9932\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0369 - accuracy: 0.9869\n",
      "\n",
      "Epoch:  272\n",
      "378/378 - 11s - loss: 0.0161 - accuracy: 0.9940 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0220 - accuracy: 0.9917\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0422 - accuracy: 0.9853\n",
      "\n",
      "Epoch:  273\n",
      "378/378 - 11s - loss: 0.0170 - accuracy: 0.9937 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0476 - accuracy: 0.9817\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0669 - accuracy: 0.9782\n",
      "\n",
      "Epoch:  274\n",
      "378/378 - 11s - loss: 0.0208 - accuracy: 0.9919 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0288 - accuracy: 0.9882\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0545 - accuracy: 0.9820\n",
      "\n",
      "Epoch:  275\n",
      "378/378 - 11s - loss: 0.0182 - accuracy: 0.9932 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0209 - accuracy: 0.9917\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0431 - accuracy: 0.9861\n",
      "\n",
      "Epoch:  276\n",
      "378/378 - 12s - loss: 0.0184 - accuracy: 0.9932 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0207 - accuracy: 0.9927\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0402 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  277\n",
      "378/378 - 12s - loss: 0.0187 - accuracy: 0.9930 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0196 - accuracy: 0.9926\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0327 - accuracy: 0.9879\n",
      "\n",
      "Epoch:  278\n",
      "378/378 - 16s - loss: 0.0189 - accuracy: 0.9924 - 16s/epoch - 43ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0140 - accuracy: 0.9948\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0300 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  279\n",
      "378/378 - 11s - loss: 0.0173 - accuracy: 0.9935 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0085 - accuracy: 0.9970\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0261 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  280\n",
      "378/378 - 12s - loss: 0.0155 - accuracy: 0.9942 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0122 - accuracy: 0.9956\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0314 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  281\n",
      "378/378 - 12s - loss: 0.0194 - accuracy: 0.9927 - 12s/epoch - 31ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0140 - accuracy: 0.9944\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0324 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  282\n",
      "378/378 - 12s - loss: 0.0150 - accuracy: 0.9944 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0111 - accuracy: 0.9959\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0304 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  283\n",
      "378/378 - 11s - loss: 0.0185 - accuracy: 0.9928 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0254 - accuracy: 0.9902\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0417 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  284\n",
      "378/378 - 11s - loss: 0.0147 - accuracy: 0.9946 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0309 - accuracy: 0.9878\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0560 - accuracy: 0.9808\n",
      "\n",
      "Epoch:  285\n",
      "378/378 - 13s - loss: 0.0167 - accuracy: 0.9939 - 13s/epoch - 35ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0142 - accuracy: 0.9942\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0361 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  286\n",
      "378/378 - 12s - loss: 0.0203 - accuracy: 0.9922 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0111 - accuracy: 0.9961\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0306 - accuracy: 0.9889\n",
      "\n",
      "Epoch:  287\n",
      "378/378 - 12s - loss: 0.0138 - accuracy: 0.9949 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0137 - accuracy: 0.9948\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0302 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  288\n",
      "378/378 - 12s - loss: 0.0191 - accuracy: 0.9929 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0096 - accuracy: 0.9968\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0251 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  289\n",
      "378/378 - 11s - loss: 0.0128 - accuracy: 0.9953 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0144 - accuracy: 0.9952\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0295 - accuracy: 0.9894\n",
      "\n",
      "Epoch:  290\n",
      "378/378 - 11s - loss: 0.0182 - accuracy: 0.9931 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0447 - accuracy: 0.9860\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0643 - accuracy: 0.9814\n",
      "\n",
      "Epoch:  291\n",
      "378/378 - 12s - loss: 0.0169 - accuracy: 0.9937 - 12s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0172 - accuracy: 0.9932\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0380 - accuracy: 0.9863\n",
      "\n",
      "Epoch:  292\n",
      "378/378 - 15s - loss: 0.0168 - accuracy: 0.9939 - 15s/epoch - 39ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0077 - accuracy: 0.9977\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0253 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  293\n",
      "378/378 - 12s - loss: 0.0131 - accuracy: 0.9951 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0262 - accuracy: 0.9898\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0465 - accuracy: 0.9849\n",
      "\n",
      "Epoch:  294\n",
      "378/378 - 12s - loss: 0.0170 - accuracy: 0.9942 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0130 - accuracy: 0.9949\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0316 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  295\n",
      "378/378 - 11s - loss: 0.0165 - accuracy: 0.9933 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0107 - accuracy: 0.9964\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0321 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  296\n",
      "378/378 - 11s - loss: 0.0223 - accuracy: 0.9920 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0166 - accuracy: 0.9932\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0404 - accuracy: 0.9869\n",
      "\n",
      "Epoch:  297\n",
      "378/378 - 12s - loss: 0.0166 - accuracy: 0.9939 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0087 - accuracy: 0.9971\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0239 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  298\n",
      "378/378 - 11s - loss: 0.0123 - accuracy: 0.9956 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0106 - accuracy: 0.9963\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0299 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  299\n",
      "378/378 - 12s - loss: 0.0175 - accuracy: 0.9933 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0122 - accuracy: 0.9962\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0306 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  300\n",
      "378/378 - 11s - loss: 0.0141 - accuracy: 0.9949 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0167 - accuracy: 0.9937\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0334 - accuracy: 0.9886\n",
      "\n",
      "Epoch:  301\n",
      "378/378 - 12s - loss: 0.0174 - accuracy: 0.9935 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 6ms/step - loss: 0.0146 - accuracy: 0.9945\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0381 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  302\n",
      "378/378 - 13s - loss: 0.0151 - accuracy: 0.9941 - 13s/epoch - 34ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0202 - accuracy: 0.9919\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0416 - accuracy: 0.9852\n",
      "\n",
      "Epoch:  303\n",
      "378/378 - 11s - loss: 0.0165 - accuracy: 0.9942 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0147 - accuracy: 0.9942\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0324 - accuracy: 0.9894\n",
      "\n",
      "Epoch:  304\n",
      "378/378 - 11s - loss: 0.0157 - accuracy: 0.9940 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0184 - accuracy: 0.9933\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0437 - accuracy: 0.9848\n",
      "\n",
      "Epoch:  305\n",
      "378/378 - 12s - loss: 0.0137 - accuracy: 0.9946 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0131 - accuracy: 0.9952\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0317 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  306\n",
      "378/378 - 12s - loss: 0.0146 - accuracy: 0.9945 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.0165 - accuracy: 0.9937\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0324 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  307\n",
      "378/378 - 12s - loss: 0.0169 - accuracy: 0.9933 - 12s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0327 - accuracy: 0.9872\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0544 - accuracy: 0.9835\n",
      "\n",
      "Epoch:  308\n",
      "378/378 - 11s - loss: 0.0160 - accuracy: 0.9940 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0418 - accuracy: 0.9846\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0608 - accuracy: 0.9819\n",
      "\n",
      "Epoch:  309\n",
      "378/378 - 21s - loss: 0.0148 - accuracy: 0.9946 - 21s/epoch - 56ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0386 - accuracy: 0.9856\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0616 - accuracy: 0.9797\n",
      "\n",
      "Epoch:  310\n",
      "378/378 - 16s - loss: 0.0138 - accuracy: 0.9948 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0144 - accuracy: 0.9945\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0351 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  311\n",
      "378/378 - 16s - loss: 0.0170 - accuracy: 0.9939 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0143 - accuracy: 0.9946\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0329 - accuracy: 0.9894\n",
      "\n",
      "Epoch:  312\n",
      "378/378 - 16s - loss: 0.0162 - accuracy: 0.9938 - 16s/epoch - 43ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0158 - accuracy: 0.9941\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0330 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  313\n",
      "378/378 - 15s - loss: 0.0139 - accuracy: 0.9949 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0103 - accuracy: 0.9965\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0261 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  314\n",
      "378/378 - 16s - loss: 0.0132 - accuracy: 0.9947 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0212 - accuracy: 0.9914\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0388 - accuracy: 0.9867\n",
      "\n",
      "Epoch:  315\n",
      "378/378 - 20s - loss: 0.0142 - accuracy: 0.9947 - 20s/epoch - 53ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0101 - accuracy: 0.9961\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0317 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  316\n",
      "378/378 - 15s - loss: 0.0134 - accuracy: 0.9946 - 15s/epoch - 41ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0079 - accuracy: 0.9972\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0279 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  317\n",
      "378/378 - 15s - loss: 0.0134 - accuracy: 0.9954 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0109 - accuracy: 0.9962\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0257 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  318\n",
      "378/378 - 15s - loss: 0.0152 - accuracy: 0.9943 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0120 - accuracy: 0.9955\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0325 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  319\n",
      "378/378 - 15s - loss: 0.0156 - accuracy: 0.9943 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0168 - accuracy: 0.9931\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0372 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  320\n",
      "378/378 - 16s - loss: 0.0109 - accuracy: 0.9962 - 16s/epoch - 41ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0143 - accuracy: 0.9945\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0395 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  321\n",
      "378/378 - 16s - loss: 0.0151 - accuracy: 0.9941 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0098 - accuracy: 0.9961\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0375 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  322\n",
      "378/378 - 16s - loss: 0.0148 - accuracy: 0.9946 - 16s/epoch - 41ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0064 - accuracy: 0.9980\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0269 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  323\n",
      "378/378 - 16s - loss: 0.0125 - accuracy: 0.9955 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0140 - accuracy: 0.9948\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0319 - accuracy: 0.9904\n",
      "\n",
      "Epoch:  324\n",
      "378/378 - 16s - loss: 0.0138 - accuracy: 0.9952 - 16s/epoch - 41ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0216 - accuracy: 0.9911\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0510 - accuracy: 0.9849\n",
      "\n",
      "Epoch:  325\n",
      "378/378 - 15s - loss: 0.0152 - accuracy: 0.9943 - 15s/epoch - 39ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0116 - accuracy: 0.9958\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0309 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  326\n",
      "378/378 - 15s - loss: 0.0114 - accuracy: 0.9959 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0068 - accuracy: 0.9976\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0283 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  327\n",
      "378/378 - 15s - loss: 0.0097 - accuracy: 0.9962 - 15s/epoch - 41ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0059 - accuracy: 0.9981\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0257 - accuracy: 0.9918\n",
      "\n",
      "Epoch:  328\n",
      "378/378 - 15s - loss: 0.0174 - accuracy: 0.9933 - 15s/epoch - 39ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0360 - accuracy: 0.9860\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0575 - accuracy: 0.9821\n",
      "\n",
      "Epoch:  329\n",
      "378/378 - 15s - loss: 0.0149 - accuracy: 0.9943 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0171 - accuracy: 0.9939\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0418 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  330\n",
      "378/378 - 15s - loss: 0.0118 - accuracy: 0.9954 - 15s/epoch - 41ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0098 - accuracy: 0.9963\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0292 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  331\n",
      "378/378 - 15s - loss: 0.0101 - accuracy: 0.9962 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0113 - accuracy: 0.9955\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0348 - accuracy: 0.9902\n",
      "\n",
      "Epoch:  332\n",
      "378/378 - 15s - loss: 0.0119 - accuracy: 0.9953 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0174 - accuracy: 0.9938\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0335 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  333\n",
      "378/378 - 16s - loss: 0.0095 - accuracy: 0.9965 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0065 - accuracy: 0.9978\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0309 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  334\n",
      "378/378 - 15s - loss: 0.0201 - accuracy: 0.9927 - 15s/epoch - 41ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0101 - accuracy: 0.9956\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0369 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  335\n",
      "378/378 - 16s - loss: 0.0104 - accuracy: 0.9963 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0165 - accuracy: 0.9936\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0362 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  336\n",
      "378/378 - 16s - loss: 0.0139 - accuracy: 0.9946 - 16s/epoch - 43ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0071 - accuracy: 0.9978\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0234 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  337\n",
      "378/378 - 18s - loss: 0.0103 - accuracy: 0.9961 - 18s/epoch - 47ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0113 - accuracy: 0.9959\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0319 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  338\n",
      "378/378 - 16s - loss: 0.0134 - accuracy: 0.9948 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0183 - accuracy: 0.9927\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0400 - accuracy: 0.9866\n",
      "\n",
      "Epoch:  339\n",
      "378/378 - 16s - loss: 0.0102 - accuracy: 0.9962 - 16s/epoch - 43ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0059 - accuracy: 0.9980\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0291 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  340\n",
      "378/378 - 16s - loss: 0.0135 - accuracy: 0.9951 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0086 - accuracy: 0.9970\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.0248 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  341\n",
      "378/378 - 20s - loss: 0.0117 - accuracy: 0.9959 - 20s/epoch - 53ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0238 - accuracy: 0.9909\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0548 - accuracy: 0.9839\n",
      "\n",
      "Epoch:  342\n",
      "378/378 - 16s - loss: 0.0163 - accuracy: 0.9940 - 16s/epoch - 43ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0161 - accuracy: 0.9940\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0346 - accuracy: 0.9902\n",
      "\n",
      "Epoch:  343\n",
      "378/378 - 15s - loss: 0.0117 - accuracy: 0.9954 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0061 - accuracy: 0.9978\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0258 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  344\n",
      "378/378 - 16s - loss: 0.0088 - accuracy: 0.9967 - 16s/epoch - 41ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0129 - accuracy: 0.9950\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0383 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  345\n",
      "378/378 - 16s - loss: 0.0112 - accuracy: 0.9960 - 16s/epoch - 43ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0129 - accuracy: 0.9947\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0361 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  346\n",
      "378/378 - 16s - loss: 0.0126 - accuracy: 0.9954 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0091 - accuracy: 0.9966\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0319 - accuracy: 0.9904\n",
      "\n",
      "Epoch:  347\n",
      "378/378 - 16s - loss: 0.0148 - accuracy: 0.9945 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0138 - accuracy: 0.9951\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0330 - accuracy: 0.9912\n",
      "\n",
      "Epoch:  348\n",
      "378/378 - 16s - loss: 0.0101 - accuracy: 0.9963 - 16s/epoch - 41ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0195 - accuracy: 0.9921\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0485 - accuracy: 0.9855\n",
      "\n",
      "Epoch:  349\n",
      "378/378 - 16s - loss: 0.0120 - accuracy: 0.9958 - 16s/epoch - 43ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0120 - accuracy: 0.9949\n",
      "for testing\n",
      "378/378 [==============================] - 4s 12ms/step - loss: 0.0410 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  350\n",
      "378/378 - 17s - loss: 0.0094 - accuracy: 0.9965 - 17s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0056 - accuracy: 0.9980\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0244 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  351\n",
      "378/378 - 16s - loss: 0.0104 - accuracy: 0.9961 - 16s/epoch - 43ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0141 - accuracy: 0.9944\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0399 - accuracy: 0.9885\n",
      "\n",
      "Epoch:  352\n",
      "378/378 - 16s - loss: 0.0144 - accuracy: 0.9945 - 16s/epoch - 43ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0106 - accuracy: 0.9958\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0301 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  353\n",
      "378/378 - 15s - loss: 0.0117 - accuracy: 0.9955 - 15s/epoch - 41ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0075 - accuracy: 0.9973\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0276 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  354\n",
      "378/378 - 16s - loss: 0.0078 - accuracy: 0.9970 - 16s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0045 - accuracy: 0.9986\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0243 - accuracy: 0.9931\n",
      "\n",
      "Epoch:  355\n",
      "378/378 - 16s - loss: 0.0163 - accuracy: 0.9940 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0117 - accuracy: 0.9953\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0382 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  356\n",
      "378/378 - 16s - loss: 0.0138 - accuracy: 0.9948 - 16s/epoch - 41ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0103 - accuracy: 0.9962\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0309 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  357\n",
      "378/378 - 15s - loss: 0.0104 - accuracy: 0.9958 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0073 - accuracy: 0.9971\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0311 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  358\n",
      "378/378 - 15s - loss: 0.0086 - accuracy: 0.9969 - 15s/epoch - 41ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0060 - accuracy: 0.9981\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0272 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  359\n",
      "378/378 - 16s - loss: 0.0198 - accuracy: 0.9933 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0047 - accuracy: 0.9987\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0250 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  360\n",
      "378/378 - 15s - loss: 0.0062 - accuracy: 0.9979 - 15s/epoch - 41ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0085 - accuracy: 0.9966\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0344 - accuracy: 0.9902\n",
      "\n",
      "Epoch:  361\n",
      "378/378 - 15s - loss: 0.0110 - accuracy: 0.9962 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0309 - accuracy: 0.9884\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0535 - accuracy: 0.9830\n",
      "\n",
      "Epoch:  362\n",
      "378/378 - 15s - loss: 0.0149 - accuracy: 0.9944 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0041 - accuracy: 0.9987\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0240 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  363\n",
      "378/378 - 16s - loss: 0.0079 - accuracy: 0.9971 - 16s/epoch - 41ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0034 - accuracy: 0.9991\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0222 - accuracy: 0.9941\n",
      "\n",
      "Epoch:  364\n",
      "378/378 - 15s - loss: 0.0080 - accuracy: 0.9969 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0050 - accuracy: 0.9985\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0253 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  365\n",
      "378/378 - 15s - loss: 0.0109 - accuracy: 0.9961 - 15s/epoch - 41ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0157 - accuracy: 0.9937\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0347 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  366\n",
      "378/378 - 16s - loss: 0.0104 - accuracy: 0.9960 - 16s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 18s 12ms/step - loss: 0.0171 - accuracy: 0.9932\n",
      "for testing\n",
      "378/378 [==============================] - 5s 12ms/step - loss: 0.0412 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  367\n",
      "378/378 - 20s - loss: 0.0147 - accuracy: 0.9950 - 20s/epoch - 53ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0069 - accuracy: 0.9977\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0300 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  368\n",
      "378/378 - 16s - loss: 0.0099 - accuracy: 0.9961 - 16s/epoch - 43ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0065 - accuracy: 0.9978\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0296 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  369\n",
      "378/378 - 16s - loss: 0.0096 - accuracy: 0.9962 - 16s/epoch - 41ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0045 - accuracy: 0.9987\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0251 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  370\n",
      "378/378 - 16s - loss: 0.0106 - accuracy: 0.9963 - 16s/epoch - 43ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0062 - accuracy: 0.9979\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0250 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  371\n",
      "378/378 - 16s - loss: 0.0107 - accuracy: 0.9959 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0062 - accuracy: 0.9980\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0287 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  372\n",
      "378/378 - 16s - loss: 0.0140 - accuracy: 0.9951 - 16s/epoch - 41ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0132 - accuracy: 0.9950\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0397 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  373\n",
      "378/378 - 17s - loss: 0.0101 - accuracy: 0.9961 - 17s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 19s 13ms/step - loss: 0.0066 - accuracy: 0.9975\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0342 - accuracy: 0.9902\n",
      "\n",
      "Epoch:  374\n",
      "378/378 - 18s - loss: 0.0069 - accuracy: 0.9973 - 18s/epoch - 48ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0101 - accuracy: 0.9963\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0357 - accuracy: 0.9904\n",
      "\n",
      "Epoch:  375\n",
      "378/378 - 17s - loss: 0.0109 - accuracy: 0.9958 - 17s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0139 - accuracy: 0.9948\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0383 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  376\n",
      "378/378 - 16s - loss: 0.0132 - accuracy: 0.9945 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0200 - accuracy: 0.9922\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0460 - accuracy: 0.9860\n",
      "\n",
      "Epoch:  377\n",
      "378/378 - 16s - loss: 0.0093 - accuracy: 0.9962 - 16s/epoch - 41ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0058 - accuracy: 0.9980\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0258 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  378\n",
      "378/378 - 15s - loss: 0.0113 - accuracy: 0.9961 - 15s/epoch - 39ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0037 - accuracy: 0.9991\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0237 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  379\n",
      "378/378 - 14s - loss: 0.0080 - accuracy: 0.9973 - 14s/epoch - 38ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0081 - accuracy: 0.9969\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0348 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  380\n",
      "378/378 - 14s - loss: 0.0113 - accuracy: 0.9956 - 14s/epoch - 37ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 10ms/step - loss: 0.0105 - accuracy: 0.9959\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.0366 - accuracy: 0.9902\n",
      "\n",
      "Epoch:  381\n",
      "378/378 - 15s - loss: 0.0103 - accuracy: 0.9962 - 15s/epoch - 39ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0096 - accuracy: 0.9963\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0348 - accuracy: 0.9887\n",
      "\n",
      "Epoch:  382\n",
      "378/378 - 14s - loss: 0.0074 - accuracy: 0.9976 - 14s/epoch - 37ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0088 - accuracy: 0.9969\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0340 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  383\n",
      "378/378 - 13s - loss: 0.0110 - accuracy: 0.9958 - 13s/epoch - 36ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0181 - accuracy: 0.9928\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0459 - accuracy: 0.9859\n",
      "\n",
      "Epoch:  384\n",
      "378/378 - 13s - loss: 0.0140 - accuracy: 0.9952 - 13s/epoch - 34ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0101 - accuracy: 0.9958\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0388 - accuracy: 0.9892\n",
      "\n",
      "Epoch:  385\n",
      "378/378 - 15s - loss: 0.0074 - accuracy: 0.9973 - 15s/epoch - 38ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0147 - accuracy: 0.9942\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0385 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  386\n",
      "378/378 - 14s - loss: 0.0082 - accuracy: 0.9969 - 14s/epoch - 37ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0115 - accuracy: 0.9958\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0337 - accuracy: 0.9889\n",
      "\n",
      "Epoch:  387\n",
      "378/378 - 14s - loss: 0.0065 - accuracy: 0.9977 - 14s/epoch - 36ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0274 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  388\n",
      "378/378 - 13s - loss: 0.0147 - accuracy: 0.9945 - 13s/epoch - 36ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0057 - accuracy: 0.9977\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0296 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  389\n",
      "378/378 - 16s - loss: 0.0058 - accuracy: 0.9979 - 16s/epoch - 41ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0049 - accuracy: 0.9982\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0303 - accuracy: 0.9912\n",
      "\n",
      "Epoch:  390\n",
      "378/378 - 15s - loss: 0.0101 - accuracy: 0.9965 - 15s/epoch - 39ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0167 - accuracy: 0.9938\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0505 - accuracy: 0.9871\n",
      "\n",
      "Epoch:  391\n",
      "378/378 - 15s - loss: 0.0137 - accuracy: 0.9953 - 15s/epoch - 39ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0143 - accuracy: 0.9946\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0428 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  392\n",
      "378/378 - 17s - loss: 0.0050 - accuracy: 0.9983 - 17s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0083 - accuracy: 0.9969\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0297 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  393\n",
      "378/378 - 14s - loss: 0.0114 - accuracy: 0.9957 - 14s/epoch - 38ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0123 - accuracy: 0.9956\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0391 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  394\n",
      "378/378 - 17s - loss: 0.0111 - accuracy: 0.9961 - 17s/epoch - 45ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0025 - accuracy: 0.9995\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0250 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  395\n",
      "378/378 - 13s - loss: 0.0070 - accuracy: 0.9976 - 13s/epoch - 35ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0064 - accuracy: 0.9975\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0346 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  396\n",
      "378/378 - 14s - loss: 0.0118 - accuracy: 0.9957 - 14s/epoch - 37ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0202 - accuracy: 0.9927\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0427 - accuracy: 0.9871\n",
      "\n",
      "Epoch:  397\n",
      "378/378 - 13s - loss: 0.0100 - accuracy: 0.9964 - 13s/epoch - 35ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0032 - accuracy: 0.9990\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0278 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  398\n",
      "378/378 - 14s - loss: 0.0050 - accuracy: 0.9984 - 14s/epoch - 38ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0070 - accuracy: 0.9973\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0343 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  399\n",
      "378/378 - 15s - loss: 0.0053 - accuracy: 0.9980 - 15s/epoch - 39ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0082 - accuracy: 0.9971\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0393 - accuracy: 0.9894\n",
      "\n",
      "Epoch:  400\n",
      "378/378 - 14s - loss: 0.0144 - accuracy: 0.9947 - 14s/epoch - 36ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0254 - accuracy: 0.9933\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for x in range(400):\n",
    "    print(\"\\nEpoch: \",x+1)\n",
    "    history = model.fit(X_train ,y_train ,batch_size=BATCH_SIZE ,epochs=1, verbose=2, shuffle=True)\n",
    "    if history_dataframe.size == 0:\n",
    "        history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    else:\n",
    "        history_dataframe = pd.concat([history_dataframe,pd.DataFrame.from_dict(history.history)],axis=0,ignore_index=True)\n",
    "    \n",
    "    print(\"for training\")\n",
    "    train_eva.append(model.evaluate(X_train,y_train))\n",
    "    print(\"for testing\")\n",
    "    test_eva.append(model.evaluate(X_test, y_test))\n",
    "    \n",
    "#     clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ec37c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.623773</td>\n",
       "      <td>0.645957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.553715</td>\n",
       "      <td>0.719308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333724</td>\n",
       "      <td>0.852079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.288693</td>\n",
       "      <td>0.873677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.263767</td>\n",
       "      <td>0.884590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.011801</td>\n",
       "      <td>0.995680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.010046</td>\n",
       "      <td>0.996424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.998429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.998037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.014387</td>\n",
       "      <td>0.994730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy\n",
       "0    0.623773  0.645957\n",
       "1    0.553715  0.719308\n",
       "2    0.333724  0.852079\n",
       "3    0.288693  0.873677\n",
       "4    0.263767  0.884590\n",
       "..        ...       ...\n",
       "395  0.011801  0.995680\n",
       "396  0.010046  0.996424\n",
       "397  0.004988  0.998429\n",
       "398  0.005319  0.998037\n",
       "399  0.014387  0.994730\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c8463e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva_df = pd.DataFrame(train_eva,columns=['loss','accuracy'])\n",
    "test_eva_df = pd.DataFrame(test_eva,columns=['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cc95506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(df,title,xlabel,ylabel,values=['loss'],legends=[]):\n",
    "    \n",
    "    for value in values:\n",
    "        epoch_count = range(1, len(df.index) + 1)\n",
    "        plt.plot(epoch_count, df[value].tolist())\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    if legends==[]:\n",
    "        legends = values\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35c781fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB220lEQVR4nO3deVxU5f4H8M/MAMMim+yIIO64oeKSa26RWuZatpm2W2ZZ2S3zltatn9VtsbK0xSW7muYtzZtLYu674q6oKCggIPu+z5zfHw9zmGFAAQcPDJ/368VL5pwzM88zB+d8z/fZVJIkSSAiIiKyEmqlC0BERERkSQxuiIiIyKowuCEiIiKrwuCGiIiIrAqDGyIiIrIqDG6IiIjIqjC4ISIiIqvC4IaIiIisCoMbIiIisioMboioQVGpVDX62bVr122/V0FBAebPn2+R1yKihsNG6QIQERk7ePCgyeN//etf2LlzJ3bs2GGyvVOnTrf9XgUFBXjvvfcAAEOGDLnt1yOihoHBDRE1KHfddZfJYy8vL6jVarPtRETVYbMUETU6JSUl+OCDD9CxY0dotVp4eXnhySefRGpqqslxO3bswJAhQ+Dh4QEHBwcEBgZi4sSJKCgowNWrV+Hl5QUAeO+99+TmrmnTpilQIyKyJGZuiKhR0ev1GDt2LPbu3Yt//OMf6N+/P65du4Z58+ZhyJAhOHbsGBwcHHD16lXcd999GDRoEJYtWwY3Nzdcv34dW7duRUlJCfz8/LB161aMHDkSTz/9NJ555hkAkAMeImq8GNwQUaPy66+/YuvWrfjtt98wYcIEeXtoaCh69+6NFStW4IUXXkBkZCSKiorw73//G6GhofJxjz76qPx7WFgYACAgIIDNXkRWhM1SRNSo/Pnnn3Bzc8OYMWNQVlYm/3Tv3h2+vr7yyKfu3bvDzs4Ozz33HH766SfExMQoW3AiumMY3BBRo3Ljxg1kZWXBzs4Otra2Jj/JyclIS0sDALRp0wbbt2+Ht7c3ZsyYgTZt2qBNmzb48ssvFa4BEdU3NksRUaPi6ekJDw8PbN26tcr9zs7O8u+DBg3CoEGDoNPpcOzYMXz99deYNWsWfHx88PDDD9+pIhPRHcbghogalfvvvx9r1qyBTqdD3759a/QcjUaDvn37omPHjli1ahWOHz+Ohx9+GFqtFgBQWFhYn0UmojuMwQ0RNSoPP/wwVq1ahdGjR+OVV15Bnz59YGtri4SEBOzcuRNjx47F+PHjsWTJEuzYsQP33XcfAgMDUVRUhGXLlgEARowYAUBkeYKCgvDHH39g+PDhaN68OTw9PdGqVSsFa0hEt4t9boioUdFoNNi4cSPefvtt/P777xg/fjzGjRuHjz76CPb29ujatSsA0aG4rKwM8+bNw6hRozBlyhSkpqZi48aNCA8Pl19v6dKlcHR0xAMPPIDevXtj/vz5CtWMiCxFJUmSpHQhiIiIiCyFmRsiIiKyKgxuiIiIyKowuCEiIiKrwuCGiIiIrAqDGyIiIrIqDG6IiIjIqjS5Sfz0ej0SExPh7OwMlUqldHGIiIioBiRJQm5uLvz9/aFW3zw30+SCm8TERLRs2VLpYhAREVEdxMfHIyAg4KbHNLngxrCoXnx8PFxcXBQuDREREdVETk4OWrZsabI4bnWaXHBjaIpycXFhcENERNTI1KRLCTsUExERkVVhcENERERWhcENERERWZUm1+empnQ6HUpLS5UuBtWCra0tNBqN0sUgIiKFMbipRJIkJCcnIysrS+miUB24ubnB19eXcxgRETVhDG4qMQQ23t7ecHR05EWykZAkCQUFBUhJSQEA+Pn5KVwiIiJSCoMbIzqdTg5sPDw8lC4O1ZKDgwMAICUlBd7e3myiIiJqotih2Iihj42jo6PCJaG6Mpw79pciImq6FA1u9uzZgzFjxsDf3x8qlQobNmy45XN2796NsLAw2Nvbo3Xr1liyZInFy8WmqMaL546IiBQNbvLz8xEaGopFixbV6PjY2FiMHj0agwYNwokTJ/D222/j5Zdfxm+//VbPJSUiIqLGQtE+N6NGjcKoUaNqfPySJUsQGBiIhQsXAgBCQkJw7NgxfPrpp5g4cWI9lbJxGDJkCLp37y5/NkRERE1Vo+pzc/DgQYSHh5tsu/fee3Hs2LFq+1gUFxcjJyfH5IeIiIisV6MKbpKTk+Hj42OyzcfHB2VlZUhLS6vyOQsWLICrq6v807JlyztRVCIiIsvSlQJlxUqX4tYKMgBJUrQIjSq4Acw7jErlH2B1HUnnzJmD7Oxs+Sc+Pr7ey6i0zMxMPPHEE3B3d4ejoyNGjRqF6Ohoef+1a9cwZswYuLu7w8nJCZ07d8bmzZvl5z722GPw8vKCg4MD2rVrh+XLlytVFSKqTmFWxQWktKjmFz1JArKvA8V5FdvKSgC9vmbPz0sFMmJufVxJPpB22XRbQYZ5OYtygFNrgMyrNXv/6mReA3Z9LOqmKwOi/gecWw8UZpoeV1oEHPkBSIis2JYRC5z9HYjZXfGZZl8XdQCA0kIgv/wGujgXOPEf8X4AkJMkym54XvoV4NAS0/ctKwH0OvH76XXA0nAg9WL58xOB/80SZQLE6ySdBg58DRxaLF4fAK4dBL4MBT5tL97foCgHOLUW2Ps5sOffwPb54rWqCi6i/gRWjgP++5So080knQZO/yr+Toz/VjJixHm8tE3slyTx+W37pzjfhZnA0nuAjS+JeiukUc1z4+vri+TkZJNtKSkpsLGxqXZeGq1WC61WW+f3lCQJhaW6Oj//djjYauo0+mfatGmIjo7Gxo0b4eLigjfffBOjR4/G+fPnYWtrixkzZqCkpAR79uyBk5MTzp8/j2bNmgEA3nnnHZw/fx5btmyBp6cnLl++jMLCW/wnIKpvZSWAjV31+zOvAs18AFsx1xH0OrGtJA9o3hqwdQLUVdzLlRaKi4tHG/ElHb0N8GgLuAeL46P+B8QdAjqMBvRlQKtBpq8jSYCuBLDRiovl7o+Arg8B2maAf0/A2Ud82ZcUAK4txPGZscCNc4BvN8A9yLQ8SaeBpJOAs5+4sHWdJI7b9k8RFIyYD1zbB6THACdXAUPeAlr0AjZMF5+RRxtR54d/AeIOAMF3A4nHgaNLRRlDHhDPiz8MqG2B/jOBvBTgzDogoDfw2K+AnZP556QrBUoLgIPfAPu/AnTFwMDXAPdWIoAY/AYQ1A9IvQSkXRLvGbkCKEgHuj4IjPkKSIkCVtwHBPQCOt4PxB8CvDoCV/cBV/eK9wnsB3SbDLTsAzRvA+QmAkmngDbDRblzEoEejwNeHcTxeSnAlZ1AejRw9EfxWZ/4D2BrL8oBACoNEDwYGLlABAI7PwRid4t9g2YDxTnlgUV5MDDhB/F38b9XAFtHoNMDQOweIDcZ6PYQkJ0gyqu2Bfo+DxxbDpTmA0EDRNn+fBUoKwLO/Co+/2v7gevHAc92wKNrxf6SXOCbPoCjJ1CYAUjlgeWWNwGp0vVmxwfAPe8Df80Fysq/i/+YAdjYi5/1z4tzXtn2+eLzVanEubJzBNY+VrH/yg7x99xqoDg3d70g6pabJOq/7Z+iHuJDBB74CrBxAH5/FtDYir97ALiwSfxfSzoJRK4Uf/s510UQWZQNNPMyL9sdoJIkhXNH5VQqFdavX49x48ZVe8ybb76J//3vfzh//ry87YUXXsDJkydx8ODBGr1PTk4OXF1dkZ2dDRcXF5N9RUVFiI2NRXBwMOzt7QEABSVl6PTuX7WvkAWcf/9eONrVLP40dCieMWMG2rdvj/3796N///4AgPT0dLRs2RI//fQTHnzwQXTr1g0TJ07EvHnzzF7ngQcegKenJ5YtW2bRutwpVZ3DJkOvB/JTxQXVkvLTxcXCcNFLiQKOLQO6TBIXIZVK3M1p7ADXAPPnJ58Fdi0AAu8SF9PSIiA/BXALFHfYMTvFHXKboYC9q+nzTq4WF9LjP4uLZ9AAwL+H+NLOjBVfzqfXii94jR0Q/iGQdwOIXC4urMbUtoB3CDDsHeDgooov8ex4oNvDQIuewJZ/iGNVasDB3fw1Br8BDPun+P3SX8Cfr4kL05ObgZ/HizIZNG8DPL8bWDYSuHFWlDUtGsgz3KCpgGFzASdvESCkXhQX89pSqSsujgZaV6A4+2ZPgnwxN+YVAnQeD/R+BnDyEOdn/xciK1BaUP3L2bsCk5YBvzxScdEz1n8mEB0BpF6opjia8joYlcnZX1zMCzNFEFBQnjnx6QI8v1f83X3TpyKIqczRA3Dyqvo9NVrxd9VQqW2BtiPE32jSyYrtft1FAHh4senxnu1FcKpSi/+L1/ZX/9rO/lX/ndk63vwcV6ZSix99mfk+u2bAU38Bvl1q/no1cLPrt1nxlAxu8vLycPmySFv26NEDn3/+OYYOHYrmzZsjMDAQc+bMwfXr17Fy5UoAYih4ly5d8Pzzz+PZZ5/FwYMHMX36dPzyyy81Hi1l7cHNsGHDMHHiRBQVFZnM0NujRw+MHz8e7777Ln788Ue88MIL6NOnD0aMGIGJEyeiW7duAIAtW7Zg4sSJaN++PcLDwzFu3Dg5SGoMGmRwU5IvUspthgLqSrMmp0SJL9+QsVVnFozp9eIimRUn7qBD7hdf+glHxcXlyg5xxzz+e7HPxgGABKx+SNzxBt8NnN8AdH9MXMB+nSLukoe8BUS8K+6+HvgaOPw9cPwncVEJeUA8R2MH3P+FeLy4P5BWnlJ3cBd3hbsWiLv70IcBZ1/AoTnQZSKw5xNxRw0AUAEzI8Wd3/VIEaCkXwH05YMBVGogoI/4ci7Krv7iY2MPuAWJMnSeIF4r61rVx9k6mDdLVBUM1Fbw3eJuvqoAwVhAb3F+jKltRYYl9YL4XHWlFa+jthGZpsoX7GY+ImirTushQJ/nRFNGXKUbPXs3kWGQJODaAcDeBbj3Q9EEs/tjETC2GQZsfkNkIABxXp/bBez7QmRgDNwCgXv+JbILh5YAGVfMA0BA/H11vF8EOhteqLrMboGiiacwE7j7LSBsqsggnf1d/F2U5FZf37HfAB7tgGXh4u88dDLg3Vn87RxeLALGZ/8W75F+Bdg4U1zwnbxFQD54tshmnfhZvF7/l4GwacDXPSveo+cTQOijwOk14sLf8X7gwFcikzfuW5ExOvoDYOcM9HpS7AMAzw7A2EVAxDyR2QrqL74Dtr4p9qvUIki+uFn8X+w0FtA6Az+NEdm5cYtFsGLnKG4EFnYRNy2GenebDCwfVfF3FTIGePAn0++WQ0uAmF3ita9HinICIuh4+aTIVl3bD6RcEFmo5NMVz209RAS1/t2BoXPFsZvfAKI2iv3dHxcZLAc3cXOwdoq4WRn8hvg/V5Au9vv3qP781VGjCW527dqFoUOHmm2fOnUqVqxYgWnTpuHq1avYtWuXvG/37t149dVXce7cOfj7++PNN9/E9OnTa/yetQ1uGkuzlCG4GTp0KCZNmmQW3HTv3h0TJ07EO++8AwCIj4/Hpk2bsG3bNvz555/47LPPMHPmTABAamoqNm3ahO3bt+O3337DjBkz8Omnn1q+gvXgpsFN5jWRTnXxL29OKDVv6kiLFhecys0FBpIkvhTsRDMeru0HOowSXyZhU4G//yXuZNqFAz2niIvrptniy2XQ6+JL3PCeV3aKO92yQqDtPUAzb3GH6x0i9l+PBI6vFF/OTl6AW0tg/5cVZbnZRVqlEV/OAb1ECrs6ahsRtGycWf7YtiLYMDvWVgRCO/5V+c1Q5UXexqEijX4rWhfxJVollbg4F2UDp36p+hCNVjRVGL6kB74qvpjVNiJlX1YCFGUB3w+peB8be3GcR1vgt6crXuvFw+LLev0L4iL+7A7RTPTzeJFlMuYXKppNDCb8KJqSru4FfnoA8ufi3VmcD9+uIkNkYw8sHgCknBP7W/YFwj8QddC6iGySo6doQvFoA4Q9KdL/1/aLc2DnLILWyxHi+dM2A60GiH44n7YTQYVbEDBpOeDVXlw8byUnCbi8Hdi/EEi/LD6X9Mvi8x+7CGg/SgQ9lYPwnERgYbeKv5uHfwE6jha/60qBL7pUZKtGfyoCKq2LyGoVZQOJJ4AO95m+bkEGsPZxkbnwbA9c2iqatvJTRDONsW4PAxO+E7+XFYsmpnbhot7GirLF+xq+U/PTxDmw0QLT94mg7wOfiqaYt+JMM4mV6UrFe/n3EH8HC7uK7NKk5UCXCabHSpL4f5h+GRg+T5yryiSpomzGdn8i/g5snYDZl0SzT1mxuJlR24pgRHOLm+DYvSLb2mks0Hmc+f7US0DEO+JmIXSy+f6yEuDSFpHZq/y55qeJm67gu6suvwU1muBGCbUNbhqLmjRLrVy5EpMmTTJ77pw5c7Bp0yacPn3abN93332HN954o9EMoa/yHBbliGzBpa3icefx4kvr1FrgoZVA+/LpBc7/Aax7UvwHDXtSNLH0myG+vP9+D/DuJFLr8YfEnZy9q/jylVW6yHuFAM9sBxa0MC1k+1HiIrf3M/P2dcPrtAsHrvxddcq3soDe4gtW0htlSarh31Nkd25l7DfiArN9vihrbrK4QKltRJlGfiS+KD8PqXiOa0txYc+KE3ffkETzyOSV4u583TRxnNoGeHCFyFpd+BO4+03xHmsfFxfPu98Eru4Hkk8BIz8WgYXhwrdummjCMTAEY2HTxB3lsnvF3fqLByv63xg7+C3w1xzx+4wjFX03lt4rzmuH0cAj5QGUrkxkjwzNcTmJ4px5dhAZBv8e4nM4tlT01en7vGhKMNj2TsXd/LRNom+Dsf1fiQsKAExeJbJttXFxC/DLwyID9uKhigvLmsfE5zp8HjDotdq9JiD6wKy4r+LxPe8DA165+XN2/xvY+QHQzBd49ZzpxdZwcQ55AJj8s8jWqDQiM3Er+vKmqtwk8f+xtAjY9DpwanVFYP/470Db4bWuJgDRUValqjjHJ1eLTNMDi8TNSW0knRI3R10mWvYiX5Qtbj5aDwF6PWW5122EGNzchLUHNwsXLsS4ceMQHR2N7777Ds7Oznjrrbdw+fJluUPxrFmzMGrUKLRv3x6ZmZl44YUX0KpVK6xduxbvvvsuwsLC0LlzZxQXF+Ott95CSkoKDh8+rGwFSwvFRbUoW3TObN5axBJlxeIuuDwla3IONQCuHxN3enEHq890OHoCfaeLO8rKWYth/wQu7xCdM2tK6yLKU5gpLrgn/1P9sV0fFPW5uKnq/a2HiqDq0DfisbOfuHhc3CyCAajEhc27o9j/97+AvZWybJ4dgCnrxQUioJcYUbLr/4DA/uVNGJW+AgL7AU+VB4L56SL9vOEF0bfFYHa0yDQtGVSRLRn/fcVdX8wucVc78FXxnrpSkaUqyRcXy5a9b/4ZVufw98CWN8Tv/V4Cek4V5brrRdFHJOWC6GtRXSfG4lxRDq8OwH2fVWzPSwWOfC+aF1z861a2ysqKRUZIbQtMXGqe8ci9AXzTWzQ5vXDw1nffVYmOEH1QXPwqtuWliAxM14fq9pqSBPw4Qvzf6fYwMH7JrS/WujIR5AX0FpmpyvtidgHBg0SWxBKSzwJb3xIZ1Mn/qVs9q1NWbLlykkUxuLmJphDcZGZm4pVXXsHGjRtRUlKCwYMH4+uvv0a7du0AADNnzsSWLVuQkJAAFxcXjBw5El988QU8PDzwwQcfYPXq1bh69SocHBwwaNAgfPHFFwgODq59oYpyREdUzU1GuRhIkmgu0OvE3bvhy1SSREBy46xpYGLXrHyYpiTuAt1bAfYuKEqJRezVawjWxcB+z/sV/S1UanH3nHm1+j4AgOj0KUliREplDs1F+3ZpoRgJUZ2nt4vRGMbNN4H9RGDi2U70i3BoDgx/V7RNS5JIZ+tKRMdN1xbiGM/2wJQN4g7X0LQ1+T+iDHq96Ofi4i8uyAa6UpGh8ukCrJ8umtdGfgQ4Njf9rJNPi8zSjbMiK+PbVWQRLm4BntxifoE6tKSiz4Bne+Cl8vb+v+aKzrkA8MopcR7qU/IZYEl5BuSRNaJJsDHLTxP/P+xv/kV9x2XFi7/hrg/yQk8NBoObm7DW4KZBKMwWbeJOngBUYuSIjYO4Sy4tEBdvB3cRwBRmioyASi2OTb9cMZyxeRuRjclOECM+7JpVPdTRmEYLeLRFUeJZxF5PRfD+12GfFy86EKo14i6//0viwv7fp8Rd6aPrRHv/BqM+W09sBFrfLY77aYzoO6FSi34pYdPEMdHbgVXlHdh7Pys6Y55eKzre2rsB/4gRneo+71SRCZr6p7hzBUT2wMbh5nebZSWi+cZwty9J4jWdPGt6NmpPVyoCRgc3833xR8TcFYBIjd//hfg9OgJYNQlwaSEySvW9cKleD3zbV/QtmRnZ8IICIqo3tQluGtU8N9RA6MpEwFD5QpZ/Q1wcjQORskLRkTMrXvQvUWnE44J0EeCUFpr3O8lNEk1QhiGlhtezcxIXUeORJF4hQGqU6BthGCpq0GMKMOZL01EEKhXwoNGkhN4dRUAW8a5o/gkeXHHcw6vFRd2rg+jMa9BqgAi+yorEHBjBg8Xx5zeI/jxqjWiyGfWR6MjX66mKwAaoWefOyh2dVar6DWwA0dm6qsAGEJkdQ3+bIKPOkG1HiOHX/t3rP7ABRLD3THlfJAY2RFQNBjckmnv0OnFxAyqaiGy04iJuOEZXKrIO2fHiQufSoqK5Q5JE35GqGM88mp1QMcS3cjbG3k0EPoa5Fir3kbGxFx15DdQ25c1e5XNWGIbKal2AkZ8Ane41H3pdlbtmiNdtPcT0Am3vArQbYX68rYPocJh+GQgqbyLpMEqMsjFulun9jPixBrYOYoKy+COmnWZVKpERu5MY1BDRLTC4IZFVKcwUQz+1zUSHxNxEETR4h4hsTFac6bwj+jIxeqS0QAQ2Du4Q/V/UooNkblL58N48AEYBSnVzl6g0IjuSXirm2rCxr5jvwzBiSKMtz2B4iXkf3ALFdjtHoNDodbXOQJseNQtsANE81OfZmn5aQrcHzbcZOvVaqzFf3voYIqIGgMFNUyJJoinFECRkx4smJsNMpjnXxXBLw+yVumIxN0xRpUnQ7JqJoEZfWjG5lKFJyNaxfBI3d5EJKi0SGRW1Rrx/YYYIZBw9RHOQvbtowlGryycwCxbZIXs3sc3GviLDY+jY6OIv+tIYmm5snSo6Dtu7AvnKrWdCRETKY3Bj7cpKRCBi10wEGfkpIvOhdTafWbS0QIycMWYIbBzcxfNKC8Tv2QnmM78CFc1GhkDEzlEELIAIblxbiOBGpRIBjo1deafichpb05E9tg7mwY1KbdonxXi+DEcvIP36rT8XIiKyWgxurE1JvphXw6Z8Wve0S+ZztxRmVj/6yDB7q6HpBxBZEhd/08mu7N0qgpvmrStWCa5q4jQDlQpQGf3J2dZgRJra6HhNNUNS7ZwAl4DygKcGw86JiMiqMbhpzPJTxVwyjh5ilEteimhaAsTImrLiqqfS15eV92NRV6zu6hogmqkMnP1EJ2O1piKwMWbvKmYjtbUXv7sFicDI3s2ydTQscwDcfO0lw6RtRUXVH0NERE0Cg5vGRFcqRuhonUUwkpciApPiHKC00sJ6+YZh0SoxlNmwQF9qVMUxtvZiThlJJ5p88lNFnxytswhqqltfCRDBjvGsqI7NTZuTLEXbTIxA4kRiRERUQwxuGpPCLBF8lBWLTrs6o46zhsDG3k0EHoYmI8fmFU1FhgnzDNPta7TlE8mV/xl4tBEBk1M1U9crxcFd6RIQEVEjwuCmodKVAVKZmJE1P1U0OxVlle+Uqu7MC4igB6jY38ynYp9KVdEMBZhPFKexExkhIiKiRozBTUNiWGNIbSvmiSkrLp8VtlQMoTZmaHZS25YPuS4fEWXI0jRvI/6t3JyjsTMKbtjUQ0RE1ofBjdIkvWhuMgQcuUmm+yt3CDbM2ltW3nFWYyuyNdnXRSdgg+pmcTXMQgxUP/rIQkpLS2Fra3vrA4mIiCzoJsNP6I7IvQFkXRNBTeXAxsDRU6yh5ORVnpExGrmksRWjlXw6YevOfRg4cCDc3Nzg4eGB+++/H1euXJEPTUhIwMPPvILmnYfAqW1/9BpwNw4fPizv37hxI3r16gV7e3t4enpiwoQJ8j6VSoUNGzaYFMvNzQ0rVqwAAFy9ehUqlQq//vorhgwZAnt7e/znP/9Beno6HnnkEQQEBMDR0RFdu3bFL7/8YvI6er0eH3/8Mdq2bQutVovAwEB8+OGHAIBhw4bhpZdMp/dPT0+HVqvFjh07avghExFRU8LMza1IUsVaR/Xx2jnXTTsGqzQVC0m6thQLSzbzEf1jDP1hbOzFgpSASSYmPz8fr732Grp27Yr8/Hy8++67GD9+PE6ePImCggLcfffdaOHjiY3Lv4CvlweOJxRBrxdLI2zatAkTJkzA3Llz8fPPP6OkpASbNm2qdZXefPNNfPbZZ1i+fDm0Wi2KiooQFhaGN998Ey4uLti0aROmTJmC1q1bo2/fvgCAOXPm4IcffsAXX3yBgQMHIikpCRcuXAAAPPPMM3jppZfw2WefQasVmaZVq1bB398fQ4cOrXX5iIjI+jG4uZXSAuD//JV577cTKybNM2brUBHcqCs6BU+cONHksKVLl8Lb2xvnz5/HgQMHkJqaiqO7t6G5WkzU13ZAD/nYDz/8EA8//DDee+89eVtoaGitizxr1iyTjA8AzJ49W/595syZ2Lp1K9atW4e+ffsiNzcXX375JRYtWoSpU6cCANq0aYOBAwfKdZo5cyb++OMPPPTQQwCA5cuXY9q0aVDdiVWoiYio0WGzVGNkvDK2UebmypUrePTRR9G6dWu4uLggOFgsexAXF4eTJ0+iR48eaN6itcgAeXYwecmTJ09i+PDht120Xr16mTzW6XT48MMP0a1bN3h4eKBZs2bYtm0b4uLiAABRUVEoLi6u9r21Wi0ef/xxLFu2TC7nqVOnMG3atNsuKxERWSdmbm7F1lFkUCyhtFCMftLYAgWZQLa4wKN5W0BbVYbG0XwbYLrEgVFwM2bMGLRs2RI//PAD/P39odfr0aVLF5SUlMDBwTDXjarKeWzk/dVQqVSQJMm0OqXmsx87OZnW47PPPsMXX3yBhQsXomvXrnBycsKsWbNQUlJSo/cFRNNU9+7dkZCQgGXLlmH48OEICrrJBINERNSkMXNzK4b1lG73R68TyxvkJovHJbkiSHFvBTh7V/2c6ppdjIMbtQhu0tPTERUVhX/+858YPnw4QkJCkJlZMRdOt27dcPLkSWRkZFR+NXn/33//Xe3H4OXlhaSkig7P0dHRKCi4dV+kvXv3YuzYsXj88ccRGhqK1q1bIzo6Wt7frl07ODg43PS9u3btil69euGHH37A6tWr8dRTT93yfYmIqOlicHMnSHog86r4vaxQLINgGMpdl9mA1RrA2V88t3yuGnd3d3h4eOD777/H5cuXsWPHDrz22mvyUx555BH4+vpi3Lhx2L9/P2JiYvDbb7/h4MGDAIB58+bhl19+wbx58xAVFYUzZ87gk08+kZ8/bNgwLFq0CMePH8exY8cwffr0Gg3zbtu2LSIiInDgwAFERUXh+eefR3Jyxcrj9vb2ePPNN/GPf/wDK1euxJUrV3Do0CEsXbrU5HWeeeYZfPTRR9DpdBg/fnztPzMiImoyGNzcCYVZFSOggIrZgzVa03lnasPZR/SdKc/uqNVqrFmzBpGRkejSpQteffVV/Pvf/5YPt7Ozw7Zt2+Dt7Y3Ro0eja9eu+Oijj6DRaAAAQ4YMwbp167Bx40Z0794dw4YNMxkm/tlnn6Fly5YYPHgwHn30UcyePRuOjtU0mxl555130LNnT9x7770YMmSIHGBVPub111/Hu+++i5CQEEyePBkpKSkmxzzyyCOwsbHBo48+Cnv7GqwmTkRETZZKqtyRwsrl5OTA1dUV2dnZcHExneiuqKgIsbGxCA4OtuwFNCMGKMqueGzrKEZhOTS/+eKUJIuPj0erVq1w9OhR9OzZs9rj6u0cEhGRom52/a6MHYrrm14HFImh1/LSB4Z5c+xunflo6kpLS5GUlIS33noLd911100DGyIiIoDNUvWvOBeAJAIbezfTfVXNYUMm9u/fj6CgIERGRmLJkiVKF4eIiBoBZm7qmyFLo3U2XYVbbQvY3HoYdFM3ZMgQsyHoREREN8PMTX0zXoHbeKFKe9fqh3oTERFRnTFzUwWLZAoKMoC8FEBfJh5r7EwzNw5ut/8eZIZZHiIiYubGiGHelppMTndL+SliTht9+Sy+mvLMjY29aI5if5t6YTh3NZmDh4iIrBMzN0Y0Gg3c3NzkOVYcHR3rtjijJAGFhQCMsghlekBfDDi3Eo+LS6p6JtWRJEkoKChASkoK3Nzc5Pl7iIio6WFwU4mvry8AmE0iVyu6UiDX6PkqNZAff5slo5pwc3OTzyERETVNDG4qUalU8PPzg7e3d5ULQ9bIxS3A/ncqHjt5A09utkwBqVq2trbM2BAREYOb6mg0mrpfKG9EAnlGmZqiVICz5RIREd0R7FBcH5LPmD4OvEuZchARETVBzNzUh4wY8e8Di4CEo8Cg15UtDxERURPC4MbSJEnMbwMAwYOAnlOULQ8REVETw2YpSyvOBcqKxO9O3sqWhYiIqAlicGNphqyNnTNX/SYiIlIAgxtLy7sh/m3GrA0REZESGNxYmhzc+ChbDiIioiaKwY2l5aeKf5m5ISIiUgSDG0tj5oaIiEhRDG4sjX1uiIiIFMXgxtIMo6UY3BARESmCwY2lycENm6WIiIiUwODG0pi5ISIiUhSDG0srzBD/OnooWw4iIqImisGNpZUVi39t7JUtBxERURPF4MaS9DoAkvhdzTVJiYiIlMDgxpJ0JRW/a+yUKwcREVETxuDGkhjcEBERKY7BjSXpyip+19gqVw4iIqImjMGNJRkyN2obQKVStixERERNFIMbSzIEN2ySIiIiUgyDG0vSlzdLqdkkRUREpBQGN5YkZ24Y3BARESmFwY0lsVmKiIhIcYoHN99++y2Cg4Nhb2+PsLAw7N2796bHr1q1CqGhoXB0dISfnx+efPJJpKen36HS3oKuVPyr4QR+RERESlE0uFm7di1mzZqFuXPn4sSJExg0aBBGjRqFuLi4Ko/ft28fnnjiCTz99NM4d+4c1q1bh6NHj+KZZ565wyWvhhzcMHNDRESkFEWDm88//xxPP/00nnnmGYSEhGDhwoVo2bIlFi9eXOXxhw4dQqtWrfDyyy8jODgYAwcOxPPPP49jx47d4ZJXg81SREREilMsuCkpKUFkZCTCw8NNtoeHh+PAgQNVPqd///5ISEjA5s2bIUkSbty4gf/+97+47777qn2f4uJi5OTkmPzUG0PmhutKERERKUax4CYtLQ06nQ4+Pj4m2318fJCcnFzlc/r3749Vq1Zh8uTJsLOzg6+vL9zc3PD1119X+z4LFiyAq6ur/NOyZUuL1sOEns1SRERESlO8Q7Gq0ky+kiSZbTM4f/48Xn75Zbz77ruIjIzE1q1bERsbi+nTp1f7+nPmzEF2drb8Ex8fb9Hym2CzFBERkeIUaz/x9PSERqMxy9KkpKSYZXMMFixYgAEDBuCNN94AAHTr1g1OTk4YNGgQPvjgA/j5+Zk9R6vVQqvVWr4CVZE7FHOeGyIiIqUolrmxs7NDWFgYIiIiTLZHRESgf//+VT6noKAAarVpkTUaDQCR8VEcgxsiIiLFKdos9dprr+HHH3/EsmXLEBUVhVdffRVxcXFyM9OcOXPwxBNPyMePGTMGv//+OxYvXoyYmBjs378fL7/8Mvr06QN/f3+lqlGBzVJERESKU3RYz+TJk5Geno73338fSUlJ6NKlCzZv3oygoCAAQFJSksmcN9OmTUNubi4WLVqE119/HW5ubhg2bBg+/vhjpapgissvEBERKU4lNYj2nDsnJycHrq6uyM7OhouLi2Vf/OC3wF9zgC6TgElLLfvaRERETVhtrt+Kj5ayKhwKTkREpDgGN5bEZikiIiLFMbixJI6WIiIiUhyDG0viwplERESKY3BjSWyWIiIiUhyDG0uSF85kcENERKQUBjeWxNFSREREimNwY0lsliIiIlIcgxtL4mgpIiIixTG4sSSOliIiIlIcgxtLYrMUERGR4hjcWBJHSxERESmOwY0lyZkbNksREREphcGNJenLxL9sliIiIlIMgxtLYuaGiIhIcQxuLIkdiomIiBTH4MaSdGyWIiIiUhqDG0tisxQREZHiGNxYkiG44VBwIiIixTC4sSSOliIiIlIcgxtLYrMUERGR4hjcWBJHSxERESmOwY0lcbQUERGR4hjcWBKbpYiIiBTH4MZSJImjpYiIiBoABjeWotcBkMTvbJYiIiJSDIMbS9GXVvzOZikiIiLFMLixFEOTFMDMDRERkYIY3FiKzihzwz43REREimFwYymG4EZtA6j5sRIRESnFRukCWA0Hd2DK+vKOxURERKQUBjeWYmsPtBmmdCmIiIiaPLafEBERkVVhcENERERWhcENERERWRUGN0RERGRVGNwQERGRVWFwQ0RERFaFwQ0RERFZFQY3REREZFUY3BAREZFVYXBDREREVoXBDREREVkVBjdERERkVRjcEBERkVVhcENERERWhcENERERWRUGN0RERGRVGNwQERGRVWFwQ0RERFaFwQ0RERFZFQY3REREZFUY3BAREZFVYXBDREREVoXBDREREVkVBjdERERkVRjcEBERkVVhcENERERWRfHg5ttvv0VwcDDs7e0RFhaGvXv33vT44uJizJ07F0FBQdBqtWjTpg2WLVt2h0pLREREDZ2Nkm++du1azJo1C99++y0GDBiA7777DqNGjcL58+cRGBhY5XMeeugh3LhxA0uXLkXbtm2RkpKCsrKyO1xyIiIiaqhUkiRJSr1537590bNnTyxevFjeFhISgnHjxmHBggVmx2/duhUPP/wwYmJi0Lx58zq9Z05ODlxdXZGdnQ0XF5c6l52IiIjunNpcvxVrliopKUFkZCTCw8NNtoeHh+PAgQNVPmfjxo3o1asXPvnkE7Ro0QLt27fH7NmzUVhYWO37FBcXIycnx+SHiIiIrJdizVJpaWnQ6XTw8fEx2e7j44Pk5OQqnxMTE4N9+/bB3t4e69evR1paGl588UVkZGRU2+9mwYIFeO+99yxefiIiImqYFO9QrFKpTB5LkmS2zUCv10OlUmHVqlXo06cPRo8ejc8//xwrVqyoNnszZ84cZGdnyz/x8fEWrwMRERE1HIplbjw9PaHRaMyyNCkpKWbZHAM/Pz+0aNECrq6u8raQkBBIkoSEhAS0a9fO7DlarRZardayhSciIqIGS7HMjZ2dHcLCwhAREWGyPSIiAv3796/yOQMGDEBiYiLy8vLkbZcuXYJarUZAQEC9lvdW8orL8MOeGHy/54qi5SAiImrqFG2Weu211/Djjz9i2bJliIqKwquvvoq4uDhMnz4dgGhSeuKJJ+TjH330UXh4eODJJ5/E+fPnsWfPHrzxxht46qmn4ODgoFQ1AAAFxWX4cHMUPt56UdFyEBERNXWKznMzefJkpKen4/3330dSUhK6dOmCzZs3IygoCACQlJSEuLg4+fhmzZohIiICM2fORK9eveDh4YGHHnoIH3zwgVJVkGnUop+QTi/dtN8QERER1S9F57lRQn3Nc5NdWIrQ97YBAC59MAp2Nor31SYiIrIajWKeG2tjq6nI1JTp9QqWhIiIqGljcGMhhmYpACjTN6lkGBERUYPC4MZCbNUVH2WZjsENERGRUhjcWIharYIheVOmY7MUERGRUhjcWJBNefamlM1SREREimFwY0E25Z2KdWyWIiIiUgyDGwuyKW+XKuVoKSIiIsUwuLEgW434ONmhmIiISDkMbizIMByc89wQEREph8GNBTFzQ0REpDwGNxZk6FDMzA0REZFyGNxYkKFZqpSZGyIiIsUwuLEgwyzFOs5zQ0REpJg6BTfx8fFISEiQHx85cgSzZs3C999/b7GCNUaGZqlSzlBMRESkmDoFN48++ih27twJAEhOTsY999yDI0eO4O2338b7779v0QI2JjbsUExERKS4OgU3Z8+eRZ8+fQAAv/76K7p06YIDBw5g9erVWLFihSXL16jYyEPBGdwQEREppU7BTWlpKbRaLQBg+/bteOCBBwAAHTt2RFJSkuVK18jYcJ4bIiIixdUpuOncuTOWLFmCvXv3IiIiAiNHjgQAJCYmwsPDw6IFbEw4zw0REZHy6hTcfPzxx/juu+8wZMgQPPLIIwgNDQUAbNy4UW6uaooqhoIzc0NERKQUm7o8aciQIUhLS0NOTg7c3d3l7c899xwcHR0tVrjGxtawKjj73BARESmmTpmbwsJCFBcXy4HNtWvXsHDhQly8eBHe3t4WLWBjYlM+z00pgxsiIiLF1Cm4GTt2LFauXAkAyMrKQt++ffHZZ59h3LhxWLx4sUUL2JhoDMsvsFmKiIhIMXUKbo4fP45BgwYBAP773//Cx8cH165dw8qVK/HVV19ZtICNia2azVJERERKq1NwU1BQAGdnZwDAtm3bMGHCBKjVatx11124du2aRQvYmBgm8ePaUkRERMqpU3DTtm1bbNiwAfHx8fjrr78QHh4OAEhJSYGLi4tFC9iY2LJZioiISHF1Cm7effddzJ49G61atUKfPn3Qr18/ACKL06NHD4sWsDGRh4KzWYqIiEgxdRoKPmnSJAwcOBBJSUnyHDcAMHz4cIwfP95ihWtsbORVwZm5ISIiUkqdghsA8PX1ha+vLxISEqBSqdCiRYsmPYEfYNwsxcwNERGRUurULKXX6/H+++/D1dUVQUFBCAwMhJubG/71r39B34SzFho1OxQTEREprU6Zm7lz52Lp0qX46KOPMGDAAEiShP3792P+/PkoKirChx9+aOlyNgpy5qYJB3hERERKq1Nw89NPP+HHH3+UVwMHgNDQULRo0QIvvvhikw1uDH1uytihmIiISDF1apbKyMhAx44dzbZ37NgRGRkZt12oxsqGQ8GJiIgUV6fgJjQ0FIsWLTLbvmjRInTr1u22C9VY2ajZoZiIiEhpdWqW+uSTT3Dfffdh+/bt6NevH1QqFQ4cOID4+Hhs3rzZ0mVsNAwzFLNZioiISDl1ytzcfffduHTpEsaPH4+srCxkZGRgwoQJOHfuHJYvX27pMjYa7FBMRESkvDrPc+Pv72/WcfjUqVP46aefsGzZstsuWGMkz1DMZikiIiLF1ClzQ1WzNYyWYodiIiIixTC4sSB5tBT73BARESmGwY0FaThaioiISHG16nMzYcKEm+7Pysq6nbI0erbyaCk2SxERESmlVsGNq6vrLfc/8cQTt1Wgxkye54bNUkRERIqpVXDTlId514ScuWGzFBERkWLY58aCKoaCs1mKiIhIKQxuLIijpYiIiJTH4MaCDM1SOgY3REREimFwY0FsliIiIlIegxsLqpihmJkbIiIipTC4sSAbLpxJRESkOAY3FsR5boiIiJTH4MaCbDjPDRERkeIY3FiQDTsUExERKY7BjQVxKDgREZHyGNxYkMaoz40kMcAhIiJSAoMbC7ItHy0FsFMxERGRUhjcWJChQzHATsVERERKYXBjQYYOxQDnuiEiIlIKgxsLMglumLkhIiJSBIMbC9IYBTelzNwQEREpQvHg5ttvv0VwcDDs7e0RFhaGvXv31uh5+/fvh42NDbp3716/BawFlUoldyrmcHAiIiJlKBrcrF27FrNmzcLcuXNx4sQJDBo0CKNGjUJcXNxNn5ednY0nnngCw4cPv0MlrTmb8sUzS8sY3BARESlB0eDm888/x9NPP41nnnkGISEhWLhwIVq2bInFixff9HnPP/88Hn30UfTr1+8OlbTm7GzER1rCWYqJiIgUoVhwU1JSgsjISISHh5tsDw8Px4EDB6p93vLly3HlyhXMmzevRu9TXFyMnJwck5/6ZJiluKSMwQ0REZESFAtu0tLSoNPp4OPjY7Ldx8cHycnJVT4nOjoab731FlatWgUbG5savc+CBQvg6uoq/7Rs2fK2y34z2vLMDdeXIiIiUobiHYpVKpXJY0mSzLYBgE6nw6OPPor33nsP7du3r/Hrz5kzB9nZ2fJPfHz8bZf5ZgwditksRUREpIyapT/qgaenJzQajVmWJiUlxSybAwC5ubk4duwYTpw4gZdeegkAoNfrIUkSbGxssG3bNgwbNszseVqtFlqttn4qUQVDn5tSNksREREpQrHMjZ2dHcLCwhAREWGyPSIiAv379zc73sXFBWfOnMHJkyfln+nTp6NDhw44efIk+vbte6eKflOGPjfFzNwQEREpQrHMDQC89tprmDJlCnr16oV+/frh+++/R1xcHKZPnw5ANCldv34dK1euhFqtRpcuXUye7+3tDXt7e7PtSmLmhoiISFmKBjeTJ09Geno63n//fSQlJaFLly7YvHkzgoKCAABJSUm3nPOmoZFHSzFzQ0REpAiVJElNara5nJwcuLq6Ijs7Gy4uLhZ//SlLD2NvdBq+mByK8T0CLP76RERETVFtrt+Kj5ayNpznhoiISFkMbizMTm6WalIJMSIiogaDwY2F2dowc0NERKQkBjcWZsjccIZiIiIiZTC4sTA7m/IZipm5ISIiUgSDGwtj5oaIiEhZDG4sjKOliIiIlMXgxsIMMxRzEj8iIiJlMLixMGZuiIiIlMXgxsLktaWYuSEiIlIEgxsLs2PmhoiISFEMbizMViOGgpdyhmIiIiJFMLixMDsbDQCgmJkbIiIiRTC4sbCKzA2DGyIiIiUwuLEwdigmIiJSFoMbC2OHYiIiImUxuLEwZm6IiIiUxeDGwgyT+LFDMRERkTIY3FgYMzdERETKYnBjYfLyCwxuiIiIFMHgxsK0hsxNGSfxIyIiUgKDGwtj5oaIiEhZDG4sTO5zww7FREREimBwY2GGGYqLmbkhIiJSBIMbCzMeLSVJ7HdDRER0pzG4sTDDDMWSBJTpGdwQERHdaQxuLMyQuQE41w0REZESGNxYmGG0FMD1pYiIiJTA4MbCbNQqqESfYg4HJyIiUgCDGwtTqVQVc90wc0NERHTHMbipB1qNYcQUOxQTERHdaQxu6oGtDTM3RERESmFwUw/sNFwZnIiISCkMbuqBrU35LMXM3BAREd1xDG7qgdZGAwAoLtMpXBIiIqKmh8FNPXB3tAUAZOSXICm7UOHSEBERNS0MbuqBZzMtAGD+xvPot2AH1hyJU7hERERETQeDm3rg5SyCm7S8YgDAnPVnlCwOERFRk8Lgph54lWduDBxtNQqVhIiIqOlhcFMPPJ0rBTdaG4VKQkRE1PQwuKkHlTM3TnbM3BAREd0pDG7qgVelzI2dDT9mIiKiO4VX3XpQuVkqr6hMoZIQERE1PQxu6oFnMzuTx9mFpQqVhIiIqOlhcFMPDDMUG+SX6LjOFBER0R3C4OYOyWH2hoiI6I5gcHOH5LDfDRER0R3B4KaefPpgKDr6OsuP2e+GiIjozmBwU08mhQVg66zBCPFzAVAR3Lz122n8cwOXYyAiIqovDG7qmYu9mJ04u7AUaXnFWHM0Hv85FIfU3GKFS0ZERGSdGNzUM1cHWwAiuDFumorLKFCqSERERFaNwU09MwQ3OYWlyCookbdfS89XqkhERERWjcFNPTMNbioyN1fTmbkhIiKqDwxu6plxs1SmUXDDzA0REVH9YHBTzwyLaCZmF5k0SzFzQ0REVD8Y3NSz1l7NAAAxqXkmzVLM3BAREdUPBjf1rLWXEwDgelYhknOK5O1ZBaYdjImIiMgyGNzUMw8nO7g62EKSgBNxmSb74jMKFSoVERGR9VI8uPn2228RHBwMe3t7hIWFYe/evdUe+/vvv+Oee+6Bl5cXXFxc0K9fP/z11193sLS1p1Kp5OzNlVTTpijjTA4RERFZhqLBzdq1azFr1izMnTsXJ06cwKBBgzBq1CjExcVVefyePXtwzz33YPPmzYiMjMTQoUMxZswYnDhx4g6XvHbalPe7MbDTiI+dwQ0REZHlqSRJkpR68759+6Jnz55YvHixvC0kJATjxo3DggULavQanTt3xuTJk/Huu+/W6PicnBy4uroiOzsbLi4udSp3bX276zI+2XpRfhwa4IpTCdmYMbQN3ri34x0pAxERUWNWm+u3YpmbkpISREZGIjw83GR7eHg4Dhw4UKPX0Ov1yM3NRfPmzas9pri4GDk5OSY/d1o7b2eTxx19xUlJymbmhoiIyNIUC27S0tKg0+ng4+Njst3HxwfJyck1eo3PPvsM+fn5eOihh6o9ZsGCBXB1dZV/WrZseVvlrot+bTygVlU87ugngp1kBjdEREQWp3iHYpVKZfJYkiSzbVX55ZdfMH/+fKxduxbe3t7VHjdnzhxkZ2fLP/Hx8bdd5tpqprVB95Zu8uP2PuXBDfvcEBERWZyNUm/s6ekJjUZjlqVJSUkxy+ZUtnbtWjz99NNYt24dRowYcdNjtVottFrtbZf3dg0P8cHxuCwAQAs3BwAic1PTYK4qt/NcIiIia6VY5sbOzg5hYWGIiIgw2R4REYH+/ftX+7xffvkF06ZNw+rVq3HffffVdzEt5qkBwQjv5IM37u0AX1d7AEBBiQ45RWV1er0X/hOJsd/sR5lOb8liEhERNXqKZW4A4LXXXsOUKVPQq1cv9OvXD99//z3i4uIwffp0AKJJ6fr161i5ciUAEdg88cQT+PLLL3HXXXfJWR8HBwe4uroqVo+acLDT4PsnesmP3RxtkVVQiuTsInlxzZoqKdNjy1lR96ikXHQNaNh1JyIiupMU7XMzefJkLFy4EO+//z66d++OPXv2YPPmzQgKCgIAJCUlmcx5891336GsrAwzZsyAn5+f/PPKK68oVYU683UR2ZvLKXm1fm56frH8O1uliIiITCmauQGAF198ES+++GKV+1asWGHyeNeuXfVfoDtkcHsvXEjOxbrIeNzXza9Wz03LrViTqqBEZ+miERERNWqKj5Zqqh7pEwgA2H0pFfEZBbV6blpeReYmv7hufXaIiIisFYMbhQR7OqF/Gw9IErD5TFKtnmsc3OQyuCEiIjLB4EZBQzp4AQCOXs28xZGm0vIqmqXqkrm5kVOEUo6yIiIiK8XgRkG9W4llIyKvZUCvr1jiKyW36KazF99Os1RUUg76/t/feOzHw7UsLRERUeOgeIfipqyzvyvsbdXILCjF4dgM/LA3BgPbeuLziEuw1aiw/61hcLQzP0XpRsFNXi2Dm3XHEgAAR2Izbq/wREREDRSDGwXZ2ajRvaUbDsVk4JEfDgEAdlxIkfdfupFnsmyDgXGzVF4tJwHUMFdHRERWjpc6hQ3rWP26WD8duIq3fjuNwkrDvU2apUpqF9yojVbwlCTpJkcSERE1TszcKOypAcEo1Un4z6FrSKrUz2b9iesAAF9Xe8wa0V7enmbSLFW7eW40RrP+FZbqqmz2IiIiasyYuVGYjUaNGUPb4uCc4fhuSliVx1xLr5gHR6eXkJFf99FSRv2WkV1YWrvCEhERNQK8bW9A7m7vhSEdvHA9sxDRRssyxKbl45udl3EkNgP3dfMzCVBq2+fGOBjKLiyFn6vDbZebiIioIWFw04DY22qw4sk+SMkpQp//+1vefjI+CyfjswAAh2PTTZ5T29FSxsdnFzBzQ0RE1ofNUg2Ql7O22n1FpWLyPa2NOHX5JWXILijFz4eumXU8ropxcJNTy6wPERFRY8DgpgFSqVT4ZFI3TLkrqNpjurRwBSCamT6LuIh3NpzFD3tj5P3f7b6C5ftjzZ5n3IzFPjdERGSNGNw0UA/1aol/jeuCqf1EgPP84NYIcK/oH9PF3wUAkFtUJk/IdyJOLONwI6cIC7ZcwPt/nkdOkWkAk1fM4IaIiKwb+9w0cLPv7YDB7b0wtIM3LiTnIiGzEEBF5qa4TI8LybkAgHOJOQAgP5YkIDY1H6FGEwEadyjOYXBDRERWiJmbBs7Z3hbDQ3ygVqvQ2stJ3m4Iboyl5BYjNbcYl8qDGwCIScszOSaXmRsiIrJyDG4akTZezQAAapX43a6KtRTOJWbj4o2K4CY2Nd9k/80yN7Fp+Zix+jjOJWZbsthERER3FJulGpEOvs4AgFYeTrCzUUNvtHyCSiWaoaYtP2rynCtpFcGNTi+hwGhEVeXMzQv/icSF5FxEXs3EobeH10cViIiI6h0zN41IryB3vHN/J3w8qRsAoMxoNr9nB7Wu8jnGmZvK61BV7mxs6KuTnGO6DAQREVFjwsxNI6JSqfD0wGD58YyhbbD1bDK+fqQnWns5IcjDEf/ccBbG62HGpuVDr5egVqvMZjNuLH1uJEmCymhNLCIiopth5qYRe+Pejvj79SHo5O8Ce1sNHusbhENzhqOzvwsevysQNmoVCkt1OBGfhb/OJeNGpYyMcXCTmltssk+nr92K4cVlOiRnWz7jk1tUiqGf7sI/N5yx+GsTEZF1YubGyvi42GPTy4MAAAmZhdh1MRUTFx8wOcbBVoPCUh1ScouxYn8srmcVYlA7L5NjknOK0MKt5utOPbXiKPZfTsffr98td3y2hHOJObiaXoC84mR8MK6rxV6XiIisFzM3Vmx2eIcqtwd5OCLY0wmSBMz/33n8sDcWP+4znc04IaMAkdcycSE5p8rXKCrV4fEfD+Pff11AmU6P/ZfFmlebTidZtA6Z5Sug5xSWQZJql00iIqKmicGNFevSwhXPDW6NIA9HfD8lTN6eW1SGPq2amxy751KqyePIuExM/u4gRi7ca9ZkBQC7LqZg3+U0fLPzCk6UL+oJAM20lk0GZpYv7lmi08vrahEREd0Mgxsr9/boEOx+YyjCO/vK265nFaJPcPMqj/d1sQcA/H78ujwaa8nuK2bHJRn1r/l252X594zyTIulZBZUvF51HaCLSnUY/eVevPnf0xZ9byIiapwY3DQhn0wUQ8in392myuBGpQIe6O4PALicUjGz8c+HriE9zzR7cyW1Yv/OixVZn/R88yzP7cg0CpYqD103iLyWifNJOVh7LB4FJVzpnIioqWNw04Q81Lslds0eglfvaYcAdwc8N7g1BrXzlPe39WqG7kbrUBmUlOnx+/HrJtuupOSbHQcAqbmWzdxk1CBzU2g0MeHZ61X3ESIioqaDwU0T08rTCVobDVQqFd4eHYIVT/aR93k202JEiA/cHW3lba8MbwcA+HBzFKYsPYzeH27H3uhUk8yNsbRKGZ4TcZmISy8AAPx1LhlTlh7G7HWnkJpbjJIyPfS3GHKeVVAR0GQXVB3cGGeLThn1/yEioqaJQ8GbOI1aJS/dMKyjN+xs1Hj1nvZ4949z8HWxx7ODW+OHvTEoKNFhb3QaAOD1X08hpbyT8bF/jkBsWj6ib+Th7fVnTAKNxKxCTFpyEHpJwvJpvfHpXxcRXd7cVVBShr/O3cCLQ9rg6YHBsNWo4VRFZ+SMGjRLpeVVHHMqIeu2PxMiImrcGNwQNr88CPsvp+HJAWL24yl3BcHBVoMQPxc009pgwYSu2B6VglYejvh6x2U5sPF21sKzmfjxdtYCANJyS1BSpsfaY/HQ6fTyZIBPrTgK4yTN5jPJAICvd1zGqsNx8HbWYssrg1Ci0yM9rwT+5XPsZNWgWcp4NBeDm/rF2aKJqDFgcEMI8XNBiJ+L/FilUuHBXi3lx2O7t8DY7i0AAC72tvhwcxQAoFuAm3yMZzMR3BSW6jB3/Rmsi0wweY+btT5l5JcgI78EKbnFWLg9GmuPxmHZtN4Y0sHbJHNjCG4SswqxNzoV43sEwM5GbdIUFp9RiOyCUrgaNa2RZbyx7hQOXEnH1lmD4GzPz5eIGi4GN1QrTw8MRucWLkjNLcaAthWdkZ20NvLMx5UDG2MB7g5IyCysct/5pBz8ciQOAPDkiqOI/mAUcozWw8opFL9PXXYE0Sl5SMkpxszh7ZCeZ9qJ+UpaHnoGute5jlS1iKgbyCooRVRSbrVTCRARNQTsUEy1olar0L+NJ8Z2byFnaww8mtlV+Zxx5cPLAeC+rn7QqKtu1th2Lln+XZKAr3ZcNtlvyNwY+u2sPyFGcFXuxByTWvVILqo7nV6SP39Lz2VERGRpDG7IYkrKqp5B+In+reTf2/k4I8jDUX5sZ1PxJ/jLkXiT5331d7TJ4+zCUpPRVcXl72cIbnq3Etma9ScSsGhHNMp0NZ/R+MCVtFpdtC8k52DnxZQaH9/Y5RSWyqvNV/6cEjILTIbjExEpjcENWUxYkAgu7DRqDGjrIW/vHuCGwe290NzJDkM7eMkLa4YFuWP/m8PwzaM9TV5nWv9WmB3e3uz1c4pKkWS0snlOUSnKdHp5iQZDU8n+y+n4dNslbDiZWKNy77yYgkd/OIy562u+8vgzPx3Dk8uPIj5DDHOPvpGLAR/twOrDcTV+jcYky6gzt/Gs0XHpBRj8yU489/MxJYpFRFQlBjdkMS8Pb4fpd7fBgTnD8FT5yKvWXk5Qq1VYOrUXDs4ZBo9mWnT0dQYAhPg5w8tZix6Bbiav0ze4OV4a1s5kvh1AZA+upVU0OeUWleFCci4AQK2qCK4Mdly4UaNyH7gshrgfikk3WZxTp5eQnldstmBnQUmZ3G8oprw8Oy+m4HpWIf53qiKgmr/xHEYu3GMVzTjGAY1xH6cLyTnQS2L1diKihoIdislijEddDQ/xwepn+6K1p8jS2Goq4uip/VvBRq3GQ70DAAB+rvbo0sIF5xJz0LtVcwxu7wUA+GPGQLz260l08nfByoPXkJZXIgczBvvLA5PmTlq09XI22bf3UhpKdXqT967KqfhsAGKRzsTsIrQoH4b+8dYL+H5PDFp7OuGrR3qgSwtXAGK0lkFydmH5NpFRulGeWdLrJaw4cBWAWJvr7dEhN//wGjjjIfnGgY5hjqGM/JIafdZERHcCv4mo3vRv4wlfV3uz7Z7NtHhlRDv4uYogQqVS4Y8ZA3F2/r349fl+8mR+gR6O+O8L/eUsUFpeMd7/87zJa608eK38Ne3Qwt3BZF9ucRnGfL0POy+mmGVfDMp0epy5ni0/Plf+u04v4b/lo75i0vKxyqi5Kd5otJchqEkqD3KSsosgSZLJiLB95ZMfNmbGM0Wn5xsHNxWdua0hQ0VE1oHBDTUIGrWqyhmKAcDLWQu7ShmBPq1E/5rr5VmUJ/q1gkatwvS722BAWw+MLR+hdSE5F08uP4ovtld0Tp7z+2kM/XQXUnOLsftSKgpLjdamKm9eORmfZXKxPmsUABkHLsnZhuBG/FtYqkNOURku3ajIMJ1Pyql2uYrGItMouMkwmoXaOLgxnkyxPq3YH4vPIy7dkfdqqq6m5WPF/thadconakjYLEUNnpPWBr881xdXUvLxj99OAwBeGdEONmoVfj2WgPu7+WFoR28AwFujOgIA8ovLMCLEBwdj0rH6cBxWHryKmcPaIjO/BGuOxkOSgOGf7TKZRwcQmZvDMemYuvwIACA0wBWnErIRlZSDtUfj0CfYAwmZBfLx1zLycS4xW87gACLgiU4xDWYOxaTLHalTcorg4mALe1tNlfUtLNFh5i8n0NnfBa/eY96xur4YOmd7OWvN9pk0S+VXBDp3OrgpKdPjX5uioNNLeKhXAALcHW/9JKq1DzZFYXvUDdho1Hj8rqDbeq2k7EJ8u/MKpvZvhbbezSxUQqKbY3BDjUJYUHOEBTVHO59mOB6Xhf5tPKBSqdC3tUeVxztpbTAm1B+ju/ph27lkpOWVYN/lNMRnFMhDmo0Dm4d7t8Sao/E4EpuB/VfSUFQq7lif6NcK/9p0HlkFpXjztzNo4eYgd4gGgEMxGbjvq30m752UXYjoG6Z9gy6XBzuXU/Iw+qu9CHB3wJrn7oK3sz2Ssgux/3I6hnbwwucRl+DiYIvtUTew62IKnh3cGs20NijT6ZGUXYSWzWt2Mc8uLMXjPx5GaEtX/GtslxotmfDK2pPYciYJf80ajHY+pv2XTJulqg5o7kRwk5JbJC/pkZBZaLHgprBEh50XUzC4vReaVZNBrA8R52+guZOdWWd4pV1OEX+/uy6m3HZwM3vdKey/nI6t55JxdO4ISxQP28/fwOYzSWjv64zpd7exyGuSdWFwQ41Kj0B39KjF7MMatQqjuvjh50PXMHP1CeQVm2ZqnLU2OPHuPVCrVDgSmyGPfgKAh3oF4L5ufvj1WDwOx2YAEM1g17OqnmHZ4EZOReZmWEdv7LiQgv8eS8Cui6nILixFSZkeMan5eGLpEfz+Yn88veIYzieZjzYq00s4HJOO4SE++HjrBfywNxZLp/bC8BAfFJXq8MSyIwj2cMLHk7rJz0nLK8aX26Ph46LFmevZOHM9G36uDpgxtK3Z65fq9Hjzt9OwVavx4tA22HQ6CQCwZHcMPnso1ORY407ERaV6FJbo4GCnMVm0NDWv/oObGzmmC7PWxYErafB21qKtd0UAt+LAVXy89QJeGtoWs+/tcNvlBMQ6XHM3nIUkAQsmdDXbfy09H8+uFEPoYxeMrvWaXWU6PZbtj0X/Np5yZ3cAKCrVIfpGHjr7u0BdzYSZN6PTS/Lf+MEr6Sgp05vMR1VbR2MzAVgu+D0Uk45nVlZMPTApLMBsQtG6MvTB69LClZ3jGzmePbJ643uKdbEMgY1aBXRv6QYAWDCxK2w0aqjVKjwzqLX8nCWP98Qnk0Jhb6tBsKdTrd4vNq0A0eV3vqO7+gEQnZtj0/JN+vFcSM7FOxvOVRnYGOy7LEZ8/bA3FgDw0ZYLAIATcVk4EpuBtcfiTZqM3tlwFj8fuoZPt1X0Sfny72gUl1X0K8orLsPC7Zew5mg8fj9+HWuPxeP+ryuyT/mVAkDAfNFSQ/YmrZrMjSRJZqu477yQgojzN6rt3F0TN4zmObpezTIeNxOfUYDHfjyMacuPmmw3nINLlTJutyMhsxCrD8fhlyNxVV7Yr6ZXNG8mG9WrpvZEp+L/Nl/Ae/87Z7L9k60XMWbRPmw1mvG7NpJzilCqE+cov0SHE3GZt3xOQUkZXlp9HBvKZw03djuBUWWSJJn1t6puOZe6+GbnFYz/9gC+qEOfrsSsQhwpvwki5TG4IavXM9Ad66b3w6wR7fDS0LZY8WQfrHy6D/6YMQD3d6tYGmJCzxboGSgmHLynk6+8fcbQtujfxgMrnuyNaUazLVdnye4rKCrVI8DdASNCvM32uzvaYvWzfaFWAb8dr34dLgDYfSkVOy9UzIScU1QKSZJMOjifiMuSfz961fzLtaRMLzeLAcDc9WewcHs03tlwVt6Wa9REdzXdfPkK48wNIPrdFJXqkGsUCBlfwJftv4pu87dhY/m8P1kFJXh25TH5R3ezlVRvwtCBGwASs80vajsvppg1CRo7n5QDSRIXxEyjQPNaeZ1vlZWrDeNzVNXr3jCqS12WDInPEK9pHCQBQFR5oGb8/rURV+n19kSn3vI53+2OwZ+nkzBr7UmzfVqj4Kau593gdEI2jsRmwE6jlqdsMO4DV1tlOr1Jmb7YLoKab3ddqfVr3fvFHjz03UGcjM+qc3mqklVQglFf7jWbsZ1ujsENNQm9WzXHrBHtMfveDhjc3gsu9rYILc/eGNjbavD7iwOw8qk+JutftWzuiNXP3oUhHbzx7v2d8OqI9nh7dMdbvue0/q3g5mi63taksAB8/UhP9G/jiWEdzQMfb2ctHukTiM8fCoWdjRoxqfl47udIef+NnGJcSy/A2cSKC9dxozvryqPKfFxEuv6hJQcx+JOduJ5ViD9uMXPz5ZQ8FJWaLqdg6ERsaDlJzy82W9PLENyU6vRYsltcHJbuExmnC8m5KCu/iGyPSkHkNVHmlJyiWmVyjDM3CZmFOHs9G2/+9zQSswpxPjEHTy4/avJ5VWYcRBhGsEmShNjy5sibNXXp9BL2X05DcZkOa47EIfLaze/SjacYqCrLZHxRjqnDaLqUXPFZpOYWm2TmbpRvr2ugZph12/B/YG8NpjK4kFyRfay8FIdxc5uhzHVl+Lvv18ZDXm6lrpmbkjI9whfuwbhv9st/g452FZ38a/N3KUmSHOjviKp68tDcolKz/zM1sWxfLKKSchQdIXghOQcPLNqHvTUIdBsKBjdEtaBWq/DKiHZ4bnAbfPtYT4zt7o8lj/dEcyc7PD0wWD7OWWuDyb1bmj3/0wdDMbCdWE19ZBc/s/2ju/phwYSumNAzAIsf6wnP8sVIVaqKO+DHfjxsEqAYgpvcIjEJobFR5e+RX6JDXEYBXl1z0uw9+1XqlF2ml3DpRi7S8orxyPeHsHRfrNws1a58tEv0jTyT/jYAcORqBiLO38DGk4lyoHMqPgtXUvPMsilHYtPx/v/Oo8///Y3VR2q+ZIVx882JuCzc//U+rD0Wj+X7Y3GsPNiITcs3CYKMGQ/JN2SzMgtK5cxVZkEpCkrMm+UAYO3ReDz242EM+3Q33vr9DJ7/+Tj0eglfbo/GyIV7TC7wQKXgJss8u2B8Ub5Sh8yNcf+jG9kVv6eUb69Lsx0AxJcHXYbg+8z17FvOYRSbZh40AmIyS+Nm04TMQuy5lGoSkNdGbPnn1MarmdyZvK71vJySh5jUfJy5ni1P5dDcqeJmxJAZqwnjZtvKIzABEfw8uOQghn26S54Tq6auG43EvJ3M1/G4TKRXE1xJkoQTcZlmNzUGH2+5gNMJ2Ziy9MhtNSvfSexQTFRHo7v6yX1qRnbxg14vwc3BFsVleoR39oGzvVg+Yu7oEHy4OQqLHzNdQ+ueEB/59+cGt4aq/F+D4SE+2PuPYYhOyUUzrQ0izt/Agi0XzO7I919Ox4CPdphtv7u9FzqVzxhtcKSKZqsJPVvgYEy6ybYV+69Ca6vBwZh0k30jQnxw6UYejl3LkBdAddbayHetzxp19NSoVdDpJfx6NB4F5XfzTnYa5JfoTPoErT4ch/E9WuC9jecR6OGIqf1b4YuIS7h0IxdfTO5u0lnUuFnKuHP4qfhsk7l4TsVnIbxzRdOiQUwVwU3lZrjrmYVo5+OM7IJS6CRJvuB9vUM0Cxg+57S8YpxKyJKbMkYu3IsDbw2Dv5uDWdNhVdkF0+Cm9pkb4wAuMbsQgR6OyCsukz+XumZu4sozN72C3BGfUYALybnYfzkNY0L9qzw+u7AUl26Yfq6GDs5ZhaVyxg4AjsRm4N9/XQQAXPxgJLQ2VU+HYCw+owB/nUvGE/1ayUFUsJcTbMozS3VtljLuXxWdkgd/NweTUYEnE7IQ6FGz0XhJ2cYZRfPyJGYXybOr/7g3Fu/c36nG5TRd+qQY3i7mE6Peyv9OJWLmLycwIsQbP07tbbZ/69lkvLDqOO7r6odvKn1PAaZryx28ko7+bT3lx2U6PdLySqqcsFVJzNwQWYharcLM4e0w+94O6BbgJm9/emAwjs4dgVFdTTM1ro62eHJAK7TycMRzg1tjzugQeFQa9eFgp0G3ADe09mqGZwa1xrJpveBRfrFVq4CA8lmZjS9kA9t6YvUzfbFwcnd5OYzKDKN3hnbwMinrpLAAqFXA7yeu45dKGZWegW7y3fxf525g/kbRkfXuDl4YEeKDjr5irTC1Crinkw8+mShGca04cFVeQf3xfubDii/dyMVra09h7bF4/Puvixj48Q4s3ReLvdFp+PngNVy6kYvsglI8teKoPGqtstj0fJxJqAgmTiVkVXmc8Wi4y+UBxdU00+AmIasQxWU63L9oL8K/2C0HCw5VzEv0c/kM2QaGjFpCZqFJsFVVdsH4nNWlz01KFSPHjAOeGzlFKK3lJHySJMlBX2BzRwwqzzJ++Xd0tcFS5SyMoTM9YD5CavfFimaN84k5yMgvwbZzyWbZAL1ewkdbLuC1tScx5/cz+GBTFFYevCoHN609neS//do0Sxln5S4aBTeXU/JMAkNABMi3ci09HzlFpSZBd+U5riq/1m/HE5BfXIYrqXk1yoIYB77GQVT0jVz8c8OZKjurl+n0Jtkkw6LA26NSzI4FgOXlS8VsOpMkTwNgzLh/2KpK3wvvbjyHuxb8jUPlN0ENJbPDzA1RPVOrVVVOjAcA88Z0xrwxnWv0Ohq1CsM6+mDzK4Pwzw1ncU+ID0Z19cWZ69lIzi7Ca7+eAgB4NLOT76wc7MwvyH1aNccjfQLRyc8FQR6OJvO6PNInEAPaeuDVtafMnvdwn0B0DagYcpyYXYTWnk6YMzpE7txZptOjVCfBwU4DSZKw9piYO8hwAbq/qz++2x0DAGjj5YTCEh0Ss4tMRvZkFZTKGZ4v/47Gl39Hm2SHjN3d3gt7olORmlts8iVvWC/MWEZ+icmd+a6LqTh4Jd2sQ+71zEJsO3dDbpY4djUDvVs1R2wVHa1/rzQ6yJCtqdxP5WBMOn6LTMB93fxgb6tBqU5v0jyRmF2I3ZdSMaitJzILSvD1jsuY3Lslvvo7GmFB7iYj+QyM+69UFdzoJZHpquncSBeSc/DTgWs4l5gDW40K3Vq6oUsLV/xxMhGXU/Lwyi8n8N8X+ps9z7DwrEG0URan8oXXOHN4Ii4Lb/z3NC6n5OHbx3rKWVBJkjBv4zn8fMg0cNxxIUXOKgV7OslNKNezCiFJElQqFZKzi/DyLyfw2F2BGNu9hfzc7IJSzFl/GpvPJGNcd3+8N7aLSVPp5ZRcs6bMY5WynEWlOiRmFSKwuSNsNGqcTsjChG8PoHer5iZZrfiMAlxNy8fiXVdwXzc/DG7vZRLcZBWU4rmfj2H/5XS890BnTC0fpPD78QSU6SU81KuiObugpEyuMyDm0Apt6QZJknDfV/tQotOjuFSPfz9oOnXDjNXHsedSGtY8dxdUKtOmsvS8Yng000KSJBSW6mBvozH5LEZ8vgdzR4fg2fIscl5xmUlz964LKXj8x8PwctZi7n0hWF2+NM1PB66imdYG05YfxeTeAXjj3lv3S6xPDG6IGhkfF3v88EQv+XH/NiKQ0UvA59su4skBFX1/7G01+PLh7kjPK4GXsxarDl/DvyeJL0LjDtVfTA5FTGo+ega6ISzIHf6uDliy+wr6t/HE/22JgrPWBvd384PWRgMfF63c32P1s3eZpKNtNGoYWhpUKhXee6AzRn25V97fzqcZ/jGyA7aeTcY3j/bEoh2XsfZYPADg/bGdUVKmR36xDo/2DUTvD7fLz6sc2Lw1qiMir2Xi00mhGPvNPjlAMTSFHbmage92X8Gzg1qjVK/Hn6eS8Ef5yC1nexu5j80jPxySAzNbjQqlOgmJWYX4yyjY2hudhiup+ZAkMax5eEdv9GvjgXkbz8kTQrbxcsKV8v4bAORM1fgeLbD+xHUUlOjw+rpT+HTbRfQMcse47i2gL3+9sEB3HIxJx9RlR+DrYo/O/i74+0IKVh2+hlKdhC1nkzGuRwv8dOAq/o5KwXdTwqBRq0wyQ4aLj3E2BwD+9ed5zL63A9pXmpQREEuM/OO/p/DWqI7o2sINYxftR3GZyPQ8P7iN/Ln89kJ/DP9sN45dy8TJ+Cx5GgWDneXZmEf6tMQvR+JxITlXDjZS86rvQPzb8QQ5S/S/U4lycLPxVKJZYAMAB66IzIC9rRq+LvYoKc9KFZTokJpXDG9neyzZfQVHrmbgyNUM3NPJB452YgLMp346Kndi33AyEQ52NmaZG0NwYwisz1zPxh8nr8PF3haD2nli+n8isetiKlzsbbDiqT5YdSgOZXoJB2PSEWgUQOol4J0/zmJvdBrWHovHa/e0NxtBtf+yqMu8jecwtX8rpORW3Jx08nORm/Uup+TBOBFiyNxsO39Drn9EpQ7MGfkl+Ouc2Db2m/0mnaQBkVmKyyjAW7+dQUxaHrq3dDP5WwKADzdHIdDDEfd29sWV8nPk7iia3PNLdNhXHtC62FeEENezCjFx8QEUl+nxzc4rmB3eodZzN1kSgxsiKzEpLACTwgLMthvfwVbXb2J8D9Pn9W3tIc/+3NHPGe6OdnC0E18X/7i3Iz756wI+mtjtlu3sIX4uWPJ4GGasPo7uLd1gb6vBi0Pa4sUhYlLBcT1a4NfIeDzaJxBT7goy+TKcFBYgL15qYGejRvcAN5NZaYM8nOTgZkw3P9zIKcbBmHQs2HIB+y6nIaeozOTOeUKPFvBy1sr9fq5nFcLORo1H+wRixYGrZsOADSO+AGBAGw8sfjwMAHDsaqY81P2RPoH4YFMU4jIK8PXf0Yg4Ly4uj/UNxHqj7E5SdhE2nU7C1rMieAps7ohl03rjX5vOY/XhOCTnFMmdpg1zzQCi+evrHZcBAIM+2Wn2OVeVuQHERXD/5TT88EQv9G/riX3RaUjOKcLEni3wj/+ewqUbeXhqxTF8MrGbHNgM6eCFl4ZVTPrYsrkj7g/1w+/Hr+ObnZfx3eNhyCspw/rj13HkagYup+RBrQKm390Gvx+/jriMAmw6k4T7u/nLmZuwIHc5uDA4l1jRAdswiuhkfJY8RcGIEB9sr2LkUSsPJ6jVKtirNQjycMS19AKM/nIffFy0JlmOdccSMLV/K3y3JwaR1zLhrLXBi0Pb4uOtF/D78QS5voC44Bs+u+6BbkjKKkJMWj5eqaIDfk5RGVYeuGqSbTQE6AbGmTvjUU6P9Ak0a+6NSc2T++MAwHv/O4fvp/SCu5OdSad0oKLP2Q97YuRtWQWluJqWj1bl83HtvmTa9FRQokOf4OYoLtXhVEI2Libn4usdl+XP/OhVcV7u6eSDd+/vhAVborD5TDLmrj+LAW095QC0o68LbG3U2HOpomnxJ6Nm2dMJpmWNTctHay/llttgcENENzWonZfJ44lhAZhYRRBVnZFdfLHnH0NN7vIM+rXxwPn3RlbZfDZvTCfc19UPidmFmLv+LEaEeOPbx8JgqzG9G+zbujl2l3/hzhvTGS4Otvj1WDzmbTwnX2RcHWwxtX8r3NvZB538XKBSqfBIn0AM+XQXcovK8OSAVhjTzR9rjsahqFQPtUp0GP+zfNZmA+P+SbNGtJODm7vbe2HFgatIyCzEZ+UXM29nLcKC3NHCzQHXswrxf+O7wttZiy+2X8K5xBxo1Cq8OqI9HOw0+L/xXTGgjSdmrD5e5Wf45S3mOLmeWYi49AJsPms+cV9+iQ4vrj6OMd385YxIcZnOpBPwP8sDipeHt8NrVaxn9tSAYKw/cR0R52/guZ+PISGz0OSC3DPQHUEeTnhhSBss3B6Nl1afwNqj8fArD357BrohObuo2n47R69m4qElB3E8LhNleglhQe5Y8nhP9PtoB1Jzi+XPEIBJP7J/TwrFS6uPIyXXfGqChdsvoWuAKxaVB4XzH+iMsd398d2eK3LzpLujLbIKS5FVUIrfj4sg1MfZHi3cHEz6ZxkENndEXEYBNlQznUIrD0eTZs5x3f3lY31d7DG2u79ZcPPTgasmQf3Rq5no83/bsXByD2w+I/7+mjvZISO/BInZRUjILMCxa5lQqUTzXExqPkZ+uQcrn+qLPsHN8Xd5v5r2Ps3g42KPMd38Mb5nC/z7r4s4lZCNX4/FIy2vGG6Otvh4YjesLw9InxkYjJbNHfH5Q90RlbQXsWn5mPDtfvnvpK13M7g52poEN4C44SgpM+/bdexqpqLBjUpqKL1/7pCcnBy4uroiOzsbLi5Vd7YkooZDkiTsjU5DtwBXs3mDADGx4c8Hr+GBUH+T/iXnE3Ow/kQCikr1eGZQMII8zGea3nUxBbsupmL2vR3QTGuD7MJSRF7LQLBnM7TycETwnM0ARBYhxM8Z0/q3Mun0veVMEtLySzDlriBMW34Eu8qbaDr6OuPZQa0xMSwA5xKzcSOnCMM6itFxaXnF+GFPDIZ19DZZG624TIcO/9xqUj57WzXsbTXyxbiTnwu8XbTy+wCiY3nlEcI9At1wIi4Ls0a0Q8T5GyZZkptZ/2L/apc32XDiOv7x22n5QubqYIuuLVyx73IaPn8oFBN6BqCoVIfHfjxslqX519jOOBiTjs1nRPD1xr0dcCE5F91auOLTbRdNsij3dPLBF5O7o5nWBvEZBbiYnIu23s2waOdltHBzwGN3BcLbuSJjmFdchk2nE/Hmb2fkbV1buJpkPbq0cMH/XhoIlUqFl1Yfl4PWN+7tgPOJOdh0piKInX53G3Rv6Yrp/xGB5p43huKTvy4gJbcYn04Kxd2f7pSbiipnFz+Z2E1e3LeZ1gYn370H3++NgdZGgwdC/eFgp0HX+X+huquug60GhVUMx35rVEd8tOUCerdyx7COYjmWfq09MLqbn5zpcrTTYHZ4B3y89QKKy/T4/cX+6Gl0Ln89Gi+XDQDGdvfHlw/3qLIcG08l4uVfTphsW/xYTwR5OGH0V3tNto/q4ouT8Vlyk9nzg1vjuz0xeDAswKwv0O2qzfWbmRsiatBUKhUGt/eqdr+LvW2Va2d18ndBJ/+bD7kd0sEbQzpUTKbo6mArByEAsOLJ3jiTkI3pQ9pUudaQ8Qi45wa1xo2cYrx+T3uM6FTxGp39XdHZv6IjtmczLeaMDjF7La2NBk8OaIXl+6/i6YHB2Ho2GVP6BaGDrzOeLF8u4pNJ3dClhSuGf7YLV1LzEVTeL+J7o2YKAHh2UGt5EdDwTr6YsHg/bDVqvPdAZ8z745zch2nmsLbYeCoR19IL0NzJziQzVdm4Hi1gb6vB9P+ISRLfHt0Rk3sHoqhUJ69wb2+rwbrn+2HruWS8uEoEB8GeTpjQMwBZBaVycGN8vj7aekH+/c+ZA03WyWrZ3FEOWD+t5kLZTGuDyb0DsfpIPE7FZ2FYR298NLErHv7ukJx9mTGkrZwdmdgzAH+eTkJnfxd56gUvZy1WlI8Y8nO1R3gnX8wf0wm9WjVHoIcjFj1aMTy6s78Lzl7PgZ1GjbdHh6CoVCcHS2Gt3OU+O/3beMBGo5abYA0M2ZanBgQj2NMR7/xRsXzGjtl3w9vZHs//fEwe2RTa0g29WzUHILI6huafsd398VCvlmjt6YR3/ziLK6n5eP/P8wBE02KPSn2j2vmYZlGqmkTU4P6ufvj54FWciMvCC0PaYGz3FvKK7htmDIBaBTywaD8AkZkd290fc9efxb8f7AYVVPhuTwyOVQpw7zRmboiIGoiSMj1OJWShV5C7SVPF5jNJyCooxaN9AwGIvjULNkdh2oBgdPR1lgOJnoFuOBybgW8e6wmX8nmWDMc72GngYm+LjacS8VtkAu7p5INH+wSioFSHxbsuo1dQcwy9yQXP4M/TiUjKKsLTA4NvujDn59suYsPJRCx+vCc6+7sir7gMM1Ydx8C2nvJIHAD4ZOsFfLvrCh7rG4gPx5svMFpTaXnFWLovFo/fFYQWbg7IKy7D1zuiIUnAWyM7mpT1SGwGOvg6w9Wh4jPaeCoR284l490xnUwyQ5V9tOUCluy+ggdC/fHVIz2QV1yGKUsPo6hUj40vDUBMaj6+3xODf4zsAJ8q5qRZsCUK3+2OwS/P3oV+bTyw9WwSXlp9Ah18nbHp5UEAxN/Boh3RWH/yOt4f2wXdWriiz//9LU/iF+ThiD9nDpTn0rqeVYjnfz6Gi8m56N/GE9881tNsdXtJkvDq2pPYcDIRdho1Dr89HO5O5plQg+IyHUp1ktnrGLz8ywkkZRfi56f7ysEtIOY9GvDRDnRv6Yal03rVaC6jmqrN9ZvBDRERKaawRIejVzMwoK2nybInDVVuUSnWHInHpLAAOTjQ6yWoVKjR6KBSnR6ZBSUmAVRydhGctBo5WKnK4Zh0fLz1AiQAix8Lq9OkeYYmXjsbNe6qNDO5Jen0Ur2cSwY3N8HghoiIqPGpzfWbMxQTERGRVVE8uPn2228RHBwMe3t7hIWFYe/evTc9fvfu3QgLC4O9vT1at26NJUuW3KGSEhERUWOgaHCzdu1azJo1C3PnzsWJEycwaNAgjBo1CnFxVa8SHBsbi9GjR2PQoEE4ceIE3n77bbz88sv47bff7nDJiYiIqKFStM9N37590bNnTyxevFjeFhISgnHjxmHBggVmx7/55pvYuHEjoqKi5G3Tp0/HqVOncPDgwRq9J/vcEBERNT6Nos9NSUkJIiMjER4ebrI9PDwcBw4cqPI5Bw8eNDv+3nvvxbFjx1BaWlrlc4iIiKhpUWwSv7S0NOh0Ovj4+Jhs9/HxQXKy+RTiAJCcnFzl8WVlZUhLS4Ofn5/Zc4qLi1FcXDEtd05OzWbqJCIiosZJ8Q7FlecFMKwmW5vjq9pusGDBAri6uso/LVu2rPI4IiIisg6KBTeenp7QaDRmWZqUlBSz7IyBr69vlcfb2NjAw6PqCYnmzJmD7Oxs+Sc+Pr7K44iIiMg6KBbc2NnZISwsDBERESbbIyIi0L9//yqf069fP7Pjt23bhl69esHWtuqZHbVaLVxcXEx+iIiIyHop2iz12muv4ccff8SyZcsQFRWFV199FXFxcZg+fToAkXV54okn5OOnT5+Oa9eu4bXXXkNUVBSWLVuGpUuXYvbs2UpVgYiIiBoYRVcFnzx5MtLT0/H+++8jKSkJXbp0webNmxEUFAQASEpKMpnzJjg4GJs3b8arr76Kb775Bv7+/vjqq68wceJEpapAREREDQzXliIiIqIGr1HMc0NERERUHxjcEBERkVVRtM+NEgytcJzMj4iIqPEwXLdr0pumyQU3ubm5AMDJ/IiIiBqh3NxcuLq63vSYJtehWK/XIzExEc7OzjedCbm2cnJy0LJlS8THx1tlR2Vrrx9g/XW09voB1l9Ha68fYP11tPb6AfVXR0mSkJubC39/f6jVN+9V0+QyN2q1GgEBAfX2+tY+UaC11w+w/jpae/0A66+jtdcPsP46Wnv9gPqp460yNgbsUExERERWhcENERERWRUGNxai1Woxb948aLVapYtSL6y9foD119Ha6wdYfx2tvX6A9dfR2usHNIw6NrkOxURERGTdmLkhIiIiq8LghoiIiKwKgxsiIiKyKgxuiIiIyKowuLGAb7/9FsHBwbC3t0dYWBj27t2rdJHqbP78+VCpVCY/vr6+8n5JkjB//nz4+/vDwcEBQ4YMwblz5xQs8c3t2bMHY8aMgb+/P1QqFTZs2GCyvyb1KS4uxsyZM+Hp6QknJyc88MADSEhIuIO1uLlb1XHatGlm5/Suu+4yOaYh13HBggXo3bs3nJ2d4e3tjXHjxuHixYsmxzTm81iT+jX2c7h48WJ069ZNntStX79+2LJli7y/MZ8/4Nb1a+znr7IFCxZApVJh1qxZ8raGdg4Z3NymtWvXYtasWZg7dy5OnDiBQYMGYdSoUYiLi1O6aHXWuXNnJCUlyT9nzpyR933yySf4/PPPsWjRIhw9ehS+vr6455575DW7Gpr8/HyEhoZi0aJFVe6vSX1mzZqF9evXY82aNdi3bx/y8vJw//33Q6fT3alq3NSt6ggAI0eONDmnmzdvNtnfkOu4e/duzJgxA4cOHUJERATKysoQHh6O/Px8+ZjGfB5rUj+gcZ/DgIAAfPTRRzh27BiOHTuGYcOGYezYsfLFrzGfP+DW9QMa9/kzdvToUXz//ffo1q2byfYGdw4lui19+vSRpk+fbrKtY8eO0ltvvaVQiW7PvHnzpNDQ0Cr36fV6ydfXV/roo4/kbUVFRZKrq6u0ZMmSO1TCugMgrV+/Xn5ck/pkZWVJtra20po1a+Rjrl+/LqnVamnr1q13rOw1VbmOkiRJU6dOlcaOHVvtcxpbHVNSUiQA0u7duyVJsr7zWLl+kmR951CSJMnd3V368ccfre78GRjqJ0nWc/5yc3Oldu3aSREREdLdd98tvfLKK5IkNcz/g8zc3IaSkhJERkYiPDzcZHt4eDgOHDigUKluX3R0NPz9/REcHIyHH34YMTExAIDY2FgkJyeb1Fer1eLuu+9ulPWtSX0iIyNRWlpqcoy/vz+6dOnSqOq8a9cueHt7o3379nj22WeRkpIi72tsdczOzgYANG/eHID1ncfK9TOwlnOo0+mwZs0a5Ofno1+/flZ3/irXz8Aazt+MGTNw3333YcSIESbbG+I5bHILZ1pSWloadDodfHx8TLb7+PggOTlZoVLdnr59+2LlypVo3749bty4gQ8++AD9+/fHuXPn5DpVVd9r164pUdzbUpP6JCcnw87ODu7u7mbHNJZzPGrUKDz44IMICgpCbGws3nnnHQwbNgyRkZHQarWNqo6SJOG1117DwIED0aVLFwDWdR6rqh9gHefwzJkz6NevH4qKitCsWTOsX78enTp1ki9sjf38VVc/wDrO35o1axAZGYljx46Z7WuI/wcZ3FiASqUyeSxJktm2xmLUqFHy7127dkW/fv3Qpk0b/PTTT3IHOGuqL1C3+jSmOk+ePFn+vUuXLujVqxeCgoKwadMmTJgwodrnNcQ6vvTSSzh9+jT27dtnts8azmN19bOGc9ihQwecPHkSWVlZ+O233zB16lTs3r1b3t/Yz1919evUqVOjP3/x8fF45ZVXsG3bNtjb21d7XEM6h2yWug2enp7QaDRmUWdKSopZBNtYOTk5oWvXroiOjpZHTVlLfWtSH19fX5SUlCAzM7PaYxobPz8/BAUFITo6GkDjqePMmTOxceNG7Ny5EwEBAfJ2azmP1dWvKo3xHNrZ2aFt27bo1asXFixYgNDQUHz55ZdWc/6qq19VGtv5i4yMREpKCsLCwmBjYwMbGxvs3r0bX331FWxsbOQyNqRzyODmNtjZ2SEsLAwREREm2yMiItC/f3+FSmVZxcXFiIqKgp+fH4KDg+Hr62tS35KSEuzevbtR1rcm9QkLC4Otra3JMUlJSTh79myjrDMApKenIz4+Hn5+fgAafh0lScJLL72E33//HTt27EBwcLDJ/sZ+Hm9Vv6o0tnNYFUmSUFxc3OjPX3UM9atKYzt/w4cPx5kzZ3Dy5En5p1evXnjsscdw8uRJtG7duuGdQ4t3UW5i1qxZI9na2kpLly6Vzp8/L82aNUtycnKSrl69qnTR6uT111+Xdu3aJcXExEiHDh2S7r//fsnZ2Vmuz0cffSS5urpKv//+u3TmzBnpkUcekfz8/KScnByFS1613Nxc6cSJE9KJEyckANLnn38unThxQrp27ZokSTWrz/Tp06WAgABp+/bt0vHjx6Vhw4ZJoaGhUllZmVLVMnGzOubm5kqvv/66dODAASk2NlbauXOn1K9fP6lFixaNpo4vvPCC5OrqKu3atUtKSkqSfwoKCuRjGvN5vFX9rOEczpkzR9qzZ48UGxsrnT59Wnr77bcltVotbdu2TZKkxn3+JOnm9bOG81cV49FSktTwziGDGwv45ptvpKCgIMnOzk7q2bOnyRDOxmby5MmSn5+fZGtrK/n7+0sTJkyQzp07J+/X6/XSvHnzJF9fX0mr1UqDBw+Wzpw5o2CJb27nzp0SALOfqVOnSpJUs/oUFhZKL730ktS8eXPJwcFBuv/++6W4uDgFalO1m9WxoKBACg8Pl7y8vCRbW1spMDBQmjp1qln5G3Idq6obAGn58uXyMY35PN6qftZwDp966in5O9LLy0saPny4HNhIUuM+f5J08/pZw/mrSuXgpqGdQ5UkSZLl80FEREREymCfGyIiIrIqDG6IiIjIqjC4ISIiIqvC4IaIiIisCoMbIiIisioMboiIiMiqMLghIiIiq8LghogIYtG/DRs2KF0MIrIABjdEpLhp06ZBpVKZ/YwcOVLpohFRI2SjdAGIiABg5MiRWL58uck2rVarUGmIqDFj5oaIGgStVgtfX1+TH3d3dwCiyWjx4sUYNWoUHBwcEBwcjHXr1pk8/8yZMxg2bBgcHBzg4eGB5557Dnl5eSbHLFu2DJ07d4ZWq4Wfnx9eeuklk/1paWkYP348HB0d0a5dO2zcuLF+K01E9YLBDRE1Cu+88w4mTpyIU6dO4fHHH8cjjzyCqKgoAEBBQQFGjhwJd3d3HD16FOvWrcP27dtNgpfFixdjxowZeO6553DmzBls3LgRbdu2NXmP9957Dw899BBOnz6N0aNH47HHHkNGRsYdrScRWUC9LMdJRFQLU6dOlTQajeTk5GTy8/7770uSJFbOnj59uslz+vbtK73wwguSJEnS999/L7m7u0t5eXny/k2bNklqtVpKTk6WJEmS/P39pblz51ZbBgDSP//5T/lxXl6epFKppC1btlisnkR0Z7DPDRE1CEOHDsXixYtNtjVv3lz+vV+/fib7+vXrh5MnTwIAoqKiEBoaCicnJ3n/gAEDoNfrcfHiRahUKiQmJmL48OE3LUO3bt3k352cnODs7IyUlJS6VomIFMLghogaBCcnJ7NmoltRqVQAAEmS5N+rOsbBwaFGr2dra2v2XL1eX6syEZHy2OeGiBqFQ4cOmT3u2LEjAKBTp044efIk8vPz5f379++HWq1G+/bt4ezsjFatWuHvv/++o2UmImUwc0NEDUJxcTGSk5NNttnY2MDT0xMAsG7dOvTq1QsDBw7EqlWrcOTIESxduhQA8Nhjj2HevHmYOnUq5s+fj9TUVMycORNTpkyBj48PAGD+/PmYPn06vL29MWrUKOTm5mL//v2YOXPmna0oEdU7BjdE1CBs3boVfn5+Jts6dOiACxcuABAjmdasWYMXX3wRvr6+WLVqFTp16gQAcHR0xF9//YVXXnkFvXv3hqOjIyZOnIjPP/9cfq2pU6eiqKgIX3zxBWbPng1PT09MmjTpzlWQiO4YlSRJktKFICK6GZVKhfXr12PcuHFKF4WIGgH2uSEiIiKrwuCGiIiIrAr73BBRg8fWcyKqDWZuiIiIyKowuCEiIiKrwuCGiIiIrAqDGyIiIrIqDG6IiIjIqjC4ISIiIqvC4IaIiIisCoMbIiIisioMboiIiMiq/D9FpCfRnyTPJQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(train_eva_df,'Train','Epoch','Loss',['loss','accuracy'])\n",
    "plot_graph(test_eva_df,'Test','Epoch','Loss',['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9ad12d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
