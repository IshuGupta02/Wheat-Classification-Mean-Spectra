{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c4fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35daa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6aebd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'wheat_30_var_2_species.csv'\n",
    "\n",
    "def dir(file_name):\n",
    "    return '../data/'+file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a19daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_X_Y(dataframe):\n",
    "    return (dataframe.drop('classes', axis =1), dataframe.loc[:,'classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "554bc6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class filter_method(Enum):\n",
    "    none = 0\n",
    "    snv = 1\n",
    "    msc = 2\n",
    "    savgol = 3\n",
    "\n",
    "FILT = 3\n",
    "FILTER = filter_method(FILT).name\n",
    "\n",
    "# to be set if filter chosen is savgol\n",
    "WINDOW = 7\n",
    "ORDER = 2\n",
    "DERIVATIVE = 1\n",
    "\n",
    "#will be used for test dataset in msc\n",
    "reference= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c20231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def create_test_train(X, y, test_size = 0.2, shuffle = True):\n",
    "    return train_test_split(X,y, test_size = test_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e9301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Normal Variate\n",
    "def snv(input_data):\n",
    "  \n",
    "    # Define a new array and populate it with the corrected data  \n",
    "    output_data = np.zeros_like(input_data)\n",
    "    for i in range(input_data.shape[0]):\n",
    " \n",
    "        # Apply correction\n",
    "        output_data[i,:] = (input_data[i,:] - np.mean(input_data[i,:])) / np.std(input_data[i,:])\n",
    " \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d925acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicative scatter correction\n",
    "def msc(input_data, reference=None):\n",
    "#     print(reference)\n",
    "    ''' Perform Multiplicative scatter correction'''\n",
    "\n",
    "    # Baseline correction\n",
    "    for i in range(input_data.shape[0]):\n",
    "        input_data[i,:] -= input_data[i,:].mean()\n",
    "\n",
    "    # Get the reference spectrum. If not given, estimate from the mean    \n",
    "    if reference is None:    \n",
    "        # Calculate mean\n",
    "        matm = np.mean(input_data, axis=0)\n",
    "    else:\n",
    "        matm = reference\n",
    "\n",
    "    # Define a new data matrix and populate it with the corrected data    \n",
    "    output_data = np.zeros_like(input_data)\n",
    "    for i in range(input_data.shape[0]):\n",
    "        # Run regression\n",
    "        fit = np.polyfit(matm, input_data[i,:], 1, full=True)\n",
    "        # Apply correction\n",
    "        output_data[i,:] = (input_data[i,:] - fit[0][1]) / fit[0][0] \n",
    "\n",
    "    return (output_data, matm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b5090be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter, general_gaussian\n",
    "def savgol(input_data):\n",
    "    w = WINDOW\n",
    "    p = ORDER\n",
    "    d = DERIVATIVE\n",
    "    \n",
    "    output_data = savgol_filter(np.array(input_data), w, polyorder = p, deriv=d)\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b68affd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X,y, type=\"train\"):\n",
    "    if FILTER == \"snv\":\n",
    "        return {\"X\": snv(np.array(X)), \"y\": y}\n",
    "    elif FILTER == \"msc\":\n",
    "        msc_output = msc(np.array(X), reference = reference if type==\"test\" else None)\n",
    "        X = msc_output[0]\n",
    "        ref = msc_output[1]\n",
    "        return {\n",
    "            \"X\": X,\n",
    "            \"y\": y,\n",
    "            \"ref\": ref\n",
    "        }\n",
    "    elif FILTER == \"savgol\":\n",
    "        return {\n",
    "            \"X\": savgol(X),\n",
    "            \"y\": y\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"X\":X,\n",
    "            \"y\":y\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8dec1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(dir(file_name))\n",
    "X,y = seperate_X_Y(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58535347",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_set = set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e8c8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_CLASSES = len(y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd357e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = create_test_train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f79eb839",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_results = preprocess_data(X_train_raw,y_train_raw)\n",
    "X_train, y_train = preprocessed_results[\"X\"], preprocessed_results[\"y\"]\n",
    "\n",
    "if FILTER == \"msc\":\n",
    "    reference = preprocessed_results[\"ref\"]\n",
    "    \n",
    "preprocessed_results_test = preprocess_data(X_test_raw, y_test_raw, type=\"test\")\n",
    "X_test, y_test = preprocessed_results_test[\"X\"], preprocessed_results_test[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e1e570e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48384, 147, 1)\n",
      "(12096, 147, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec820add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Input, Conv1D, Flatten, Dense, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba682707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(input_shape,num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=5, input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=5 ))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d95ace51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(X_train.shape[1:],NUM_OF_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33a0377c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 143, 32)           192       \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 28, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 896)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1000)              897000    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 2002      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 899,194\n",
      "Trainable params: 899,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20cd1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva = []\n",
    "test_eva = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fd5eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dataframe = pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "863f63f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  1\n",
      "378/378 - 17s - loss: 0.6472 - accuracy: 0.6120 - 17s/epoch - 44ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.5846 - accuracy: 0.6991\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.5852 - accuracy: 0.6964\n",
      "\n",
      "Epoch:  2\n",
      "378/378 - 14s - loss: 0.5310 - accuracy: 0.7442 - 14s/epoch - 36ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.4776 - accuracy: 0.7841\n",
      "for testing\n",
      "378/378 [==============================] - 3s 6ms/step - loss: 0.4779 - accuracy: 0.7851\n",
      "\n",
      "Epoch:  3\n",
      "378/378 - 11s - loss: 0.4467 - accuracy: 0.7951 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.4096 - accuracy: 0.8155\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.4079 - accuracy: 0.8162\n",
      "\n",
      "Epoch:  4\n",
      "378/378 - 11s - loss: 0.3962 - accuracy: 0.8230 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.3647 - accuracy: 0.8437\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.3635 - accuracy: 0.8454\n",
      "\n",
      "Epoch:  5\n",
      "378/378 - 9s - loss: 0.3559 - accuracy: 0.8453 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.3536 - accuracy: 0.8462\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.3514 - accuracy: 0.8526\n",
      "\n",
      "Epoch:  6\n",
      "378/378 - 10s - loss: 0.3199 - accuracy: 0.8654 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.2960 - accuracy: 0.8783\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.2947 - accuracy: 0.8815\n",
      "\n",
      "Epoch:  7\n",
      "378/378 - 9s - loss: 0.2932 - accuracy: 0.8767 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.2695 - accuracy: 0.8892\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.2677 - accuracy: 0.8900\n",
      "\n",
      "Epoch:  8\n",
      "378/378 - 9s - loss: 0.2685 - accuracy: 0.8893 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.2496 - accuracy: 0.9001\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.2478 - accuracy: 0.9026\n",
      "\n",
      "Epoch:  9\n",
      "378/378 - 9s - loss: 0.2481 - accuracy: 0.8993 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.2305 - accuracy: 0.9078\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.2284 - accuracy: 0.9117\n",
      "\n",
      "Epoch:  10\n",
      "378/378 - 10s - loss: 0.2314 - accuracy: 0.9064 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.2322 - accuracy: 0.9002\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.2290 - accuracy: 0.9035\n",
      "\n",
      "Epoch:  11\n",
      "378/378 - 11s - loss: 0.2182 - accuracy: 0.9123 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.2240 - accuracy: 0.9106\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.2245 - accuracy: 0.9112\n",
      "\n",
      "Epoch:  12\n",
      "378/378 - 10s - loss: 0.2123 - accuracy: 0.9145 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1957 - accuracy: 0.9225\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1940 - accuracy: 0.9243\n",
      "\n",
      "Epoch:  13\n",
      "378/378 - 10s - loss: 0.1992 - accuracy: 0.9205 - 10s/epoch - 26ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.1959 - accuracy: 0.9175\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1928 - accuracy: 0.9211\n",
      "\n",
      "Epoch:  14\n",
      "378/378 - 16s - loss: 0.1976 - accuracy: 0.9203 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1834 - accuracy: 0.9254\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1805 - accuracy: 0.9277\n",
      "\n",
      "Epoch:  15\n",
      "378/378 - 10s - loss: 0.1879 - accuracy: 0.9243 - 10s/epoch - 25ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1827 - accuracy: 0.9298\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1820 - accuracy: 0.9306\n",
      "\n",
      "Epoch:  16\n",
      "378/378 - 10s - loss: 0.1797 - accuracy: 0.9281 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1681 - accuracy: 0.9328\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1660 - accuracy: 0.9351\n",
      "\n",
      "Epoch:  17\n",
      "378/378 - 11s - loss: 0.1743 - accuracy: 0.9301 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1778 - accuracy: 0.9241\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1739 - accuracy: 0.9281\n",
      "\n",
      "Epoch:  18\n",
      "378/378 - 11s - loss: 0.1772 - accuracy: 0.9280 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.1739 - accuracy: 0.9269\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1705 - accuracy: 0.9310\n",
      "\n",
      "Epoch:  19\n",
      "378/378 - 9s - loss: 0.1676 - accuracy: 0.9319 - 9s/epoch - 25ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.2046 - accuracy: 0.9108\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.1999 - accuracy: 0.9129\n",
      "\n",
      "Epoch:  20\n",
      "378/378 - 12s - loss: 0.1673 - accuracy: 0.9317 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.1656 - accuracy: 0.9302\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1623 - accuracy: 0.9342\n",
      "\n",
      "Epoch:  21\n",
      "378/378 - 9s - loss: 0.1639 - accuracy: 0.9342 - 9s/epoch - 25ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.1528 - accuracy: 0.9388\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1506 - accuracy: 0.9411\n",
      "\n",
      "Epoch:  22\n",
      "378/378 - 9s - loss: 0.1556 - accuracy: 0.9368 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.1858 - accuracy: 0.9206\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1812 - accuracy: 0.9225\n",
      "\n",
      "Epoch:  23\n",
      "378/378 - 10s - loss: 0.1572 - accuracy: 0.9375 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1432 - accuracy: 0.9434\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1414 - accuracy: 0.9466\n",
      "\n",
      "Epoch:  24\n",
      "378/378 - 12s - loss: 0.1559 - accuracy: 0.9369 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1455 - accuracy: 0.9434\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1443 - accuracy: 0.9448\n",
      "\n",
      "Epoch:  25\n",
      "378/378 - 9s - loss: 0.1510 - accuracy: 0.9394 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1412 - accuracy: 0.9437\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1391 - accuracy: 0.9462\n",
      "\n",
      "Epoch:  26\n",
      "378/378 - 9s - loss: 0.1530 - accuracy: 0.9388 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.1629 - accuracy: 0.9356\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1631 - accuracy: 0.9358\n",
      "\n",
      "Epoch:  27\n",
      "378/378 - 11s - loss: 0.1566 - accuracy: 0.9361 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.1369 - accuracy: 0.9456\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1350 - accuracy: 0.9473\n",
      "\n",
      "Epoch:  28\n",
      "378/378 - 13s - loss: 0.1484 - accuracy: 0.9406 - 13s/epoch - 34ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1394 - accuracy: 0.9434\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1361 - accuracy: 0.9497\n",
      "\n",
      "Epoch:  29\n",
      "378/378 - 13s - loss: 0.1463 - accuracy: 0.9415 - 13s/epoch - 33ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1523 - accuracy: 0.9361\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1485 - accuracy: 0.9403\n",
      "\n",
      "Epoch:  30\n",
      "378/378 - 11s - loss: 0.1437 - accuracy: 0.9423 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.1464 - accuracy: 0.9431\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1460 - accuracy: 0.9422\n",
      "\n",
      "Epoch:  31\n",
      "378/378 - 10s - loss: 0.1430 - accuracy: 0.9426 - 10s/epoch - 26ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1318 - accuracy: 0.9475\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1294 - accuracy: 0.9494\n",
      "\n",
      "Epoch:  32\n",
      "378/378 - 11s - loss: 0.1406 - accuracy: 0.9431 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1470 - accuracy: 0.9391\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1433 - accuracy: 0.9424\n",
      "\n",
      "Epoch:  33\n",
      "378/378 - 9s - loss: 0.1397 - accuracy: 0.9435 - 9s/epoch - 25ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1340 - accuracy: 0.9475\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1338 - accuracy: 0.9476\n",
      "\n",
      "Epoch:  34\n",
      "378/378 - 9s - loss: 0.1468 - accuracy: 0.9409 - 9s/epoch - 25ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1283 - accuracy: 0.9497\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1259 - accuracy: 0.9531\n",
      "\n",
      "Epoch:  35\n",
      "378/378 - 9s - loss: 0.1390 - accuracy: 0.9450 - 9s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1299 - accuracy: 0.9473\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1279 - accuracy: 0.9506\n",
      "\n",
      "Epoch:  36\n",
      "378/378 - 9s - loss: 0.1346 - accuracy: 0.9458 - 9s/epoch - 25ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1261 - accuracy: 0.9508\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1246 - accuracy: 0.9544\n",
      "\n",
      "Epoch:  37\n",
      "378/378 - 9s - loss: 0.1328 - accuracy: 0.9476 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.1269 - accuracy: 0.9493\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1243 - accuracy: 0.9530\n",
      "\n",
      "Epoch:  38\n",
      "378/378 - 9s - loss: 0.1355 - accuracy: 0.9463 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1252 - accuracy: 0.9499\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1227 - accuracy: 0.9540\n",
      "\n",
      "Epoch:  39\n",
      "378/378 - 8s - loss: 0.1344 - accuracy: 0.9469 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1222 - accuracy: 0.9516\n",
      "for testing\n",
      "378/378 [==============================] - 1s 4ms/step - loss: 0.1203 - accuracy: 0.9549\n",
      "\n",
      "Epoch:  40\n",
      "378/378 - 9s - loss: 0.1325 - accuracy: 0.9472 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1273 - accuracy: 0.9487\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1246 - accuracy: 0.9511\n",
      "\n",
      "Epoch:  41\n",
      "378/378 - 11s - loss: 0.1292 - accuracy: 0.9481 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1350 - accuracy: 0.9451\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1317 - accuracy: 0.9472\n",
      "\n",
      "Epoch:  42\n",
      "378/378 - 9s - loss: 0.1326 - accuracy: 0.9473 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1223 - accuracy: 0.9511\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1200 - accuracy: 0.9547\n",
      "\n",
      "Epoch:  43\n",
      "378/378 - 9s - loss: 0.1303 - accuracy: 0.9478 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1245 - accuracy: 0.9516\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1240 - accuracy: 0.9518\n",
      "\n",
      "Epoch:  44\n",
      "378/378 - 8s - loss: 0.1318 - accuracy: 0.9472 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1249 - accuracy: 0.9494\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1232 - accuracy: 0.9521\n",
      "\n",
      "Epoch:  45\n",
      "378/378 - 8s - loss: 0.1303 - accuracy: 0.9491 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1199 - accuracy: 0.9526\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1171 - accuracy: 0.9569\n",
      "\n",
      "Epoch:  46\n",
      "378/378 - 8s - loss: 0.1317 - accuracy: 0.9469 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1648 - accuracy: 0.9317\n",
      "for testing\n",
      "378/378 [==============================] - 1s 4ms/step - loss: 0.1593 - accuracy: 0.9333\n",
      "\n",
      "Epoch:  47\n",
      "378/378 - 8s - loss: 0.1263 - accuracy: 0.9490 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1224 - accuracy: 0.9509\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1195 - accuracy: 0.9538\n",
      "\n",
      "Epoch:  48\n",
      "378/378 - 8s - loss: 0.1259 - accuracy: 0.9505 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1313 - accuracy: 0.9462\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1277 - accuracy: 0.9485\n",
      "\n",
      "Epoch:  49\n",
      "378/378 - 8s - loss: 0.1263 - accuracy: 0.9501 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1239 - accuracy: 0.9496\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1213 - accuracy: 0.9525\n",
      "\n",
      "Epoch:  50\n",
      "378/378 - 8s - loss: 0.1275 - accuracy: 0.9500 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1160 - accuracy: 0.9542\n",
      "for testing\n",
      "378/378 [==============================] - 1s 4ms/step - loss: 0.1140 - accuracy: 0.9578\n",
      "\n",
      "Epoch:  51\n",
      "378/378 - 8s - loss: 0.1244 - accuracy: 0.9506 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1591 - accuracy: 0.9344\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1541 - accuracy: 0.9384\n",
      "\n",
      "Epoch:  52\n",
      "378/378 - 8s - loss: 0.1260 - accuracy: 0.9496 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1226 - accuracy: 0.9504\n",
      "for testing\n",
      "378/378 [==============================] - 1s 4ms/step - loss: 0.1199 - accuracy: 0.9530\n",
      "\n",
      "Epoch:  53\n",
      "378/378 - 8s - loss: 0.1250 - accuracy: 0.9505 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1145 - accuracy: 0.9547\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1122 - accuracy: 0.9579\n",
      "\n",
      "Epoch:  54\n",
      "378/378 - 8s - loss: 0.1243 - accuracy: 0.9495 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1460 - accuracy: 0.9418\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1460 - accuracy: 0.9399\n",
      "\n",
      "Epoch:  55\n",
      "378/378 - 8s - loss: 0.1269 - accuracy: 0.9493 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1505 - accuracy: 0.9406\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1507 - accuracy: 0.9406\n",
      "\n",
      "Epoch:  56\n",
      "378/378 - 9s - loss: 0.1277 - accuracy: 0.9492 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1124 - accuracy: 0.9563\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1109 - accuracy: 0.9595\n",
      "\n",
      "Epoch:  57\n",
      "378/378 - 8s - loss: 0.1211 - accuracy: 0.9513 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1132 - accuracy: 0.9553\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1121 - accuracy: 0.9591\n",
      "\n",
      "Epoch:  58\n",
      "378/378 - 9s - loss: 0.1248 - accuracy: 0.9492 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1128 - accuracy: 0.9558\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1110 - accuracy: 0.9593\n",
      "\n",
      "Epoch:  59\n",
      "378/378 - 9s - loss: 0.1240 - accuracy: 0.9507 - 9s/epoch - 25ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1162 - accuracy: 0.9534\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1145 - accuracy: 0.9564\n",
      "\n",
      "Epoch:  60\n",
      "378/378 - 9s - loss: 0.1237 - accuracy: 0.9503 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1158 - accuracy: 0.9542\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1147 - accuracy: 0.9562\n",
      "\n",
      "Epoch:  61\n",
      "378/378 - 9s - loss: 0.1189 - accuracy: 0.9537 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.1177 - accuracy: 0.9529\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1149 - accuracy: 0.9546\n",
      "\n",
      "Epoch:  62\n",
      "378/378 - 11s - loss: 0.1192 - accuracy: 0.9530 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1210 - accuracy: 0.9515\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1185 - accuracy: 0.9537\n",
      "\n",
      "Epoch:  63\n",
      "378/378 - 8s - loss: 0.1187 - accuracy: 0.9528 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1439 - accuracy: 0.9402\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1404 - accuracy: 0.9424\n",
      "\n",
      "Epoch:  64\n",
      "378/378 - 8s - loss: 0.1236 - accuracy: 0.9508 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1091 - accuracy: 0.9582\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1079 - accuracy: 0.9595\n",
      "\n",
      "Epoch:  65\n",
      "378/378 - 8s - loss: 0.1174 - accuracy: 0.9532 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1217 - accuracy: 0.9508\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1186 - accuracy: 0.9533\n",
      "\n",
      "Epoch:  66\n",
      "378/378 - 8s - loss: 0.1184 - accuracy: 0.9534 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1081 - accuracy: 0.9580\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1060 - accuracy: 0.9605\n",
      "\n",
      "Epoch:  67\n",
      "378/378 - 8s - loss: 0.1153 - accuracy: 0.9549 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1077 - accuracy: 0.9581\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1059 - accuracy: 0.9604\n",
      "\n",
      "Epoch:  68\n",
      "378/378 - 8s - loss: 0.1184 - accuracy: 0.9534 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1240 - accuracy: 0.9509\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1233 - accuracy: 0.9519\n",
      "\n",
      "Epoch:  69\n",
      "378/378 - 8s - loss: 0.1225 - accuracy: 0.9514 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1067 - accuracy: 0.9592\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1051 - accuracy: 0.9609\n",
      "\n",
      "Epoch:  70\n",
      "378/378 - 13s - loss: 0.1138 - accuracy: 0.9558 - 13s/epoch - 36ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1051 - accuracy: 0.9595\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1034 - accuracy: 0.9611\n",
      "\n",
      "Epoch:  71\n",
      "378/378 - 9s - loss: 0.1160 - accuracy: 0.9547 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1355 - accuracy: 0.9471\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1357 - accuracy: 0.9472\n",
      "\n",
      "Epoch:  72\n",
      "378/378 - 9s - loss: 0.1172 - accuracy: 0.9532 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1186 - accuracy: 0.9538\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1180 - accuracy: 0.9541\n",
      "\n",
      "Epoch:  73\n",
      "378/378 - 8s - loss: 0.1123 - accuracy: 0.9565 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1211 - accuracy: 0.9501\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1181 - accuracy: 0.9530\n",
      "\n",
      "Epoch:  74\n",
      "378/378 - 9s - loss: 0.1164 - accuracy: 0.9540 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1056 - accuracy: 0.9593\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1046 - accuracy: 0.9616\n",
      "\n",
      "Epoch:  75\n",
      "378/378 - 10s - loss: 0.1189 - accuracy: 0.9536 - 10s/epoch - 26ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1501 - accuracy: 0.9401\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1500 - accuracy: 0.9382\n",
      "\n",
      "Epoch:  76\n",
      "378/378 - 8s - loss: 0.1125 - accuracy: 0.9562 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1290 - accuracy: 0.9463\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.1268 - accuracy: 0.9469\n",
      "\n",
      "Epoch:  77\n",
      "378/378 - 14s - loss: 0.1155 - accuracy: 0.9544 - 14s/epoch - 36ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1031 - accuracy: 0.9598\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1012 - accuracy: 0.9624\n",
      "\n",
      "Epoch:  78\n",
      "378/378 - 9s - loss: 0.1130 - accuracy: 0.9553 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1040 - accuracy: 0.9595\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1027 - accuracy: 0.9616\n",
      "\n",
      "Epoch:  79\n",
      "378/378 - 8s - loss: 0.1101 - accuracy: 0.9564 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1118 - accuracy: 0.9565\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1106 - accuracy: 0.9566\n",
      "\n",
      "Epoch:  80\n",
      "378/378 - 12s - loss: 0.1104 - accuracy: 0.9569 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.1120 - accuracy: 0.9551\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1097 - accuracy: 0.9567\n",
      "\n",
      "Epoch:  81\n",
      "378/378 - 10s - loss: 0.1136 - accuracy: 0.9552 - 10s/epoch - 26ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1049 - accuracy: 0.9590\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1021 - accuracy: 0.9603\n",
      "\n",
      "Epoch:  82\n",
      "378/378 - 9s - loss: 0.1136 - accuracy: 0.9554 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1057 - accuracy: 0.9584\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1040 - accuracy: 0.9617\n",
      "\n",
      "Epoch:  83\n",
      "378/378 - 10s - loss: 0.1114 - accuracy: 0.9565 - 10s/epoch - 26ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1174 - accuracy: 0.9527\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1141 - accuracy: 0.9548\n",
      "\n",
      "Epoch:  84\n",
      "378/378 - 9s - loss: 0.1107 - accuracy: 0.9560 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1000 - accuracy: 0.9617\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0983 - accuracy: 0.9627\n",
      "\n",
      "Epoch:  85\n",
      "378/378 - 9s - loss: 0.1107 - accuracy: 0.9563 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0996 - accuracy: 0.9617\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0977 - accuracy: 0.9636\n",
      "\n",
      "Epoch:  86\n",
      "378/378 - 11s - loss: 0.1077 - accuracy: 0.9573 - 11s/epoch - 30ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.1174 - accuracy: 0.9534\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1159 - accuracy: 0.9540\n",
      "\n",
      "Epoch:  87\n",
      "378/378 - 9s - loss: 0.1095 - accuracy: 0.9569 - 9s/epoch - 25ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0981 - accuracy: 0.9621\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0956 - accuracy: 0.9649\n",
      "\n",
      "Epoch:  88\n",
      "378/378 - 9s - loss: 0.1066 - accuracy: 0.9584 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0986 - accuracy: 0.9616\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0962 - accuracy: 0.9642\n",
      "\n",
      "Epoch:  89\n",
      "378/378 - 10s - loss: 0.1124 - accuracy: 0.9555 - 10s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1123 - accuracy: 0.9562\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1106 - accuracy: 0.9582\n",
      "\n",
      "Epoch:  90\n",
      "378/378 - 9s - loss: 0.1093 - accuracy: 0.9578 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1013 - accuracy: 0.9618\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0995 - accuracy: 0.9628\n",
      "\n",
      "Epoch:  91\n",
      "378/378 - 9s - loss: 0.1079 - accuracy: 0.9579 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0964 - accuracy: 0.9634\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0949 - accuracy: 0.9645\n",
      "\n",
      "Epoch:  92\n",
      "378/378 - 10s - loss: 0.1039 - accuracy: 0.9596 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.1601 - accuracy: 0.9342\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.1555 - accuracy: 0.9353\n",
      "\n",
      "Epoch:  93\n",
      "378/378 - 11s - loss: 0.1080 - accuracy: 0.9578 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.1019 - accuracy: 0.9609\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1012 - accuracy: 0.9620\n",
      "\n",
      "Epoch:  94\n",
      "378/378 - 9s - loss: 0.1053 - accuracy: 0.9585 - 9s/epoch - 25ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1081 - accuracy: 0.9569\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1046 - accuracy: 0.9597\n",
      "\n",
      "Epoch:  95\n",
      "378/378 - 10s - loss: 0.1037 - accuracy: 0.9595 - 10s/epoch - 26ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.1130 - accuracy: 0.9543\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1095 - accuracy: 0.9575\n",
      "\n",
      "Epoch:  96\n",
      "378/378 - 10s - loss: 0.1057 - accuracy: 0.9589 - 10s/epoch - 26ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1017 - accuracy: 0.9602\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0989 - accuracy: 0.9615\n",
      "\n",
      "Epoch:  97\n",
      "378/378 - 11s - loss: 0.1066 - accuracy: 0.9583 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1017 - accuracy: 0.9605\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0981 - accuracy: 0.9617\n",
      "\n",
      "Epoch:  98\n",
      "378/378 - 9s - loss: 0.1006 - accuracy: 0.9611 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1339 - accuracy: 0.9463\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1343 - accuracy: 0.9455\n",
      "\n",
      "Epoch:  99\n",
      "378/378 - 9s - loss: 0.1061 - accuracy: 0.9577 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1346 - accuracy: 0.9464\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1290 - accuracy: 0.9478\n",
      "\n",
      "Epoch:  100\n",
      "378/378 - 10s - loss: 0.1014 - accuracy: 0.9605 - 10s/epoch - 26ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0956 - accuracy: 0.9632\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0936 - accuracy: 0.9665\n",
      "\n",
      "Epoch:  101\n",
      "378/378 - 10s - loss: 0.1046 - accuracy: 0.9597 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0954 - accuracy: 0.9639\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0943 - accuracy: 0.9647\n",
      "\n",
      "Epoch:  102\n",
      "378/378 - 10s - loss: 0.1057 - accuracy: 0.9589 - 10s/epoch - 26ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.1100 - accuracy: 0.9554\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.1069 - accuracy: 0.9582\n",
      "\n",
      "Epoch:  103\n",
      "378/378 - 9s - loss: 0.1052 - accuracy: 0.9593 - 9s/epoch - 25ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0979 - accuracy: 0.9622\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0957 - accuracy: 0.9640\n",
      "\n",
      "Epoch:  104\n",
      "378/378 - 10s - loss: 0.1030 - accuracy: 0.9600 - 10s/epoch - 25ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.1138 - accuracy: 0.9548\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.1136 - accuracy: 0.9568\n",
      "\n",
      "Epoch:  105\n",
      "378/378 - 11s - loss: 0.1030 - accuracy: 0.9594 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 8s 5ms/step - loss: 0.1287 - accuracy: 0.9490\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.1230 - accuracy: 0.9516\n",
      "\n",
      "Epoch:  106\n",
      "378/378 - 12s - loss: 0.1038 - accuracy: 0.9596 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1311 - accuracy: 0.9464\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1274 - accuracy: 0.9475\n",
      "\n",
      "Epoch:  107\n",
      "378/378 - 9s - loss: 0.1043 - accuracy: 0.9586 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0922 - accuracy: 0.9647\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0897 - accuracy: 0.9680\n",
      "\n",
      "Epoch:  108\n",
      "378/378 - 9s - loss: 0.0988 - accuracy: 0.9621 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1186 - accuracy: 0.9522\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1183 - accuracy: 0.9543\n",
      "\n",
      "Epoch:  109\n",
      "378/378 - 9s - loss: 0.0995 - accuracy: 0.9617 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1042 - accuracy: 0.9592\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1033 - accuracy: 0.9622\n",
      "\n",
      "Epoch:  110\n",
      "378/378 - 10s - loss: 0.1066 - accuracy: 0.9582 - 10s/epoch - 26ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 6ms/step - loss: 0.0923 - accuracy: 0.9643\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0900 - accuracy: 0.9657\n",
      "\n",
      "Epoch:  111\n",
      "378/378 - 11s - loss: 0.1013 - accuracy: 0.9606 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0900 - accuracy: 0.9658\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0877 - accuracy: 0.9678\n",
      "\n",
      "Epoch:  112\n",
      "378/378 - 9s - loss: 0.1000 - accuracy: 0.9606 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0898 - accuracy: 0.9664\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0873 - accuracy: 0.9678\n",
      "\n",
      "Epoch:  113\n",
      "378/378 - 9s - loss: 0.0987 - accuracy: 0.9618 - 9s/epoch - 25ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0924 - accuracy: 0.9652\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0898 - accuracy: 0.9668\n",
      "\n",
      "Epoch:  114\n",
      "378/378 - 8s - loss: 0.0990 - accuracy: 0.9615 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.1006 - accuracy: 0.9607\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0971 - accuracy: 0.9619\n",
      "\n",
      "Epoch:  115\n",
      "378/378 - 10s - loss: 0.0992 - accuracy: 0.9614 - 10s/epoch - 25ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0979 - accuracy: 0.9621\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0968 - accuracy: 0.9635\n",
      "\n",
      "Epoch:  116\n",
      "378/378 - 8s - loss: 0.1020 - accuracy: 0.9609 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0894 - accuracy: 0.9667\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0870 - accuracy: 0.9681\n",
      "\n",
      "Epoch:  117\n",
      "378/378 - 8s - loss: 0.0963 - accuracy: 0.9629 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0898 - accuracy: 0.9649\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0874 - accuracy: 0.9673\n",
      "\n",
      "Epoch:  118\n",
      "378/378 - 8s - loss: 0.0989 - accuracy: 0.9615 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0912 - accuracy: 0.9653\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0894 - accuracy: 0.9666\n",
      "\n",
      "Epoch:  119\n",
      "378/378 - 8s - loss: 0.0978 - accuracy: 0.9618 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0977 - accuracy: 0.9622\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0952 - accuracy: 0.9637\n",
      "\n",
      "Epoch:  120\n",
      "378/378 - 8s - loss: 0.1031 - accuracy: 0.9609 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0899 - accuracy: 0.9659\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0882 - accuracy: 0.9674\n",
      "\n",
      "Epoch:  121\n",
      "378/378 - 9s - loss: 0.0966 - accuracy: 0.9630 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0916 - accuracy: 0.9646\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0885 - accuracy: 0.9663\n",
      "\n",
      "Epoch:  122\n",
      "378/378 - 8s - loss: 0.0989 - accuracy: 0.9619 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0874 - accuracy: 0.9664\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0847 - accuracy: 0.9688\n",
      "\n",
      "Epoch:  123\n",
      "378/378 - 8s - loss: 0.0986 - accuracy: 0.9616 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1012 - accuracy: 0.9610\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0963 - accuracy: 0.9640\n",
      "\n",
      "Epoch:  124\n",
      "378/378 - 8s - loss: 0.0991 - accuracy: 0.9607 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0888 - accuracy: 0.9670\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0872 - accuracy: 0.9680\n",
      "\n",
      "Epoch:  125\n",
      "378/378 - 8s - loss: 0.0951 - accuracy: 0.9633 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0879 - accuracy: 0.9671\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0858 - accuracy: 0.9693\n",
      "\n",
      "Epoch:  126\n",
      "378/378 - 8s - loss: 0.0951 - accuracy: 0.9631 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0890 - accuracy: 0.9660\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0864 - accuracy: 0.9676\n",
      "\n",
      "Epoch:  127\n",
      "378/378 - 9s - loss: 0.0963 - accuracy: 0.9630 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1001 - accuracy: 0.9608\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0967 - accuracy: 0.9621\n",
      "\n",
      "Epoch:  128\n",
      "378/378 - 8s - loss: 0.0944 - accuracy: 0.9634 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1006 - accuracy: 0.9605\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0960 - accuracy: 0.9622\n",
      "\n",
      "Epoch:  129\n",
      "378/378 - 8s - loss: 0.0942 - accuracy: 0.9640 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0869 - accuracy: 0.9669\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0847 - accuracy: 0.9691\n",
      "\n",
      "Epoch:  130\n",
      "378/378 - 8s - loss: 0.0941 - accuracy: 0.9633 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0883 - accuracy: 0.9670\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0870 - accuracy: 0.9679\n",
      "\n",
      "Epoch:  131\n",
      "378/378 - 8s - loss: 0.0946 - accuracy: 0.9627 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0866 - accuracy: 0.9675\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0854 - accuracy: 0.9689\n",
      "\n",
      "Epoch:  132\n",
      "378/378 - 8s - loss: 0.0942 - accuracy: 0.9641 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0855 - accuracy: 0.9676\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0834 - accuracy: 0.9700\n",
      "\n",
      "Epoch:  133\n",
      "378/378 - 8s - loss: 0.0987 - accuracy: 0.9613 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0860 - accuracy: 0.9674\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0831 - accuracy: 0.9713\n",
      "\n",
      "Epoch:  134\n",
      "378/378 - 9s - loss: 0.0959 - accuracy: 0.9636 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0939 - accuracy: 0.9637\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0923 - accuracy: 0.9656\n",
      "\n",
      "Epoch:  135\n",
      "378/378 - 8s - loss: 0.0963 - accuracy: 0.9634 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0873 - accuracy: 0.9662\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0853 - accuracy: 0.9682\n",
      "\n",
      "Epoch:  136\n",
      "378/378 - 9s - loss: 0.0944 - accuracy: 0.9636 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0905 - accuracy: 0.9650\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0872 - accuracy: 0.9685\n",
      "\n",
      "Epoch:  137\n",
      "378/378 - 9s - loss: 0.0918 - accuracy: 0.9647 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0961 - accuracy: 0.9633\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0939 - accuracy: 0.9645\n",
      "\n",
      "Epoch:  138\n",
      "378/378 - 8s - loss: 0.0940 - accuracy: 0.9642 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1403 - accuracy: 0.9439\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1342 - accuracy: 0.9461\n",
      "\n",
      "Epoch:  139\n",
      "378/378 - 8s - loss: 0.0938 - accuracy: 0.9641 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1658 - accuracy: 0.9313\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1681 - accuracy: 0.9296\n",
      "\n",
      "Epoch:  140\n",
      "378/378 - 8s - loss: 0.0925 - accuracy: 0.9648 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0902 - accuracy: 0.9658\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0892 - accuracy: 0.9663\n",
      "\n",
      "Epoch:  141\n",
      "378/378 - 8s - loss: 0.0935 - accuracy: 0.9645 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0864 - accuracy: 0.9675\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0831 - accuracy: 0.9697\n",
      "\n",
      "Epoch:  142\n",
      "378/378 - 8s - loss: 0.0940 - accuracy: 0.9641 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0834 - accuracy: 0.9693\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0809 - accuracy: 0.9702\n",
      "\n",
      "Epoch:  143\n",
      "378/378 - 8s - loss: 0.0914 - accuracy: 0.9648 - 8s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0887 - accuracy: 0.9659\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0865 - accuracy: 0.9673\n",
      "\n",
      "Epoch:  144\n",
      "378/378 - 8s - loss: 0.0914 - accuracy: 0.9653 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0829 - accuracy: 0.9688\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0806 - accuracy: 0.9701\n",
      "\n",
      "Epoch:  145\n",
      "378/378 - 8s - loss: 0.0919 - accuracy: 0.9651 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0968 - accuracy: 0.9619\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0970 - accuracy: 0.9636\n",
      "\n",
      "Epoch:  146\n",
      "378/378 - 8s - loss: 0.0906 - accuracy: 0.9652 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0821 - accuracy: 0.9692\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0801 - accuracy: 0.9717\n",
      "\n",
      "Epoch:  147\n",
      "378/378 - 8s - loss: 0.0897 - accuracy: 0.9658 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0814 - accuracy: 0.9694\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0790 - accuracy: 0.9722\n",
      "\n",
      "Epoch:  148\n",
      "378/378 - 8s - loss: 0.0965 - accuracy: 0.9625 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0857 - accuracy: 0.9676\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0835 - accuracy: 0.9696\n",
      "\n",
      "Epoch:  149\n",
      "378/378 - 8s - loss: 0.0890 - accuracy: 0.9660 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0837 - accuracy: 0.9684\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0826 - accuracy: 0.9704\n",
      "\n",
      "Epoch:  150\n",
      "378/378 - 8s - loss: 0.0925 - accuracy: 0.9648 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0863 - accuracy: 0.9674\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0842 - accuracy: 0.9687\n",
      "\n",
      "Epoch:  151\n",
      "378/378 - 8s - loss: 0.0926 - accuracy: 0.9641 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1270 - accuracy: 0.9485\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1271 - accuracy: 0.9485\n",
      "\n",
      "Epoch:  152\n",
      "378/378 - 8s - loss: 0.0906 - accuracy: 0.9658 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0832 - accuracy: 0.9685\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0815 - accuracy: 0.9705\n",
      "\n",
      "Epoch:  153\n",
      "378/378 - 8s - loss: 0.0899 - accuracy: 0.9659 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1016 - accuracy: 0.9602\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0973 - accuracy: 0.9618\n",
      "\n",
      "Epoch:  154\n",
      "378/378 - 8s - loss: 0.0927 - accuracy: 0.9651 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0912 - accuracy: 0.9652\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0909 - accuracy: 0.9658\n",
      "\n",
      "Epoch:  155\n",
      "378/378 - 8s - loss: 0.0907 - accuracy: 0.9653 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0820 - accuracy: 0.9689\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0804 - accuracy: 0.9706\n",
      "\n",
      "Epoch:  156\n",
      "378/378 - 8s - loss: 0.0905 - accuracy: 0.9648 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0863 - accuracy: 0.9676\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0831 - accuracy: 0.9688\n",
      "\n",
      "Epoch:  157\n",
      "378/378 - 8s - loss: 0.0913 - accuracy: 0.9651 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0905 - accuracy: 0.9651\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0902 - accuracy: 0.9668\n",
      "\n",
      "Epoch:  158\n",
      "378/378 - 8s - loss: 0.0875 - accuracy: 0.9664 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0884 - accuracy: 0.9662\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0841 - accuracy: 0.9694\n",
      "\n",
      "Epoch:  159\n",
      "378/378 - 8s - loss: 0.0882 - accuracy: 0.9661 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0866 - accuracy: 0.9671\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0856 - accuracy: 0.9683\n",
      "\n",
      "Epoch:  160\n",
      "378/378 - 8s - loss: 0.0903 - accuracy: 0.9656 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0810 - accuracy: 0.9697\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0786 - accuracy: 0.9717\n",
      "\n",
      "Epoch:  161\n",
      "378/378 - 8s - loss: 0.0907 - accuracy: 0.9664 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0799 - accuracy: 0.9696\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0787 - accuracy: 0.9710\n",
      "\n",
      "Epoch:  162\n",
      "378/378 - 8s - loss: 0.0889 - accuracy: 0.9657 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0834 - accuracy: 0.9687\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0808 - accuracy: 0.9697\n",
      "\n",
      "Epoch:  163\n",
      "378/378 - 8s - loss: 0.0883 - accuracy: 0.9666 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0820 - accuracy: 0.9689\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0803 - accuracy: 0.9699\n",
      "\n",
      "Epoch:  164\n",
      "378/378 - 9s - loss: 0.0931 - accuracy: 0.9640 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0818 - accuracy: 0.9694\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0795 - accuracy: 0.9717\n",
      "\n",
      "Epoch:  165\n",
      "378/378 - 10s - loss: 0.0879 - accuracy: 0.9672 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0791 - accuracy: 0.9704\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0769 - accuracy: 0.9721\n",
      "\n",
      "Epoch:  166\n",
      "378/378 - 8s - loss: 0.0879 - accuracy: 0.9664 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0851 - accuracy: 0.9675\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0812 - accuracy: 0.9705\n",
      "\n",
      "Epoch:  167\n",
      "378/378 - 8s - loss: 0.0889 - accuracy: 0.9657 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0818 - accuracy: 0.9691\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0797 - accuracy: 0.9708\n",
      "\n",
      "Epoch:  168\n",
      "378/378 - 8s - loss: 0.0888 - accuracy: 0.9664 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0901 - accuracy: 0.9652\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0886 - accuracy: 0.9669\n",
      "\n",
      "Epoch:  169\n",
      "378/378 - 8s - loss: 0.0884 - accuracy: 0.9663 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0895 - accuracy: 0.9655\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0861 - accuracy: 0.9671\n",
      "\n",
      "Epoch:  170\n",
      "378/378 - 8s - loss: 0.0899 - accuracy: 0.9651 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1014 - accuracy: 0.9602\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1014 - accuracy: 0.9602\n",
      "\n",
      "Epoch:  171\n",
      "378/378 - 8s - loss: 0.0863 - accuracy: 0.9672 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0824 - accuracy: 0.9691\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0797 - accuracy: 0.9710\n",
      "\n",
      "Epoch:  172\n",
      "378/378 - 8s - loss: 0.0862 - accuracy: 0.9673 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0791 - accuracy: 0.9704\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0769 - accuracy: 0.9724\n",
      "\n",
      "Epoch:  173\n",
      "378/378 - 8s - loss: 0.0902 - accuracy: 0.9654 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0791 - accuracy: 0.9702\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0768 - accuracy: 0.9713\n",
      "\n",
      "Epoch:  174\n",
      "378/378 - 8s - loss: 0.0852 - accuracy: 0.9678 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0774 - accuracy: 0.9706\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0762 - accuracy: 0.9729\n",
      "\n",
      "Epoch:  175\n",
      "378/378 - 8s - loss: 0.0896 - accuracy: 0.9648 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0789 - accuracy: 0.9703\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0771 - accuracy: 0.9717\n",
      "\n",
      "Epoch:  176\n",
      "378/378 - 8s - loss: 0.0870 - accuracy: 0.9669 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0799 - accuracy: 0.9703\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0776 - accuracy: 0.9721\n",
      "\n",
      "Epoch:  177\n",
      "378/378 - 8s - loss: 0.0866 - accuracy: 0.9667 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0849 - accuracy: 0.9676\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0812 - accuracy: 0.9692\n",
      "\n",
      "Epoch:  178\n",
      "378/378 - 8s - loss: 0.0875 - accuracy: 0.9677 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0780 - accuracy: 0.9708\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0760 - accuracy: 0.9724\n",
      "\n",
      "Epoch:  179\n",
      "378/378 - 8s - loss: 0.0830 - accuracy: 0.9690 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0955 - accuracy: 0.9627\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0903 - accuracy: 0.9654\n",
      "\n",
      "Epoch:  180\n",
      "378/378 - 8s - loss: 0.0851 - accuracy: 0.9680 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0772 - accuracy: 0.9709\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0758 - accuracy: 0.9723\n",
      "\n",
      "Epoch:  181\n",
      "378/378 - 8s - loss: 0.0872 - accuracy: 0.9666 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0918 - accuracy: 0.9651\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0875 - accuracy: 0.9670\n",
      "\n",
      "Epoch:  182\n",
      "378/378 - 9s - loss: 0.0881 - accuracy: 0.9666 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0986 - accuracy: 0.9622\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0939 - accuracy: 0.9635\n",
      "\n",
      "Epoch:  183\n",
      "378/378 - 8s - loss: 0.0867 - accuracy: 0.9663 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0793 - accuracy: 0.9695\n",
      "for testing\n",
      "378/378 [==============================] - 1s 4ms/step - loss: 0.0770 - accuracy: 0.9716\n",
      "\n",
      "Epoch:  184\n",
      "378/378 - 8s - loss: 0.0841 - accuracy: 0.9684 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0771 - accuracy: 0.9713\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0750 - accuracy: 0.9727\n",
      "\n",
      "Epoch:  185\n",
      "378/378 - 8s - loss: 0.0859 - accuracy: 0.9668 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0791 - accuracy: 0.9697\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0775 - accuracy: 0.9719\n",
      "\n",
      "Epoch:  186\n",
      "378/378 - 8s - loss: 0.0845 - accuracy: 0.9678 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1241 - accuracy: 0.9488\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1251 - accuracy: 0.9502\n",
      "\n",
      "Epoch:  187\n",
      "378/378 - 8s - loss: 0.0859 - accuracy: 0.9669 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1422 - accuracy: 0.9443\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1352 - accuracy: 0.9463\n",
      "\n",
      "Epoch:  188\n",
      "378/378 - 8s - loss: 0.0845 - accuracy: 0.9684 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0782 - accuracy: 0.9704\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0767 - accuracy: 0.9716\n",
      "\n",
      "Epoch:  189\n",
      "378/378 - 8s - loss: 0.0853 - accuracy: 0.9683 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0808 - accuracy: 0.9697\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0783 - accuracy: 0.9711\n",
      "\n",
      "Epoch:  190\n",
      "378/378 - 8s - loss: 0.0834 - accuracy: 0.9686 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0791 - accuracy: 0.9703\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0779 - accuracy: 0.9719\n",
      "\n",
      "Epoch:  191\n",
      "378/378 - 8s - loss: 0.0886 - accuracy: 0.9660 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0865 - accuracy: 0.9673\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0821 - accuracy: 0.9697\n",
      "\n",
      "Epoch:  192\n",
      "378/378 - 8s - loss: 0.0851 - accuracy: 0.9678 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.1118 - accuracy: 0.9546\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1123 - accuracy: 0.9553\n",
      "\n",
      "Epoch:  193\n",
      "378/378 - 8s - loss: 0.0839 - accuracy: 0.9680 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0898 - accuracy: 0.9649\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0902 - accuracy: 0.9648\n",
      "\n",
      "Epoch:  194\n",
      "378/378 - 8s - loss: 0.0860 - accuracy: 0.9662 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0773 - accuracy: 0.9708\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0754 - accuracy: 0.9721\n",
      "\n",
      "Epoch:  195\n",
      "378/378 - 8s - loss: 0.0847 - accuracy: 0.9685 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0754 - accuracy: 0.9721\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0730 - accuracy: 0.9747\n",
      "\n",
      "Epoch:  196\n",
      "378/378 - 8s - loss: 0.0834 - accuracy: 0.9681 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0771 - accuracy: 0.9712\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0752 - accuracy: 0.9741\n",
      "\n",
      "Epoch:  197\n",
      "378/378 - 8s - loss: 0.0825 - accuracy: 0.9689 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0755 - accuracy: 0.9722\n",
      "for testing\n",
      "378/378 [==============================] - 1s 4ms/step - loss: 0.0736 - accuracy: 0.9730\n",
      "\n",
      "Epoch:  198\n",
      "378/378 - 8s - loss: 0.0810 - accuracy: 0.9695 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0787 - accuracy: 0.9707\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0771 - accuracy: 0.9721\n",
      "\n",
      "Epoch:  199\n",
      "378/378 - 11s - loss: 0.0826 - accuracy: 0.9683 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0768 - accuracy: 0.9712\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0761 - accuracy: 0.9724\n",
      "\n",
      "Epoch:  200\n",
      "378/378 - 12s - loss: 0.0862 - accuracy: 0.9674 - 12s/epoch - 31ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0779 - accuracy: 0.9705\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0758 - accuracy: 0.9714\n",
      "\n",
      "Epoch:  201\n",
      "378/378 - 11s - loss: 0.0822 - accuracy: 0.9697 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0929 - accuracy: 0.9644\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0884 - accuracy: 0.9661\n",
      "\n",
      "Epoch:  202\n",
      "378/378 - 11s - loss: 0.0820 - accuracy: 0.9689 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0744 - accuracy: 0.9724\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0732 - accuracy: 0.9730\n",
      "\n",
      "Epoch:  203\n",
      "378/378 - 11s - loss: 0.0815 - accuracy: 0.9693 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0743 - accuracy: 0.9719\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0728 - accuracy: 0.9742\n",
      "\n",
      "Epoch:  204\n",
      "378/378 - 11s - loss: 0.0856 - accuracy: 0.9668 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0779 - accuracy: 0.9711\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0753 - accuracy: 0.9719\n",
      "\n",
      "Epoch:  205\n",
      "378/378 - 12s - loss: 0.0797 - accuracy: 0.9702 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0767 - accuracy: 0.9711\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0749 - accuracy: 0.9726\n",
      "\n",
      "Epoch:  206\n",
      "378/378 - 12s - loss: 0.0843 - accuracy: 0.9680 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0862 - accuracy: 0.9671\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0829 - accuracy: 0.9693\n",
      "\n",
      "Epoch:  207\n",
      "378/378 - 11s - loss: 0.0807 - accuracy: 0.9699 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0938 - accuracy: 0.9640\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0897 - accuracy: 0.9654\n",
      "\n",
      "Epoch:  208\n",
      "378/378 - 11s - loss: 0.0820 - accuracy: 0.9688 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0789 - accuracy: 0.9705\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0765 - accuracy: 0.9718\n",
      "\n",
      "Epoch:  209\n",
      "378/378 - 10s - loss: 0.0814 - accuracy: 0.9691 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0975 - accuracy: 0.9611\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0977 - accuracy: 0.9618\n",
      "\n",
      "Epoch:  210\n",
      "378/378 - 11s - loss: 0.0820 - accuracy: 0.9689 - 11s/epoch - 28ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0771 - accuracy: 0.9711\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0757 - accuracy: 0.9712\n",
      "\n",
      "Epoch:  211\n",
      "378/378 - 10s - loss: 0.0826 - accuracy: 0.9684 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0818 - accuracy: 0.9690\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0815 - accuracy: 0.9696\n",
      "\n",
      "Epoch:  212\n",
      "378/378 - 10s - loss: 0.0808 - accuracy: 0.9698 - 10s/epoch - 26ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0740 - accuracy: 0.9722\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0721 - accuracy: 0.9734\n",
      "\n",
      "Epoch:  213\n",
      "378/378 - 15s - loss: 0.0818 - accuracy: 0.9683 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0733 - accuracy: 0.9726\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0724 - accuracy: 0.9739\n",
      "\n",
      "Epoch:  214\n",
      "378/378 - 13s - loss: 0.0799 - accuracy: 0.9695 - 13s/epoch - 35ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0775 - accuracy: 0.9704\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0764 - accuracy: 0.9734\n",
      "\n",
      "Epoch:  215\n",
      "378/378 - 13s - loss: 0.0819 - accuracy: 0.9695 - 13s/epoch - 35ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 11ms/step - loss: 0.0731 - accuracy: 0.9725\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0712 - accuracy: 0.9748\n",
      "\n",
      "Epoch:  216\n",
      "378/378 - 13s - loss: 0.0840 - accuracy: 0.9683 - 13s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0938 - accuracy: 0.9626\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0937 - accuracy: 0.9638\n",
      "\n",
      "Epoch:  217\n",
      "378/378 - 9s - loss: 0.0829 - accuracy: 0.9681 - 9s/epoch - 25ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0779 - accuracy: 0.9708\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0758 - accuracy: 0.9716\n",
      "\n",
      "Epoch:  218\n",
      "378/378 - 10s - loss: 0.0790 - accuracy: 0.9701 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0762 - accuracy: 0.9714\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0752 - accuracy: 0.9729\n",
      "\n",
      "Epoch:  219\n",
      "378/378 - 12s - loss: 0.0808 - accuracy: 0.9695 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0734 - accuracy: 0.9730\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0706 - accuracy: 0.9750\n",
      "\n",
      "Epoch:  220\n",
      "378/378 - 11s - loss: 0.0803 - accuracy: 0.9697 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0804 - accuracy: 0.9694\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0781 - accuracy: 0.9703\n",
      "\n",
      "Epoch:  221\n",
      "378/378 - 11s - loss: 0.0851 - accuracy: 0.9674 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0735 - accuracy: 0.9728\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0710 - accuracy: 0.9743\n",
      "\n",
      "Epoch:  222\n",
      "378/378 - 9s - loss: 0.0825 - accuracy: 0.9683 - 9s/epoch - 25ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0881 - accuracy: 0.9668\n",
      "for testing\n",
      "378/378 [==============================] - 2s 6ms/step - loss: 0.0841 - accuracy: 0.9684\n",
      "\n",
      "Epoch:  223\n",
      "378/378 - 10s - loss: 0.0809 - accuracy: 0.9685 - 10s/epoch - 26ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1140 - accuracy: 0.9541\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.1163 - accuracy: 0.9526\n",
      "\n",
      "Epoch:  224\n",
      "378/378 - 10s - loss: 0.0816 - accuracy: 0.9684 - 10s/epoch - 26ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0716 - accuracy: 0.9733\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0700 - accuracy: 0.9746\n",
      "\n",
      "Epoch:  225\n",
      "378/378 - 10s - loss: 0.0804 - accuracy: 0.9696 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0731 - accuracy: 0.9726\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0712 - accuracy: 0.9733\n",
      "\n",
      "Epoch:  226\n",
      "378/378 - 10s - loss: 0.0796 - accuracy: 0.9702 - 10s/epoch - 26ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0887 - accuracy: 0.9649\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0896 - accuracy: 0.9662\n",
      "\n",
      "Epoch:  227\n",
      "378/378 - 10s - loss: 0.0871 - accuracy: 0.9657 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0734 - accuracy: 0.9721\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0729 - accuracy: 0.9726\n",
      "\n",
      "Epoch:  228\n",
      "378/378 - 11s - loss: 0.0777 - accuracy: 0.9709 - 11s/epoch - 29ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0851 - accuracy: 0.9667\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0847 - accuracy: 0.9675\n",
      "\n",
      "Epoch:  229\n",
      "378/378 - 11s - loss: 0.0818 - accuracy: 0.9691 - 11s/epoch - 29ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0741 - accuracy: 0.9723\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0723 - accuracy: 0.9726\n",
      "\n",
      "Epoch:  230\n",
      "378/378 - 10s - loss: 0.0810 - accuracy: 0.9695 - 10s/epoch - 26ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 11s 7ms/step - loss: 0.0717 - accuracy: 0.9728\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0696 - accuracy: 0.9750\n",
      "\n",
      "Epoch:  231\n",
      "378/378 - 11s - loss: 0.0786 - accuracy: 0.9710 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1211 - accuracy: 0.9505\n",
      "for testing\n",
      "378/378 [==============================] - 4s 9ms/step - loss: 0.1221 - accuracy: 0.9494\n",
      "\n",
      "Epoch:  232\n",
      "378/378 - 12s - loss: 0.0819 - accuracy: 0.9684 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0924 - accuracy: 0.9634\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0932 - accuracy: 0.9647\n",
      "\n",
      "Epoch:  233\n",
      "378/378 - 9s - loss: 0.0795 - accuracy: 0.9700 - 9s/epoch - 25ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.1404 - accuracy: 0.9420\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1426 - accuracy: 0.9398\n",
      "\n",
      "Epoch:  234\n",
      "378/378 - 10s - loss: 0.0816 - accuracy: 0.9692 - 10s/epoch - 26ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0696 - accuracy: 0.9743\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0680 - accuracy: 0.9756\n",
      "\n",
      "Epoch:  235\n",
      "378/378 - 10s - loss: 0.0802 - accuracy: 0.9697 - 10s/epoch - 26ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 10s 7ms/step - loss: 0.0695 - accuracy: 0.9739\n",
      "for testing\n",
      "378/378 [==============================] - 3s 7ms/step - loss: 0.0674 - accuracy: 0.9763\n",
      "\n",
      "Epoch:  236\n",
      "378/378 - 10s - loss: 0.0807 - accuracy: 0.9699 - 10s/epoch - 27ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0875 - accuracy: 0.9662\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0832 - accuracy: 0.9686\n",
      "\n",
      "Epoch:  237\n",
      "378/378 - 11s - loss: 0.0795 - accuracy: 0.9700 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0780 - accuracy: 0.9708\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0752 - accuracy: 0.9725\n",
      "\n",
      "Epoch:  238\n",
      "378/378 - 12s - loss: 0.0784 - accuracy: 0.9697 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0693 - accuracy: 0.9738\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0683 - accuracy: 0.9750\n",
      "\n",
      "Epoch:  239\n",
      "378/378 - 12s - loss: 0.0771 - accuracy: 0.9711 - 12s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0714 - accuracy: 0.9740\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0706 - accuracy: 0.9745\n",
      "\n",
      "Epoch:  240\n",
      "378/378 - 12s - loss: 0.0792 - accuracy: 0.9691 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0708 - accuracy: 0.9733\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0688 - accuracy: 0.9758\n",
      "\n",
      "Epoch:  241\n",
      "378/378 - 12s - loss: 0.0775 - accuracy: 0.9701 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0707 - accuracy: 0.9741\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0684 - accuracy: 0.9750\n",
      "\n",
      "Epoch:  242\n",
      "378/378 - 12s - loss: 0.0794 - accuracy: 0.9695 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0779 - accuracy: 0.9702\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0775 - accuracy: 0.9702\n",
      "\n",
      "Epoch:  243\n",
      "378/378 - 12s - loss: 0.0786 - accuracy: 0.9698 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0724 - accuracy: 0.9733\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0692 - accuracy: 0.9756\n",
      "\n",
      "Epoch:  244\n",
      "378/378 - 12s - loss: 0.0822 - accuracy: 0.9684 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0708 - accuracy: 0.9735\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0692 - accuracy: 0.9741\n",
      "\n",
      "Epoch:  245\n",
      "378/378 - 12s - loss: 0.0789 - accuracy: 0.9697 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0813 - accuracy: 0.9693\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0777 - accuracy: 0.9716\n",
      "\n",
      "Epoch:  246\n",
      "378/378 - 12s - loss: 0.0795 - accuracy: 0.9695 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0737 - accuracy: 0.9719\n",
      "for testing\n",
      "378/378 [==============================] - 6s 15ms/step - loss: 0.0733 - accuracy: 0.9723\n",
      "\n",
      "Epoch:  247\n",
      "378/378 - 12s - loss: 0.0771 - accuracy: 0.9715 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0707 - accuracy: 0.9734\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0694 - accuracy: 0.9757\n",
      "\n",
      "Epoch:  248\n",
      "378/378 - 12s - loss: 0.0771 - accuracy: 0.9713 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.1038 - accuracy: 0.9575\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.1044 - accuracy: 0.9584\n",
      "\n",
      "Epoch:  249\n",
      "378/378 - 12s - loss: 0.0782 - accuracy: 0.9703 - 12s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0720 - accuracy: 0.9732\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0692 - accuracy: 0.9748\n",
      "\n",
      "Epoch:  250\n",
      "378/378 - 14s - loss: 0.0776 - accuracy: 0.9705 - 14s/epoch - 37ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0702 - accuracy: 0.9740\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0675 - accuracy: 0.9757\n",
      "\n",
      "Epoch:  251\n",
      "378/378 - 12s - loss: 0.0750 - accuracy: 0.9720 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0702 - accuracy: 0.9741\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0696 - accuracy: 0.9753\n",
      "\n",
      "Epoch:  252\n",
      "378/378 - 13s - loss: 0.0780 - accuracy: 0.9699 - 13s/epoch - 34ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0832 - accuracy: 0.9679\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0836 - accuracy: 0.9678\n",
      "\n",
      "Epoch:  253\n",
      "378/378 - 14s - loss: 0.0793 - accuracy: 0.9693 - 14s/epoch - 36ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0684 - accuracy: 0.9746\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0676 - accuracy: 0.9758\n",
      "\n",
      "Epoch:  254\n",
      "378/378 - 12s - loss: 0.0787 - accuracy: 0.9707 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0758 - accuracy: 0.9710\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0738 - accuracy: 0.9716\n",
      "\n",
      "Epoch:  255\n",
      "378/378 - 15s - loss: 0.0775 - accuracy: 0.9703 - 15s/epoch - 40ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0700 - accuracy: 0.9736\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0682 - accuracy: 0.9749\n",
      "\n",
      "Epoch:  256\n",
      "378/378 - 14s - loss: 0.0776 - accuracy: 0.9703 - 14s/epoch - 38ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0727 - accuracy: 0.9726\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0698 - accuracy: 0.9741\n",
      "\n",
      "Epoch:  257\n",
      "378/378 - 11s - loss: 0.0768 - accuracy: 0.9705 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0807 - accuracy: 0.9690\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0794 - accuracy: 0.9709\n",
      "\n",
      "Epoch:  258\n",
      "378/378 - 11s - loss: 0.0798 - accuracy: 0.9692 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0837 - accuracy: 0.9672\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0840 - accuracy: 0.9686\n",
      "\n",
      "Epoch:  259\n",
      "378/378 - 11s - loss: 0.0770 - accuracy: 0.9710 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0764 - accuracy: 0.9709\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0734 - accuracy: 0.9732\n",
      "\n",
      "Epoch:  260\n",
      "378/378 - 11s - loss: 0.0764 - accuracy: 0.9710 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0705 - accuracy: 0.9732\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0688 - accuracy: 0.9747\n",
      "\n",
      "Epoch:  261\n",
      "378/378 - 11s - loss: 0.0779 - accuracy: 0.9695 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0693 - accuracy: 0.9741\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0679 - accuracy: 0.9758\n",
      "\n",
      "Epoch:  262\n",
      "378/378 - 11s - loss: 0.0746 - accuracy: 0.9716 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0745 - accuracy: 0.9714\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0746 - accuracy: 0.9727\n",
      "\n",
      "Epoch:  263\n",
      "378/378 - 11s - loss: 0.0759 - accuracy: 0.9717 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0761 - accuracy: 0.9708\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0732 - accuracy: 0.9726\n",
      "\n",
      "Epoch:  264\n",
      "378/378 - 11s - loss: 0.0740 - accuracy: 0.9726 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0692 - accuracy: 0.9744\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0682 - accuracy: 0.9744\n",
      "\n",
      "Epoch:  265\n",
      "378/378 - 12s - loss: 0.0782 - accuracy: 0.9705 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1318 - accuracy: 0.9456\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1349 - accuracy: 0.9435\n",
      "\n",
      "Epoch:  266\n",
      "378/378 - 11s - loss: 0.0766 - accuracy: 0.9707 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0921 - accuracy: 0.9642\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0884 - accuracy: 0.9664\n",
      "\n",
      "Epoch:  267\n",
      "378/378 - 12s - loss: 0.0761 - accuracy: 0.9710 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0669 - accuracy: 0.9754\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0665 - accuracy: 0.9758\n",
      "\n",
      "Epoch:  268\n",
      "378/378 - 11s - loss: 0.0762 - accuracy: 0.9716 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0725 - accuracy: 0.9728\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0716 - accuracy: 0.9732\n",
      "\n",
      "Epoch:  269\n",
      "378/378 - 11s - loss: 0.0740 - accuracy: 0.9729 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0669 - accuracy: 0.9754\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0664 - accuracy: 0.9754\n",
      "\n",
      "Epoch:  270\n",
      "378/378 - 12s - loss: 0.0734 - accuracy: 0.9716 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0686 - accuracy: 0.9744\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0668 - accuracy: 0.9750\n",
      "\n",
      "Epoch:  271\n",
      "378/378 - 12s - loss: 0.0786 - accuracy: 0.9701 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0702 - accuracy: 0.9738\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0682 - accuracy: 0.9748\n",
      "\n",
      "Epoch:  272\n",
      "378/378 - 11s - loss: 0.0755 - accuracy: 0.9717 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0678 - accuracy: 0.9747\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0663 - accuracy: 0.9759\n",
      "\n",
      "Epoch:  273\n",
      "378/378 - 11s - loss: 0.0755 - accuracy: 0.9709 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0981 - accuracy: 0.9616\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0932 - accuracy: 0.9637\n",
      "\n",
      "Epoch:  274\n",
      "378/378 - 11s - loss: 0.0794 - accuracy: 0.9701 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0726 - accuracy: 0.9728\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0699 - accuracy: 0.9744\n",
      "\n",
      "Epoch:  275\n",
      "378/378 - 11s - loss: 0.0748 - accuracy: 0.9717 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0983 - accuracy: 0.9614\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0952 - accuracy: 0.9619\n",
      "\n",
      "Epoch:  276\n",
      "378/378 - 11s - loss: 0.0751 - accuracy: 0.9715 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0683 - accuracy: 0.9743\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0675 - accuracy: 0.9759\n",
      "\n",
      "Epoch:  277\n",
      "378/378 - 12s - loss: 0.0759 - accuracy: 0.9714 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0676 - accuracy: 0.9758\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0677 - accuracy: 0.9746\n",
      "\n",
      "Epoch:  278\n",
      "378/378 - 12s - loss: 0.0725 - accuracy: 0.9724 - 12s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 16s 10ms/step - loss: 0.0718 - accuracy: 0.9724\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0696 - accuracy: 0.9739\n",
      "\n",
      "Epoch:  279\n",
      "378/378 - 14s - loss: 0.0796 - accuracy: 0.9698 - 14s/epoch - 36ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0667 - accuracy: 0.9754\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0653 - accuracy: 0.9757\n",
      "\n",
      "Epoch:  280\n",
      "378/378 - 12s - loss: 0.0744 - accuracy: 0.9719 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0668 - accuracy: 0.9752\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0665 - accuracy: 0.9754\n",
      "\n",
      "Epoch:  281\n",
      "378/378 - 13s - loss: 0.0725 - accuracy: 0.9735 - 13s/epoch - 34ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0796 - accuracy: 0.9686\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0802 - accuracy: 0.9696\n",
      "\n",
      "Epoch:  282\n",
      "378/378 - 12s - loss: 0.0754 - accuracy: 0.9714 - 12s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0692 - accuracy: 0.9748\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0671 - accuracy: 0.9754\n",
      "\n",
      "Epoch:  283\n",
      "378/378 - 13s - loss: 0.0721 - accuracy: 0.9725 - 13s/epoch - 35ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0673 - accuracy: 0.9754\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0675 - accuracy: 0.9754\n",
      "\n",
      "Epoch:  284\n",
      "378/378 - 12s - loss: 0.0725 - accuracy: 0.9726 - 12s/epoch - 30ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0731 - accuracy: 0.9722\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0724 - accuracy: 0.9721\n",
      "\n",
      "Epoch:  285\n",
      "378/378 - 11s - loss: 0.0749 - accuracy: 0.9719 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0782 - accuracy: 0.9704\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0757 - accuracy: 0.9711\n",
      "\n",
      "Epoch:  286\n",
      "378/378 - 12s - loss: 0.0731 - accuracy: 0.9726 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0668 - accuracy: 0.9758\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0646 - accuracy: 0.9764\n",
      "\n",
      "Epoch:  287\n",
      "378/378 - 12s - loss: 0.0739 - accuracy: 0.9725 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0673 - accuracy: 0.9745\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0674 - accuracy: 0.9743\n",
      "\n",
      "Epoch:  288\n",
      "378/378 - 12s - loss: 0.0727 - accuracy: 0.9722 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0684 - accuracy: 0.9752\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0679 - accuracy: 0.9755\n",
      "\n",
      "Epoch:  289\n",
      "378/378 - 13s - loss: 0.0729 - accuracy: 0.9736 - 13s/epoch - 33ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0654 - accuracy: 0.9754\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0642 - accuracy: 0.9768\n",
      "\n",
      "Epoch:  290\n",
      "378/378 - 12s - loss: 0.0776 - accuracy: 0.9702 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0681 - accuracy: 0.9744\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0665 - accuracy: 0.9745\n",
      "\n",
      "Epoch:  291\n",
      "378/378 - 12s - loss: 0.0709 - accuracy: 0.9736 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0654 - accuracy: 0.9752\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0644 - accuracy: 0.9764\n",
      "\n",
      "Epoch:  292\n",
      "378/378 - 14s - loss: 0.0749 - accuracy: 0.9723 - 14s/epoch - 36ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0710 - accuracy: 0.9730\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0707 - accuracy: 0.9737\n",
      "\n",
      "Epoch:  293\n",
      "378/378 - 11s - loss: 0.0738 - accuracy: 0.9725 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0687 - accuracy: 0.9740\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0674 - accuracy: 0.9752\n",
      "\n",
      "Epoch:  294\n",
      "378/378 - 12s - loss: 0.0737 - accuracy: 0.9721 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 14s 9ms/step - loss: 0.0758 - accuracy: 0.9713\n",
      "for testing\n",
      "378/378 [==============================] - 4s 12ms/step - loss: 0.0725 - accuracy: 0.9728\n",
      "\n",
      "Epoch:  295\n",
      "378/378 - 15s - loss: 0.0747 - accuracy: 0.9717 - 15s/epoch - 39ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0653 - accuracy: 0.9761\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0655 - accuracy: 0.9754\n",
      "\n",
      "Epoch:  296\n",
      "378/378 - 13s - loss: 0.0742 - accuracy: 0.9716 - 13s/epoch - 34ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0639 - accuracy: 0.9762\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0629 - accuracy: 0.9773\n",
      "\n",
      "Epoch:  297\n",
      "378/378 - 13s - loss: 0.0706 - accuracy: 0.9739 - 13s/epoch - 35ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0659 - accuracy: 0.9761\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0657 - accuracy: 0.9758\n",
      "\n",
      "Epoch:  298\n",
      "378/378 - 12s - loss: 0.0722 - accuracy: 0.9729 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0646 - accuracy: 0.9760\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0640 - accuracy: 0.9767\n",
      "\n",
      "Epoch:  299\n",
      "378/378 - 12s - loss: 0.0707 - accuracy: 0.9727 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0981 - accuracy: 0.9605\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0995 - accuracy: 0.9600\n",
      "\n",
      "Epoch:  300\n",
      "378/378 - 12s - loss: 0.0713 - accuracy: 0.9737 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0639 - accuracy: 0.9764\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0634 - accuracy: 0.9778\n",
      "\n",
      "Epoch:  301\n",
      "378/378 - 12s - loss: 0.0747 - accuracy: 0.9710 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0744 - accuracy: 0.9719\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0746 - accuracy: 0.9726\n",
      "\n",
      "Epoch:  302\n",
      "378/378 - 12s - loss: 0.0736 - accuracy: 0.9722 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0628 - accuracy: 0.9766\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0619 - accuracy: 0.9773\n",
      "\n",
      "Epoch:  303\n",
      "378/378 - 12s - loss: 0.0713 - accuracy: 0.9737 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 8ms/step - loss: 0.0686 - accuracy: 0.9741\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0675 - accuracy: 0.9749\n",
      "\n",
      "Epoch:  304\n",
      "378/378 - 12s - loss: 0.0709 - accuracy: 0.9734 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0641 - accuracy: 0.9762\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0638 - accuracy: 0.9758\n",
      "\n",
      "Epoch:  305\n",
      "378/378 - 11s - loss: 0.0732 - accuracy: 0.9721 - 11s/epoch - 30ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.1175 - accuracy: 0.9542\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.1146 - accuracy: 0.9556\n",
      "\n",
      "Epoch:  306\n",
      "378/378 - 12s - loss: 0.0738 - accuracy: 0.9718 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0827 - accuracy: 0.9687\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0795 - accuracy: 0.9692\n",
      "\n",
      "Epoch:  307\n",
      "378/378 - 12s - loss: 0.0712 - accuracy: 0.9739 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 12s 8ms/step - loss: 0.0667 - accuracy: 0.9754\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0648 - accuracy: 0.9769\n",
      "\n",
      "Epoch:  308\n",
      "378/378 - 12s - loss: 0.0697 - accuracy: 0.9734 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0739 - accuracy: 0.9718\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0715 - accuracy: 0.9731\n",
      "\n",
      "Epoch:  309\n",
      "378/378 - 12s - loss: 0.0725 - accuracy: 0.9721 - 12s/epoch - 32ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 17s 11ms/step - loss: 0.0693 - accuracy: 0.9740\n",
      "for testing\n",
      "378/378 [==============================] - 4s 11ms/step - loss: 0.0691 - accuracy: 0.9743\n",
      "\n",
      "Epoch:  310\n",
      "378/378 - 16s - loss: 0.0699 - accuracy: 0.9732 - 16s/epoch - 42ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 13s 9ms/step - loss: 0.0689 - accuracy: 0.9735\n",
      "for testing\n",
      "378/378 [==============================] - 3s 8ms/step - loss: 0.0683 - accuracy: 0.9740\n",
      "\n",
      "Epoch:  311\n",
      "378/378 - 12s - loss: 0.0700 - accuracy: 0.9738 - 12s/epoch - 31ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 15s 10ms/step - loss: 0.0759 - accuracy: 0.9707\n",
      "for testing\n",
      "378/378 [==============================] - 3s 9ms/step - loss: 0.0773 - accuracy: 0.9710\n",
      "\n",
      "Epoch:  312\n",
      "378/378 - 12s - loss: 0.0711 - accuracy: 0.9729 - 12s/epoch - 32ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0788 - accuracy: 0.9708\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0753 - accuracy: 0.9727\n",
      "\n",
      "Epoch:  313\n",
      "378/378 - 8s - loss: 0.0735 - accuracy: 0.9726 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0636 - accuracy: 0.9761\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0628 - accuracy: 0.9771\n",
      "\n",
      "Epoch:  314\n",
      "378/378 - 8s - loss: 0.0710 - accuracy: 0.9730 - 8s/epoch - 21ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0882 - accuracy: 0.9655\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0892 - accuracy: 0.9645\n",
      "\n",
      "Epoch:  315\n",
      "378/378 - 8s - loss: 0.0684 - accuracy: 0.9740 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0632 - accuracy: 0.9765\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0622 - accuracy: 0.9763\n",
      "\n",
      "Epoch:  316\n",
      "378/378 - 8s - loss: 0.0778 - accuracy: 0.9697 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0773 - accuracy: 0.9701\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0777 - accuracy: 0.9702\n",
      "\n",
      "Epoch:  317\n",
      "378/378 - 8s - loss: 0.0713 - accuracy: 0.9729 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0622 - accuracy: 0.9771\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0615 - accuracy: 0.9783\n",
      "\n",
      "Epoch:  318\n",
      "378/378 - 8s - loss: 0.0695 - accuracy: 0.9734 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0673 - accuracy: 0.9750\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0672 - accuracy: 0.9751\n",
      "\n",
      "Epoch:  319\n",
      "378/378 - 8s - loss: 0.0711 - accuracy: 0.9727 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0664 - accuracy: 0.9753\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0672 - accuracy: 0.9750\n",
      "\n",
      "Epoch:  320\n",
      "378/378 - 8s - loss: 0.0688 - accuracy: 0.9742 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0663 - accuracy: 0.9751\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0670 - accuracy: 0.9751\n",
      "\n",
      "Epoch:  321\n",
      "378/378 - 8s - loss: 0.0694 - accuracy: 0.9741 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0614 - accuracy: 0.9775\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0606 - accuracy: 0.9782\n",
      "\n",
      "Epoch:  322\n",
      "378/378 - 8s - loss: 0.0705 - accuracy: 0.9731 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0808 - accuracy: 0.9688\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0772 - accuracy: 0.9711\n",
      "\n",
      "Epoch:  323\n",
      "378/378 - 8s - loss: 0.0716 - accuracy: 0.9729 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0884 - accuracy: 0.9648\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0899 - accuracy: 0.9652\n",
      "\n",
      "Epoch:  324\n",
      "378/378 - 9s - loss: 0.0735 - accuracy: 0.9715 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0613 - accuracy: 0.9778\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0611 - accuracy: 0.9776\n",
      "\n",
      "Epoch:  325\n",
      "378/378 - 8s - loss: 0.0709 - accuracy: 0.9732 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0715 - accuracy: 0.9725\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0724 - accuracy: 0.9732\n",
      "\n",
      "Epoch:  326\n",
      "378/378 - 9s - loss: 0.0676 - accuracy: 0.9747 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0743 - accuracy: 0.9721\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0717 - accuracy: 0.9735\n",
      "\n",
      "Epoch:  327\n",
      "378/378 - 9s - loss: 0.0698 - accuracy: 0.9732 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0810 - accuracy: 0.9686\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0780 - accuracy: 0.9704\n",
      "\n",
      "Epoch:  328\n",
      "378/378 - 9s - loss: 0.0695 - accuracy: 0.9732 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0617 - accuracy: 0.9770\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0612 - accuracy: 0.9773\n",
      "\n",
      "Epoch:  329\n",
      "378/378 - 8s - loss: 0.0679 - accuracy: 0.9745 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0629 - accuracy: 0.9768\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0631 - accuracy: 0.9761\n",
      "\n",
      "Epoch:  330\n",
      "378/378 - 9s - loss: 0.0682 - accuracy: 0.9742 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0623 - accuracy: 0.9767\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0614 - accuracy: 0.9772\n",
      "\n",
      "Epoch:  331\n",
      "378/378 - 8s - loss: 0.0685 - accuracy: 0.9737 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0827 - accuracy: 0.9674\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0835 - accuracy: 0.9672\n",
      "\n",
      "Epoch:  332\n",
      "378/378 - 8s - loss: 0.0721 - accuracy: 0.9728 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0613 - accuracy: 0.9778\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0609 - accuracy: 0.9787\n",
      "\n",
      "Epoch:  333\n",
      "378/378 - 8s - loss: 0.0676 - accuracy: 0.9745 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0696 - accuracy: 0.9737\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0673 - accuracy: 0.9750\n",
      "\n",
      "Epoch:  334\n",
      "378/378 - 9s - loss: 0.0707 - accuracy: 0.9732 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0677 - accuracy: 0.9746\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0667 - accuracy: 0.9750\n",
      "\n",
      "Epoch:  335\n",
      "378/378 - 8s - loss: 0.0673 - accuracy: 0.9748 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0640 - accuracy: 0.9760\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0628 - accuracy: 0.9773\n",
      "\n",
      "Epoch:  336\n",
      "378/378 - 8s - loss: 0.0727 - accuracy: 0.9718 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0608 - accuracy: 0.9780\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0609 - accuracy: 0.9777\n",
      "\n",
      "Epoch:  337\n",
      "378/378 - 8s - loss: 0.0705 - accuracy: 0.9733 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0652 - accuracy: 0.9757\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0634 - accuracy: 0.9763\n",
      "\n",
      "Epoch:  338\n",
      "378/378 - 8s - loss: 0.0697 - accuracy: 0.9739 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0630 - accuracy: 0.9762\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0615 - accuracy: 0.9779\n",
      "\n",
      "Epoch:  339\n",
      "378/378 - 8s - loss: 0.0680 - accuracy: 0.9748 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0655 - accuracy: 0.9752\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0651 - accuracy: 0.9762\n",
      "\n",
      "Epoch:  340\n",
      "378/378 - 9s - loss: 0.0718 - accuracy: 0.9731 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0714 - accuracy: 0.9726\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0705 - accuracy: 0.9735\n",
      "\n",
      "Epoch:  341\n",
      "378/378 - 8s - loss: 0.0670 - accuracy: 0.9748 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0637 - accuracy: 0.9762\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0645 - accuracy: 0.9759\n",
      "\n",
      "Epoch:  342\n",
      "378/378 - 8s - loss: 0.0688 - accuracy: 0.9747 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0681 - accuracy: 0.9741\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0678 - accuracy: 0.9757\n",
      "\n",
      "Epoch:  343\n",
      "378/378 - 8s - loss: 0.0678 - accuracy: 0.9746 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0995 - accuracy: 0.9597\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.1008 - accuracy: 0.9606\n",
      "\n",
      "Epoch:  344\n",
      "378/378 - 8s - loss: 0.0690 - accuracy: 0.9738 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0615 - accuracy: 0.9776\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0615 - accuracy: 0.9774\n",
      "\n",
      "Epoch:  345\n",
      "378/378 - 8s - loss: 0.0699 - accuracy: 0.9743 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0776 - accuracy: 0.9695\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0797 - accuracy: 0.9686\n",
      "\n",
      "Epoch:  346\n",
      "378/378 - 8s - loss: 0.0658 - accuracy: 0.9751 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0902 - accuracy: 0.9661\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0862 - accuracy: 0.9677\n",
      "\n",
      "Epoch:  347\n",
      "378/378 - 8s - loss: 0.0651 - accuracy: 0.9763 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0662 - accuracy: 0.9746\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0651 - accuracy: 0.9765\n",
      "\n",
      "Epoch:  348\n",
      "378/378 - 8s - loss: 0.0683 - accuracy: 0.9739 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0594 - accuracy: 0.9782\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0594 - accuracy: 0.9781\n",
      "\n",
      "Epoch:  349\n",
      "378/378 - 8s - loss: 0.0688 - accuracy: 0.9740 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0599 - accuracy: 0.9778\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0594 - accuracy: 0.9790\n",
      "\n",
      "Epoch:  350\n",
      "378/378 - 8s - loss: 0.0686 - accuracy: 0.9736 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0757 - accuracy: 0.9710\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0770 - accuracy: 0.9705\n",
      "\n",
      "Epoch:  351\n",
      "378/378 - 8s - loss: 0.0737 - accuracy: 0.9721 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0678 - accuracy: 0.9738\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0673 - accuracy: 0.9748\n",
      "\n",
      "Epoch:  352\n",
      "378/378 - 8s - loss: 0.0662 - accuracy: 0.9749 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 6s 4ms/step - loss: 0.0596 - accuracy: 0.9778\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0592 - accuracy: 0.9780\n",
      "\n",
      "Epoch:  353\n",
      "378/378 - 8s - loss: 0.0679 - accuracy: 0.9740 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0966 - accuracy: 0.9607\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0977 - accuracy: 0.9607\n",
      "\n",
      "Epoch:  354\n",
      "378/378 - 8s - loss: 0.0699 - accuracy: 0.9734 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0795 - accuracy: 0.9693\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0763 - accuracy: 0.9707\n",
      "\n",
      "Epoch:  355\n",
      "378/378 - 9s - loss: 0.0672 - accuracy: 0.9746 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0616 - accuracy: 0.9768\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0602 - accuracy: 0.9779\n",
      "\n",
      "Epoch:  356\n",
      "378/378 - 8s - loss: 0.0666 - accuracy: 0.9753 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0955 - accuracy: 0.9623\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0960 - accuracy: 0.9635\n",
      "\n",
      "Epoch:  357\n",
      "378/378 - 9s - loss: 0.0683 - accuracy: 0.9745 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0608 - accuracy: 0.9777\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0613 - accuracy: 0.9767\n",
      "\n",
      "Epoch:  358\n",
      "378/378 - 9s - loss: 0.0657 - accuracy: 0.9752 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0680 - accuracy: 0.9739\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0662 - accuracy: 0.9761\n",
      "\n",
      "Epoch:  359\n",
      "378/378 - 9s - loss: 0.0680 - accuracy: 0.9739 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0636 - accuracy: 0.9762\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0639 - accuracy: 0.9753\n",
      "\n",
      "Epoch:  360\n",
      "378/378 - 9s - loss: 0.0671 - accuracy: 0.9743 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 9s 6ms/step - loss: 0.0613 - accuracy: 0.9768\n",
      "for testing\n",
      "378/378 [==============================] - 4s 10ms/step - loss: 0.0612 - accuracy: 0.9779\n",
      "\n",
      "Epoch:  361\n",
      "378/378 - 9s - loss: 0.0676 - accuracy: 0.9745 - 9s/epoch - 25ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0599 - accuracy: 0.9781\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0585 - accuracy: 0.9791\n",
      "\n",
      "Epoch:  362\n",
      "378/378 - 9s - loss: 0.0652 - accuracy: 0.9756 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0610 - accuracy: 0.9773\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0615 - accuracy: 0.9774\n",
      "\n",
      "Epoch:  363\n",
      "378/378 - 9s - loss: 0.0664 - accuracy: 0.9746 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0587 - accuracy: 0.9785\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0584 - accuracy: 0.9783\n",
      "\n",
      "Epoch:  364\n",
      "378/378 - 9s - loss: 0.0681 - accuracy: 0.9741 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0646 - accuracy: 0.9769\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0653 - accuracy: 0.9744\n",
      "\n",
      "Epoch:  365\n",
      "378/378 - 9s - loss: 0.0657 - accuracy: 0.9753 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0595 - accuracy: 0.9787\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0599 - accuracy: 0.9776\n",
      "\n",
      "Epoch:  366\n",
      "378/378 - 9s - loss: 0.0663 - accuracy: 0.9755 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0577 - accuracy: 0.9788\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0579 - accuracy: 0.9788\n",
      "\n",
      "Epoch:  367\n",
      "378/378 - 9s - loss: 0.0641 - accuracy: 0.9765 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0676 - accuracy: 0.9743\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0661 - accuracy: 0.9754\n",
      "\n",
      "Epoch:  368\n",
      "378/378 - 9s - loss: 0.0651 - accuracy: 0.9758 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0593 - accuracy: 0.9782\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0589 - accuracy: 0.9788\n",
      "\n",
      "Epoch:  369\n",
      "378/378 - 9s - loss: 0.0675 - accuracy: 0.9743 - 9s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0619 - accuracy: 0.9769\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0614 - accuracy: 0.9777\n",
      "\n",
      "Epoch:  370\n",
      "378/378 - 9s - loss: 0.0646 - accuracy: 0.9753 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0591 - accuracy: 0.9778\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0585 - accuracy: 0.9795\n",
      "\n",
      "Epoch:  371\n",
      "378/378 - 8s - loss: 0.0678 - accuracy: 0.9745 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0586 - accuracy: 0.9790\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0587 - accuracy: 0.9782\n",
      "\n",
      "Epoch:  372\n",
      "378/378 - 9s - loss: 0.0648 - accuracy: 0.9758 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0741 - accuracy: 0.9708\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0751 - accuracy: 0.9722\n",
      "\n",
      "Epoch:  373\n",
      "378/378 - 9s - loss: 0.0674 - accuracy: 0.9743 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0692 - accuracy: 0.9735\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0700 - accuracy: 0.9746\n",
      "\n",
      "Epoch:  374\n",
      "378/378 - 8s - loss: 0.0654 - accuracy: 0.9755 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0842 - accuracy: 0.9659\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0864 - accuracy: 0.9659\n",
      "\n",
      "Epoch:  375\n",
      "378/378 - 9s - loss: 0.0629 - accuracy: 0.9765 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0594 - accuracy: 0.9779\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0592 - accuracy: 0.9801\n",
      "\n",
      "Epoch:  376\n",
      "378/378 - 9s - loss: 0.0648 - accuracy: 0.9757 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0938 - accuracy: 0.9636\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0910 - accuracy: 0.9645\n",
      "\n",
      "Epoch:  377\n",
      "378/378 - 9s - loss: 0.0678 - accuracy: 0.9745 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0576 - accuracy: 0.9787\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0580 - accuracy: 0.9782\n",
      "\n",
      "Epoch:  378\n",
      "378/378 - 9s - loss: 0.0665 - accuracy: 0.9754 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0667 - accuracy: 0.9746\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0658 - accuracy: 0.9769\n",
      "\n",
      "Epoch:  379\n",
      "378/378 - 9s - loss: 0.0631 - accuracy: 0.9765 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0605 - accuracy: 0.9772\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0604 - accuracy: 0.9779\n",
      "\n",
      "Epoch:  380\n",
      "378/378 - 9s - loss: 0.0649 - accuracy: 0.9757 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0627 - accuracy: 0.9767\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0633 - accuracy: 0.9759\n",
      "\n",
      "Epoch:  381\n",
      "378/378 - 9s - loss: 0.0674 - accuracy: 0.9741 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0633 - accuracy: 0.9754\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0634 - accuracy: 0.9756\n",
      "\n",
      "Epoch:  382\n",
      "378/378 - 9s - loss: 0.0652 - accuracy: 0.9752 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0711 - accuracy: 0.9727\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0702 - accuracy: 0.9743\n",
      "\n",
      "Epoch:  383\n",
      "378/378 - 9s - loss: 0.0642 - accuracy: 0.9757 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0736 - accuracy: 0.9715\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0714 - accuracy: 0.9730\n",
      "\n",
      "Epoch:  384\n",
      "378/378 - 9s - loss: 0.0675 - accuracy: 0.9743 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0641 - accuracy: 0.9753\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0638 - accuracy: 0.9764\n",
      "\n",
      "Epoch:  385\n",
      "378/378 - 9s - loss: 0.0636 - accuracy: 0.9758 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0645 - accuracy: 0.9757\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0654 - accuracy: 0.9749\n",
      "\n",
      "Epoch:  386\n",
      "378/378 - 8s - loss: 0.0642 - accuracy: 0.9755 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0577 - accuracy: 0.9786\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0574 - accuracy: 0.9785\n",
      "\n",
      "Epoch:  387\n",
      "378/378 - 8s - loss: 0.0675 - accuracy: 0.9748 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0744 - accuracy: 0.9713\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0735 - accuracy: 0.9726\n",
      "\n",
      "Epoch:  388\n",
      "378/378 - 9s - loss: 0.0675 - accuracy: 0.9747 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0782 - accuracy: 0.9697\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0767 - accuracy: 0.9711\n",
      "\n",
      "Epoch:  389\n",
      "378/378 - 9s - loss: 0.0633 - accuracy: 0.9761 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0677 - accuracy: 0.9737\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0669 - accuracy: 0.9755\n",
      "\n",
      "Epoch:  390\n",
      "378/378 - 8s - loss: 0.0653 - accuracy: 0.9744 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0636 - accuracy: 0.9761\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0627 - accuracy: 0.9768\n",
      "\n",
      "Epoch:  391\n",
      "378/378 - 9s - loss: 0.0648 - accuracy: 0.9754 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0586 - accuracy: 0.9786\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0581 - accuracy: 0.9785\n",
      "\n",
      "Epoch:  392\n",
      "378/378 - 8s - loss: 0.0660 - accuracy: 0.9749 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0588 - accuracy: 0.9787\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0590 - accuracy: 0.9783\n",
      "\n",
      "Epoch:  393\n",
      "378/378 - 8s - loss: 0.0629 - accuracy: 0.9766 - 8s/epoch - 22ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0770 - accuracy: 0.9711\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0738 - accuracy: 0.9725\n",
      "\n",
      "Epoch:  394\n",
      "378/378 - 9s - loss: 0.0619 - accuracy: 0.9772 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0636 - accuracy: 0.9756\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0651 - accuracy: 0.9771\n",
      "\n",
      "Epoch:  395\n",
      "378/378 - 9s - loss: 0.0627 - accuracy: 0.9769 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0577 - accuracy: 0.9787\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0580 - accuracy: 0.9784\n",
      "\n",
      "Epoch:  396\n",
      "378/378 - 9s - loss: 0.0627 - accuracy: 0.9761 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 5ms/step - loss: 0.0644 - accuracy: 0.9759\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0640 - accuracy: 0.9764\n",
      "\n",
      "Epoch:  397\n",
      "378/378 - 9s - loss: 0.0631 - accuracy: 0.9759 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0595 - accuracy: 0.9777\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0594 - accuracy: 0.9778\n",
      "\n",
      "Epoch:  398\n",
      "378/378 - 9s - loss: 0.0638 - accuracy: 0.9758 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0582 - accuracy: 0.9784\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0579 - accuracy: 0.9799\n",
      "\n",
      "Epoch:  399\n",
      "378/378 - 9s - loss: 0.0632 - accuracy: 0.9761 - 9s/epoch - 23ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0553 - accuracy: 0.9801\n",
      "for testing\n",
      "378/378 [==============================] - 2s 4ms/step - loss: 0.0548 - accuracy: 0.9798\n",
      "\n",
      "Epoch:  400\n",
      "378/378 - 9s - loss: 0.0626 - accuracy: 0.9764 - 9s/epoch - 24ms/step\n",
      "for training\n",
      "1512/1512 [==============================] - 7s 4ms/step - loss: 0.0555 - accuracy: 0.9796\n",
      "for testing\n",
      "378/378 [==============================] - 2s 5ms/step - loss: 0.0566 - accuracy: 0.9783\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for x in range(400):\n",
    "    print(\"\\nEpoch: \",x+1)\n",
    "    history = model.fit(X_train ,y_train ,batch_size=BATCH_SIZE ,epochs=1, verbose=2, shuffle=True)\n",
    "    if history_dataframe.size == 0:\n",
    "        history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    else:\n",
    "        history_dataframe = pd.concat([history_dataframe,pd.DataFrame.from_dict(history.history)],axis=0,ignore_index=True)\n",
    "    \n",
    "    print(\"for training\")\n",
    "    train_eva.append(model.evaluate(X_train,y_train))\n",
    "    print(\"for testing\")\n",
    "    test_eva.append(model.evaluate(X_test, y_test))\n",
    "    \n",
    "#     clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ec37c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.647243</td>\n",
       "      <td>0.612041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.530980</td>\n",
       "      <td>0.744192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.446708</td>\n",
       "      <td>0.795118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.396233</td>\n",
       "      <td>0.822958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.355914</td>\n",
       "      <td>0.845321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.062748</td>\n",
       "      <td>0.976128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.063072</td>\n",
       "      <td>0.975860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.063788</td>\n",
       "      <td>0.975839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.063166</td>\n",
       "      <td>0.976087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.062557</td>\n",
       "      <td>0.976438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy\n",
       "0    0.647243  0.612041\n",
       "1    0.530980  0.744192\n",
       "2    0.446708  0.795118\n",
       "3    0.396233  0.822958\n",
       "4    0.355914  0.845321\n",
       "..        ...       ...\n",
       "395  0.062748  0.976128\n",
       "396  0.063072  0.975860\n",
       "397  0.063788  0.975839\n",
       "398  0.063166  0.976087\n",
       "399  0.062557  0.976438\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c8463e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva_df = pd.DataFrame(train_eva,columns=['loss','accuracy'])\n",
    "test_eva_df = pd.DataFrame(test_eva,columns=['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cc95506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(df,title,xlabel,ylabel,values=['loss'],legends=[]):\n",
    "    \n",
    "    for value in values:\n",
    "        epoch_count = range(1, len(df.index) + 1)\n",
    "        plt.plot(epoch_count, df[value].tolist())\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    if legends==[]:\n",
    "        legends = values\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35c781fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(train_eva_df,'Train','Epoch','Loss',['loss','accuracy'])\n",
    "plot_graph(test_eva_df,'Test','Epoch','Loss',['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e98088e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
