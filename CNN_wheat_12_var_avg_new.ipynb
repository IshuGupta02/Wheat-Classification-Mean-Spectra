{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c4fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35daa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6aebd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'wheat_12_var_avg_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "554bc6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class filter_method(Enum):\n",
    "    none = 0\n",
    "    snv = 1\n",
    "    msc = 2\n",
    "    savgol = 3\n",
    "\n",
    "FILT = 2\n",
    "FILTER = filter_method(FILT).name\n",
    "\n",
    "# to be set if filter chosen is savgol\n",
    "WINDOW = 7\n",
    "ORDER = 2\n",
    "DERIVATIVE = 1\n",
    "\n",
    "#will be used for test dataset in msc\n",
    "reference= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76302420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_file_name(file_name):\n",
    "    name = \"./dataset/\"+str(file_name)\n",
    "    if FILT != 0:\n",
    "        name+=\"_FILTER_\"+str(FILTER)\n",
    "    if FILTER == \"savgol\":\n",
    "        name+=\"_WINDOW_\"+str(WINDOW)+\"_ORDER_\"+str(ORDER)+\"_DERIVATIVE_\"+str(DERIVATIVE)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "810bdbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILE_NAME = dataset_file_name(file_name)\n",
    "X_train_file = DATASET_FILE_NAME+\"_train_dataset.npy\"\n",
    "y_train_file = DATASET_FILE_NAME+\"_train_dataset_label.npy\"\n",
    "X_test_file = DATASET_FILE_NAME+\"_test_dataset.npy\"\n",
    "y_test_file = DATASET_FILE_NAME+\"_test_dataset_label.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8dec1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =  np.load(X_train_file)\n",
    "y_train =  np.load(y_train_file)\n",
    "X_test  =  np.load(X_test_file)\n",
    "y_test  =  np.load(y_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58535347",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_set = set(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e8c8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_CLASSES = len(y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e1e570e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19353, 147, 1)\n",
      "(4839, 147, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec820add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Input, Conv1D, Flatten, Dense, MaxPooling1D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba682707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(input_shape,num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=5, input_shape=input_shape,activation='LeakyReLU'))\n",
    "    model.add(MaxPooling1D(pool_size=5 ))\n",
    "    model.add(Conv1D(filters=64, kernel_size=5, activation='LeakyReLU'))\n",
    "    model.add(MaxPooling1D(pool_size=5 ))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(800, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(400, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d95ace51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(X_train.shape[1:],NUM_OF_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33a0377c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 143, 32)           192       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 28, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 24, 64)            10304     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 4, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              257000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 800)               800800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 400)               320400    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 1604      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,390,300\n",
      "Trainable params: 1,390,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20cd1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva = []\n",
    "test_eva = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fd5eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dataframe = pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "863f63f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  1\n",
      "152/152 - 7s - loss: 1.3867 - accuracy: 0.2523 - 7s/epoch - 43ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 5ms/step - loss: 1.3864 - accuracy: 0.2511\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3865 - accuracy: 0.2455\n",
      "\n",
      "Epoch:  2\n",
      "152/152 - 5s - loss: 1.3856 - accuracy: 0.2591 - 5s/epoch - 34ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 1.3689 - accuracy: 0.2747\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.3712 - accuracy: 0.2724\n",
      "\n",
      "Epoch:  3\n",
      "152/152 - 5s - loss: 1.3472 - accuracy: 0.3254 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 1.2905 - accuracy: 0.3938\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.2869 - accuracy: 0.4030\n",
      "\n",
      "Epoch:  4\n",
      "152/152 - 5s - loss: 1.3007 - accuracy: 0.3721 - 5s/epoch - 34ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 1.3069 - accuracy: 0.3516\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 1.2912 - accuracy: 0.3614\n",
      "\n",
      "Epoch:  5\n",
      "152/152 - 5s - loss: 1.2706 - accuracy: 0.3935 - 5s/epoch - 34ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 1.2697 - accuracy: 0.3866\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.2547 - accuracy: 0.3974\n",
      "\n",
      "Epoch:  6\n",
      "152/152 - 5s - loss: 1.2509 - accuracy: 0.4052 - 5s/epoch - 34ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 1.2614 - accuracy: 0.4227\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.2549 - accuracy: 0.4259\n",
      "\n",
      "Epoch:  7\n",
      "152/152 - 5s - loss: 1.1957 - accuracy: 0.4480 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 1.1843 - accuracy: 0.4491\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 1.1767 - accuracy: 0.4486\n",
      "\n",
      "Epoch:  8\n",
      "152/152 - 5s - loss: 1.1719 - accuracy: 0.4635 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 1.1702 - accuracy: 0.4622\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.1622 - accuracy: 0.4629\n",
      "\n",
      "Epoch:  9\n",
      "152/152 - 5s - loss: 1.1275 - accuracy: 0.4832 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 1.0916 - accuracy: 0.5049\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.0874 - accuracy: 0.5115\n",
      "\n",
      "Epoch:  10\n",
      "152/152 - 5s - loss: 1.0755 - accuracy: 0.5134 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 1.1378 - accuracy: 0.4733\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.1137 - accuracy: 0.4790\n",
      "\n",
      "Epoch:  11\n",
      "152/152 - 6s - loss: 1.0181 - accuracy: 0.5495 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 1.0276 - accuracy: 0.5349\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 1.0279 - accuracy: 0.5418\n",
      "\n",
      "Epoch:  12\n",
      "152/152 - 6s - loss: 0.9177 - accuracy: 0.6003 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.7475 - accuracy: 0.6835\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.7327 - accuracy: 0.6923\n",
      "\n",
      "Epoch:  13\n",
      "152/152 - 5s - loss: 0.8561 - accuracy: 0.6306 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.6910 - accuracy: 0.7076\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.6872 - accuracy: 0.7142\n",
      "\n",
      "Epoch:  14\n",
      "152/152 - 5s - loss: 0.7974 - accuracy: 0.6589 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.6950 - accuracy: 0.7088\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.6988 - accuracy: 0.7094\n",
      "\n",
      "Epoch:  15\n",
      "152/152 - 5s - loss: 0.7179 - accuracy: 0.6994 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.6107 - accuracy: 0.7424\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.6108 - accuracy: 0.7433\n",
      "\n",
      "Epoch:  16\n",
      "152/152 - 5s - loss: 0.6937 - accuracy: 0.7073 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.5437 - accuracy: 0.7959\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.5418 - accuracy: 0.7987\n",
      "\n",
      "Epoch:  17\n",
      "152/152 - 5s - loss: 0.6544 - accuracy: 0.7244 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.5109 - accuracy: 0.8012\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.5160 - accuracy: 0.7993\n",
      "\n",
      "Epoch:  18\n",
      "152/152 - 5s - loss: 0.6210 - accuracy: 0.7387 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.4886 - accuracy: 0.7953\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4875 - accuracy: 0.7940\n",
      "\n",
      "Epoch:  19\n",
      "152/152 - 5s - loss: 0.5997 - accuracy: 0.7537 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.4334 - accuracy: 0.8380\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4311 - accuracy: 0.8359\n",
      "\n",
      "Epoch:  20\n",
      "152/152 - 5s - loss: 0.5728 - accuracy: 0.7650 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.4143 - accuracy: 0.8448\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4138 - accuracy: 0.8415\n",
      "\n",
      "Epoch:  21\n",
      "152/152 - 5s - loss: 0.5359 - accuracy: 0.7796 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.4316 - accuracy: 0.8251\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.4341 - accuracy: 0.8225\n",
      "\n",
      "Epoch:  22\n",
      "152/152 - 5s - loss: 0.5353 - accuracy: 0.7829 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.4903 - accuracy: 0.8010\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4899 - accuracy: 0.7981\n",
      "\n",
      "Epoch:  23\n",
      "152/152 - 5s - loss: 0.5244 - accuracy: 0.7875 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.3488 - accuracy: 0.8752\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.3480 - accuracy: 0.8756\n",
      "\n",
      "Epoch:  24\n",
      "152/152 - 5s - loss: 0.5033 - accuracy: 0.7942 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.3754 - accuracy: 0.8600\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.3741 - accuracy: 0.8626\n",
      "\n",
      "Epoch:  25\n",
      "152/152 - 5s - loss: 0.5069 - accuracy: 0.7938 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.4093 - accuracy: 0.8474\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.4072 - accuracy: 0.8491\n",
      "\n",
      "Epoch:  26\n",
      "152/152 - 5s - loss: 0.4745 - accuracy: 0.8063 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.3415 - accuracy: 0.8720\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.3454 - accuracy: 0.8717\n",
      "\n",
      "Epoch:  27\n",
      "152/152 - 5s - loss: 0.4874 - accuracy: 0.8034 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.3846 - accuracy: 0.8579\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.3830 - accuracy: 0.8549\n",
      "\n",
      "Epoch:  28\n",
      "152/152 - 5s - loss: 0.4555 - accuracy: 0.8161 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.4273 - accuracy: 0.8233\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.4195 - accuracy: 0.8241\n",
      "\n",
      "Epoch:  29\n",
      "152/152 - 5s - loss: 0.4548 - accuracy: 0.8136 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.3270 - accuracy: 0.8789\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.3236 - accuracy: 0.8803\n",
      "\n",
      "Epoch:  30\n",
      "152/152 - 5s - loss: 0.4572 - accuracy: 0.8158 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.3219 - accuracy: 0.8831\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.3224 - accuracy: 0.8845\n",
      "\n",
      "Epoch:  31\n",
      "152/152 - 5s - loss: 0.4397 - accuracy: 0.8231 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.4065 - accuracy: 0.8386\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.4078 - accuracy: 0.8330\n",
      "\n",
      "Epoch:  32\n",
      "152/152 - 5s - loss: 0.4449 - accuracy: 0.8216 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.3123 - accuracy: 0.8884\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.3159 - accuracy: 0.8822\n",
      "\n",
      "Epoch:  33\n",
      "152/152 - 5s - loss: 0.4247 - accuracy: 0.8285 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.3007 - accuracy: 0.8857\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.2972 - accuracy: 0.8868\n",
      "\n",
      "Epoch:  34\n",
      "152/152 - 5s - loss: 0.4264 - accuracy: 0.8315 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.2948 - accuracy: 0.8898\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2925 - accuracy: 0.8909\n",
      "\n",
      "Epoch:  35\n",
      "152/152 - 5s - loss: 0.4335 - accuracy: 0.8260 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.3173 - accuracy: 0.8763\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.3240 - accuracy: 0.8717\n",
      "\n",
      "Epoch:  36\n",
      "152/152 - 5s - loss: 0.4239 - accuracy: 0.8318 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2922 - accuracy: 0.8908\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2915 - accuracy: 0.8905\n",
      "\n",
      "Epoch:  37\n",
      "152/152 - 5s - loss: 0.4088 - accuracy: 0.8351 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.3035 - accuracy: 0.8847\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.3065 - accuracy: 0.8816\n",
      "\n",
      "Epoch:  38\n",
      "152/152 - 5s - loss: 0.4119 - accuracy: 0.8356 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2716 - accuracy: 0.9039\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2710 - accuracy: 0.9043\n",
      "\n",
      "Epoch:  39\n",
      "152/152 - 5s - loss: 0.4035 - accuracy: 0.8386 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2619 - accuracy: 0.9108\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2590 - accuracy: 0.9109\n",
      "\n",
      "Epoch:  40\n",
      "152/152 - 5s - loss: 0.3951 - accuracy: 0.8416 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.3010 - accuracy: 0.8841\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.3106 - accuracy: 0.8768\n",
      "\n",
      "Epoch:  41\n",
      "152/152 - 5s - loss: 0.4001 - accuracy: 0.8404 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.2579 - accuracy: 0.9064\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2562 - accuracy: 0.9113\n",
      "\n",
      "Epoch:  42\n",
      "152/152 - 6s - loss: 0.4021 - accuracy: 0.8392 - 6s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2793 - accuracy: 0.8985\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2782 - accuracy: 0.8979\n",
      "\n",
      "Epoch:  43\n",
      "152/152 - 5s - loss: 0.3930 - accuracy: 0.8424 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2833 - accuracy: 0.8920\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2848 - accuracy: 0.8917\n",
      "\n",
      "Epoch:  44\n",
      "152/152 - 5s - loss: 0.3832 - accuracy: 0.8496 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2478 - accuracy: 0.9139\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2472 - accuracy: 0.9130\n",
      "\n",
      "Epoch:  45\n",
      "152/152 - 5s - loss: 0.3698 - accuracy: 0.8550 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2750 - accuracy: 0.8964\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2784 - accuracy: 0.8958\n",
      "\n",
      "Epoch:  46\n",
      "152/152 - 5s - loss: 0.3840 - accuracy: 0.8462 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2434 - accuracy: 0.9095\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2431 - accuracy: 0.9085\n",
      "\n",
      "Epoch:  47\n",
      "152/152 - 5s - loss: 0.3847 - accuracy: 0.8475 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2549 - accuracy: 0.9100\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.2602 - accuracy: 0.9074\n",
      "\n",
      "Epoch:  48\n",
      "152/152 - 5s - loss: 0.3833 - accuracy: 0.8471 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.3033 - accuracy: 0.8782\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.3060 - accuracy: 0.8737\n",
      "\n",
      "Epoch:  49\n",
      "152/152 - 5s - loss: 0.3663 - accuracy: 0.8526 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2733 - accuracy: 0.8933\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2680 - accuracy: 0.8985\n",
      "\n",
      "Epoch:  50\n",
      "152/152 - 6s - loss: 0.3809 - accuracy: 0.8494 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.3080 - accuracy: 0.8768\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.3062 - accuracy: 0.8793\n",
      "\n",
      "Epoch:  51\n",
      "152/152 - 6s - loss: 0.3657 - accuracy: 0.8541 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.2711 - accuracy: 0.8938\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2664 - accuracy: 0.8954\n",
      "\n",
      "Epoch:  52\n",
      "152/152 - 6s - loss: 0.3538 - accuracy: 0.8596 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.2829 - accuracy: 0.8820\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2888 - accuracy: 0.8789\n",
      "\n",
      "Epoch:  53\n",
      "152/152 - 6s - loss: 0.3557 - accuracy: 0.8576 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.2487 - accuracy: 0.9058\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2499 - accuracy: 0.9060\n",
      "\n",
      "Epoch:  54\n",
      "152/152 - 6s - loss: 0.3740 - accuracy: 0.8534 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.3005 - accuracy: 0.8792\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2985 - accuracy: 0.8841\n",
      "\n",
      "Epoch:  55\n",
      "152/152 - 6s - loss: 0.3519 - accuracy: 0.8617 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.2613 - accuracy: 0.8992\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2565 - accuracy: 0.9018\n",
      "\n",
      "Epoch:  56\n",
      "152/152 - 5s - loss: 0.3501 - accuracy: 0.8596 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.2737 - accuracy: 0.9031\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2761 - accuracy: 0.8989\n",
      "\n",
      "Epoch:  57\n",
      "152/152 - 5s - loss: 0.3629 - accuracy: 0.8541 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2361 - accuracy: 0.9063\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2348 - accuracy: 0.9111\n",
      "\n",
      "Epoch:  58\n",
      "152/152 - 5s - loss: 0.3453 - accuracy: 0.8632 - 5s/epoch - 35ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 5ms/step - loss: 0.1995 - accuracy: 0.9312\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.1992 - accuracy: 0.9316\n",
      "\n",
      "Epoch:  59\n",
      "152/152 - 5s - loss: 0.3413 - accuracy: 0.8637 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.2484 - accuracy: 0.9067\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.2483 - accuracy: 0.9051\n",
      "\n",
      "Epoch:  60\n",
      "152/152 - 5s - loss: 0.3384 - accuracy: 0.8685 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.2683 - accuracy: 0.8919\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.2666 - accuracy: 0.8954\n",
      "\n",
      "Epoch:  61\n",
      "152/152 - 5s - loss: 0.3556 - accuracy: 0.8590 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.2696 - accuracy: 0.8957\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2645 - accuracy: 0.8977\n",
      "\n",
      "Epoch:  62\n",
      "152/152 - 5s - loss: 0.3461 - accuracy: 0.8637 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2075 - accuracy: 0.9270\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.2087 - accuracy: 0.9258\n",
      "\n",
      "Epoch:  63\n",
      "152/152 - 5s - loss: 0.3302 - accuracy: 0.8714 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.2324 - accuracy: 0.9090\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2369 - accuracy: 0.9068\n",
      "\n",
      "Epoch:  64\n",
      "152/152 - 5s - loss: 0.3242 - accuracy: 0.8718 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2232 - accuracy: 0.9210\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.2280 - accuracy: 0.9184\n",
      "\n",
      "Epoch:  65\n",
      "152/152 - 5s - loss: 0.3227 - accuracy: 0.8738 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2141 - accuracy: 0.9248\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2196 - accuracy: 0.9221\n",
      "\n",
      "Epoch:  66\n",
      "152/152 - 5s - loss: 0.3454 - accuracy: 0.8614 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2331 - accuracy: 0.9083\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.2322 - accuracy: 0.9089\n",
      "\n",
      "Epoch:  67\n",
      "152/152 - 5s - loss: 0.3220 - accuracy: 0.8740 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1900 - accuracy: 0.9319\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.1911 - accuracy: 0.9328\n",
      "\n",
      "Epoch:  68\n",
      "152/152 - 5s - loss: 0.3184 - accuracy: 0.8736 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2139 - accuracy: 0.9224\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2156 - accuracy: 0.9198\n",
      "\n",
      "Epoch:  69\n",
      "152/152 - 5s - loss: 0.3229 - accuracy: 0.8731 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2696 - accuracy: 0.8914\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2672 - accuracy: 0.8936\n",
      "\n",
      "Epoch:  70\n",
      "152/152 - 5s - loss: 0.3237 - accuracy: 0.8730 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1780 - accuracy: 0.9376\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1833 - accuracy: 0.9335\n",
      "\n",
      "Epoch:  71\n",
      "152/152 - 5s - loss: 0.3140 - accuracy: 0.8758 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1834 - accuracy: 0.9322\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1868 - accuracy: 0.9366\n",
      "\n",
      "Epoch:  72\n",
      "152/152 - 6s - loss: 0.3288 - accuracy: 0.8707 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2336 - accuracy: 0.9097\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2376 - accuracy: 0.9082\n",
      "\n",
      "Epoch:  73\n",
      "152/152 - 5s - loss: 0.3086 - accuracy: 0.8793 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2410 - accuracy: 0.9040\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.2492 - accuracy: 0.9047\n",
      "\n",
      "Epoch:  74\n",
      "152/152 - 5s - loss: 0.3213 - accuracy: 0.8741 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2004 - accuracy: 0.9242\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2018 - accuracy: 0.9233\n",
      "\n",
      "Epoch:  75\n",
      "152/152 - 5s - loss: 0.3216 - accuracy: 0.8736 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1957 - accuracy: 0.9301\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.1962 - accuracy: 0.9279\n",
      "\n",
      "Epoch:  76\n",
      "152/152 - 5s - loss: 0.3046 - accuracy: 0.8785 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2213 - accuracy: 0.9206\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2224 - accuracy: 0.9186\n",
      "\n",
      "Epoch:  77\n",
      "152/152 - 5s - loss: 0.3139 - accuracy: 0.8782 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1764 - accuracy: 0.9398\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1782 - accuracy: 0.9366\n",
      "\n",
      "Epoch:  78\n",
      "152/152 - 5s - loss: 0.3023 - accuracy: 0.8822 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1747 - accuracy: 0.9387\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1773 - accuracy: 0.9351\n",
      "\n",
      "Epoch:  79\n",
      "152/152 - 5s - loss: 0.2952 - accuracy: 0.8833 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1909 - accuracy: 0.9271\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1961 - accuracy: 0.9242\n",
      "\n",
      "Epoch:  80\n",
      "152/152 - 5s - loss: 0.3030 - accuracy: 0.8820 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1786 - accuracy: 0.9374\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1843 - accuracy: 0.9333\n",
      "\n",
      "Epoch:  81\n",
      "152/152 - 5s - loss: 0.3032 - accuracy: 0.8827 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1779 - accuracy: 0.9388\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1823 - accuracy: 0.9364\n",
      "\n",
      "Epoch:  82\n",
      "152/152 - 5s - loss: 0.3009 - accuracy: 0.8825 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2043 - accuracy: 0.9172\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.2141 - accuracy: 0.9142\n",
      "\n",
      "Epoch:  83\n",
      "152/152 - 5s - loss: 0.2971 - accuracy: 0.8840 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2117 - accuracy: 0.9218\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2191 - accuracy: 0.9198\n",
      "\n",
      "Epoch:  84\n",
      "152/152 - 5s - loss: 0.3047 - accuracy: 0.8790 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2067 - accuracy: 0.9162\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2102 - accuracy: 0.9140\n",
      "\n",
      "Epoch:  85\n",
      "152/152 - 5s - loss: 0.2971 - accuracy: 0.8831 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1845 - accuracy: 0.9343\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1880 - accuracy: 0.9330\n",
      "\n",
      "Epoch:  86\n",
      "152/152 - 5s - loss: 0.2923 - accuracy: 0.8855 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2039 - accuracy: 0.9210\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2093 - accuracy: 0.9202\n",
      "\n",
      "Epoch:  87\n",
      "152/152 - 5s - loss: 0.2890 - accuracy: 0.8868 - 5s/epoch - 36ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2039 - accuracy: 0.9173\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.2107 - accuracy: 0.9153\n",
      "\n",
      "Epoch:  88\n",
      "152/152 - 5s - loss: 0.2967 - accuracy: 0.8818 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2186 - accuracy: 0.9118\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2240 - accuracy: 0.9099\n",
      "\n",
      "Epoch:  89\n",
      "152/152 - 5s - loss: 0.2976 - accuracy: 0.8828 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.1859 - accuracy: 0.9286\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1912 - accuracy: 0.9268\n",
      "\n",
      "Epoch:  90\n",
      "152/152 - 5s - loss: 0.2870 - accuracy: 0.8881 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1592 - accuracy: 0.9430\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1643 - accuracy: 0.9415\n",
      "\n",
      "Epoch:  91\n",
      "152/152 - 5s - loss: 0.2939 - accuracy: 0.8848 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2033 - accuracy: 0.9183\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2074 - accuracy: 0.9196\n",
      "\n",
      "Epoch:  92\n",
      "152/152 - 5s - loss: 0.2992 - accuracy: 0.8814 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.1937 - accuracy: 0.9251\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1993 - accuracy: 0.9198\n",
      "\n",
      "Epoch:  93\n",
      "152/152 - 5s - loss: 0.2883 - accuracy: 0.8865 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1668 - accuracy: 0.9414\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1697 - accuracy: 0.9370\n",
      "\n",
      "Epoch:  94\n",
      "152/152 - 5s - loss: 0.2756 - accuracy: 0.8919 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1954 - accuracy: 0.9245\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.1979 - accuracy: 0.9240\n",
      "\n",
      "Epoch:  95\n",
      "152/152 - 5s - loss: 0.2789 - accuracy: 0.8886 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1662 - accuracy: 0.9427\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.1708 - accuracy: 0.9399\n",
      "\n",
      "Epoch:  96\n",
      "152/152 - 5s - loss: 0.2836 - accuracy: 0.8897 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.1732 - accuracy: 0.9328\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1807 - accuracy: 0.9324\n",
      "\n",
      "Epoch:  97\n",
      "152/152 - 5s - loss: 0.2798 - accuracy: 0.8900 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1838 - accuracy: 0.9285\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1890 - accuracy: 0.9277\n",
      "\n",
      "Epoch:  98\n",
      "152/152 - 5s - loss: 0.2727 - accuracy: 0.8922 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1594 - accuracy: 0.9438\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1633 - accuracy: 0.9399\n",
      "\n",
      "Epoch:  99\n",
      "152/152 - 5s - loss: 0.2819 - accuracy: 0.8902 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2087 - accuracy: 0.9210\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2195 - accuracy: 0.9173\n",
      "\n",
      "Epoch:  100\n",
      "152/152 - 5s - loss: 0.2823 - accuracy: 0.8895 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2000 - accuracy: 0.9285\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2039 - accuracy: 0.9275\n",
      "\n",
      "Epoch:  101\n",
      "152/152 - 5s - loss: 0.2818 - accuracy: 0.8894 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1576 - accuracy: 0.9411\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1628 - accuracy: 0.9426\n",
      "\n",
      "Epoch:  102\n",
      "152/152 - 5s - loss: 0.2735 - accuracy: 0.8944 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1997 - accuracy: 0.9269\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2068 - accuracy: 0.9200\n",
      "\n",
      "Epoch:  103\n",
      "152/152 - 5s - loss: 0.2829 - accuracy: 0.8862 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1745 - accuracy: 0.9329\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1855 - accuracy: 0.9291\n",
      "\n",
      "Epoch:  104\n",
      "152/152 - 5s - loss: 0.2794 - accuracy: 0.8893 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1498 - accuracy: 0.9448\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1575 - accuracy: 0.9382\n",
      "\n",
      "Epoch:  105\n",
      "152/152 - 5s - loss: 0.2852 - accuracy: 0.8871 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1704 - accuracy: 0.9414\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1770 - accuracy: 0.9372\n",
      "\n",
      "Epoch:  106\n",
      "152/152 - 5s - loss: 0.2679 - accuracy: 0.8961 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1600 - accuracy: 0.9443\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1684 - accuracy: 0.9401\n",
      "\n",
      "Epoch:  107\n",
      "152/152 - 5s - loss: 0.2713 - accuracy: 0.8954 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1612 - accuracy: 0.9421\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1682 - accuracy: 0.9355\n",
      "\n",
      "Epoch:  108\n",
      "152/152 - 5s - loss: 0.2714 - accuracy: 0.8939 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1503 - accuracy: 0.9462\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1566 - accuracy: 0.9419\n",
      "\n",
      "Epoch:  109\n",
      "152/152 - 5s - loss: 0.2596 - accuracy: 0.8987 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1813 - accuracy: 0.9321\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1812 - accuracy: 0.9341\n",
      "\n",
      "Epoch:  110\n",
      "152/152 - 6s - loss: 0.2651 - accuracy: 0.8951 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1511 - accuracy: 0.9468\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1552 - accuracy: 0.9426\n",
      "\n",
      "Epoch:  111\n",
      "152/152 - 6s - loss: 0.2648 - accuracy: 0.8967 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.3148 - accuracy: 0.8664\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.3220 - accuracy: 0.8646\n",
      "\n",
      "Epoch:  112\n",
      "152/152 - 5s - loss: 0.2683 - accuracy: 0.8958 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1369 - accuracy: 0.9497\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1449 - accuracy: 0.9436\n",
      "\n",
      "Epoch:  113\n",
      "152/152 - 5s - loss: 0.2593 - accuracy: 0.8986 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1471 - accuracy: 0.9463\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1543 - accuracy: 0.9386\n",
      "\n",
      "Epoch:  114\n",
      "152/152 - 5s - loss: 0.2517 - accuracy: 0.9024 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1352 - accuracy: 0.9514\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1461 - accuracy: 0.9471\n",
      "\n",
      "Epoch:  115\n",
      "152/152 - 5s - loss: 0.2634 - accuracy: 0.8952 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1652 - accuracy: 0.9344\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1737 - accuracy: 0.9341\n",
      "\n",
      "Epoch:  116\n",
      "152/152 - 5s - loss: 0.2504 - accuracy: 0.9027 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1972 - accuracy: 0.9273\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2058 - accuracy: 0.9206\n",
      "\n",
      "Epoch:  117\n",
      "152/152 - 5s - loss: 0.2700 - accuracy: 0.8935 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1433 - accuracy: 0.9474\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1542 - accuracy: 0.9426\n",
      "\n",
      "Epoch:  118\n",
      "152/152 - 5s - loss: 0.2459 - accuracy: 0.9040 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1452 - accuracy: 0.9455\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1534 - accuracy: 0.9409\n",
      "\n",
      "Epoch:  119\n",
      "152/152 - 5s - loss: 0.2529 - accuracy: 0.9015 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2163 - accuracy: 0.9103\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.2281 - accuracy: 0.9095\n",
      "\n",
      "Epoch:  120\n",
      "152/152 - 5s - loss: 0.2786 - accuracy: 0.8893 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1772 - accuracy: 0.9323\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1820 - accuracy: 0.9306\n",
      "\n",
      "Epoch:  121\n",
      "152/152 - 5s - loss: 0.2618 - accuracy: 0.8952 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1427 - accuracy: 0.9505\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1525 - accuracy: 0.9452\n",
      "\n",
      "Epoch:  122\n",
      "152/152 - 5s - loss: 0.2504 - accuracy: 0.8989 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1843 - accuracy: 0.9362\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1933 - accuracy: 0.9333\n",
      "\n",
      "Epoch:  123\n",
      "152/152 - 5s - loss: 0.2563 - accuracy: 0.9010 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1488 - accuracy: 0.9425\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1573 - accuracy: 0.9366\n",
      "\n",
      "Epoch:  124\n",
      "152/152 - 5s - loss: 0.2590 - accuracy: 0.9008 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1512 - accuracy: 0.9434\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1600 - accuracy: 0.9423\n",
      "\n",
      "Epoch:  125\n",
      "152/152 - 5s - loss: 0.2517 - accuracy: 0.9009 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1465 - accuracy: 0.9463\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1507 - accuracy: 0.9444\n",
      "\n",
      "Epoch:  126\n",
      "152/152 - 5s - loss: 0.2414 - accuracy: 0.9059 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1383 - accuracy: 0.9474\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1483 - accuracy: 0.9432\n",
      "\n",
      "Epoch:  127\n",
      "152/152 - 5s - loss: 0.2415 - accuracy: 0.9064 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1547 - accuracy: 0.9404\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1646 - accuracy: 0.9361\n",
      "\n",
      "Epoch:  128\n",
      "152/152 - 5s - loss: 0.2532 - accuracy: 0.8996 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1661 - accuracy: 0.9394\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1713 - accuracy: 0.9370\n",
      "\n",
      "Epoch:  129\n",
      "152/152 - 5s - loss: 0.2412 - accuracy: 0.9059 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1566 - accuracy: 0.9417\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1683 - accuracy: 0.9370\n",
      "\n",
      "Epoch:  130\n",
      "152/152 - 5s - loss: 0.2546 - accuracy: 0.9008 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1494 - accuracy: 0.9425\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1558 - accuracy: 0.9376\n",
      "\n",
      "Epoch:  131\n",
      "152/152 - 5s - loss: 0.2444 - accuracy: 0.9043 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1384 - accuracy: 0.9512\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1482 - accuracy: 0.9450\n",
      "\n",
      "Epoch:  132\n",
      "152/152 - 5s - loss: 0.2389 - accuracy: 0.9085 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1495 - accuracy: 0.9431\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1591 - accuracy: 0.9409\n",
      "\n",
      "Epoch:  133\n",
      "152/152 - 5s - loss: 0.2501 - accuracy: 0.9031 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1279 - accuracy: 0.9557\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1388 - accuracy: 0.9502\n",
      "\n",
      "Epoch:  134\n",
      "152/152 - 5s - loss: 0.2475 - accuracy: 0.9041 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1265 - accuracy: 0.9546\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1371 - accuracy: 0.9490\n",
      "\n",
      "Epoch:  135\n",
      "152/152 - 5s - loss: 0.2415 - accuracy: 0.9045 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1734 - accuracy: 0.9271\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1833 - accuracy: 0.9246\n",
      "\n",
      "Epoch:  136\n",
      "152/152 - 5s - loss: 0.2460 - accuracy: 0.9031 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1312 - accuracy: 0.9544\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1371 - accuracy: 0.9496\n",
      "\n",
      "Epoch:  137\n",
      "152/152 - 5s - loss: 0.2366 - accuracy: 0.9095 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1323 - accuracy: 0.9512\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1430 - accuracy: 0.9463\n",
      "\n",
      "Epoch:  138\n",
      "152/152 - 5s - loss: 0.2499 - accuracy: 0.9018 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1474 - accuracy: 0.9457\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1612 - accuracy: 0.9395\n",
      "\n",
      "Epoch:  139\n",
      "152/152 - 5s - loss: 0.2499 - accuracy: 0.9018 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.2038 - accuracy: 0.9169\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.2195 - accuracy: 0.9105\n",
      "\n",
      "Epoch:  140\n",
      "152/152 - 5s - loss: 0.2460 - accuracy: 0.9050 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1308 - accuracy: 0.9542\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1407 - accuracy: 0.9494\n",
      "\n",
      "Epoch:  141\n",
      "152/152 - 5s - loss: 0.2417 - accuracy: 0.9060 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1244 - accuracy: 0.9573\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1359 - accuracy: 0.9506\n",
      "\n",
      "Epoch:  142\n",
      "152/152 - 6s - loss: 0.2367 - accuracy: 0.9098 - 6s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1208 - accuracy: 0.9583\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1301 - accuracy: 0.9543\n",
      "\n",
      "Epoch:  143\n",
      "152/152 - 5s - loss: 0.2363 - accuracy: 0.9080 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1500 - accuracy: 0.9446\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1561 - accuracy: 0.9432\n",
      "\n",
      "Epoch:  144\n",
      "152/152 - 6s - loss: 0.2432 - accuracy: 0.9059 - 6s/epoch - 37ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1579 - accuracy: 0.9381\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1657 - accuracy: 0.9351\n",
      "\n",
      "Epoch:  145\n",
      "152/152 - 5s - loss: 0.2403 - accuracy: 0.9053 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1363 - accuracy: 0.9522\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1438 - accuracy: 0.9481\n",
      "\n",
      "Epoch:  146\n",
      "152/152 - 5s - loss: 0.2414 - accuracy: 0.9056 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1217 - accuracy: 0.9561\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1322 - accuracy: 0.9487\n",
      "\n",
      "Epoch:  147\n",
      "152/152 - 5s - loss: 0.2239 - accuracy: 0.9129 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1292 - accuracy: 0.9534\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1397 - accuracy: 0.9483\n",
      "\n",
      "Epoch:  148\n",
      "152/152 - 5s - loss: 0.2320 - accuracy: 0.9093 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1240 - accuracy: 0.9562\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1370 - accuracy: 0.9490\n",
      "\n",
      "Epoch:  149\n",
      "152/152 - 5s - loss: 0.2347 - accuracy: 0.9106 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1632 - accuracy: 0.9380\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1781 - accuracy: 0.9322\n",
      "\n",
      "Epoch:  150\n",
      "152/152 - 5s - loss: 0.2341 - accuracy: 0.9093 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1413 - accuracy: 0.9469\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1514 - accuracy: 0.9415\n",
      "\n",
      "Epoch:  151\n",
      "152/152 - 5s - loss: 0.2401 - accuracy: 0.9080 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1355 - accuracy: 0.9486\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1458 - accuracy: 0.9438\n",
      "\n",
      "Epoch:  152\n",
      "152/152 - 5s - loss: 0.2284 - accuracy: 0.9119 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1195 - accuracy: 0.9556\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1302 - accuracy: 0.9516\n",
      "\n",
      "Epoch:  153\n",
      "152/152 - 5s - loss: 0.2469 - accuracy: 0.9036 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1419 - accuracy: 0.9513\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1557 - accuracy: 0.9446\n",
      "\n",
      "Epoch:  154\n",
      "152/152 - 5s - loss: 0.2321 - accuracy: 0.9085 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1193 - accuracy: 0.9565\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1306 - accuracy: 0.9510\n",
      "\n",
      "Epoch:  155\n",
      "152/152 - 5s - loss: 0.2356 - accuracy: 0.9074 - 5s/epoch - 35ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1437 - accuracy: 0.9481\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1570 - accuracy: 0.9407\n",
      "\n",
      "Epoch:  156\n",
      "152/152 - 5s - loss: 0.2321 - accuracy: 0.9104 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1292 - accuracy: 0.9546\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1350 - accuracy: 0.9516\n",
      "\n",
      "Epoch:  157\n",
      "152/152 - 6s - loss: 0.2243 - accuracy: 0.9127 - 6s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1605 - accuracy: 0.9369\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1744 - accuracy: 0.9322\n",
      "\n",
      "Epoch:  158\n",
      "152/152 - 5s - loss: 0.2335 - accuracy: 0.9080 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1145 - accuracy: 0.9644\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1248 - accuracy: 0.9570\n",
      "\n",
      "Epoch:  159\n",
      "152/152 - 6s - loss: 0.2335 - accuracy: 0.9106 - 6s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1664 - accuracy: 0.9370\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1776 - accuracy: 0.9324\n",
      "\n",
      "Epoch:  160\n",
      "152/152 - 5s - loss: 0.2402 - accuracy: 0.9078 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1355 - accuracy: 0.9497\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1465 - accuracy: 0.9434\n",
      "\n",
      "Epoch:  161\n",
      "152/152 - 6s - loss: 0.2222 - accuracy: 0.9114 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1268 - accuracy: 0.9514\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1405 - accuracy: 0.9461\n",
      "\n",
      "Epoch:  162\n",
      "152/152 - 5s - loss: 0.2172 - accuracy: 0.9152 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1092 - accuracy: 0.9613\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1203 - accuracy: 0.9533\n",
      "\n",
      "Epoch:  163\n",
      "152/152 - 6s - loss: 0.2254 - accuracy: 0.9127 - 6s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1299 - accuracy: 0.9521\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1442 - accuracy: 0.9450\n",
      "\n",
      "Epoch:  164\n",
      "152/152 - 6s - loss: 0.2112 - accuracy: 0.9185 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.1094 - accuracy: 0.9644\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.1237 - accuracy: 0.9514\n",
      "\n",
      "Epoch:  165\n",
      "152/152 - 6s - loss: 0.2225 - accuracy: 0.9139 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1616 - accuracy: 0.9353\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1696 - accuracy: 0.9324\n",
      "\n",
      "Epoch:  166\n",
      "152/152 - 6s - loss: 0.2189 - accuracy: 0.9169 - 6s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1223 - accuracy: 0.9549\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1352 - accuracy: 0.9469\n",
      "\n",
      "Epoch:  167\n",
      "152/152 - 5s - loss: 0.2279 - accuracy: 0.9117 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1299 - accuracy: 0.9541\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1429 - accuracy: 0.9492\n",
      "\n",
      "Epoch:  168\n",
      "152/152 - 5s - loss: 0.2336 - accuracy: 0.9090 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1367 - accuracy: 0.9462\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1486 - accuracy: 0.9461\n",
      "\n",
      "Epoch:  169\n",
      "152/152 - 6s - loss: 0.2291 - accuracy: 0.9095 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1099 - accuracy: 0.9621\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1203 - accuracy: 0.9578\n",
      "\n",
      "Epoch:  170\n",
      "152/152 - 5s - loss: 0.2093 - accuracy: 0.9199 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1190 - accuracy: 0.9553\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1337 - accuracy: 0.9483\n",
      "\n",
      "Epoch:  171\n",
      "152/152 - 6s - loss: 0.2261 - accuracy: 0.9122 - 6s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1143 - accuracy: 0.9601\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1231 - accuracy: 0.9552\n",
      "\n",
      "Epoch:  172\n",
      "152/152 - 5s - loss: 0.2045 - accuracy: 0.9208 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1089 - accuracy: 0.9597\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1232 - accuracy: 0.9521\n",
      "\n",
      "Epoch:  173\n",
      "152/152 - 5s - loss: 0.2175 - accuracy: 0.9167 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1159 - accuracy: 0.9564\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1269 - accuracy: 0.9514\n",
      "\n",
      "Epoch:  174\n",
      "152/152 - 5s - loss: 0.2077 - accuracy: 0.9179 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1126 - accuracy: 0.9615\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1283 - accuracy: 0.9527\n",
      "\n",
      "Epoch:  175\n",
      "152/152 - 5s - loss: 0.2230 - accuracy: 0.9139 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1126 - accuracy: 0.9598\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1237 - accuracy: 0.9549\n",
      "\n",
      "Epoch:  176\n",
      "152/152 - 5s - loss: 0.2147 - accuracy: 0.9174 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1255 - accuracy: 0.9537\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1416 - accuracy: 0.9440\n",
      "\n",
      "Epoch:  177\n",
      "152/152 - 5s - loss: 0.2220 - accuracy: 0.9139 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1071 - accuracy: 0.9624\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1186 - accuracy: 0.9556\n",
      "\n",
      "Epoch:  178\n",
      "152/152 - 5s - loss: 0.2078 - accuracy: 0.9197 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1244 - accuracy: 0.9504\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1409 - accuracy: 0.9426\n",
      "\n",
      "Epoch:  179\n",
      "152/152 - 5s - loss: 0.2064 - accuracy: 0.9201 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1129 - accuracy: 0.9617\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1247 - accuracy: 0.9566\n",
      "\n",
      "Epoch:  180\n",
      "152/152 - 5s - loss: 0.2151 - accuracy: 0.9153 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1285 - accuracy: 0.9528\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1407 - accuracy: 0.9500\n",
      "\n",
      "Epoch:  181\n",
      "152/152 - 5s - loss: 0.2015 - accuracy: 0.9240 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1515 - accuracy: 0.9387\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1693 - accuracy: 0.9310\n",
      "\n",
      "Epoch:  182\n",
      "152/152 - 5s - loss: 0.2087 - accuracy: 0.9188 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1398 - accuracy: 0.9446\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1497 - accuracy: 0.9417\n",
      "\n",
      "Epoch:  183\n",
      "152/152 - 6s - loss: 0.2177 - accuracy: 0.9155 - 6s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1214 - accuracy: 0.9606\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1363 - accuracy: 0.9539\n",
      "\n",
      "Epoch:  184\n",
      "152/152 - 5s - loss: 0.2029 - accuracy: 0.9203 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1010 - accuracy: 0.9628\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1149 - accuracy: 0.9545\n",
      "\n",
      "Epoch:  185\n",
      "152/152 - 5s - loss: 0.2086 - accuracy: 0.9199 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1221 - accuracy: 0.9537\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1380 - accuracy: 0.9461\n",
      "\n",
      "Epoch:  186\n",
      "152/152 - 5s - loss: 0.2288 - accuracy: 0.9103 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1467 - accuracy: 0.9461\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1616 - accuracy: 0.9386\n",
      "\n",
      "Epoch:  187\n",
      "152/152 - 6s - loss: 0.2012 - accuracy: 0.9231 - 6s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.1261 - accuracy: 0.9519\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1363 - accuracy: 0.9485\n",
      "\n",
      "Epoch:  188\n",
      "152/152 - 5s - loss: 0.2067 - accuracy: 0.9206 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0963 - accuracy: 0.9665\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1113 - accuracy: 0.9585\n",
      "\n",
      "Epoch:  189\n",
      "152/152 - 5s - loss: 0.2057 - accuracy: 0.9217 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1485 - accuracy: 0.9429\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1616 - accuracy: 0.9372\n",
      "\n",
      "Epoch:  190\n",
      "152/152 - 5s - loss: 0.2168 - accuracy: 0.9180 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1039 - accuracy: 0.9657\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1158 - accuracy: 0.9568\n",
      "\n",
      "Epoch:  191\n",
      "152/152 - 5s - loss: 0.2162 - accuracy: 0.9160 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1357 - accuracy: 0.9469\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1492 - accuracy: 0.9417\n",
      "\n",
      "Epoch:  192\n",
      "152/152 - 6s - loss: 0.2144 - accuracy: 0.9157 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1297 - accuracy: 0.9506\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1442 - accuracy: 0.9434\n",
      "\n",
      "Epoch:  193\n",
      "152/152 - 5s - loss: 0.2150 - accuracy: 0.9149 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1207 - accuracy: 0.9566\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1318 - accuracy: 0.9529\n",
      "\n",
      "Epoch:  194\n",
      "152/152 - 5s - loss: 0.2074 - accuracy: 0.9198 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1143 - accuracy: 0.9581\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1233 - accuracy: 0.9564\n",
      "\n",
      "Epoch:  195\n",
      "152/152 - 6s - loss: 0.2078 - accuracy: 0.9189 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1196 - accuracy: 0.9556\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1335 - accuracy: 0.9479\n",
      "\n",
      "Epoch:  196\n",
      "152/152 - 5s - loss: 0.2025 - accuracy: 0.9200 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1015 - accuracy: 0.9666\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1142 - accuracy: 0.9585\n",
      "\n",
      "Epoch:  197\n",
      "152/152 - 5s - loss: 0.1955 - accuracy: 0.9226 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0972 - accuracy: 0.9638\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1149 - accuracy: 0.9539\n",
      "\n",
      "Epoch:  198\n",
      "152/152 - 5s - loss: 0.1967 - accuracy: 0.9258 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1057 - accuracy: 0.9607\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1218 - accuracy: 0.9533\n",
      "\n",
      "Epoch:  199\n",
      "152/152 - 6s - loss: 0.2011 - accuracy: 0.9221 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1493 - accuracy: 0.9387\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1674 - accuracy: 0.9318\n",
      "\n",
      "Epoch:  200\n",
      "152/152 - 5s - loss: 0.1981 - accuracy: 0.9246 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0934 - accuracy: 0.9679\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1085 - accuracy: 0.9589\n",
      "\n",
      "Epoch:  201\n",
      "152/152 - 5s - loss: 0.1899 - accuracy: 0.9250 - 5s/epoch - 36ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0998 - accuracy: 0.9633\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1155 - accuracy: 0.9570\n",
      "\n",
      "Epoch:  202\n",
      "152/152 - 6s - loss: 0.1963 - accuracy: 0.9241 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0989 - accuracy: 0.9652\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1148 - accuracy: 0.9562\n",
      "\n",
      "Epoch:  203\n",
      "152/152 - 5s - loss: 0.1959 - accuracy: 0.9255 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1521 - accuracy: 0.9396\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1686 - accuracy: 0.9392\n",
      "\n",
      "Epoch:  204\n",
      "152/152 - 5s - loss: 0.2168 - accuracy: 0.9165 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1057 - accuracy: 0.9639\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1194 - accuracy: 0.9578\n",
      "\n",
      "Epoch:  205\n",
      "152/152 - 5s - loss: 0.1771 - accuracy: 0.9328 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1016 - accuracy: 0.9622\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1115 - accuracy: 0.9609\n",
      "\n",
      "Epoch:  206\n",
      "152/152 - 6s - loss: 0.1968 - accuracy: 0.9250 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1193 - accuracy: 0.9533\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1356 - accuracy: 0.9463\n",
      "\n",
      "Epoch:  207\n",
      "152/152 - 6s - loss: 0.2069 - accuracy: 0.9211 - 6s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1157 - accuracy: 0.9591\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1305 - accuracy: 0.9506\n",
      "\n",
      "Epoch:  208\n",
      "152/152 - 5s - loss: 0.1944 - accuracy: 0.9245 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1159 - accuracy: 0.9586\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1332 - accuracy: 0.9502\n",
      "\n",
      "Epoch:  209\n",
      "152/152 - 5s - loss: 0.1997 - accuracy: 0.9238 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1223 - accuracy: 0.9550\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1398 - accuracy: 0.9481\n",
      "\n",
      "Epoch:  210\n",
      "152/152 - 6s - loss: 0.1971 - accuracy: 0.9238 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1047 - accuracy: 0.9629\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1203 - accuracy: 0.9537\n",
      "\n",
      "Epoch:  211\n",
      "152/152 - 6s - loss: 0.2126 - accuracy: 0.9172 - 6s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1078 - accuracy: 0.9641\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1229 - accuracy: 0.9552\n",
      "\n",
      "Epoch:  212\n",
      "152/152 - 6s - loss: 0.1952 - accuracy: 0.9246 - 6s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0933 - accuracy: 0.9691\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1100 - accuracy: 0.9580\n",
      "\n",
      "Epoch:  213\n",
      "152/152 - 5s - loss: 0.1956 - accuracy: 0.9250 - 5s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1080 - accuracy: 0.9575\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1224 - accuracy: 0.9514\n",
      "\n",
      "Epoch:  214\n",
      "152/152 - 6s - loss: 0.1914 - accuracy: 0.9253 - 6s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0962 - accuracy: 0.9648\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1130 - accuracy: 0.9572\n",
      "\n",
      "Epoch:  215\n",
      "152/152 - 6s - loss: 0.1979 - accuracy: 0.9240 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1281 - accuracy: 0.9460\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1530 - accuracy: 0.9376\n",
      "\n",
      "Epoch:  216\n",
      "152/152 - 6s - loss: 0.1941 - accuracy: 0.9245 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1046 - accuracy: 0.9638\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1214 - accuracy: 0.9543\n",
      "\n",
      "Epoch:  217\n",
      "152/152 - 6s - loss: 0.1962 - accuracy: 0.9236 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1308 - accuracy: 0.9501\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1462 - accuracy: 0.9442\n",
      "\n",
      "Epoch:  218\n",
      "152/152 - 6s - loss: 0.1890 - accuracy: 0.9270 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0901 - accuracy: 0.9704\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.1023 - accuracy: 0.9628\n",
      "\n",
      "Epoch:  219\n",
      "152/152 - 6s - loss: 0.2032 - accuracy: 0.9204 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0883 - accuracy: 0.9691\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1042 - accuracy: 0.9614\n",
      "\n",
      "Epoch:  220\n",
      "152/152 - 6s - loss: 0.1964 - accuracy: 0.9237 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1386 - accuracy: 0.9474\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1583 - accuracy: 0.9403\n",
      "\n",
      "Epoch:  221\n",
      "152/152 - 6s - loss: 0.1942 - accuracy: 0.9251 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1207 - accuracy: 0.9573\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1356 - accuracy: 0.9492\n",
      "\n",
      "Epoch:  222\n",
      "152/152 - 6s - loss: 0.1961 - accuracy: 0.9235 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1149 - accuracy: 0.9574\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1287 - accuracy: 0.9545\n",
      "\n",
      "Epoch:  223\n",
      "152/152 - 6s - loss: 0.1925 - accuracy: 0.9248 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1220 - accuracy: 0.9525\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1407 - accuracy: 0.9477\n",
      "\n",
      "Epoch:  224\n",
      "152/152 - 6s - loss: 0.1855 - accuracy: 0.9271 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0985 - accuracy: 0.9651\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1143 - accuracy: 0.9574\n",
      "\n",
      "Epoch:  225\n",
      "152/152 - 6s - loss: 0.1939 - accuracy: 0.9249 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0935 - accuracy: 0.9661\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1103 - accuracy: 0.9570\n",
      "\n",
      "Epoch:  226\n",
      "152/152 - 6s - loss: 0.1915 - accuracy: 0.9280 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1270 - accuracy: 0.9496\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1477 - accuracy: 0.9419\n",
      "\n",
      "Epoch:  227\n",
      "152/152 - 6s - loss: 0.2037 - accuracy: 0.9227 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0968 - accuracy: 0.9665\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1146 - accuracy: 0.9566\n",
      "\n",
      "Epoch:  228\n",
      "152/152 - 6s - loss: 0.1947 - accuracy: 0.9278 - 6s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1048 - accuracy: 0.9613\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1241 - accuracy: 0.9541\n",
      "\n",
      "Epoch:  229\n",
      "152/152 - 6s - loss: 0.1854 - accuracy: 0.9296 - 6s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0932 - accuracy: 0.9660\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1074 - accuracy: 0.9597\n",
      "\n",
      "Epoch:  230\n",
      "152/152 - 6s - loss: 0.1879 - accuracy: 0.9290 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0866 - accuracy: 0.9696\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1026 - accuracy: 0.9605\n",
      "\n",
      "Epoch:  231\n",
      "152/152 - 6s - loss: 0.1937 - accuracy: 0.9257 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1059 - accuracy: 0.9624\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1268 - accuracy: 0.9512\n",
      "\n",
      "Epoch:  232\n",
      "152/152 - 6s - loss: 0.1886 - accuracy: 0.9257 - 6s/epoch - 36ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0827 - accuracy: 0.9714\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0998 - accuracy: 0.9622\n",
      "\n",
      "Epoch:  233\n",
      "152/152 - 6s - loss: 0.1984 - accuracy: 0.9222 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1209 - accuracy: 0.9565\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1353 - accuracy: 0.9496\n",
      "\n",
      "Epoch:  234\n",
      "152/152 - 6s - loss: 0.1952 - accuracy: 0.9260 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1034 - accuracy: 0.9633\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1224 - accuracy: 0.9523\n",
      "\n",
      "Epoch:  235\n",
      "152/152 - 6s - loss: 0.1883 - accuracy: 0.9263 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0996 - accuracy: 0.9623\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1137 - accuracy: 0.9572\n",
      "\n",
      "Epoch:  236\n",
      "152/152 - 6s - loss: 0.1828 - accuracy: 0.9283 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1129 - accuracy: 0.9591\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1344 - accuracy: 0.9549\n",
      "\n",
      "Epoch:  237\n",
      "152/152 - 6s - loss: 0.1929 - accuracy: 0.9243 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0931 - accuracy: 0.9656\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1116 - accuracy: 0.9578\n",
      "\n",
      "Epoch:  238\n",
      "152/152 - 6s - loss: 0.1776 - accuracy: 0.9327 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0837 - accuracy: 0.9707\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1024 - accuracy: 0.9638\n",
      "\n",
      "Epoch:  239\n",
      "152/152 - 6s - loss: 0.1838 - accuracy: 0.9291 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1122 - accuracy: 0.9554\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1358 - accuracy: 0.9469\n",
      "\n",
      "Epoch:  240\n",
      "152/152 - 6s - loss: 0.1832 - accuracy: 0.9297 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0902 - accuracy: 0.9697\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1122 - accuracy: 0.9595\n",
      "\n",
      "Epoch:  241\n",
      "152/152 - 6s - loss: 0.1784 - accuracy: 0.9303 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0753 - accuracy: 0.9749\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0947 - accuracy: 0.9649\n",
      "\n",
      "Epoch:  242\n",
      "152/152 - 6s - loss: 0.1826 - accuracy: 0.9310 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0876 - accuracy: 0.9693\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1058 - accuracy: 0.9595\n",
      "\n",
      "Epoch:  243\n",
      "152/152 - 6s - loss: 0.1801 - accuracy: 0.9297 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1242 - accuracy: 0.9516\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1480 - accuracy: 0.9450\n",
      "\n",
      "Epoch:  244\n",
      "152/152 - 6s - loss: 0.1760 - accuracy: 0.9341 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0912 - accuracy: 0.9662\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1112 - accuracy: 0.9572\n",
      "\n",
      "Epoch:  245\n",
      "152/152 - 6s - loss: 0.1829 - accuracy: 0.9298 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0783 - accuracy: 0.9747\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0919 - accuracy: 0.9663\n",
      "\n",
      "Epoch:  246\n",
      "152/152 - 6s - loss: 0.1832 - accuracy: 0.9281 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1119 - accuracy: 0.9559\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1325 - accuracy: 0.9477\n",
      "\n",
      "Epoch:  247\n",
      "152/152 - 6s - loss: 0.1862 - accuracy: 0.9288 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1062 - accuracy: 0.9623\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1268 - accuracy: 0.9541\n",
      "\n",
      "Epoch:  248\n",
      "152/152 - 6s - loss: 0.1823 - accuracy: 0.9300 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1089 - accuracy: 0.9560\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1287 - accuracy: 0.9465\n",
      "\n",
      "Epoch:  249\n",
      "152/152 - 6s - loss: 0.1776 - accuracy: 0.9301 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1211 - accuracy: 0.9512\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1404 - accuracy: 0.9434\n",
      "\n",
      "Epoch:  250\n",
      "152/152 - 6s - loss: 0.1812 - accuracy: 0.9308 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1575 - accuracy: 0.9329\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1737 - accuracy: 0.9271\n",
      "\n",
      "Epoch:  251\n",
      "152/152 - 6s - loss: 0.1893 - accuracy: 0.9260 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1365 - accuracy: 0.9481\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1584 - accuracy: 0.9417\n",
      "\n",
      "Epoch:  252\n",
      "152/152 - 6s - loss: 0.1885 - accuracy: 0.9260 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0845 - accuracy: 0.9704\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1024 - accuracy: 0.9622\n",
      "\n",
      "Epoch:  253\n",
      "152/152 - 6s - loss: 0.1942 - accuracy: 0.9255 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0923 - accuracy: 0.9682\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1085 - accuracy: 0.9587\n",
      "\n",
      "Epoch:  254\n",
      "152/152 - 6s - loss: 0.1782 - accuracy: 0.9331 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0978 - accuracy: 0.9626\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1203 - accuracy: 0.9506\n",
      "\n",
      "Epoch:  255\n",
      "152/152 - 6s - loss: 0.1708 - accuracy: 0.9351 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0840 - accuracy: 0.9685\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1079 - accuracy: 0.9580\n",
      "\n",
      "Epoch:  256\n",
      "152/152 - 6s - loss: 0.1755 - accuracy: 0.9301 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0933 - accuracy: 0.9656\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.1157 - accuracy: 0.9572\n",
      "\n",
      "Epoch:  257\n",
      "152/152 - 6s - loss: 0.1764 - accuracy: 0.9337 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0784 - accuracy: 0.9732\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0950 - accuracy: 0.9653\n",
      "\n",
      "Epoch:  258\n",
      "152/152 - 6s - loss: 0.1721 - accuracy: 0.9337 - 6s/epoch - 37ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0845 - accuracy: 0.9686\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1037 - accuracy: 0.9599\n",
      "\n",
      "Epoch:  259\n",
      "152/152 - 6s - loss: 0.1756 - accuracy: 0.9312 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0996 - accuracy: 0.9670\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1248 - accuracy: 0.9552\n",
      "\n",
      "Epoch:  260\n",
      "152/152 - 6s - loss: 0.1666 - accuracy: 0.9359 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0794 - accuracy: 0.9721\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0986 - accuracy: 0.9607\n",
      "\n",
      "Epoch:  261\n",
      "152/152 - 6s - loss: 0.1797 - accuracy: 0.9304 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0818 - accuracy: 0.9705\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1026 - accuracy: 0.9576\n",
      "\n",
      "Epoch:  262\n",
      "152/152 - 6s - loss: 0.1737 - accuracy: 0.9312 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1079 - accuracy: 0.9547\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1304 - accuracy: 0.9465\n",
      "\n",
      "Epoch:  263\n",
      "152/152 - 6s - loss: 0.1811 - accuracy: 0.9300 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1061 - accuracy: 0.9592\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1283 - accuracy: 0.9516\n",
      "\n",
      "Epoch:  264\n",
      "152/152 - 6s - loss: 0.1690 - accuracy: 0.9346 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0783 - accuracy: 0.9728\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0985 - accuracy: 0.9618\n",
      "\n",
      "Epoch:  265\n",
      "152/152 - 6s - loss: 0.1770 - accuracy: 0.9322 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0928 - accuracy: 0.9651\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1145 - accuracy: 0.9570\n",
      "\n",
      "Epoch:  266\n",
      "152/152 - 6s - loss: 0.1670 - accuracy: 0.9363 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0976 - accuracy: 0.9611\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1207 - accuracy: 0.9514\n",
      "\n",
      "Epoch:  267\n",
      "152/152 - 6s - loss: 0.1821 - accuracy: 0.9302 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0926 - accuracy: 0.9697\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1132 - accuracy: 0.9589\n",
      "\n",
      "Epoch:  268\n",
      "152/152 - 6s - loss: 0.1699 - accuracy: 0.9344 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0896 - accuracy: 0.9669\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1108 - accuracy: 0.9560\n",
      "\n",
      "Epoch:  269\n",
      "152/152 - 6s - loss: 0.1740 - accuracy: 0.9327 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0983 - accuracy: 0.9641\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1193 - accuracy: 0.9527\n",
      "\n",
      "Epoch:  270\n",
      "152/152 - 6s - loss: 0.1751 - accuracy: 0.9316 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1070 - accuracy: 0.9570\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.1261 - accuracy: 0.9494\n",
      "\n",
      "Epoch:  271\n",
      "152/152 - 6s - loss: 0.1696 - accuracy: 0.9358 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0713 - accuracy: 0.9749\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0907 - accuracy: 0.9649\n",
      "\n",
      "Epoch:  272\n",
      "152/152 - 6s - loss: 0.1745 - accuracy: 0.9336 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0878 - accuracy: 0.9675\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1150 - accuracy: 0.9585\n",
      "\n",
      "Epoch:  273\n",
      "152/152 - 6s - loss: 0.1832 - accuracy: 0.9279 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0924 - accuracy: 0.9666\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1114 - accuracy: 0.9576\n",
      "\n",
      "Epoch:  274\n",
      "152/152 - 6s - loss: 0.1663 - accuracy: 0.9364 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0868 - accuracy: 0.9666\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1117 - accuracy: 0.9556\n",
      "\n",
      "Epoch:  275\n",
      "152/152 - 6s - loss: 0.1679 - accuracy: 0.9361 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1119 - accuracy: 0.9522\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1340 - accuracy: 0.9448\n",
      "\n",
      "Epoch:  276\n",
      "152/152 - 6s - loss: 0.1765 - accuracy: 0.9307 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0969 - accuracy: 0.9640\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1211 - accuracy: 0.9531\n",
      "\n",
      "Epoch:  277\n",
      "152/152 - 6s - loss: 0.1635 - accuracy: 0.9355 - 6s/epoch - 37ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0866 - accuracy: 0.9697\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1075 - accuracy: 0.9614\n",
      "\n",
      "Epoch:  278\n",
      "152/152 - 6s - loss: 0.1666 - accuracy: 0.9367 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0786 - accuracy: 0.9727\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0987 - accuracy: 0.9636\n",
      "\n",
      "Epoch:  279\n",
      "152/152 - 6s - loss: 0.1687 - accuracy: 0.9332 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0922 - accuracy: 0.9655\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1146 - accuracy: 0.9543\n",
      "\n",
      "Epoch:  280\n",
      "152/152 - 6s - loss: 0.1729 - accuracy: 0.9338 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0757 - accuracy: 0.9728\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0979 - accuracy: 0.9624\n",
      "\n",
      "Epoch:  281\n",
      "152/152 - 6s - loss: 0.1715 - accuracy: 0.9345 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0861 - accuracy: 0.9667\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1048 - accuracy: 0.9585\n",
      "\n",
      "Epoch:  282\n",
      "152/152 - 6s - loss: 0.1640 - accuracy: 0.9365 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0791 - accuracy: 0.9715\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1025 - accuracy: 0.9634\n",
      "\n",
      "Epoch:  283\n",
      "152/152 - 6s - loss: 0.1742 - accuracy: 0.9327 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0802 - accuracy: 0.9739\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0998 - accuracy: 0.9642\n",
      "\n",
      "Epoch:  284\n",
      "152/152 - 6s - loss: 0.1665 - accuracy: 0.9347 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0861 - accuracy: 0.9724\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1063 - accuracy: 0.9620\n",
      "\n",
      "Epoch:  285\n",
      "152/152 - 6s - loss: 0.1696 - accuracy: 0.9341 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0974 - accuracy: 0.9633\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1184 - accuracy: 0.9525\n",
      "\n",
      "Epoch:  286\n",
      "152/152 - 6s - loss: 0.1769 - accuracy: 0.9325 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0866 - accuracy: 0.9671\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1041 - accuracy: 0.9611\n",
      "\n",
      "Epoch:  287\n",
      "152/152 - 6s - loss: 0.1627 - accuracy: 0.9373 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0861 - accuracy: 0.9689\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1094 - accuracy: 0.9599\n",
      "\n",
      "Epoch:  288\n",
      "152/152 - 6s - loss: 0.1713 - accuracy: 0.9334 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0842 - accuracy: 0.9701\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1024 - accuracy: 0.9642\n",
      "\n",
      "Epoch:  289\n",
      "152/152 - 6s - loss: 0.1579 - accuracy: 0.9398 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0749 - accuracy: 0.9733\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0991 - accuracy: 0.9628\n",
      "\n",
      "Epoch:  290\n",
      "152/152 - 6s - loss: 0.1620 - accuracy: 0.9385 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0736 - accuracy: 0.9761\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0995 - accuracy: 0.9640\n",
      "\n",
      "Epoch:  291\n",
      "152/152 - 6s - loss: 0.1595 - accuracy: 0.9388 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0718 - accuracy: 0.9752\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0987 - accuracy: 0.9628\n",
      "\n",
      "Epoch:  292\n",
      "152/152 - 6s - loss: 0.1588 - accuracy: 0.9406 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0798 - accuracy: 0.9719\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1041 - accuracy: 0.9616\n",
      "\n",
      "Epoch:  293\n",
      "152/152 - 6s - loss: 0.1634 - accuracy: 0.9388 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0945 - accuracy: 0.9657\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1187 - accuracy: 0.9570\n",
      "\n",
      "Epoch:  294\n",
      "152/152 - 6s - loss: 0.1553 - accuracy: 0.9410 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0937 - accuracy: 0.9644\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1172 - accuracy: 0.9529\n",
      "\n",
      "Epoch:  295\n",
      "152/152 - 6s - loss: 0.1782 - accuracy: 0.9323 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1029 - accuracy: 0.9616\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1266 - accuracy: 0.9537\n",
      "\n",
      "Epoch:  296\n",
      "152/152 - 6s - loss: 0.1701 - accuracy: 0.9352 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0772 - accuracy: 0.9731\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1022 - accuracy: 0.9593\n",
      "\n",
      "Epoch:  297\n",
      "152/152 - 6s - loss: 0.1528 - accuracy: 0.9416 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0821 - accuracy: 0.9709\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1078 - accuracy: 0.9607\n",
      "\n",
      "Epoch:  298\n",
      "152/152 - 6s - loss: 0.1585 - accuracy: 0.9411 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1002 - accuracy: 0.9576\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1235 - accuracy: 0.9471\n",
      "\n",
      "Epoch:  299\n",
      "152/152 - 6s - loss: 0.1558 - accuracy: 0.9382 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0797 - accuracy: 0.9696\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1020 - accuracy: 0.9595\n",
      "\n",
      "Epoch:  300\n",
      "152/152 - 6s - loss: 0.1639 - accuracy: 0.9375 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0847 - accuracy: 0.9670\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1077 - accuracy: 0.9583\n",
      "\n",
      "Epoch:  301\n",
      "152/152 - 6s - loss: 0.1533 - accuracy: 0.9413 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0685 - accuracy: 0.9768\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0931 - accuracy: 0.9649\n",
      "\n",
      "Epoch:  302\n",
      "152/152 - 6s - loss: 0.1583 - accuracy: 0.9391 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0684 - accuracy: 0.9773\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0897 - accuracy: 0.9673\n",
      "\n",
      "Epoch:  303\n",
      "152/152 - 6s - loss: 0.1570 - accuracy: 0.9410 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0690 - accuracy: 0.9751\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0903 - accuracy: 0.9682\n",
      "\n",
      "Epoch:  304\n",
      "152/152 - 6s - loss: 0.1645 - accuracy: 0.9386 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0732 - accuracy: 0.9739\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0956 - accuracy: 0.9638\n",
      "\n",
      "Epoch:  305\n",
      "152/152 - 6s - loss: 0.1478 - accuracy: 0.9454 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0732 - accuracy: 0.9734\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0972 - accuracy: 0.9616\n",
      "\n",
      "Epoch:  306\n",
      "152/152 - 6s - loss: 0.1636 - accuracy: 0.9367 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0688 - accuracy: 0.9735\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0930 - accuracy: 0.9657\n",
      "\n",
      "Epoch:  307\n",
      "152/152 - 6s - loss: 0.1666 - accuracy: 0.9359 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0766 - accuracy: 0.9739\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1027 - accuracy: 0.9624\n",
      "\n",
      "Epoch:  308\n",
      "152/152 - 6s - loss: 0.1596 - accuracy: 0.9399 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0710 - accuracy: 0.9752\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0952 - accuracy: 0.9638\n",
      "\n",
      "Epoch:  309\n",
      "152/152 - 6s - loss: 0.1593 - accuracy: 0.9393 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0922 - accuracy: 0.9657\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1144 - accuracy: 0.9574\n",
      "\n",
      "Epoch:  310\n",
      "152/152 - 6s - loss: 0.1532 - accuracy: 0.9415 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0791 - accuracy: 0.9727\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1098 - accuracy: 0.9620\n",
      "\n",
      "Epoch:  311\n",
      "152/152 - 6s - loss: 0.1617 - accuracy: 0.9385 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0781 - accuracy: 0.9716\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1037 - accuracy: 0.9620\n",
      "\n",
      "Epoch:  312\n",
      "152/152 - 6s - loss: 0.1581 - accuracy: 0.9394 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0729 - accuracy: 0.9730\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0947 - accuracy: 0.9609\n",
      "\n",
      "Epoch:  313\n",
      "152/152 - 6s - loss: 0.1498 - accuracy: 0.9446 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0710 - accuracy: 0.9742\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0957 - accuracy: 0.9622\n",
      "\n",
      "Epoch:  314\n",
      "152/152 - 6s - loss: 0.1524 - accuracy: 0.9407 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0771 - accuracy: 0.9717\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0990 - accuracy: 0.9601\n",
      "\n",
      "Epoch:  315\n",
      "152/152 - 6s - loss: 0.1666 - accuracy: 0.9361 - 6s/epoch - 38ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1015 - accuracy: 0.9602\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1213 - accuracy: 0.9539\n",
      "\n",
      "Epoch:  316\n",
      "152/152 - 6s - loss: 0.1651 - accuracy: 0.9375 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0760 - accuracy: 0.9730\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0973 - accuracy: 0.9624\n",
      "\n",
      "Epoch:  317\n",
      "152/152 - 6s - loss: 0.1524 - accuracy: 0.9427 - 6s/epoch - 42ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0715 - accuracy: 0.9751\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0941 - accuracy: 0.9649\n",
      "\n",
      "Epoch:  318\n",
      "152/152 - 6s - loss: 0.1561 - accuracy: 0.9385 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0785 - accuracy: 0.9701\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1079 - accuracy: 0.9591\n",
      "\n",
      "Epoch:  319\n",
      "152/152 - 6s - loss: 0.1583 - accuracy: 0.9403 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0886 - accuracy: 0.9674\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1196 - accuracy: 0.9560\n",
      "\n",
      "Epoch:  320\n",
      "152/152 - 6s - loss: 0.1626 - accuracy: 0.9364 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0995 - accuracy: 0.9602\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1224 - accuracy: 0.9483\n",
      "\n",
      "Epoch:  321\n",
      "152/152 - 6s - loss: 0.1546 - accuracy: 0.9389 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0702 - accuracy: 0.9772\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0937 - accuracy: 0.9636\n",
      "\n",
      "Epoch:  322\n",
      "152/152 - 6s - loss: 0.1519 - accuracy: 0.9422 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1021 - accuracy: 0.9602\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1246 - accuracy: 0.9502\n",
      "\n",
      "Epoch:  323\n",
      "152/152 - 6s - loss: 0.1575 - accuracy: 0.9388 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0990 - accuracy: 0.9612\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1248 - accuracy: 0.9533\n",
      "\n",
      "Epoch:  324\n",
      "152/152 - 6s - loss: 0.1522 - accuracy: 0.9417 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0736 - accuracy: 0.9730\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0968 - accuracy: 0.9636\n",
      "\n",
      "Epoch:  325\n",
      "152/152 - 6s - loss: 0.1570 - accuracy: 0.9396 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0679 - accuracy: 0.9754\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0967 - accuracy: 0.9614\n",
      "\n",
      "Epoch:  326\n",
      "152/152 - 6s - loss: 0.1470 - accuracy: 0.9436 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0955 - accuracy: 0.9627\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1267 - accuracy: 0.9500\n",
      "\n",
      "Epoch:  327\n",
      "152/152 - 6s - loss: 0.1571 - accuracy: 0.9387 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0794 - accuracy: 0.9713\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1033 - accuracy: 0.9618\n",
      "\n",
      "Epoch:  328\n",
      "152/152 - 6s - loss: 0.1518 - accuracy: 0.9414 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0696 - accuracy: 0.9773\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0925 - accuracy: 0.9676\n",
      "\n",
      "Epoch:  329\n",
      "152/152 - 6s - loss: 0.1573 - accuracy: 0.9383 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0769 - accuracy: 0.9732\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1031 - accuracy: 0.9587\n",
      "\n",
      "Epoch:  330\n",
      "152/152 - 6s - loss: 0.1474 - accuracy: 0.9431 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0869 - accuracy: 0.9685\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1175 - accuracy: 0.9556\n",
      "\n",
      "Epoch:  331\n",
      "152/152 - 6s - loss: 0.1564 - accuracy: 0.9417 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0728 - accuracy: 0.9728\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1027 - accuracy: 0.9574\n",
      "\n",
      "Epoch:  332\n",
      "152/152 - 6s - loss: 0.1452 - accuracy: 0.9438 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0704 - accuracy: 0.9744\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0936 - accuracy: 0.9651\n",
      "\n",
      "Epoch:  333\n",
      "152/152 - 6s - loss: 0.1522 - accuracy: 0.9406 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0732 - accuracy: 0.9761\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1003 - accuracy: 0.9630\n",
      "\n",
      "Epoch:  334\n",
      "152/152 - 6s - loss: 0.1547 - accuracy: 0.9398 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0980 - accuracy: 0.9652\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1260 - accuracy: 0.9552\n",
      "\n",
      "Epoch:  335\n",
      "152/152 - 6s - loss: 0.1467 - accuracy: 0.9430 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0827 - accuracy: 0.9662\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1054 - accuracy: 0.9574\n",
      "\n",
      "Epoch:  336\n",
      "152/152 - 6s - loss: 0.1561 - accuracy: 0.9413 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0747 - accuracy: 0.9762\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0951 - accuracy: 0.9655\n",
      "\n",
      "Epoch:  337\n",
      "152/152 - 6s - loss: 0.1531 - accuracy: 0.9406 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0889 - accuracy: 0.9685\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1131 - accuracy: 0.9587\n",
      "\n",
      "Epoch:  338\n",
      "152/152 - 6s - loss: 0.1507 - accuracy: 0.9425 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0767 - accuracy: 0.9741\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0987 - accuracy: 0.9624\n",
      "\n",
      "Epoch:  339\n",
      "152/152 - 6s - loss: 0.1494 - accuracy: 0.9426 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0833 - accuracy: 0.9666\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1096 - accuracy: 0.9576\n",
      "\n",
      "Epoch:  340\n",
      "152/152 - 6s - loss: 0.1600 - accuracy: 0.9406 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0608 - accuracy: 0.9797\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0859 - accuracy: 0.9671\n",
      "\n",
      "Epoch:  341\n",
      "152/152 - 6s - loss: 0.1468 - accuracy: 0.9432 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0676 - accuracy: 0.9755\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0896 - accuracy: 0.9651\n",
      "\n",
      "Epoch:  342\n",
      "152/152 - 6s - loss: 0.1394 - accuracy: 0.9468 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1209 - accuracy: 0.9502\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1477 - accuracy: 0.9413\n",
      "\n",
      "Epoch:  343\n",
      "152/152 - 6s - loss: 0.1572 - accuracy: 0.9390 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0841 - accuracy: 0.9654\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1130 - accuracy: 0.9533\n",
      "\n",
      "Epoch:  344\n",
      "152/152 - 6s - loss: 0.1456 - accuracy: 0.9441 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0606 - accuracy: 0.9788\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0875 - accuracy: 0.9647\n",
      "\n",
      "Epoch:  345\n",
      "152/152 - 6s - loss: 0.1472 - accuracy: 0.9427 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0658 - accuracy: 0.9780\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0915 - accuracy: 0.9663\n",
      "\n",
      "Epoch:  346\n",
      "152/152 - 6s - loss: 0.1410 - accuracy: 0.9468 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0600 - accuracy: 0.9788\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0866 - accuracy: 0.9688\n",
      "\n",
      "Epoch:  347\n",
      "152/152 - 6s - loss: 0.1509 - accuracy: 0.9438 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0807 - accuracy: 0.9719\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1108 - accuracy: 0.9578\n",
      "\n",
      "Epoch:  348\n",
      "152/152 - 6s - loss: 0.1503 - accuracy: 0.9419 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0655 - accuracy: 0.9769\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0882 - accuracy: 0.9665\n",
      "\n",
      "Epoch:  349\n",
      "152/152 - 6s - loss: 0.1395 - accuracy: 0.9452 - 6s/epoch - 38ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0671 - accuracy: 0.9759\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0953 - accuracy: 0.9620\n",
      "\n",
      "Epoch:  350\n",
      "152/152 - 6s - loss: 0.1471 - accuracy: 0.9423 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0911 - accuracy: 0.9633\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1156 - accuracy: 0.9539\n",
      "\n",
      "Epoch:  351\n",
      "152/152 - 6s - loss: 0.1371 - accuracy: 0.9476 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0554 - accuracy: 0.9818\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0792 - accuracy: 0.9721\n",
      "\n",
      "Epoch:  352\n",
      "152/152 - 6s - loss: 0.1594 - accuracy: 0.9395 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1166 - accuracy: 0.9541\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1387 - accuracy: 0.9419\n",
      "\n",
      "Epoch:  353\n",
      "152/152 - 6s - loss: 0.1465 - accuracy: 0.9442 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1111 - accuracy: 0.9518\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1303 - accuracy: 0.9448\n",
      "\n",
      "Epoch:  354\n",
      "152/152 - 6s - loss: 0.1424 - accuracy: 0.9469 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0640 - accuracy: 0.9790\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0870 - accuracy: 0.9702\n",
      "\n",
      "Epoch:  355\n",
      "152/152 - 6s - loss: 0.1330 - accuracy: 0.9485 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0546 - accuracy: 0.9821\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0794 - accuracy: 0.9704\n",
      "\n",
      "Epoch:  356\n",
      "152/152 - 6s - loss: 0.1373 - accuracy: 0.9469 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0699 - accuracy: 0.9766\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1007 - accuracy: 0.9653\n",
      "\n",
      "Epoch:  357\n",
      "152/152 - 6s - loss: 0.1452 - accuracy: 0.9458 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0657 - accuracy: 0.9785\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0917 - accuracy: 0.9653\n",
      "\n",
      "Epoch:  358\n",
      "152/152 - 6s - loss: 0.1517 - accuracy: 0.9428 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0690 - accuracy: 0.9757\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0989 - accuracy: 0.9607\n",
      "\n",
      "Epoch:  359\n",
      "152/152 - 6s - loss: 0.1481 - accuracy: 0.9425 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0729 - accuracy: 0.9728\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0976 - accuracy: 0.9605\n",
      "\n",
      "Epoch:  360\n",
      "152/152 - 6s - loss: 0.1434 - accuracy: 0.9453 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0759 - accuracy: 0.9731\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1019 - accuracy: 0.9630\n",
      "\n",
      "Epoch:  361\n",
      "152/152 - 6s - loss: 0.1429 - accuracy: 0.9454 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0565 - accuracy: 0.9818\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0823 - accuracy: 0.9686\n",
      "\n",
      "Epoch:  362\n",
      "152/152 - 6s - loss: 0.1385 - accuracy: 0.9483 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0640 - accuracy: 0.9779\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0928 - accuracy: 0.9663\n",
      "\n",
      "Epoch:  363\n",
      "152/152 - 6s - loss: 0.1464 - accuracy: 0.9417 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0651 - accuracy: 0.9769\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0909 - accuracy: 0.9657\n",
      "\n",
      "Epoch:  364\n",
      "152/152 - 6s - loss: 0.1435 - accuracy: 0.9460 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0654 - accuracy: 0.9779\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0923 - accuracy: 0.9665\n",
      "\n",
      "Epoch:  365\n",
      "152/152 - 6s - loss: 0.1494 - accuracy: 0.9430 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0877 - accuracy: 0.9678\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1152 - accuracy: 0.9556\n",
      "\n",
      "Epoch:  366\n",
      "152/152 - 6s - loss: 0.1420 - accuracy: 0.9458 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0663 - accuracy: 0.9765\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0918 - accuracy: 0.9655\n",
      "\n",
      "Epoch:  367\n",
      "152/152 - 6s - loss: 0.1421 - accuracy: 0.9466 - 6s/epoch - 42ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0593 - accuracy: 0.9807\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0877 - accuracy: 0.9653\n",
      "\n",
      "Epoch:  368\n",
      "152/152 - 6s - loss: 0.1453 - accuracy: 0.9446 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0603 - accuracy: 0.9803\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0885 - accuracy: 0.9682\n",
      "\n",
      "Epoch:  369\n",
      "152/152 - 6s - loss: 0.1445 - accuracy: 0.9455 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0684 - accuracy: 0.9733\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0948 - accuracy: 0.9614\n",
      "\n",
      "Epoch:  370\n",
      "152/152 - 6s - loss: 0.1419 - accuracy: 0.9457 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0746 - accuracy: 0.9730\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1031 - accuracy: 0.9605\n",
      "\n",
      "Epoch:  371\n",
      "152/152 - 6s - loss: 0.1406 - accuracy: 0.9464 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0586 - accuracy: 0.9794\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0863 - accuracy: 0.9661\n",
      "\n",
      "Epoch:  372\n",
      "152/152 - 6s - loss: 0.1368 - accuracy: 0.9477 - 6s/epoch - 39ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0660 - accuracy: 0.9781\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0926 - accuracy: 0.9663\n",
      "\n",
      "Epoch:  373\n",
      "152/152 - 6s - loss: 0.1477 - accuracy: 0.9447 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0672 - accuracy: 0.9763\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0959 - accuracy: 0.9611\n",
      "\n",
      "Epoch:  374\n",
      "152/152 - 6s - loss: 0.1411 - accuracy: 0.9462 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0590 - accuracy: 0.9794\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0843 - accuracy: 0.9688\n",
      "\n",
      "Epoch:  375\n",
      "152/152 - 6s - loss: 0.1391 - accuracy: 0.9476 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0738 - accuracy: 0.9730\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1057 - accuracy: 0.9595\n",
      "\n",
      "Epoch:  376\n",
      "152/152 - 6s - loss: 0.1522 - accuracy: 0.9416 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0596 - accuracy: 0.9804\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0873 - accuracy: 0.9694\n",
      "\n",
      "Epoch:  377\n",
      "152/152 - 6s - loss: 0.1333 - accuracy: 0.9476 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0605 - accuracy: 0.9796\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0884 - accuracy: 0.9671\n",
      "\n",
      "Epoch:  378\n",
      "152/152 - 6s - loss: 0.1407 - accuracy: 0.9485 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0648 - accuracy: 0.9785\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0936 - accuracy: 0.9653\n",
      "\n",
      "Epoch:  379\n",
      "152/152 - 6s - loss: 0.1337 - accuracy: 0.9493 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0654 - accuracy: 0.9776\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0945 - accuracy: 0.9634\n",
      "\n",
      "Epoch:  380\n",
      "152/152 - 6s - loss: 0.1332 - accuracy: 0.9497 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0815 - accuracy: 0.9683\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1111 - accuracy: 0.9578\n",
      "\n",
      "Epoch:  381\n",
      "152/152 - 6s - loss: 0.1441 - accuracy: 0.9471 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0640 - accuracy: 0.9779\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0886 - accuracy: 0.9682\n",
      "\n",
      "Epoch:  382\n",
      "152/152 - 6s - loss: 0.1382 - accuracy: 0.9469 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0692 - accuracy: 0.9738\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0969 - accuracy: 0.9611\n",
      "\n",
      "Epoch:  383\n",
      "152/152 - 6s - loss: 0.1310 - accuracy: 0.9489 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0641 - accuracy: 0.9761\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0931 - accuracy: 0.9626\n",
      "\n",
      "Epoch:  384\n",
      "152/152 - 6s - loss: 0.1338 - accuracy: 0.9490 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0567 - accuracy: 0.9809\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0834 - accuracy: 0.9682\n",
      "\n",
      "Epoch:  385\n",
      "152/152 - 6s - loss: 0.1339 - accuracy: 0.9484 - 6s/epoch - 41ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0609 - accuracy: 0.9776\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0923 - accuracy: 0.9655\n",
      "\n",
      "Epoch:  386\n",
      "152/152 - 6s - loss: 0.1252 - accuracy: 0.9515 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0564 - accuracy: 0.9810\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0837 - accuracy: 0.9682\n",
      "\n",
      "Epoch:  387\n",
      "152/152 - 6s - loss: 0.1381 - accuracy: 0.9471 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0526 - accuracy: 0.9818\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0797 - accuracy: 0.9709\n",
      "\n",
      "Epoch:  388\n",
      "152/152 - 6s - loss: 0.1413 - accuracy: 0.9462 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0668 - accuracy: 0.9759\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0935 - accuracy: 0.9618\n",
      "\n",
      "Epoch:  389\n",
      "152/152 - 6s - loss: 0.1409 - accuracy: 0.9452 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0636 - accuracy: 0.9791\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0862 - accuracy: 0.9673\n",
      "\n",
      "Epoch:  390\n",
      "152/152 - 6s - loss: 0.1312 - accuracy: 0.9490 - 6s/epoch - 41ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.1014 - accuracy: 0.9581\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1259 - accuracy: 0.9512\n",
      "\n",
      "Epoch:  391\n",
      "152/152 - 6s - loss: 0.1381 - accuracy: 0.9482 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0578 - accuracy: 0.9794\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0825 - accuracy: 0.9698\n",
      "\n",
      "Epoch:  392\n",
      "152/152 - 6s - loss: 0.1334 - accuracy: 0.9490 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0592 - accuracy: 0.9786\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0849 - accuracy: 0.9671\n",
      "\n",
      "Epoch:  393\n",
      "152/152 - 6s - loss: 0.1463 - accuracy: 0.9447 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0728 - accuracy: 0.9734\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1030 - accuracy: 0.9611\n",
      "\n",
      "Epoch:  394\n",
      "152/152 - 6s - loss: 0.1306 - accuracy: 0.9497 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0981 - accuracy: 0.9600\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1315 - accuracy: 0.9487\n",
      "\n",
      "Epoch:  395\n",
      "152/152 - 6s - loss: 0.1303 - accuracy: 0.9488 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0777 - accuracy: 0.9706\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1050 - accuracy: 0.9605\n",
      "\n",
      "Epoch:  396\n",
      "152/152 - 6s - loss: 0.1351 - accuracy: 0.9482 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0536 - accuracy: 0.9828\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0824 - accuracy: 0.9659\n",
      "\n",
      "Epoch:  397\n",
      "152/152 - 7s - loss: 0.1360 - accuracy: 0.9490 - 7s/epoch - 45ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0571 - accuracy: 0.9825\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0852 - accuracy: 0.9719\n",
      "\n",
      "Epoch:  398\n",
      "152/152 - 6s - loss: 0.1287 - accuracy: 0.9514 - 6s/epoch - 42ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0601 - accuracy: 0.9781\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0935 - accuracy: 0.9642\n",
      "\n",
      "Epoch:  399\n",
      "152/152 - 6s - loss: 0.1347 - accuracy: 0.9490 - 6s/epoch - 43ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0670 - accuracy: 0.9760\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0998 - accuracy: 0.9632\n",
      "\n",
      "Epoch:  400\n",
      "152/152 - 6s - loss: 0.1306 - accuracy: 0.9513 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0600 - accuracy: 0.9787\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0889 - accuracy: 0.9678\n"
     ]
    }
   ],
   "source": [
    "for x in range(400):\n",
    "    print(\"\\nEpoch: \",x+1)\n",
    "    history = model.fit(X_train ,y_train ,batch_size=BATCH_SIZE ,epochs=1, verbose=2, shuffle=True)\n",
    "    if history_dataframe.size == 0:\n",
    "        history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    else:\n",
    "        history_dataframe = pd.concat([history_dataframe,pd.DataFrame.from_dict(history.history)],axis=0,ignore_index=True)\n",
    "    \n",
    "    print(\"for training\")\n",
    "    train_eva.append(model.evaluate(X_train,y_train))\n",
    "    print(\"for testing\")\n",
    "    test_eva.append(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ec37c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.386653</td>\n",
       "      <td>0.252261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.385624</td>\n",
       "      <td>0.259081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.347169</td>\n",
       "      <td>0.325376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.300652</td>\n",
       "      <td>0.372087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.270555</td>\n",
       "      <td>0.393479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.135096</td>\n",
       "      <td>0.948173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.135956</td>\n",
       "      <td>0.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.128685</td>\n",
       "      <td>0.951377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.134729</td>\n",
       "      <td>0.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.130641</td>\n",
       "      <td>0.951325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy\n",
       "0    1.386653  0.252261\n",
       "1    1.385624  0.259081\n",
       "2    1.347169  0.325376\n",
       "3    1.300652  0.372087\n",
       "4    1.270555  0.393479\n",
       "..        ...       ...\n",
       "395  0.135096  0.948173\n",
       "396  0.135956  0.949000\n",
       "397  0.128685  0.951377\n",
       "398  0.134729  0.949000\n",
       "399  0.130641  0.951325\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c8463e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva_df = pd.DataFrame(train_eva,columns=['loss','accuracy'])\n",
    "test_eva_df = pd.DataFrame(test_eva,columns=['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cc95506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(df,title,xlabel,ylabel,values=['loss'],legends=[]):\n",
    "    \n",
    "    for value in values:\n",
    "        epoch_count = range(1, len(df.index) + 1)\n",
    "        plt.plot(epoch_count, df[value].tolist())\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    if legends==[]:\n",
    "        legends = values\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35c781fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAACMZElEQVR4nO3dd3xT1fsH8E9Gm+69S6FlzzIFyl6yFAEXAiqioCD4U9Gvispw4hb9iqAo4EbhK4iCDBFE9iybMktL6aR7t8n9/XGam9w2HbRp05bP+/XKq8nNvem5SeE+ec5zzlFJkiSBiIiIqJFQ27oBRERERNbE4IaIiIgaFQY3RERE1KgwuCEiIqJGhcENERERNSoMboiIiKhRYXBDREREjQqDGyIiImpUGNwQERFRo8LghoiIiBoVBjdEVK+oVKoq3Xbu3Fnj35Wbm4uFCxda5bWIqP7Q2roBRETmvvvuO8Xjb7/9Ftu2bSuzvV27djX+Xbm5uXjttdcAAIMGDarx6xFR/cDghojqlQcffFDxeP/+/di2bVuZ7URE5WG3FBE1OAaDAYsXL0aHDh3g4OAAf39/PPHEE0hLS1Psd/jwYYwYMQI+Pj5wdHREWFgYHn30UQBAdHQ0fH19AQCvvfaa3N21cOHCuj4dIrIyZm6IqMF54oknsGrVKkydOhX/93//hytXruCzzz7DsWPHsGfPHtjZ2SEpKQnDhw+Hr68vXnrpJXh4eCA6Ohq//vorAMDX1xdLly7FzJkzMX78eNx9990AgPDwcFueGhFZAYMbImpQdu/eja+++go//PADJk2aJG8fPHgwRo4ciTVr1mDSpEnYu3cv0tLSsHXrVvTo0UPe78033wQAODs7495778XMmTMRHh7Obi+iRoTdUkTUoKxZswbu7u64/fbbkZKSIt+6d+8OFxcX7NixAwDg4eEBAPjjjz9QVFRkwxYTUV1jcENEDcqFCxeQkZEBPz8/+Pr6Km7Z2dlISkoCAAwcOBD33HMPXnvtNfj4+GDs2LFYuXIlCgoKbHwGRFTb2C1FRA2KwWCAn58ffvjhB4vPG4uEVSoV1q5di/379+P333/Hli1b8Oijj+LDDz/E/v374eLiUpfNJqI6xOCGiBqUFi1a4K+//kLfvn3h6OhY6f69e/dG79698dZbb+HHH3/E5MmTsXr1akybNg0qlaoOWkxEdY3dUkTUoNx///3Q6/V44403yjxXXFyM9PR0AEBaWhokSVI836VLFwCQu6acnJwAQD6GiBoHZm6IqEEZOHAgnnjiCSxatAiRkZEYPnw47OzscOHCBaxZswaffPIJ7r33XnzzzTf4/PPPMX78eLRo0QJZWVlYvnw53NzcMHr0aACAo6Mj2rdvj59//hmtW7eGl5cXOnbsiI4dO9r4LImoJhjcEFGDs2zZMnTv3h1ffPEFXn75ZWi1WoSGhuLBBx9E3759AYgg6ODBg1i9ejUSExPh7u6Onj174ocffkBYWJj8Wl999RWeeuopPPvssygsLMSCBQsY3BA1cCqpdN6WiIiIqAFjzQ0RERE1KgxuiIiIqFFhcENERESNCoMbIiIialQY3BAREVGjwuCGiIiIGpVbbp4bg8GA69evw9XVlVOvExERNRCSJCErKwtBQUFQqyvOzdxywc3169cREhJi62YQERFRNcTGxqJJkyYV7nPLBTeurq4AxJvj5uZm49YQERFRVWRmZiIkJES+jlfklgtujF1Rbm5uDG6IiIgamKqUlLCgmIiIiBoVBjdERETUqDC4ISIiokbllqu5qSq9Xo+ioiJbN4Nugp2dHTQaja2bQURENsbgphRJkpCQkID09HRbN4WqwcPDAwEBAZzDiIjoFsbgphRjYOPn5wcnJydeJBsISZKQm5uLpKQkAEBgYKCNW0RERLZi0+Bm165deP/993HkyBHEx8dj3bp1GDduXJWO3bNnDwYOHIiOHTsiMjLSKu3R6/VyYOPt7W2V16S64+joCABISkqCn58fu6iIiG5RNi0ozsnJQefOnbFkyZKbOi49PR0PP/wwhg4datX2GGtsnJycrPq6VHeMnx3rpYiIbl02zdyMGjUKo0aNuunjZsyYgUmTJkGj0WD9+vVWbxe7ohoufnZERNTghoKvXLkSly9fxoIFC6q0f0FBATIzMxU3IiIiarwaVHBz4cIFvPTSS/j++++h1VYt6bRo0SK4u7vLt8a6aOagQYPwzDPP2LoZRERENtdgghu9Xo9JkybhtddeQ+vWrat83Ny5c5GRkSHfYmNja7GVREREZGsNZih4VlYWDh8+jGPHjmH27NkAAIPBAEmSoNVqsXXrVgwZMqTMcTqdDjqdrk7aWKw3oMggwdGOo3SIiIhspcFkbtzc3HDy5ElERkbKtxkzZqBNmzaIjIxEr169bNq+jLwinInPRFxank3bAQBpaWl4+OGH4enpCScnJ4waNQoXLlyQn7969SrGjBkDT09PODs7o0OHDti0aZN87OTJk+Hr6wtHR0e0atUKK1eutNWpEBER3TSbZm6ys7Nx8eJF+fGVK1cQGRkJLy8vNG3aFHPnzkVcXBy+/fZbqNVqdOzYUXG8n58fHBwcymy3JkmSkFekr8qeyC/SI79Ij8w8e2g1NY8bHe001Rr988gjj+DChQvYsGED3Nzc8OKLL2L06NE4c+YM7OzsMGvWLBQWFmLXrl1wdnbGmTNn4OLiAgCYN28ezpw5gz///BM+Pj64ePEi8vJsH7ARERFVlU2Dm8OHD2Pw4MHy4zlz5gAApkyZglWrViE+Ph4xMTG2ah4AIK9Ij/bzt9jkd595fQSc7G/uIzIGNXv27EGfPn0AAD/88ANCQkKwfv163HfffYiJicE999yDTp06AQCaN28uHx8TE4OuXbuiR48eAIDQ0FDrnAwREVEdsWlwM2jQIEiSVO7zq1atqvD4hQsXYuHChdZtVAN39uxZaLVaRTedt7c32rRpg7NnzwIA/u///g8zZ87E1q1bMWzYMNxzzz0IDw8HAMycORP33HMPjh49iuHDh2PcuHFykERERNQQNJiCYltxtNPgzOsjqrRvTkExrqTkQKtWoW2gm1V+d22YNm0aRowYgY0bN2Lr1q1YtGgRPvzwQzz11FMYNWoUrl69ik2bNmHbtm0YOnQoZs2ahQ8++KBW2kJERGRtDaag2FZUKhWc7LVVunk628PBTgOtRg0HO02VjyvvVp16m3bt2qG4uBgHDhyQt924cQNRUVFo3769vC0kJAQzZszAr7/+iueeew7Lly+Xn/P19cWUKVPw/fffY/Hixfjyyy9r9iYSERHVIWZurEhjFowYDBLUmrpfCqBVq1YYO3Yspk+fji+++AKurq546aWXEBwcjLFjxwIAnnnmGYwaNQqtW7dGWloaduzYgXbt2gEA5s+fj+7du6NDhw4oKCjAH3/8IT9HRETUEDBzY0UqlQrqkgBHX0EtUW1buXIlunfvjjvvvBMRERGQJAmbNm2CnZ2daJtej1mzZqFdu3YYOXIkWrdujc8//xwAYG9vj7lz5yI8PBwDBgyARqPB6tWrbXYuREREN0slVVTR2whlZmbC3d0dGRkZcHNT1sXk5+fjypUrCAsLg4ODQ7Ve/0x8Jor1BrTyc4WjPSfzq2vW+AyJiKj+qej6XRozN1Zm7Joy3FoxIxERUb3B4MbK1CVlNnoDgxsiIiJbYHBjZWo1MzdERES2xODGyjT1oKCYiIjoVsbgxsrkzI3Bxg0hIiK6RTG4sTLj1DbsliIiIrINBjdWZszcsKCYiIjINhjcWJmaQ8GJiIhsisGNlcnz3DBzQ0REZBMMbqxM7pZibENERGQTDG6sTC4oZuaGiIjIJhjcWJkpc8PgpqioyNZNICKiWxCDGyuzZUHx5s2b0a9fP3h4eMDb2xt33nknLl26JD9/7do1TJw4EV5eXnB2dkaPHj1w4MAB+fnff/8dt912GxwcHODj44Px48fLz6lUKqxfv17x+zw8PLBq1SoAQHR0NFQqFX7++WcMHDgQDg4O+OGHH3Djxg1MnDgRwcHBcHJyQqdOnfDTTz8pXsdgMOC9995Dy5YtodPp0LRpU7z11lsAgCFDhmD27NmK/ZOTk2Fvb4/t27db420jIqJGRmvrBtR7kgQU5VZ5d02xHqqiXEh6NVBYw1XB7ZyAkmCpKnJycjBnzhyEh4cjOzsb8+fPx/jx4xEZGYnc3FwMHDgQwcHB2LBhAwICAnD06FEYSmYb3LhxI8aPH49XXnkF3377LQoLC7Fp06abbvJLL72EDz/8EF27doWDgwPy8/PRvXt3vPjii3Bzc8PGjRvx0EMPoUWLFujZsycAYO7cuVi+fDk+/vhj9OvXD/Hx8Th37hwAYNq0aZg9ezY+/PBD6HQ6AMD333+P4OBgDBky5KbbR0REjZ9Kkm6t/pOKlkzPz8/HlStXEBYWBgcHB7GxMAd4O8gGLQXw8nXA3rnah6ekpMDX1xcnT57E3r178fzzzyM6OhpeXl5l9u3Tpw+aN2+O77//3uJrqVQqrFu3DuPGjZO3eXh4YPHixXjkkUcQHR2NsLAwLF68GE8//XSF7brzzjvRtm1bfPDBB8jKyoKvry8+++wzTJs2rcy++fn5CAoKwrJly3D//fcDADp37oy7774bCxYssLh/mc+QiIgavIqu36WxW6oRuXDhAiZOnIjmzZvDzc0NoaGhAICYmBhERkaia9euFgMbAIiMjMTQoUNr3IYePXooHuv1erzxxhvo1KkTvLy84OLigi1btiAmJgYAcPbsWRQUFJT7ux0cHPDQQw9hxYoVAICjR4/i1KlTeOSRR2rcViIiapzYLVUZOyeRQakiSZJw6nqm/DjM2wkuDnbV/903YcyYMWjWrBmWL1+OoKAgGAwGdOzYEYWFhXB0dKzw2MqeV6lUKJ3ks1Qw7OyszDS9//77+OSTT7B48WJ06tQJzs7OeOaZZ1BYWFil3wuIrqkuXbrg2rVrWLlyJYYMGYJmzZpVehwREd2amLmpjEoluoaqeFPpXKDWOUOyc4Jk54RCjeNNHa+43US9zY0bNxAVFYVXX30VQ4cORbt27ZCWliY/Hx4ejsjISKSmplo8Pjw8vMICXV9fX8THx8uPL1y4gNzcymuR9uzZg7Fjx+LBBx9E586d0bx5c5w/f15+vlWrVnB0dKzwd3fq1Ak9evTA8uXL8eOPP+LRRx+t9PcSEdGti8FNLWjq5SSPmiosrpuSJk9PT3h7e+PLL7/ExYsX8ffff2POnDny8xMnTkRAQADGjRuHPXv24PLly/jf//6Hffv2AQAWLFiAn376CQsWLMDZs2dx8uRJvPvuu/LxQ4YMwWeffYZjx47h8OHDmDFjBuzsKs9ItWrVCtu2bcPevXtx9uxZPPHEE0hMTJSfd3BwwIsvvogXXngB3377LS5duoT9+/fj66+/VrzOtGnT8M4770CSJMUoLiIiotIY3NQCVwc7+LmJkT1FekOd/E61Wo3Vq1fjyJEj6NixI5599lm8//778vP29vbYunUr/Pz8MHr0aHTq1AnvvPMONBoxomvQoEFYs2YNNmzYgC5dumDIkCE4ePCgfPyHH36IkJAQ9O/fH5MmTcLzzz8PJ6fKu81effVVdOvWDSNGjMCgQYPkAMvcvHnz8Nxzz2H+/Plo164dJkyYgKSkJMU+EydOhFarxcSJE1koTEREFeJoKTPWHGmTnluImNRcOOu0aOHrUqPXIjGPTosWLXDo0CF069at3P04WoqIqHG6mdFSLCiuJXYakRQrKq6bzE1jVVRUhBs3buDVV19F7969KwxsiIiIAHZL1Rp7Y3Cjl8qMMqKq27NnDwIDA3Ho0CEsW7bM1s0hIqIGgJmbWqLVqKCCChIkFOkl2GurPvKJTAYNGsTgkIiIbgozN7VEpVLBriSgSc8t5AWaiIiojjC4scBagYix7iYhMx+pOYVWeU2qGINIIiJicGPGOG9LVSanqwofF518v4CFxXXC+NlVZQ4eIiJqnFhzY0aj0cDDw0OeY8XJyQmqm5gluDSdCvB2UCEluwAF+RLy81l3U1skSUJubi6SkpLg4eEhz99DRES3HgY3pQQEBABAmUnkqiu7oBjpuUXIstMgP83eKq9J5fPw8JA/QyIiujUxuClFpVIhMDAQfn5+FheGvFnbziTgnR3n0K2pJ96/r40VWkjlsbOzY8aGiIgY3JRHo9FY5ULp4OCIuCw9fDKLOWMuERFRHWBBcS1z0Yn4MTu/5lkgIiIiqhyDm1rm6iCCm6z8Yhu3hIiI6NbA4KaWGYOb7AIGN0RERHWBwU0tM3ZL5RbqoTdwgjkiIqLaxuCmlrk4mGq2s9k1RUREVOtsGtzs2rULY8aMQVBQEFQqFdavX1/h/r/++ituv/12+Pr6ws3NDREREdiyZUvdNLaadFoN7LXibc4qYFExERFRbbNpcJOTk4POnTtjyZIlVdp/165duP3227Fp0yYcOXIEgwcPxpgxY3Ds2LFabmnNuLHuhoiIqM7YdJ6bUaNGYdSoUVXef/HixYrHb7/9Nn777Tf8/vvv6Nq1q5VbZz0uOi1Ssgs5YoqIiKgONOhJ/AwGA7KysuDl5VXuPgUFBSgoKJAfZ2Zm1kXTFIx1N6y5ISIiqn0NuqD4gw8+QHZ2Nu6///5y91m0aBHc3d3lW0hISB22UHDViRWqMzmRHxERUa1rsMHNjz/+iNdeew2//PIL/Pz8yt1v7ty5yMjIkG+xsbF12ErBhTU3REREdaZBdkutXr0a06ZNw5o1azBs2LAK99XpdNDpdHXUMstcdeyWIiIiqisNLnPz008/YerUqfjpp59wxx132Lo5VcIlGIiIiOqOTTM32dnZuHjxovz4ypUriIyMhJeXF5o2bYq5c+ciLi4O3377LQDRFTVlyhR88skn6NWrFxISEgAAjo6OcHd3t8k5VAW7pYiIiOqOTTM3hw8fRteuXeVh3HPmzEHXrl0xf/58AEB8fDxiYmLk/b/88ksUFxdj1qxZCAwMlG9PP/20TdpfVS4lBcVpuYU2bgkREVHjZ9PMzaBBgyBJ5a+3tGrVKsXjnTt31m6DaknbAFcAwMErqZAkCSqVysYtIiIiarwaXM1NQxTRwhuOdhrEZ+Tj9PW6n2eHiIjoVsLgpg442GkwoLUPAOCvs4k2bg0REVHjxuCmjgxt6w8A2Hvpho1bQkRE1LgxuKkjTTwdAQBpOSwqJiIiqk0MbuqIq4MYMcW5boiIiGoXg5s6YprIj+tLERER1SYGN3XEGNzkFOqhN5Q//J2IiIhqhsFNHTF2SwFcY4qIiKg2MbipI/ZaNXRa8XZnsmuKiIio1jC4qUMsKiYiIqp9DG7qkJsji4qJiIhqG4ObOsTMDRERUe1jcFOH3IzDwQuYuSEiIqotDG7qkGmum+IKV0MnIiKi6mNwU4dcdaJbav5vp/HAl/sZ4BAREdUCBjd1yJi5AYADV1KRydobIiIiq2NwU4fMJ/IDgJwCBjdERETWxuCmDplnbgAGN0RERLWBwU0dKh3cZDO4ISIisjoGN3WobLeU3kYtISIiarwY3NQhZ51G8ZiZGyIiIutjcFOHVFApHrPmhoiIyPoY3NSh3s29cEd4oPw4p5DBDRERkbUxuKlDWo0aSyZ1w73dmwDgGlNERES1gcGNDbjoxKgpdksRERFZH4MbG2BwQ0REVHsY3NiAc0lwk82h4ERERFbH4MYGXEqGhDNzQ0REZH0MbmzAmLnhaCkiIiLrY3BjA6ZuKQY3RERE1sbgxgZYUExERFR7GNzYgNwtxYJiIiIiq2NwYwPGgmJ2SxEREVkfgxsbcDbrlpIkycatISIialwY3NiAseam2CChoNhg49YQERE1LgxubMDZXivfZ9cUERGRdTG4sQG1WgUne07kR0REVBsY3NiIo50IbvKL2C1FRERkTQxubESjVgEA9AYWFBMREVkTgxsbYXBDRERUO2wa3OzatQtjxoxBUFAQVCoV1q9fX+kxO3fuRLdu3aDT6dCyZUusWrWq1ttZG4zBTbGB3VJERETWZNPgJicnB507d8aSJUuqtP+VK1dwxx13YPDgwYiMjMQzzzyDadOmYcuWLbXcUuvTMnNDRERUK7SV71J7Ro0ahVGjRlV5/2XLliEsLAwffvghAKBdu3bYvXs3Pv74Y4wYMaK2mlkr2C1FRERUOxpUzc2+ffswbNgwxbYRI0Zg37595R5TUFCAzMxMxa0+0KrFW8/ghoiIyLoaVHCTkJAAf39/xTZ/f39kZmYiLy/P4jGLFi2Cu7u7fAsJCamLplbKVHPD4IaIiMiaGlRwUx1z585FRkaGfIuNjbV1kwCwW4qIiKi22LTm5mYFBAQgMTFRsS0xMRFubm5wdHS0eIxOp4NOp6uL5t0UZm6IiIhqR4PK3ERERGD79u2Kbdu2bUNERISNWlR9ptFSHApORERkTTYNbrKzsxEZGYnIyEgAYqh3ZGQkYmJiAIgupYcffljef8aMGbh8+TJeeOEFnDt3Dp9//jl++eUXPPvss7Zofo2YuqVs3BAiIqJGxqbBzeHDh9G1a1d07doVADBnzhx07doV8+fPBwDEx8fLgQ4AhIWFYePGjdi2bRs6d+6MDz/8EF999VWDGwYOAFoNJ/EjIiKqDTatuRk0aBAkqfyaE0uzDw8aNAjHjh2rxVbVDQ2HghMR3ZpSLgCnfgX6Pg3YOQC5qUB2IuDdCtDUk1LYjDhAMgAeZiOMJQlQqcrum3QOiNoI9JoJ2DvVXRsrUE/exVtPSeKGBcVEZFlRHmBneaDELSF6N3B5J2DvAvR5ClBrav93ZicBl3YAHe+5uSAjOQqACvBtrdwevQc4vAIIvx9o2htQqQGdK7CkpwgcDEVA+ARgaR9AXyiCm0c3A84+ptfISgD+fhMI6ir2LcwG7JwABzfxfMpF4MRqoMtkwCsM0BcDOUmAkw8QvQs4+h3Q9SFg23zxGv2eAXxaiWNjDwFX/gEiZgPF+cD+pUBwdyD6X2D/54DWEZi6SbRBrQF+eRhoewcw4m1TG7MSgW/HAtkJQM4NYNhCYMNTwG3TgJDbqvlB1ByDGxth5oaoAcjPFBcTtyDrvm5xAXByDRA2EHBvAvz7IVCQCQyZLy6qp9cBa6YCo94Dej1u+TX0xWUvwNsWAElngfHLACevm2uTJAHbXxcXzgHPl/2Gri8GLm4DvFoAXs3FtsJs4MQvQOY1oO0Y5cXs3Cbg+jFxIU29Ii6aoX0rD9iK8oC1jwJRm0zbEk4AgZ2Bg8vFhdrZB2jWB/BtK4IElVq012AASv5vReoVYPfHgHuI6XwKsoELW4F2YwCNHXD5H0DnItpWmAN8MwZIPgdkxIpjivKBP54Vr9n3GXEuJ9cCuz4A7vovENARyLwOLOsP6AuADuOBe1YANy4C6x4X5w8AZzcA9s6Axh548FfRZgCIPQi4+IvABgBuXADebwG0GgGM/QxwcAdWTwbiDgPHvgM2zhH7OfsCPR8HDq8EclPE8Wf/ACb/Anx3t3gdrYMIWIy/XzIASaeByB+ANqNFwPjLQ0BOsrilXAAuKQfsoDAL+KK/uO8WXPJ5/wwknQGmbQdUGmDtVBHYAMCBpcC5P4D0q8DFv4BnTojztgGVVFG/UCOUmZkJd3d3ZGRkwM3NzWbtmPHdEWw+nYA3x3XEg72b2awdRPWSQS9+VvRtXZLEf97mF8vsJPFN35galyTxn/H5zcDIdwDXgJtrw2e3AamXgJDewIP/ExfCihRki4vQjYtAu7vEN1i/9sCk1cr91j4GnFoLtB4JNLkN+PsNsb3XDGD4W8Ab3qZ9F2aU/T0nfgF+mw30egIYukAEOVf3AitLlrNp2gcY/T5w8EvxbT+0r7jw/zxZdIE88APg5A1kxomLlkoFXI8Evhwojh//BdD5AdPvy4wX385TokRGwLeNCKKcvMWF1GjofCD1MhCzX7wHpWkdgP7PAQP+I35ndhJw9FsgKx4YMk9c7A99BVzYAqjtRNARu7+cN1slgqzUS+Izd/ISXSntxgA9pgI/TQKKcsSud34M9HgU2PQf8Z4MmguEDTC9X10mi8DjyErx2M4ZeD5K7Lv9dbFN5wY8tlUck5dWTpsAPLkf2PySyDpVpuUwwKMZcPhroO2d4jPMSxXPeYYBaq3y/a0RFdByqAg6KuPRFAh/ANj1Xvn79J4l/u72fALYuwL+7YHYA+I5tR0w8Seg1e3WaXqJm7l+M3NjIxoNJ/EjK5IkcVPXcIzAhW3im+3wtwCtfeX737gE/DQRuO0xoP1YcYEwZgwMepHOdg8WFzuf1uJbnUoNdH1Q2faCLJGuV6nE4x8niG+9938LnFkvLkZOXuI1I38UQcrhFcCVf4EHvgeaDwLijwNfDhKv03qk+BZ97ZDIigCAd0tgyKvK9qddBba8LDIDg+YCZzYAA18AgruJi3fqJbFf7H5xsWp3p8gsGPQiu5CTLNL0zfqKb72nfjUdc3glIOnFt9jkKPEf/7mN4qJ1aq3Y5/xmcTM6sEx8GzZXmFu2juH4apEp2PupqNWIO6IMJmL2Al8MEL//6LfAXZ8CrkGmbMgP94pMyJFV4lv8Xf8VWRmjdU8AuxcDEU+KTMnfb4rABhCZgqsp4n5eKuDsBzTtBZz93RQIGNk5i64azzBx/plxwI63RJakz/8By4cCGSWDRi7tML13ADDhO6DNKODS3yIouXER6HA3cHWPOGdIpv0Ls8UNEH8vZ9Yr27HxedFlcvYP8fjkWiDxtOn5yB/E36VRUQ6wehJw7YhpW0Em8HlvVOr8ZpERAoDZJRmXPZ9Y3jf1sngvAPHvZ9xS8Xf054tA2hWx3ckbuHeF+BvPSweOfiO6mAAR1D22TXw2ax8V2RmduwjE1z0uslfuIeI9bj1SBNnJUeJvvnSQo3MDxi4RGTGdm8hsXTuoDNJUamD8l8Cv00QQaigW28d+BrQYIv4e408APadbPbC5Wczc2MjTq4/ht8jrmHdnezzWL8xm7aBGIDtJdGHcuAg8sQtw9a94/+IC0aceNgjIvQE4eooLsEotgoobF8R/ph3vEd9QNz4v/uNqPkj8Z+Zplmn8ZYryQmLnJL6Z2zuLi3tKlMhgnN0A+LYDks+K/SatAVoPF8HU/x4D8jOAfnOAYQtEncKq0co2txkN3LdKpOjNL8JGTfuIb/GR35u2qe1EpqAwSzz27wRM+8t0Efvfo+KCXFpAuHhfMuOU2/s/Jy4UG+eIACrfLKPi6Fnxt3nXICDrevnPhw0AHDzE+2RJ50nA+KXiviSJrovcG2X307kBoz8AfnvSdOEBANdA0YVzeYfl13f2E3UalvR9Gtj7X3Hh7PKg8j32bgXc85V4z5b2MX2+zn4iSLxtmql7S5KAA18Am18s922Q9XxcZJ6MDHogJ8X0tx1/AlgxQpzvAz+KQDw7UTxeMcLU7TNzH7B/CXDs+7K/w8i/E5B4suR+R5EJWz1J1MMA4m/r9teBr83WNez/nPgS0OQ2UdPSLEIEz4dXiOCiIAMI7Q888geQHgMs6wcEdgEiZgE/3m96HZVG/I0W5QAz9ohuLkDUsZz/U/yttrsLcPQwHZOXDnzYFijOA+5cLLJUgCjqvXZIBOb+HcR+WfHid+z+WHweXiXXmoJskYHKiAUe3yneW/+OorjZnEEv/s4/bCuC6YBw8X/Mkp5AynmxT3APYHqp7qxacjPXbwY3NjLn50j8eiwOL49ui8cHtLBZO8iKshJE/7ml0QTVoS8CvhsvAo8O48V/lnv/C/SfUxJoGIANs0V9RlGuOGbwq+Lb9tFvRbCjdRD/OTXtbcqWrJ8lLlBNI0Q3QFh/8U1T6yD+wwTEf95D5wO/Py2+3Rs5uANPHxf1FOf/tBwcVIVrIPDUUZFBuLpHbFPbAf93FPjzJTHyorQ7PgQ2Plf5azeNAGLKX0wXUAGQTPf92otahPK4BYtAR6MTmRDzoMGS+78TWYp9n1l+PiBcZC2iNorPDhDfmNV24tu2sV0hvZRdMsaAMPUK8GkXsX9Yf5HZAICR7wJtR4suhbO/i4vu4JeB7+82C4RUwLjPgfUzxcPmg8SF1BiUAMAzJ0XGZeci4NBy0/a2dwL3fA2sHCkuulP/BLRms79H/gSsnyE+2/+LLHuhNDq4HNj0vLivcxeZt2/HioBEbQc8f75q9UKluyCNzv4BrJkiMk5jFottf78J7Hq/zEugxRCg37Oi1gYQGcs+s0XwtPdTIKgb0O1h0R3574fAtcNA7yfF+26UkyKC3cgfRH2O0bhlQJeJ4n5RnuhiUmtFgH5pu6keBhAByCvxyvezIifXAnFHRfFuVTKsluiLxN9yVYrWvx0rMjg9nwBGvwf8857IwAHi3+Vt06rXhpvEbqkGgMsvNBKFOaKf//JO4M//iAtM7xll90s6C+xbAgx+BXALFNmTMxtEIWCr4YCLr9lr5gJ7FouUdfS/YtueT0R3TE6yGN1w93IgoJP4D9XcsW/FN6zS/5EbiwjTr5qOMQYAxrSzMbABgIRT4iJ05Bvl6+RniK4E8+4Dc/2eFWlvfSHQpCew823L+2XFi4JaY2Dj0VR8w/31ifIDk00viJ/m2YMpf4j0+p7Fpv16PQH4tRPfogFRtJuXJrqeACgCm0k/A61HiC6Rfz80vd/mImaJNL6+oOQwtamItf9zpve6zR0iu6S1F91UNy4CzQeLtuWkiFEqg142dR1mXTcFN23vLHlNjQigmg8URaXmwc3GOYDLd6IrEBCf/6j3RfDSYZzy767dGHEDgM4TTYFWz8eBLpNE9+HpdcAdH4mAdesropshsIv4LAARGB0t+XtSqUWwa+cgvulb0vkBcQ5BXcoPbADRZeHXTtT+NOtTUhzcV7z3LYdVvRDaxc/y9nZ3Av+5JLI4Rv2fN31O7e4SWZeWw4Axn4qsW3B38fcXPkHsExguMlLm+pcTWBtHDQWEm7bZuwDt7zI9Ng8g7v9W/Pv4ergpY+TdsuqBDQB0ulfcakJjJ25VMfAlACrxbwsAOt0H7HxHtLnjPTVrRy1hcGMjxkn89HoGN7Um7ogY2jjibeV/hOkx4luLdwvxM+6oSC/np4tUbWg/8W3EKD9TFPr5tBKZjNYjgKg/xQXCwQ0485tp380vAt0fEa+Tny7mfej1OPDTA0BatLiN+xxYeYep1sDRU1wwPEPF451viwxNaTnJpvsbnwdGlHxzcvIR37Y/aivOzfifeHAPkbHZ95m46KyfKWpUIInuI2O2x5ILW8QNAJr1A67uNj1nDGya9hG1HSPfAaASKfXQfsrXyYoXRZpqrSnjYXw947f30P7iG+hXQ8XrASWFopeVryXpAUcv8c2xSQ/x/ob2E/U35sGNTxvx0xjcNOsjupM2zBYZk+6PiJoV39biswSAFoPFbVk/IOGk8vd2fVAEN0azDop6lPZ3id8tBzcjTd+inb1F4ASIi5AkKQNYQGQWzvwmgltjt0PzgSIT0+VB8XoJJ0UR6PbXxGe7aozIzgDiPfBpKUakVKTndOD4T+J9GPG2qU3mF8c7PgS6TRFZFyMnL3HhOv6j6BbzbVPx71GpgK6TK97HqPTfycAXRE3LwBeqdnxlzLtxABFsPXlA1BxFzBaF6ubF6lM3i7/PmszR4tcOclaww7jyRwlptOLmFWYKboK7Vf/31oVmEcDD602PvcKAh38T/484etqsWRVhcGMj8vILt1avoGWSJApNnX3Fxbj0cyfXAk6eokZEoxXzOqScF8WGFXUBLR9ieo17vhKZiICOwJpHRH/0jH9FAefhFcCYT4DsZDEMNPmcuGDvXiwKP/PSTUMdAcvf7s1Ffg9cPyru//kfoNUwEdQYj/3xARHYuAaKrqC0K8AnnUVqNzcVOP2r6bV07uIieuw70zaf1uL8NzwlHgd3F/8pd5siUumACLwe/k2k0/WFYtSHsXA1uLvI/JzbKIKz358u/1wG/EcU2sbsA06vN3VTuAaK+S8Ks0VKvjyDXxE/O4wXo3uadBcXtqu7TcNfOz8gLtSd7gdO/iK2jXof+PlBkU0yBmL2LqIOw97ZVGcAiKHJ5rxbKIPZpr1F90vHu03foAfPtdzekF4ioNC5A0NeEcGLg7sps9TpfhHkjlsi9pckUauQGQe0HmX5Nc3nLDHn5AVM/1u5bdwyUUjdeoT42zbW2bQYAnx9u8gGnfjF1Naq8AwFnr8oXq+ify+B4WW3jXpHFAt3ur/sc9YUNkDUctQmv7biZonWHkA1u3eM7J3FPDLXj4l/i5Vp1kfUWDXtI7JiDY1511w9xODGRrSNcZ6b4gLRTVNZWjkrQQQzXR8Sfew/PSCyBDp34MUrym9UZzeIynxAdKu0Hgn8/n/i8dQ/xX8QBoO4eDeLECNAABEkGCWeEjUIf/5H2Y7fnzFlCna8LTIdRue3iJoDSV/JSZvVbxizEzvfVe5y6Gvl46TTonj0sa3iPTNO4HXILA3e5g5xMfYKE908xuDGo5n4j/DnB02/1z1Y/Oz3rCm4CexiGrYcNlC8P4CoIZi2XVzk+v6fuDhrHUVWaOsrZU+v//Pi8wjtJ7ImxuCm1e3iNSoKbACRrTDWPTxb8i014ZTpeXsXEfgAwPA3RIbMu7nIVjSLEFmM+1aJYMq7heVvw6VHiGl14hYxW2R/mvYR26tSW9DydvE5tBllSsEDwH3fiL/ZfnOU+6tU4u9QXySyNTXl6i8yNqU5eYm//72fApBEN1GLIVV/3eqOonNwF5kuqpoJ34tsZZMele/ba4YIYj1Caz7KkcpgcGMjjbLmZv2TIoiYuVeky8vz22wx4uV6pOjjNnZ/FGSI6n3PUBGwJJ8TtRBGUZuUw2Zj9ovg5tRa0wiMBenignPRrHo/N9VytsUY2AAiMDEf8rhxjghsNDrRjeTkLSbuajFY/JTrU0o+vyf3i6HI654oO+pk/+fKx07e4j9BY23DuKWim8uzmQg0vMJKhlXbmdpm5N/B1O1i5FYS3Dh5iflJtr9u6rIClF0AfZ9WfntXqYDOE0SQVTq4aTVCWTvha/att/lgVJtfO9P9sAGmgMU1QHSvGf+jv+szkUVpNbzyIu3gHmKiM3Pm70FVtRkJTPu77Eyzwd3K7zowzhRb21oMNgWvIb1vfpI+qn3uwaYvG5VRqUyTIZLVMbixEdOq4I0kuNEXm+buOLwCGPm2+Da7bQHQcogo3jMyDuU99l3ZbqiUC2LY7C8Pi9E4RlpHEVAYh3gCQHyk+BltVg9y/ajodjEPgnKSgFP/U/6e0hfD0sN+sxPFz4fXiwAKEBcXQBRkfjnItA8g+p3bjBLdQcbuFs8w0eVkbPMDP4r3pGmEcrh2ZcWBPm1MhaZ+7UXwZ3wMiBlujTo/oJx8DRD1B3cuFt8o290Fi7Q6MX9F2hVR3Hr8J9ElZU6tBib+LDJP7ceV397KqDWi9uXU/0w1IOa/w+hmLhT3rRQjqfo/X/12GTXpXvPXqA1NI0SwrS+wnN0hIhlzYTYiZ24aS0Fx0hnTfePF/eg3Yo6J7+8RmZhdHwC/lppK/kKpOUtSzoviSfPABgDu/sJ0f0BJ0eH1yFKjYCAmUTMYys7nUXpOkIk/AcPfFN005hw8TPeb9TUFNubcgkzZEiOdq0jhm3cVdLxbuU9Ib1FoWNk8NKXZOZiKOQM6ivoAY/ExULYtlvSYKka/VJT+7jwBGPSS+B0j3ipblAmIi2r/52qeRh/+BjDnjGnejZryaApMXiPqQxorO0fRReTWRIxWIaJyMbixEa2cuTFUsmcDYZ4FMc5kmh5r2vbtXWKK+RM/K48rPZNoygXl6COjdneJGor+z4l5XAAxrPndUNP6LYAY5nx+swhm7JxNQzsBMdyyy4MiOHLxE2urPL5DTC5nNHaJ6f6ACrIA5rUmKo0oegVMGQ33pmIElpFH05rVZIx+X9R7tC0Z3mtc+A6oenaDGr7R7wFzTlt/rSuiRobdUjZSL0dL5WcCV3aJ7pWbXYHXfJry5JLgJivetK2yEUbG4cGX/hZ1NyqNGLH053/E3CAqVeU1FAGdRI3GLw+XvGYfUbR8+R8Akii4NZ/236jdGDGJmWeYmEq/+yMi/V9RXYl5nYVx2QBAdC+lRInz8Qgx7VM6Q3SzQvspa2eczAKlqmRuiIhuIQxubERry5qbjDjRPdT+LhHMFGSJtUh+f1oMQx40V4xgcfCoeheKeeYmO1EU8RqDHCPPUNOQaN+2omDYqPkgEdykXxWPAzuL+WHajBQ1OKV1e1hMMObiL35flwdFt8vyIaZh22EDxHDF56PKHm+u3zOiSyl8gghSxpSzDow58wnCzO9r7MScLYBYUdjIfMkCazAf+XMzk38REd0C2C1lI2pb1dxIkpg+/epu4M8XxPDWK/+IkULG+VV2LhJrh3zYWixYV1pBNrBjkVh0EBDzziSfU3bPJJ8TXUzmzCfGa3uH8rnmA5WPm0aInx5Nxdw2pY14G3h0CzDnLDB5LTDiTdE9M2m1qQ0th1b6dgAQo3X6zC47yVpFdKUyN5aYjzRq1rfqr10VnSeJn8ah70REJGPmxkZslrmJ+lNMRlba8dWW9z/1q3IBO0AMuz72vcicDHjONEW/sZj24jZxXFHJardaB5G1aT4YeGi9CKgGvADsX2bax6e1chK3ZhEVn4fO1TTSynz12aCuYpXczDgxbLq2mAc0Fc31Mu1vsRClcSZca2nSXQy5Nx8pRUREABjc2IymZLRJnc9zYz5s2pxxGHdpuSnAgS/FMOy+JTPZnt8qfmZdVy5k2PkBsUDcxW2myd68WwKPbBRdJ2qNaZp7QNStGIMbB3dg/DIxKijprJhMrboCOppW160t5jU3Fc1z0qR77Q0trs3gjYioAWNwYyNaWxUUmw+broyDh1i/xzizb1aCWEU6N6Xsvq5BYgZVtUZMImecyM63rZiczRKdm6noWKUS3VoVjVCqT6qauSEiojrHmhsbkUdL1WbNjSSJ1aT/fAlIPAP8tdA0asnZrL7EyWztG+NEYeOWKedSAcRMu3GHlRPpAWKytyd2ifWNtDrT4nfB3UWRb3laVDAaqb6rSs0NERHZBDM3NqKtreUXigvFJG+SBPz5InCwZPK7A0tN+2jsxdT6kd+Lx8MWiiHYZ38XRb/G7o7zm02zAFekw3hlMW7P6WKbk3fF0+YPmSeWFig92V1DwOCGiKjeYnBjI+ramMRv739Fl9DwN8XqwcbFEktz8BCLEBp5NgPuXSHqZeydlNurwnwSPKPyVkI2p3Op3vo/9YGiW8rddu0gIqIyGNzYiNUzNyfWAFtfFff//bBk3SOVmMju6h7lvkFdlYGLRzORYTEPbICy3VKl2buIaf1vxRVtS0/iR0RE9cYteFWqH6q1cGZeOrB6MhC1uexz5mspGRd09O9gmlAOEHPGdJ4o5ojxCBXbVJryZ7j1MAuAtI6iC8m4IvWgucDLcSJLdCtiQTERUb3FzI2NaEuyHTcV3ERtEnPExJ8Q86bs/RTIjBfBSumFIQFRNBzY2bSScNeHTMW+xQVASC8xmsnSJHmAcg6V2YeAolwRIF38S9Ts3MpYc0NEVG8xuLGRamVu8jPEz4wYMepp23zxuN2dloMbFz8xeqnlMFEc3Gq46TmtDnhsa8W/z6e1WFzSxV+5TlK7MVVvc2Nl7wJABUCqeJ4bIiKqcwxubKRaNTf5mab7f5t1B13dV37mBgDu/gLITlIWEVeFSnXrdjtVRq0WGZuCTGZuiIjqGdbc2Ei1MjcFZsFN7AHT/Sv/lJ+5AcTF92YDG6pc2ADAJQDwbmXrlhARkRlmbmxEU53MjXlwY+7qHtPEesb6GgBw9qtBC6lSE74HDMViJXAiIqo3mLmxEW115rkpyBI/VaU+NnnGYBXgY5ZFcL6JVa7p5qlUDGyIiOohBjc2Ur2C4pLMjfmikn5miyc6epq6ogDlrMFERES3CHZL2YhWcxPBjSSJLIExc9PpXiAjVswC7NsOSDottjt5K7M17JYiIqJbEDM3NqJWVaHmRpKAP54F3m0GpFww1dy4+ANP7gOm/K4sFC4T3FRhCQQiIqJGhpkbG6nSJH4HlwOHV4j7p9eZMjfmQ4+9mpvuO3mbAhpHL9aDEBHRLYmZGxup0mipvZ+a7sceNNXcOJgt1Gge3Dh6mjI3LuySIiKiWxODGxsx1twYygtu9MVAZpzpcewBoNBC5sajqdkxhUBAuLgf2MV6jSUiImpA2C1lI5VmbnKSTUO8tY7KOW7M1zUy73rKzwACw4E5Z1lMTEREtyxmbmxEW9lQ8Kzr4qdbMBDS07RdbSfWhTLn4CF+hg0oOSao/MUwiYiIGjleAW3ENFqqnEn8MuPFT9cAILi7WGIBEIs0lhwre2IXcHkn0Hli7TSWiIioAbF55mbJkiUIDQ2Fg4MDevXqhYMHD1a4/+LFi9GmTRs4OjoiJCQEzz77LPLz8+uotdZT6Tw3WcbgJhDwN5uoT2dhBWrPZkD3KYDW3sqtJCIianhsGtz8/PPPmDNnDhYsWICjR4+ic+fOGDFiBJKSkizu/+OPP+Kll17CggULcPbsWXz99df4+eef8fLLL9dxy2uu0pqbTGO3VBAQ0Mm0XedSyy0jIiJq2Gwa3Hz00UeYPn06pk6divbt22PZsmVwcnLCihUrLO6/d+9e9O3bF5MmTUJoaCiGDx+OiRMnVprtqY+M89xIUjkjprISxE/XQMDLbKK+3LQ6aB0REVHDZbPgprCwEEeOHMGwYcNMjVGrMWzYMOzbt8/iMX369MGRI0fkYOby5cvYtGkTRo8eXSdttiZj5gYA9JJZcFOUDyRHAcnnxOPSxcGZ1+qohURERA2TzQqKU1JSoNfr4e/vr9ju7++Pc+fOWTxm0qRJSElJQb9+/SBJEoqLizFjxowKu6UKCgpQUFAgP87MzCx337qkCG4MEuw0EF1RS/sAeWbZGdeAum8cERFRA2bzguKbsXPnTrz99tv4/PPPcfToUfz666/YuHEj3njjjXKPWbRoEdzd3eVbSEhIHba4fFqz4Eauu4k7ogxsAMA1SPy86zPxc/hbddA6IiKihstmmRsfHx9oNBokJiYqticmJiIgwHK2Yt68eXjooYcwbdo0AECnTp2Qk5ODxx9/HK+88grU6rKx2ty5czFnzhz5cWZmZr0IcBSZG31JcJN7Q/z0bgVkJ4oJ+jxK2trtIaDV7WLRTCIiIiqXzTI39vb26N69O7Zv3y5vMxgM2L59OyIiIiwek5ubWyaA0Wg0AABJsjzqSKfTwc3NTXGrDzQq88xNyVw3xuAmpBfw9HHgyQOAnaPpINeAsnPcEBERkYJNJ/GbM2cOpkyZgh49eqBnz55YvHgxcnJyMHXqVADAww8/jODgYCxatAgAMGbMGHz00Ufo2rUrevXqhYsXL2LevHkYM2aMHOQ0FGq1CmoVYJDMCopzU8VPJy9xIyIioptm0+BmwoQJSE5Oxvz585GQkIAuXbpg8+bNcpFxTEyMIlPz6quvQqVS4dVXX0VcXBx8fX0xZswYvPVWw6xD0arVKNQbTBP55aSIn07etmsUERFRA6eSyuvPqUBsbCxUKhWaNGkCADh48CB+/PFHtG/fHo8//rjVG2lNmZmZcHd3R0ZGhs27qNrO+xP5RQb8+8JghHg5Ad/fC1zcBoxdAnR90KZtIyIiqk9u5vpdrZqbSZMmYceOHQCAhIQE3H777Th48CBeeeUVvP7669V5yVuScSI/OXNjrLlh5oaIiKjaqhXcnDp1Cj17ipWqf/nlF3Ts2BF79+7FDz/8gFWrVlmzfY1amSUYctktRUREVFPVCm6Kioqg0+kAAH/99RfuuusuAEDbtm0RHx9vvdY1csa5bgxlCooZ3BAREVVXtYKbDh06YNmyZfj333+xbds2jBw5EgBw/fp1eHvzwlxVcuZGL4llFwqzxRMMboiIiKqtWsHNu+++iy+++AKDBg3CxIkT0blzZwDAhg0b5O4qqpwxc6M3SEBeSdZGrQUc3G3YKiIiooatWkPBBw0ahJSUFGRmZsLT01Pe/vjjj8PJyclqjWvs1HLNjUE5DJwT9REREVVbtTI3eXl5KCgokAObq1evYvHixYiKioKfn59VG9iYKTI3HClFRERkFdUKbsaOHYtvv/0WAJCeno5evXrhww8/xLhx47B06VKrNrAxU4yWYnBDRERkFdUKbo4ePYr+/fsDANauXQt/f39cvXoV3377LT799FOrNrAxM85zYzBIQFaC2Ojsa8MWERERNXzVCm5yc3Ph6uoKANi6dSvuvvtuqNVq9O7dG1evXrVqAxszReYmveR982xmwxYRERE1fNUKblq2bIn169cjNjYWW7ZswfDhwwEASUlJNl/SoCHRmBcUp5UENx4MboiIiGqiWsHN/Pnz8fzzzyM0NBQ9e/ZEREQEAJHF6dq1q1Ub2Ji56MRgtcy8YiAtWmxk5oaIiKhGqjUU/N5770W/fv0QHx8vz3EDAEOHDsX48eOt1rjGzs9NzPKcnJkPpMeIjczcEBER1Ui1ghsACAgIQEBAAK5duwYAaNKkCSfwu0l+riK4yUm7DhTnASo14B5i41YRERE1bNXqljIYDHj99dfh7u6OZs2aoVmzZvDw8MAbb7wBg8Fg7TY2Wr6uOjgiH6FxG8UGt2BAa2/bRhERETVw1crcvPLKK/j666/xzjvvoG/fvgCA3bt3Y+HChcjPz8dbb71l1UY2Vn6uDpir/QnjkreJDR5NbdsgIiKiRqBawc0333yDr776Sl4NHADCw8MRHByMJ598ksFNFfm56jBEs8e0gRP4ERER1Vi1uqVSU1PRtm3bMtvbtm2L1NTUGjfqVuHvUAQX5IkHWgeg28O2bRAREVEjUK3gpnPnzvjss8/KbP/ss88QHh5e40bdKvxzLkCtknBd8sKOe08iP3SIrZtERETU4FWrW+q9997DHXfcgb/++kue42bfvn2IjY3Fpk2brNrAxsz5xgkAwClDGB5fdQhzR7XFEwNb2LhVREREDVu1MjcDBw7E+fPnMX78eKSnpyM9PR133303Tp8+je+++87abWy0VPHHAQAnDM0BAF/tvmLL5hARETUK1Z7nJigoqEzh8PHjx/H111/jyy+/rHHDbgk3LgIAoiQxt81toZ62bA0REVGjUK3MDVlJcT4AIAcOAICCIs4RREREVFMMbmypuAAA4OToDADIKSy2ZWuIiIgaBQY3tlQS3DwxVAyrzynQ27I1REREjcJN1dzcfffdFT6fnp5ek7bcevQiuNHpHAEUIKeAmRsiIqKauqngxt3dvdLnH36YE9FVWUnmxsHRGUA6shncEBER1dhNBTcrV66srXbcmkqCG0dHRwBg5oaIiMgKWHNjK5Ikd0s5OomC4twiPQwGyZatIiIiavAY3NiKvlC+6+ToBEDEO3lFLComIiKqCQY3tlIyxw0AODo6Qa0S99k1RUREVDMMbmyl2JS5UWl1cLYX5U8sKiYiIqoZBje2YszcaHSASgVnnQhuONcNERFRzTC4sRVjzY1WBwBw1mkAcJZiIiKimmJwYyvGzE1JcOMiZ24Y3BAREdUEgxtbKZnjBhoR3Dix5oaIiMgqGNzYijG4kbulWHNDRERkDQxubEWvDG5cSmpucllzQ0REVCMMbmylnMwNu6WIiIhqhsGNrZSquWFBMRERkXUwuLGVUpkbU0Exa26IiIhqwubBzZIlSxAaGgoHBwf06tULBw8erHD/9PR0zJo1C4GBgdDpdGjdujU2bdpUR621In3pbqmSeW6YuSEiIqoRrS1/+c8//4w5c+Zg2bJl6NWrFxYvXowRI0YgKioKfn5+ZfYvLCzE7bffDj8/P6xduxbBwcG4evUqPDw86r7xNVVqnhtXB9bcEBERWYNNg5uPPvoI06dPx9SpUwEAy5Ytw8aNG7FixQq89NJLZfZfsWIFUlNTsXfvXtjZ2QEAQkND67LJ1mNcW6qk5sbNQZxPZl6RrVpERETUKNisW6qwsBBHjhzBsGHDTI1RqzFs2DDs27fP4jEbNmxAREQEZs2aBX9/f3Ts2BFvv/029Pry61QKCgqQmZmpuNULcubGAQDg5lgS3OQzuCEiIqoJmwU3KSkp0Ov18Pf3V2z39/dHQkKCxWMuX76MtWvXQq/XY9OmTZg3bx4+/PBDvPnmm+X+nkWLFsHd3V2+hYSEWPU8qk1eW8oeAOBuDG7y2C1FRERUEzYvKL4ZBoMBfn5++PLLL9G9e3dMmDABr7zyCpYtW1buMXPnzkVGRoZ8i42NrcMWV6B05qakWyqD3VJEREQ1YrOaGx8fH2g0GiQmJiq2JyYmIiAgwOIxgYGBsLOzg0ajkbe1a9cOCQkJKCwshL29fZljdDoddDqddRtvDXLNjWizm6P4KPKK9CgsNsBe26DiTiIionrDZldQe3t7dO/eHdu3b5e3GQwGbN++HRERERaP6du3Ly5evAiDwSBvO3/+PAIDAy0GNvVaqcyNa0nmBgCyWHdDRERUbTZND8yZMwfLly/HN998g7Nnz2LmzJnIycmRR089/PDDmDt3rrz/zJkzkZqaiqeffhrnz5/Hxo0b8fbbb2PWrFm2OoXqk+e5EUGZRq2Ca8ksxeyaIiIiqj6bDgWfMGECkpOTMX/+fCQkJKBLly7YvHmzXGQcExMDtdoUf4WEhGDLli149tlnER4ejuDgYDz99NN48cUXbXUK1SfPUOwgb3JztENWQTEy81lUTEREVF02DW4AYPbs2Zg9e7bF53bu3FlmW0REBPbv31/LraoD8tpSpu40N0c7xKXnca4bIiKiGmDVqq1Yytw4sFuKiIiophjc2EqptaUATuRHRERkDQxubKXYQnDjwIn8iIiIaorBja3INTem4MY4SzG7pYiIiKqPwY2tWMrclEzkx24pIiKi6mNwYyuWam64BAMREVGNMbixFQuZG9PimQxuiIiIqovBja1YqLlxY3BDRERUYwxubKUwW/y0d5Y3+buJQOdaWp4tWkRERNQoMLixhaJ8oChX3Hf0lDe39HOBSgXcyClESnaBjRpHRETUsDG4sYX8dPFTpQZ0bvJmJ3stQjydAADnE7Ns0DAiIqKGj8GNLeSliZ8OHoBa+RG09ncFAJxPYHBDRERUHQxubMEY3Jh1SRm1CXABAEQlZtdli4iIiBoNBje2UEFwY8zcXGC3FBERUbUwuKlrWQlARpy4X0FwE5WYBUmS6rJlREREjYLW1g24pWQlAh+2MT129CizS5iPM1QqICu/GCnZhfB11ZXZh4iIiMrHzE1durpb+dhC5sbBToMmno4AgEvJrLshIiK6WQxubMlCcAMALXxFUfHl5Jy6bA0REVGjwOCmLuWkKB+XE9w09xHBDTM3REREN4/BTV3KTlQ+Li9z4yeWZLjM4IaIiOimMbipS9lJyseVZG4up5i6pa6n5+HldSc5RJyIiKgSDG7qUk6y8nElmZvY1FwUFOsBAE/+cBQ/HojBxOX7a7WJREREDR2Dm7pUxcyNr4sO9lo1DBKQkl0IAIiMTQdgekxERESWMbipS6UzNw7uFndTqVTwcrIHAKTlMJghIiK6GQxu6ookKQuKXfwBJ+9yd/dwsgMApDK4ISIiuimcobiu5GcA+pJA5T+XAK0OUGvK3d3LuSRzk8vghoiI6GYwuKkrxi4pnRvg7FPp7p4lwU3pzI2zffkBEREREbFbqu4Yi4mdfau0u3nNjfkCmk46xqNEREQVYXBTVxJPi5/uTaq0u5y5yS1EVkGxvJ2ZGyIioooxuKkrURvFz5bDqrS7V0lBcVpOkWLElFqlsnrTiIiIGhMGN3UhLx2ILlkRvO0dVTrEvObGvO6moNhg7dYRERE1Kgxu6sKl7YChGPBpA3i3qNIh5qOlzEdMGWcsJiIiIssY3NSF2EPiZ4vBVT7E08k8c1Mkby8oYuaGiIioIgxu6kL8cfEzsEuVDzHP3KTmFMjb2S1FRERUMQY3tc1gABJOiPuBnat8mDFzU6SXEJOaK28v1BtgMEjlHUZERHTLY3BT29KuAIXZgNYB8Gld5cMc7TVwtBPDvs8nZCueK9Qze0NERFQeBje1LT5S/PTvAGhubgI+H1eRvTkak6bYzrobIiKi8jG4qW3xJV1SAeE3fWjXEE8AQHGpbiiOmCIiIiofg5valnJe/PTvcNOHRrQwrRoe5O4gd1OVLiqOSsjCp9svILewGERERLc6Bje1zRjceLe86UN7NzcFN12aekBnJz6u0pmb9zafw0fbzmPbmcTqt5OIiKiRqBfBzZIlSxAaGgoHBwf06tULBw8erNJxq1evhkqlwrhx42q3gdWlLwLSosX9mygmNgr1dkKAmwMAoEuIB3Ra8XHll6q5ib6RAwCKZRqIiIhuVTYPbn7++WfMmTMHCxYswNGjR9G5c2eMGDECSUlJFR4XHR2N559/Hv3796+jllZDWrSYmdjOGXALuunDVSoVnhjYHG38XXFneBB0WtEtVag34MjVVJy+ngFJkhCXngcAyC3So0hvwOc7L+JUXIY1z4SIiKjBsHlw89FHH2H69OmYOnUq2rdvj2XLlsHJyQkrVqwo9xi9Xo/JkyfjtddeQ/PmzeuwtVWUHiNWATd2Sfm0BKq54OXUvmHY8uwABHk4ypmb2NRc3LN0H+74dDdScwrlTE5ugR67L6Tgvc1ReHvTWaucChERUUNj0+CmsLAQR44cwbBhppWy1Wo1hg0bhn379pV73Ouvvw4/Pz889thjlf6OgoICZGZmKm61bnEnYGkf4Mou8di7lVVe1lhzc/q66RwuJJnmwMkpLMaNkq6pVHZRERHRLcqmwU1KSgr0ej38/f0V2/39/ZGQkGDxmN27d+Prr7/G8uXLq/Q7Fi1aBHd3d/kWEhJS43ZXSDIbtn18tfhZjXobS4zdUrFmMxabBzq5BXpk54t1qHILOVyciIhuTTbvlroZWVlZeOihh7B8+XL4+PhU6Zi5c+ciIyNDvsXGxtZuI/WmRS6Rny5+elmn68zYLXXRLFtz+rqptia3SI+ckqAmp4DDwomI6NZ0c1PmWpmPjw80Gg0SE5VDmBMTExEQEFBm/0uXLiE6OhpjxoyRtxkMot5Eq9UiKioKLVq0UByj0+mg0+lqofXlKM4vu82zmVVe2r4kuDHvijqjyNwUI7skqMnhnDdERHSLsmnmxt7eHt27d8f27dvlbQaDAdu3b0dERESZ/du2bYuTJ08iMjJSvt11110YPHgwIiMja7/LqSosBTfu1mmXMXNj7mKpmhtjxia/yAA9F9gkIqJbkE0zNwAwZ84cTJkyBT169EDPnj2xePFi5OTkYOrUqQCAhx9+GMHBwVi0aBEcHBzQsWNHxfEeHh4AUGa7zRTlKR9r7AEXf8v73iRjzY0586UZcgv1cuZGPC6Gq4OdVX43ERFRQ2Hz4GbChAlITk7G/PnzkZCQgC5dumDz5s1ykXFMTAzU6gZUGlRcoHzs3gSwUvstZW7M5RbqkZ1frHjM4IaIiG41Ng9uAGD27NmYPXu2xed27txZ4bGrVq2yfoNqorhU5sZKXVKAaSh4eXILihW1NtkFxbBOzoiIiKjhaEApkQaidObGw4rBjYVuKXM5hXpkF5iGgOcWcDg4ERHdehjcWFvpmhsP64yUAsrvlnLRiQRcrllBMcARU0REdGticGNtpUdLWbNbyixz0ynYXb7f0s8FAFCkl5Cea5qZOJfBDRER3YIY3Fhb6eDGr53VXtq85ua2UC/5vjG4AYCUbFNwk81uKSIiugUxuLG2opLgxqsFMHktENTFai+tVZsW3+wZZgpuQr2dYK8p+1HmcpZiIiK6BTG4sTbjaCmf1kCr26360gkZpqxQx2A3+X6wpyMc7csWG+dwfSkiIroFMbixNuNoKTsHq7+0+YTDXs728v0gd0c4WwhumLkhIqJbUb2Y56ZRMY6W0lo/uHliYHOcup6Byb2awtFOA1cHLbLyixHq4wwnXdmPMpsFxUREdAticGNtxsxNLQQ3/m4O+OUJ05pbSyd3R2puIfzdHMrJ3LBbioiIbj0MbqzNWHNj51jrv6pfKx/5vuWaG2ZuiIjo1sOaG2szjpbS6ur01zrbl41TmbkhIqJbEYMbazPOc6Ot/cyNOUs1N+aZG4N5NTIREVEjxuDG2optlbkxdUsZp8MxLsXw1sYz6P7mNsSl51k6lKrpyNVUrDt2zdbNICKiUhjcWFtR3dXcmOtoYTmG3JJ5bjadTEBabhEOXL5Rp21q7J79+Tie/fk4Ym7k2ropRERkhgXF1laLo6Uq8mDvZuja1ANRCVnwcLLDo6sOI7ugGAXFelzPEAHXVV6ErSqtZB2vjLwiG7eEiIjMMbixtuLam+emMh2C3NEhyB3xJcFMfEY+zidkQyopt4lJVQY33+2/imAPBwxp61/XTW0UCosN4qfeYOOWEBGROXZLWVstzlBcVYHujgj2cITeIGHdsTh5++nrGfjq38tIyylEzI1czFt/Cs+vOVHhax2KTsWZ65m4kJiF349fr+2mNyhFJUGNMcghIqL6gZkba6vFGYpvRo9QT8RF5mHtkVh52/nEbLy58SxOxWVgYs+mAIDUnEIUFOuh05adJyc5qwD3LdsHAGgf6IYz8ZkI9XZGpybuZfa91RTrDfJyGEXM3BAR1SvM3FibPFrK1sGNWDU8M7/sRH4bT8YjNadQfpyWY7lm5FqaqRvrbEImAOBySjYAQG+Q8L8j13D1Ro7V2tyQmHdFMXNDRFS/MLixNmNwU8ejpUrrWRLcWBLi5YQUs+DmRk6Bxf2MBbMA5Lod48rk/15IxnNrjmPeb6et0NqGxzygYeaGiKh+YXBjbTaaobi0Vn4u6NrUw+JzqTmFuJFdoHhsSXJW2aAnviS4MRYnR6cwc8OCYiKi+oXBjbXJo6Vsm7lRq1X4esptaBfoBh8Xewxr5yc/l55bpJibpbzgJimzbHCzam80erz5l1xcnJCZD0m69WY/Ns/csFuKiKh+YUGxtcnz3Ng2cwMAXs72+OOpfig2GJBfZMDJaxmY9eNRZOQV4fi1dHm/1JxCfPLXBaw7dg0/Pd4bge4iMEvOttxdlZJdgJSS5wqLDUjPLYKns32tn099ouyWuvWCOyKi+ozBjTVJUr2puTHSqFXQqDXQaTXo18oHIV6OyIgrwqVkU3fSxhPxOHw1DQCw7UwiOgS5o2Owm8XMjSWJWfm3XnCjZ80NEVF9xW4payo2CwZsPFqqPE08nMpsMwY2APDp9ou4Z+leLN15CUlZ+VV6zZf+dxJLdly0WhsbgqJiU7aG3VJERPULgxtrKjZbmLKeBjfBnhVnlIzdTafiMsvtliotMjYd72+JQnZB2WHnjVWhXm92n8ENEVF9wuDGmnJTxU+tI6Cxs21byhFSSXBjdC0tt8rdUkbGYeIGg4Sz8ZkoKNZXuH+x3oCNJ+KRlFm1DFF9UsCh4ERE9RaDG2tKjhI/fVoBKpVt21KO/q19LW73LlUzcy4hS76AO9ppoFVXfj6JJUHKqr3RGPXJv+j/7g7svpBS7v7f7LuKWT8exT3L9la1+fUGR0sREdVfDG6sKfmc+Onb1rbtqEALXxc42JX92Id3sLx4pquDFmtmROD7ab3w+eRu6N28/MkBjZmbLacTAABJWQX4dl90uftvKBlOHpuaV+4+9ZX5CClmboiI6hcGN9ZkzNz4trFtOyrxwG1Ny2wbWs7K4AFuDugY7I7ezb0xulMgVj8eATuN5SxOQmY+Cor1OBabLm+7Uc4cOgBQUFRxt1V9xqHgRET1F4eCW1MDyNwAwIsj26LYYEC/lj6Y8f1RAECXcmYz7mFhGQetWo0ifdnAJCEjHyeuZSgu/GkVBDcNuTvHvKC4oAGfBxFRY8TgxloMBiDlvLhfzzM3jvYavDmuEwBg7YwIFOkl+LhYnnSwTwvvMtucdVrklWRd1s6IwLazifjin8tIyMzHwSuiqLqVnwsuJGUjNbeCzI2FoOC7fdE4cCUVH93fBfba+ptY5NpSRET1V/29ejQ0GbFAUS6gtgM8w2zdmirrEeqFiJIAxlINdO/mZYObTx8QgccbYzugR6gXejQT2Z3EzHycvJYBABjWXnRzZeQVobici39+qW6pjNwizPvtNP44EY9/LyRX+5zqAoMbIqL6i5kbazEfKaVpmG/r2hl9sHzXZQDA5pKiYF/XshmdPi19cPq1EbDTiNg4wE3M6ZOQkS+PquoQ5AZATNqckVcEbwuZoYJSI442HI+TH2fl1+85cwr1nMSPiKi+aphX4fqo+SBg5j6gIMvWLam27s080f2h7sjILYJekjChR0i5+xoDGwDwdxeBS3J2gSLgcXe0Q0ZeEd7bHIUBrX1xR3igfIwkSYrMTU5BMdYeuSY/TqniBIK2wswNEVH9xeDGWrT2gH97W7fCKtyd7LD84R5V3t/HWQetWoVig4S4dDGs28dFBy9ne2TkFeHnw7FYe/QaOga7QafV4Pi1dPRt6YNigyn7kZ5XhOMlXVoAkJzVcIKbQo6WIiKqVxjcUI2p1SoEuDvgWpppvhofVxHcXEkRC3TqDRI+3X4Rv5+4jsJiA94Y20HxGjGpuYrH9T64MV9+oYKZmK+l5eJaWp7F2iUiIqodLCgmq2hitqyDg50azvYaeDopZz1ed+yanPHYeiZR8dzVGzmKx1Vd18qSxMx8RCXUbvegchK/8jM3/d7dgQe+3I/jZnP/EBFR7WJwQ1YRbLbauI+LDiqVCl7OpvW17DQqmPVCIT5DuZ5UdErZzM2puAwM++gfecZjS0qvX2UwSBj0/k6MWLxL7iKrjCRJSM4qgCRVvXvpZmtu9l66UeXXrqqU7IJyR6IREd3KGNyQVZhnboxz5niarVc1e3Arxf4Xk7IVj2NSRebGuMZVSnYBZv5wBBeTsvHEd0cs/s7P/r6AtvM2Y83hWHnbsdh0eQ6eyJj0KrX973NJuO2tv/Dfvy9WaX+g7EgvS8yDpTwrz8Z8MSkLPd78C1NWHrTq6xIRNQYMbsgqgi0FN2bdUnd1CcLTQ1uVOc4o+obI3LQJcAUApOYUVrjm1B8nruODrechScBrv5+RR179eTJe3iexiquNf7TtvOJnVSgLisubx8e03dpLTaw+KAK6PRetnxEiImro6kVws2TJEoSGhsLBwQG9evXCwYPlfxtdvnw5+vfvD09PT3h6emLYsGEV7k91Q5m5EUGN+VDvEE9HPHt7a6x+vLfF42NKgpvW/q5Qq6DowrLk50OmbE12QTHWHI7FV/9exhqz4eTGImV9JS8W6u0s37+WllvBnibmXVHlZW6y8osUbbSm4sreICKiW5jNg5uff/4Zc+bMwYIFC3D06FF07twZI0aMQFJSksX9d+7ciYkTJ2LHjh3Yt28fQkJCMHz4cMTFxVncn+pGiKep5sa7JLgxTu4HANpSE/4ZGScJNGY/fF118HIuO+Ff6XqY6JIC5BElq5l/tuMi3tx4Fhl5poAiJjUXf59LRLv5m/HjgZhy224eqOyMSsa0bw5jzs+R5e4PlF9zU6w34J0/z+Gf88nINJuI0Nqjvzi3DhFR+Wwe3Hz00UeYPn06pk6divbt22PZsmVwcnLCihUrLO7/ww8/4Mknn0SXLl3Qtm1bfPXVVzAYDNi+fXsdt5zMBbg7lNl2d7cmmN4/DN891rPc/W4L9VQ89nGxtzgrsnmgUFhsQFzJsPMJt4mJBhMzC+Tjl0zqBkAEN9/svYrCYgNeXney3EU808zWv/rxQAz+OpuIX4/FISGj/G4t864o89FSvxy+hmX/XMKUFQcVmZuajP6ypJgzJBMRlcumwU1hYSGOHDmCYcOGydvUajWGDRuGffv2Vek1cnNzUVRUBC+vsqtXA0BBQQEyMzMVN7I+8xmLjV0m9lo1XrmjPfq38pWfc7DTKI5r7e+qeOztrEOIWReXUVJmPnILi5FbWIy49DwYJDHkvG9LH9hpTIti3dcjBJ2C3QEAsam5isU3v/z3Mr769zJ+i1Rm+VLNgp6zCaa/jxPX0ss938JyCopPXzdNRGi+hERSZu1lbqzd5UVE1NDZNLhJSUmBXq+Hv7+/Yru/vz8SEsof/mvuxRdfRFBQkCJAMrdo0SK4u7vLt5CQ8pcUoJqZ2LMpnO01eKh3syof4+pgp3js7WKPZ4a1LrNfTGoubv9oF+78dLc80qqZlzN0Wo1chAwAnZu4I9DDARq1CgXFBpy5bgpW1hy+hjc3nsULa08ogoO0XFOGxbz364TZjMmlmWduzO/nmAUa5hmh5OwC5BYW439HrpWbQboZ5t1v2fV8HS4iorpm826pmnjnnXewevVqrFu3Dg4OZbtFAGDu3LnIyMiQb7GxsRb3o5p7e3xHHJ1/O5qY1d9UxF6jhotOmcnxcdGhfZAbvnioOzqHeMDTSQQ/W04nIC49D5dTcrBq7xUAQFNv8XuMmRoA6NTEA3YaNYI9RPbHfK4b43pVBcUGxKTmIrugGPsv30B6ruVg43gVMzdFeoNcE2TefXb1Rq5i/y93XcZza47j078vlPu6VWUeOGWadX8REZGNgxsfHx9oNBokJipnq01MTERAQECFx37wwQd45513sHXrVoSHh5e7n06ng5ubm+JGtUOlUkGn1VS63zPDxJDwD+/vDGedcgUQYzHyiA4B+G1WXwxu4wcA+POkKZNnHP4cWhLcdCwJbnxc7BFUUtPTzLviAOtCYhbuX7YPD3y5Xx6ZZVzR3OhkXEa5E/uZBzeSZOqKizVbRiI6RTnr8oHLqQDKzvFTHem5tTcSi4ioobNpcGNvb4/u3bsrioGNxcERERHlHvfee+/hjTfewObNm9GjR9UXeKT64emhrbBv7hCM6RwEF7Pgppm3E5zslcGOr5soLs6ycAFvWjKE+/b2/mjl54IpEaFQqUSA0tLPRbGvX6ki5S92XcaZeFOXlatOixAvZUCUnlukWC/L6GJSdpkh40V6AwwGCVfNgpsrpZaUOBknurniLLxmZX48EIP7v9gnZ5nMMzfsliIiUrJ5t9ScOXOwfPlyfPPNNzh79ixmzpyJnJwcTJ06FQDw8MMPY+7cufL+7777LubNm4cVK1YgNDQUCQkJSEhIQHZ2zb8NU91QqVQIdBfdRq38XWGnUaGplxO+fKhsoOrvquxubB/oVua+n6sDts0ZiKfMJgls5Weqw/FxsS9TuHys1OzFXi728HcrO0rr9PVMXEo2/W3FZ+Thjk//VXQ/AUBRsYTErHxFRqd05saYYYlLz7uppR4A4Ju90Th4JRV7Lt6A3iAhPe/mMjf/XkguU0hdntScQmw6Gc/h5kTUYNl8VfAJEyYgOTkZ8+fPR0JCArp06YLNmzfLRcYxMTFQq00x2NKlS1FYWIh7771X8ToLFizAwoUL67LpZAXBHo448PIwuDpoFSOujJqaZVNcdFr8/lQ/RMamIT23CN2beZbZ36iVvylz4+fqgDAfZ+y+mFLu/p5O9nLABQCuDlpk5Rdjxvdi6YfFE7pgXNdgHItJVyy9YFSg1ytqbABlobJi32IDUrILLQ55L09SVr78MzOvSFH4nFVJzY0kSXjoazHRZYcg9zJZLaOdUUmISc3F78ev41B0Gubc3hr/V8Gs0lT3rqXlIuZGLvq09LF1U4jqNZsHNwAwe/ZszJ492+JzO3fuVDyOjo6u/QZRnfJyti/3uYFtfPHqHe1wLCYdQ9v5QaNWoXszy8P+zbX0NV3AXRy0CPNxLrPPiA7+2HJa1Hs52WvgbzbBYJ8W3vJzAPDMz5EY2TEA5+ItTyVQpJfkWZZLC/NxxpVSWZxrabmK4GbL6QT8dDAGMwa2QO/m3op9C4sNcqCUnFWg6JICLHfZmTMPsi4mZZUb3Dyy8pDi8bf7rpYJbuLS85CQkVelz6AiWflFSMkutPi5WIvBIKHIYKhSHVhDMfmrA7h6IxdfT+mBoe38Kz+A6BZl824poorYadSY1r85lkzuhru7NanyceaLdmbnF6NFyQU92MMR7o5iBNZ/RrSV90nNKUSAWbdUnxZlvxm3nbcZn5azuGZRsQEXky13jYY3cS+zzXwUV2xqLp79ORI7o5LxwJf7y6yCfiPHNEeOpeDGvOYmv0iPf84nK5aciM8w/a7ocgIwS9mf7IKy2wa8twP3LN2Hs+UEeVX11E/HMPiDnTgWk1aj1zGKuZGLad8cxuHoVHnbQysOoP+7OxTD8xsySZLk7OAPFcy4TUQMbugWoDdI6NvCG4/1C8Nrd3XA2hkR+H12P0UGIyW7EAEl3VL2GnWFXV6WFOoN8iiodoHKEXnhTTzK7G9eVPz6H2eQW2hah2vF7iuKfc0nAEzKKkBajjLoMK+5eXr1MUxZcRCrD5kufuYLiF5ItByAWZqN2XzhT0BcXI1B095L1V+wU5Ik7IxKBgCs2BOteO5aWi5ulAzZzykoVsxTVJFnfj6Gv84m4t5lYvJPg0HC/supSMoqwOXknEqObhhumM2PdCEpy4YtIar/GNxQozXvzvaw16ix4K720GrUmHdnewxr749W/q7oVJJNGdM5CAAwrX8YmvuKLpJm3k7yfQC4MzwQJxcOt/g7jKPHC4tNwU2vMGWXTYegstMPLPrzHD7edh55hXr8Y7zQPyIKqg9Gp+J6eh6W7ryEracTFOtSJWcVKGZUBkwzIV9Ly5W70r7bd1V+Pt4scLlo4aJYpDfgWrrlEVzmGaDMPFMQVVBc/VXOzS/S5hMaJmXlY8THuzD5qwMAgBf+dwKjP/0XR65Wnt05G688r4y8IrntKVZY+iIuPQ+/Hr1W6SKstSnGbCRebGqeYtoBIlKqFzU3RLXhsX5heLB30wprLt6/NxyTejbFbaGe0GrUWPZgN4T5uCiGpLcNcIWrgx0imntj32VlxsJZJwqP1xyOlS8+vZt7YdXeaHmf8mqKPtl+Ae6OdijUGxDs4YjBbfzQM9QLB6NTMf3bwzhdkrV4c1xH+Zjk7AKciEsHADjaaZBXpJeDm1VmWZA8sxXZE82CmwtJ2ZAkCclZBVj4+2nc1z0E/1l7HCnZlicyTMjMlydETM42vU5NlpMwz6Scvi7mElKpVDh6NR05hXqcS8jCjewCnE8QAcu5hMxKM2mlR3aZB1A3u65XYbFBsWwHADz09QFcTs5Bak4hpvVvflOvZy2lg5kDV1LLTF9ARAIzN9SoVVZM6mCnQUQLb3nV8pEdA+XlHD66vzPGdA7CY/3Exeyt8R3h7WyPyb2ayscb63e+KcmUuDvaoX2gssbG1UH5HaJrUw/5/ut/nAEA9GvpA5VKhfHdggFADmwAYJ9ZF9CN7AL58dB2YoJDY23MvxdMo8Gu3siVl2hIMOuWyi3U41paHr4/EINNJxMwddWhcgMbALhqVghtHtDUJGtgPrQ+LbdILrY2n3coKiFLzrgkZxUgr7DiTFFxqYyKeXbrRgXnV9rJaxnotHALPt52XrHdGJCtPmS7Gc5Lv+fWXmmeqDFhcENUjru7NcF/J3aFo70IkJr7uuDwq8Pw1vhO+H12P6yf1bfMJH+uDlqEeDni6aGtEN7EHfd2b4IANwe8PrYDNGoVvp7SA+ue7Iv/zeyjOK5fK1HAfE+3JvBxUWZ6tp4xFRgbJOBSyYV2SFsR3GTlF6NIb8DlFBE0lMxjiNMlkwbGl6qn+WBrFKISqlbLYj4RoXkGJDYtF3+dSUT/9/7G1tNVWwfO6HKpwuvD0aLbyby+5vT1THmU1/f7Y9BhwWYs+vNslX9HqlkR9s10S7235RwKig34ZPsFnLmeWWYEnKXapG/3RePNP87c9NxFlvx5Mh5TVx6U647MxaSWnmqg5muUkXVtOH4dr64/iWLOEWVzDG6IboJxBuROTdzRJcSjzPOt/FygUqnw7O2tsWF2P3xwX2eoVCo8HBGKUwtHyMN3uzfzxIIx7eGi08LHRYcBJSun22vV+Oj+LtCYLQVRpC970Wzl5yIvMZFdUIyrN3JQpJfgZK/BiPZi6ZITJcGNsaD4qSEtoVGr8FvkdcUw94psPpWAYr0BL/3vBF77/Yy8/XxiNqZ9exixqXn4ctflCl8jM78IBrPMijELYhwKbxwddsZsRfX9Zt1/KdkFMEjAF/9cxo8WRgmVDioKiw2KbqmbCW7MX2r0p/9iwPs7FK+fXVCseGwwSHhr41l8tfsKLlhhWY2vdl/Bjqhk/HW27OdjDG5al8zhVLr2imzv/346hu/3x2DdsapNmEm1h8ENUQ08OagFvJ3tsezBbhjXJQgvj25X7r7GDJDR1L5hOPTKMOx4fiDcnUyrow9o7Yt/XxiMTyd2Lfe1ejf3hotOHJOaU4hTcSLr0crfFd2aeQAAtp5OwIdbo3C+ZITUXZ2Dqrxie5iPM3RaNf69kILn1xzH6kOx5V5MK8og7IhKQvjCrfj07wsYt2QPFm44LXdLzR7cEoDoTou5kYvrZlmRA1dSLb7ekh0XFYESoCx0BoD0vEJFoXLp4KZIb8C7m8/hf0eulXl9O42qzLakUt0/+y7dwOhP/sV3+6KRklMgT+pYehLH6jBmhiwt0RGbKrZ1Lhl9Z43V5al2XE6pfIRebmExtpxOUMxqTtbD4IaoBl4Y2RaHXhmGkR0DsfiBrmhVapmHyjjaa+DqYFdme5CHI3o3L3+ivOn9m6OJp6M8k/IzP0cCAFr7ueCO8CCoVMDRmHT812xengB3Bwyr4sRvvZt74z8j2gAA1kder3Df2LQ85BQUW1yuYaZxhue/LiAyNh2r9kbLc+3cGR6Iln4uKNQb5JXSjYW85S0pEZeehyMxadAbJDmDYpy92Sg9t0iZuckqxPX0PLzz5znEpuZi8V/nsXTnJTy35niZC4v5shZGpef0mfTVAZyJz8S8307jerrpd5fuNjLacS4Jf58TmZj8Ij1OlSzIWqw3YNGms9gRlQRAZIGM5xKXrjynS8nZiEvPg0atwm2h4u8itQ66pQwGSTGVAJXPfARhVeZWWrknGk98dwSPfXOo0n3p5jG4Iaohtbrst31r8HN1wKt3tEOAmwOa+zjjpVFt4arT4ouHuqOptxOcdVp88WB32JstW9Ha3xXBHo7oWqrLrFOwO1wd7NAjtGrz93g72+P29hUHQhN6hECnVaOw2IAOC7bIgYyRJEll5soxah/oBm8XHYaX/I71JWn8Aa18FOdjLqJk5uZfj17DPUv3YvAHO5FXqC+TWUnLKVRkmVKyC/DFP5ew7J9L6P/eDizZcUl+7kypwMVSTU3pYebmrprVJFkqss4pKMbUVYfw6KrDiE3NxYdbo3Dnf3dj48l4/H7iOr7YdRlTS2aGTs0tlLsg49JzkZZTiKkrD+J/R67JWaaBrX0RVjJNwc1kbq7eyLFYx1OZ7w9cRa+3t+OXw7YrpG4o0s1mAs+wECSXtqHkS8O/F1LKrEPXEPwWGYftFrpP6wsOBSeqx6b1b64Yejy9f3NFPU6flj54bWwHzP31JADTmlrT+zfHzB+O4rZQT/wwrbdcZOxgV3b0WNsAVzw+QLzuy7+eRE6hHl7O9mjq5QQvZ/sy3VELx7SHRq3CAz2b4vi1dJwrGbL919kknL6eAWd7LX46GIM9l8pfy2tAa1Fj1LWpCLaMo53Cm3ggLj3f4gzIMwa1wL7LN7D6UKxcG3MsJq3MqKG03CJFm1NzC/FvOeuKHbmaJtdOFesNZQIlQAxFB0zrjZnbe9FUG1Q6cxMZm47cQtP+f56Kx46SOY12X0iRh9gD4mJoniG5np6PzacTsCMqWT4GAO7t3gSeTqLgvKo1NxeTsjBy8b9Qq1R4elgrzCrpDiwtI7cIzjqNPHIQALadERevHw7E4P4eIVX6fVWVkJGPgmI9mnnX3hIcVXUtTYwu7BBUdjZxo2K9AcUGyeK/IUD5eVjqViytiacjohLFv52vd1/BG2ZTPtRHOQXFcNaJkCEpMx/P/BwJO40aJxcOr5dLnDBzQ9SAaCxkiR64LQQzB7XAgNa+8rpUozoFYs2MCKx45DbYa9WKRUnXz+qL3s29sO7JPhjbJQhzbm+Nu7s1wdguwfB2EUW+3i72UKlUFoum+7T0wUMRobDTqOVlLYzGf74Xd/53N77YdVmuA7JkQMnosNJLU3QIckMbf8trXw1o5YNOwe6Kot+jMWkWuqUKFcO/JclUxBzm44w3xnXEc7e3BiBGt5xLyESx3oBjsekWJ+kzBlrdmnri1TuUNVU7zyfJ9/8+l4SFG04ju6AYR2PSMG7JHkxafkB+fvXBWLne6PT1TGSaLXlxLj5TEdzEZ+SVySIFezhiaDs/ed6kzHzLXYGACJ4e+voA4jPycCg6DcUGCYV6Axb/dd7iSJ4T19IR8c52PPGdKfsmSRJOlRSlH49Nx7U0600amFNQjOEf/4PRn/yLtJxCZOQW4Zu90Ypg0Nryi/SITslBdEoOJnyxDyM+3oVfj4qM2JAP/sEdn+6u8Bynf3sYfd75u9wCdfPas9gqvFfm+xtHOtZXK/dcQceFW/BXSbAr5ssSxful182rL5i5IWrgVCoVXhzZtsx2Y21GaV1CPLD68QgApsyJUadgd8Sk5qJ9yRISXUM88Pe5JNhr1CgsuSiaLzCqUSmDrcJiAwqLDWjp5yLP2GzOyV4Dd0c7dC/pHvN3c4C/mw6JJXPotA9yKymAVtb5qFXiPJ8b3lqxwOeRq2kI9nRU7Fs6c2Nkr1Fj67MDYKdRy3MFHY9Nx5j/7sbgNn7YesZyit1YkO3tbI9p/ZtjWDt/fLL9AtYdi5PbbbRqbzScdRq52NuceZFpVEIW/MwWTj0bnwl7s2+/RXoJJ66ly4+fGtISD/VuBp1WA61aDZVKBG0JGfn4Zm80BrXxk6cTAIAHvxZB1SvrTikWJy3SS4hLz0NkbDr+OBGPt8Z3hIejPe5dug+FegO2n0uSJ1WMS89TLLr658kETB9Q8QSGKdkFcNFpy81uAKKL7IcDMcgsyYKdjMvAsn8uYe+lGzifmIW3xneq8HdUJi49D49/exiP9AnFfSXZpqMxaXh69THEpubJE2UCwJe7LmNIWz/5b/tQdCqaeJadGDG/SC9n0P44fh2P9A0rs495t1RiZgEKivUVZjRK71+f7b10A5Ik3p9h7f0Vc1WdT8xG24Cys7DbGoMbIpJ9PKELXrmjHYJKukz6tvLBh9vOo3szT8wa3BL5RXp54kIAGN81GBuOX0fnJu4Y3iEAZ+Mz0S7QDdP7N0dGXhE2n4pHfpEBb206ixa+zlj9eATUKuXkiuFNPLDtTCI8newQ4OaAtgFli7KNF8uBrX3x1viOuJYmlqfYEZUsj3AK9XZC9I1crD4UI09c6O5oJ9c/tPJ3kTNYnUPc4WSvQW6hHkV6SRHYBLg5IKeguMxq68aMSaiPs8U2Gu29dANNK5k5uFBvwN9RpqzPmfhMBLorgzTjshPv3tMJE24zTRypUavg4WiHtNwifL7zIn46GIs/TsTj3XvDoVWr5NokAIi+kQNDqaHyf5yIxyd/XUCh3gAHOw26hnjIF3djW+w06jLzEW08GY/pA5ojI7cIUEHxdwCIeYrGfb4Hg9v44ouHelg87wuJWRj96b+K6Q3OJWTKa5X9cCCmysFNZn4R7DXqMoHUb5FxOH09Eyv3ROO+HiHQGyQ8+f1R+W/ioNniqldScuR5owAgOiVXbtMT3x3B7MEtcV+PEEWgHltOl1PpgDouLQ/NfctmIS8mZeFkXIYic3OzRdsJGflIziqQl5GpbcYsorHb1nyW8YuJ9XOdMwY3RCSz16rlwAYQXTFrZ0QgxMtJkbExGtTGFz9N7432QW5lLna+rjo8FBGKzPwiHIxOxdguQfLcNubCg92x7Uwi2ge5QaVSyTNEmxvbRawBplKpMLlXMxTpDVi1Jxp5RSI4GdTGF7eFeuH9LVGKIdmP9g3Dx3+J2YZDzWo7nOy1+PnxCKw9EivPLm1UbJBweN4wbDmdiP/76Zi83Xyl+dYVjIo7cz2zzIXu/h5N8Mth5dBz85jjTHwm1KWyYMbMhqX33dPZHmm5RfjpoCj0TcjMx5QVBwGgzASRxguzj4s9UrIL8f6WKPm5349fx+/HlVmyOz7drXg8pK0fdkQlITI2HReTsvHQ1wegUauw/bmBiiD1p4MxKCw2YNuZRKTmFFpcduSPE/Fl5m36zWw0nqOdRs4cVSQtpxAD3t8BDyc7rH48QlG/ZOxKu5iUjSK9AXsupihm6TZXUCyeNzIWmH+z9yqu3sjFsn8u4b4eIYqFSiNj03EhMQsLNpzGf0a0kbOf6aVGr10zC27iM/LgrNPCzcEOwz7aVaYdWfnFyC0sViz7UpEnvjuMU9czseWZ/mjpd3MjNI2SsvKRlV+MFhYCsNKME4Eag7DSmZv6iDU3RFShHqFeFi+wgAg2Ilp4lwlszLk52GH5wz1wZ3iQxecn926GsV2C8OwwUQcT6O4gv96XD3XHvDvb45U72iuOsdOoMaVPKHxcdBja1g/v3hMO51LzCD09tBWeGGjqRin9LbdTE3e8MLItHOyU/w3OGNgcOq0G/qUCMW+zi/VtYV6KQO3l0W1xe3t/2GvVKCg2lJnzZlg7fzzYuylcdFqLo9CiErIQXTLyqnRdVemMDgB4OVlerwwAvt9vCtYuJ+fIs2ibTwOgUol5j4yaejmhY7DlroUhbcWaZwDw2u+nEZ+Rj2tpeTgWky7vU1hswO8nRJBikIBub2zDE98dLjPUfnvJkPi5o9ri4wmdASiXGskr0uPznZcqXd5j/+UbyMovRmxqHh786gCyzOqXjLVehXoDLiVnY03JSLNAd+XfsDF+Mp8w8cz1TBgMkjwK6FKyqNGJSjBdwE/FZWD2j8ew99INjP98L8Z/vgef/HUBqTnKEVLGzFdceh4Gf7AT0785rGinkTHzWNX12rLyi3D8Wgb0BgmHoitfVNYSSZJw13/3YOiH/yCunEVzjQqK9XKdkTG4Mc/c1NcV6hncEJFNeTnb45MHuqJHyQVUpVLh9bEdML1/GIa188dj/cLgoiv7jfalUW1x+NVh+PqR2+Dv5oDWJRkfrVqFqDdH4tnbW8PBToNN/9cf0/uHWZzA0FmnxSN9wuDjYo+/nxuIHc8PwiN9QgGUzZiYZyJcdFqsn9UX3Zp6YGSHAEzv3xzLH+6B0R0DLJ5jE08nvDG2I04sGI6nh7ZSPBfg5oAivYT9l0V3Sen5jQLcywaWHmaTPpbuArM0O66nkx26mS0+2inYHR9P6IK3xndErzAvvHtPeJlRS3d1DsKMgS1wd7dg3BEeCEC5ftmC307jhbXHcTY+E3+eilfUkADAltOJ+HKXadh9fEYeTsVlQqUC7uneBD2aWa4Je39LFJ4tmbfJkqSsfMVF/UpKDub/dhqAGPFlPmrtcHSaPOLrhZFtFK8zpI1YvuTENdPM2HHpedh9MUUxam77uSScN+t6KSg2yKOcAOBYTDo+/uu8nLnRlgSn50syZoeupCK/yICD0amKdeIAwNleI9f4VLVrynxqAvMlSwAxHUHpYej7Lt3A8I//wdEY03t2KTlHzmbtLWckoZF50JWUWYDcwmJFQBR9I1cxx099weCGiOqdsV2C8cod7W9qDqGI5t5Y8UgPHHxlmKK7pH2QG165o708jLU0ESTdjua+LgjzcZaHQvu5KTM3pYOMYA9H/PpkXyx7qLvcjVLeiuHBno5QqVRQq1XoGOyuWHW8dDDzgFl9jaOdBm4OZdttvlDoN4/2xHv3hGNYyUKqlrTwdUFzs8Li/q18oFGLLr6fn4hARAtvNDErzL67azA+ndgVL41qCyd7LcZ2DoZrqfcvKjELvxy+hjs+/Rcvl0xFMKKDMiv16d8X8d2+aGw5nYCnfhRdfN2aesLHRafoSrLXqOU5jwDg8NWyo+AAMTS951vbsWLPFQDAQ72bQaNWYd2xOOy9mIJTZkt4AMDSnZdQWGxAcx9njO4UCOOfU6C7AzoEWc5UfbBVdNsZP6PNp+IRVTLdQelFcM0Zu7SMIxaNq9qfLZlKQJJE1505Dyd7ubA8MasAqw/G4Lv9V1FYbEBceh5+ORyLiEXbFeu3nTY7R/N5mk5cS8eQD3fi0VXKSQG/2x+N84nZ+GZvtLxt9wXT9AKWCv/Nma9Nl1VQLGfGPJ3s4Oaghd4gya9RpDfgz5Pxoi7LxhjcEFGjoFKpMKStv8Vaj+pwsteib0tvBLo74JXR7dCxgjlQjDoGu+O7x3qiuY8zHrjNNC9M6W67dU/2QYiXI94c11G+GAJAnxbeGG4WIBQU6y3WnzzUuxn83XT4bFJXhPk44/6S6QCMPJzsFIHG2K7BCDULbvq08EFp5qOE2gYq6zjcnezwQM+y89y46rQwSEBOoR6t/V3w6cSueP/ecKx85DaM6OCPwmID5v12Gk98dwSHr6ZBqzaN7FOrVZgS0QxB7g74/al+eKRPqGICxx3nRMF1clYBPtp2HjO+O4Lp3x5W/P7HBzTHg71EMDjrx6NY9o/IFBmzJ8YMw4iOAdBpNQgpyXKFejuXmcagb0vxORgzOXNHtYVWrcKh6DTEpedBpQIWjulQ5j0wMs73ZAxWoxKzIEkSzpllWsznLAIAT2c7OUN4Nj4TL/16EvPWn0L3N7eh7zt/44W1JxCfkY9v9kXLx5h3452Nz5SXI3l1/SkU6SUcuZqGxMx8XL2Rg72XUuTzOWS2pIl5Bm7tkWtYuOF0uRMJxmcou602nYwHAHRq4oH2JQGisU2v/X4aM384ipfXnSz3faorLCgmIirH94/1qrS4tbT+rXzx9/ODIEkSQryc0MK37CR1HYLc8e8LQwBAcVGZcFuIIutkYdodAMDQdv44UGopDfMJ6Cb3aoq+LXxwNj4Lj/UTXXKSJGF0pwCk5xahZ1jZLiHzzI2lob2zh7TC8dgMdGrijlNxGbiQlI11T/ZBXHoe/jyZgEf7hUGn1cjDr/u38sHSnZew+XQC1CoV4jPy8cKINorf/drYjlh4V4eS99gVZ14fgSU7LuHjv87jjxPxGNrOH+M/3yPXDVlq8xMDW+DHgzFIyy3CvxdSYK9VY96d7TH/t1Ny0faIDqK7sLmPM67eyEWoj5Pi/XK212DuqHa487+imNrfTYeHejfDufgs/FwyO/MDtzXF+K7BeG7NcQBilm2DJMlBjVG3Zp7QqlXIyi/GzqhkRaalNE8ne/iXZAi3mY3YKz1Z5Km4TCzZcRHujnbyzMYAkFuox9XUXFxOzlZ0rz2/5jgOXElV1Dxdz8jHmeuZ+GhbFLafM43Uu5FTiFV7o/HL4VismRGBS8k5aB/oipZ+rvhuXzTmlXT5GRkL0HuFeSEtpxD7L6fidFwGdrjq8P1+kZnaeDIe8zPzy63VqwsMboiIynGzgU3pY8ubDdhcM28njO4UgLScIowsqdkxzsXS3EJgVB4HOw3+b0hLnInPxJODWsJZp8WuFwYr2vP55O7lHh9gdiEqnbkBRPbplxlifiS9QUJhsQGO9ho083a2mAnSatR4amgrPFWqxqg08/dYq1FjZMcAfPzXefx7IQX93v0b+UUGeDvbo6DYgOyCYtwRHoi8Qj2GtfOHSqVCkIcjnhrSCt/uu4qOwW54fngbdAx2h6+LDi/+7wSCPRwRHiwCmV7NvbEjKhk9mnmhpZ8LVk69DZeTc9CtqQc6BrvL7/ukns2g1agxc1ALbDh+Hb6uOrw8ui3UahVWTb0Nn/19Ee/f1xlhPs5Yvusy3tp0Vj4HfzcHBHk4IiY1F1NLdREBoqsxr0jUqLg5mDI3pbuHZg5qgTvDAzF+yV5k5BUpRrkBQJC7A65n5OP5NccVy4AAysyMudGf/ivfbx/opujWyi3U48GvDiAttwj+bjr8+fSAMoENAHndtl5hXnLQGXktA7tL1e78cii20s++NqkkSSrnu0HjlJmZCXd3d2RkZMDNrf5NPERElJiZj0+3X8CUPqEVDju3piK9Afcu3QsvZ3useOS2GgV2NfXL4VjMW38KBcUG+Lrq8NP0Xgh0d8Su88kY1MYPjvblT45nLr9ID61aJddRSZKEa2l5aFJSA1VabGoutp5JxIO9m8oZtMTMfDjYacodEbj7Qoo8aaKrgxYHXh6K5345jj9PJVjc/7vHeuKhr8Ww/dvb+2NM5yDFlAMtfEWw+Oqd7aDTanD353tw1GxkWqdgd0y4LQR+rjrM/OGoPKt2Kz8XvDCyrdx118rPBRcs1NM42mnw7WM90aOZJ0Z98i/OJWThvu5NsO5YnKKWq0czTxy+ank0lk6rxomFwxGbmqsY2u7pZIdnb2+N+b+dRpC7A/59cYjFWdWr62au38zcEBHVM/5uDjWeqfdm2WnUWD+rr02DGqP7e4RgaFs/JGTmo4WvizxR36hOgTf1OqUn+FOpVHLdjSUhXk54rJ9y9uHKulY6NXGHi04LjVqFLx7qDid7LR7tF4bsgmL0CvPCF7suY0pEKAI9HKBVq9C/la98bG5hMbo19YCdRiXP//PevZ3R3Wxkm5gKIB0AcGze7Yr5llY8chu+338V/m46zBzUEt7O9gj2cITOTo21M/ug82tbAQDjugThamou/Fx1mN6/uTwy8dOJXXH0ahru6xGCIr0B6yOvy7Nfmwc2GrUKfVv6YNd5UTPUM8wLOq0GYT7KuqVZg1vi/h4hOBufiXu6NUEtrSlcJczcEBER1UBSZj505WR39AapTPYi9KWNAIDBbXyxcmpPvLLuJH44IOpVzr0xUhGUHY1Jw71L92Ja/+Z4ebRybTNLivQGGCQJOq0GZ65n4rfIODwzrHWl2a6rN3Lw3C/HMalXU/xyOFaemmDtjAi0C3TDgSs3MP3bI4ho7o1Fd3eSg8RZPx7FttOJmDW4JZ4a0vKmRjjerJu5fjO4ISIiqkO/HIrFkp0X8fWUHmjp54qs/CLM+vEY2gW6Yu6osgFMTkExnOw1dZZVyy/SY+GG09AbJLx7T7gcsFhaL8tgkJBfrK/y7Mo1weCmAgxuiIiIGp6buX5znhsiIiJqVBjcEBERUaPC4IaIiIgaFQY3RERE1KgwuCEiIqJGhcENERERNSoMboiIiKhRYXBDREREjQqDGyIiImpUGNwQERFRo8LghoiIiBoVBjdERETUqDC4ISIiokaFwQ0RERE1KlpbN6CuSZIEQCydTkRERA2D8bptvI5X5JYLbrKysgAAISEhNm4JERER3aysrCy4u7tXuI9KqkoI1IgYDAZcv34drq6uUKlUVnvdzMxMhISEIDY2Fm5ublZ73fqisZ8f0PjPsbGfH9D4z7Gxnx/Q+M+xsZ8fUHvnKEkSsrKyEBQUBLW64qqaWy5zo1ar0aRJk1p7fTc3t0b7Bws0/vMDGv85NvbzAxr/OTb28wMa/zk29vMDauccK8vYGLGgmIiIiBoVBjdERETUqDC4sRKdTocFCxZAp9PZuim1orGfH9D4z7Gxnx/Q+M+xsZ8f0PjPsbGfH1A/zvGWKygmIiKixo2ZGyIiImpUGNwQERFRo8LghoiIiBoVBjdERETUqDC4sYIlS5YgNDQUDg4O6NWrFw4ePGjrJlXbwoULoVKpFLe2bdvKz+fn52PWrFnw9vaGi4sL7rnnHiQmJtqwxRXbtWsXxowZg6CgIKhUKqxfv17xvCRJmD9/PgIDA+Ho6Ihhw4bhwoULin1SU1MxefJkuLm5wcPDA4899hiys7Pr8CwqVtk5PvLII2U+05EjRyr2qc/nuGjRItx2221wdXWFn58fxo0bh6ioKMU+Vfm7jImJwR133AEnJyf4+fnhP//5D4qLi+vyVCyqyvkNGjSozGc4Y8YMxT719fwAYOnSpQgPD5cndYuIiMCff/4pP9+QPz+g8vNr6J9fae+88w5UKhWeeeYZeVu9+wwlqpHVq1dL9vb20ooVK6TTp09L06dPlzw8PKTExERbN61aFixYIHXo0EGKj4+Xb8nJyfLzM2bMkEJCQqTt27dLhw8flnr37i316dPHhi2u2KZNm6RXXnlF+vXXXyUA0rp16xTPv/POO5K7u7u0fv166fjx49Jdd90lhYWFSXl5efI+I0eOlDp37izt379f+vfff6WWLVtKEydOrOMzKV9l5zhlyhRp5MiRis80NTVVsU99PscRI0ZIK1eulE6dOiVFRkZKo0ePlpo2bSplZ2fL+1T2d1lcXCx17NhRGjZsmHTs2DFp06ZNko+PjzR37lxbnJJCVc5v4MCB0vTp0xWfYUZGhvx8fT4/SZKkDRs2SBs3bpTOnz8vRUVFSS+//LJkZ2cnnTp1SpKkhv35SVLl59fQPz9zBw8elEJDQ6Xw8HDp6aeflrfXt8+QwU0N9ezZU5o1a5b8WK/XS0FBQdKiRYts2KrqW7BggdS5c2eLz6Wnp0t2dnbSmjVr5G1nz56VAEj79u2roxZWX+kLv8FgkAICAqT3339f3paeni7pdDrpp59+kiRJks6cOSMBkA4dOiTv8+eff0oqlUqKi4urs7ZXVXnBzdixY8s9pqGdY1JSkgRA+ueffyRJqtrf5aZNmyS1Wi0lJCTI+yxdulRyc3OTCgoK6vYEKlH6/CRJXBzNLySlNaTzM/L09JS++uqrRvf5GRnPT5Iaz+eXlZUltWrVStq2bZvinOrjZ8huqRooLCzEkSNHMGzYMHmbWq3GsGHDsG/fPhu2rGYuXLiAoKAgNG/eHJMnT0ZMTAwA4MiRIygqKlKcb9u2bdG0adMGeb5XrlxBQkKC4nzc3d3Rq1cv+Xz27dsHDw8P9OjRQ95n2LBhUKvVOHDgQJ23ubp27twJPz8/tGnTBjNnzsSNGzfk5xraOWZkZAAAvLy8AFTt73Lfvn3o1KkT/P395X1GjBiBzMxMnD59ug5bX7nS52f0ww8/wMfHBx07dsTcuXORm5srP9eQzk+v12P16tXIyclBREREo/v8Sp+fUWP4/GbNmoU77rhD8VkB9fPf4C23cKY1paSkQK/XKz4sAPD398e5c+ds1Kqa6dWrF1atWoU2bdogPj4er732Gvr3749Tp04hISEB9vb28PDwUBzj7++PhIQE2zS4BoxttvT5GZ9LSEiAn5+f4nmtVgsvL68Gc84jR47E3XffjbCwMFy6dAkvv/wyRo0ahX379kGj0TSoczQYDHjmmWfQt29fdOzYEQCq9HeZkJBg8XM2PldfWDo/AJg0aRKaNWuGoKAgnDhxAi+++CKioqLw66+/AmgY53fy5ElEREQgPz8fLi4uWLduHdq3b4/IyMhG8fmVd35A4/j8Vq9ejaNHj+LQoUNlnquP/wYZ3JDCqFGj5Pvh4eHo1asXmjVrhl9++QWOjo42bBlV1wMPPCDf79SpE8LDw9GiRQvs3LkTQ4cOtWHLbt6sWbNw6tQp7N6929ZNqRXlnd/jjz8u3+/UqRMCAwMxdOhQXLp0CS1atKjrZlZLmzZtEBkZiYyMDKxduxZTpkzBP//8Y+tmWU1559e+ffsG//nFxsbi6aefxrZt2+Dg4GDr5lQJu6VqwMfHBxqNpkxFeGJiIgICAmzUKuvy8PBA69atcfHiRQQEBKCwsBDp6emKfRrq+RrbXNHnFxAQgKSkJMXzxcXFSE1NbZDnDADNmzeHj48PLl68CKDhnOPs2bPxxx9/YMeOHWjSpIm8vSp/lwEBARY/Z+Nz9UF552dJr169AEDxGdb387O3t0fLli3RvXt3LFq0CJ07d8Ynn3zSaD6/8s7Pkob2+R05cgRJSUno1q0btFottFot/vnnH3z66afQarXw9/evd58hg5sasLe3R/fu3bF9+3Z5m8FgwPbt2xV9rQ1ZdnY2Ll26hMDAQHTv3h12dnaK842KikJMTEyDPN+wsDAEBAQoziczMxMHDhyQzyciIgLp6ek4cuSIvM/ff/8Ng8Eg/wfV0Fy7dg03btxAYGAggPp/jpIkYfbs2Vi3bh3+/vtvhIWFKZ6vyt9lREQETp48qQjitm3bBjc3N7nrwFYqOz9LIiMjAUDxGdbX8yuPwWBAQUFBg//8ymM8P0sa2uc3dOhQnDx5EpGRkfKtR48emDx5sny/3n2GVi9RvsWsXr1a0ul00qpVq6QzZ85Ijz/+uOTh4aGoCG9InnvuOWnnzp3SlStXpD179kjDhg2TfHx8pKSkJEmSxHC/pk2bSn///bd0+PBhKSIiQoqIiLBxq8uXlZUlHTt2TDp27JgEQProo4+kY8eOSVevXpUkSQwF9/DwkH777TfpxIkT0tixYy0OBe/atat04MABaffu3VKrVq3qzTBpSar4HLOysqTnn39e2rdvn3TlyhXpr7/+krp16ya1atVKys/Pl1+jPp/jzJkzJXd3d2nnzp2KobS5ubnyPpX9XRqHoQ4fPlyKjIyUNm/eLPn6+taLobaVnd/Fixel119/XTp8+LB05coV6bfffpOaN28uDRgwQH6N+nx+kiRJL730kvTPP/9IV65ckU6cOCG99NJLkkqlkrZu3SpJUsP+/CSp4vNrDJ+fJaVHgNW3z5DBjRX897//lZo2bSrZ29tLPXv2lPbv32/rJlXbhAkTpMDAQMne3l4KDg6WJkyYIF28eFF+Pi8vT3ryySclT09PycnJSRo/frwUHx9vwxZXbMeOHRKAMrcpU6ZIkiSGg8+bN0/y9/eXdDqdNHToUCkqKkrxGjdu3JAmTpwoubi4SG5ubtLUqVOlrKwsG5yNZRWdY25urjR8+HDJ19dXsrOzk5o1ayZNnz69TPBdn8/R0rkBkFauXCnvU5W/y+joaGnUqFGSo6Oj5OPjIz333HNSUVFRHZ9NWZWdX0xMjDRgwADJy8tL0ul0UsuWLaX//Oc/inlSJKn+np8kSdKjjz4qNWvWTLK3t5d8fX2loUOHyoGNJDXsz0+SKj6/xvD5WVI6uKlvn6FKkiTJ+vkgIiIiIttgzQ0RERE1KgxuiIiIqFFhcENERESNCoMbIiIialQY3BAREVGjwuCGiIiIGhUGN0RERNSoMLgholueSqXC+vXrbd0MIrISBjdEZFOPPPIIVCpVmdvIkSNt3TQiaqC0tm4AEdHIkSOxcuVKxTadTmej1hBRQ8fMDRHZnE6nQ0BAgOLm6ekJQHQZLV26FKNGjYKjoyOaN2+OtWvXKo4/efIkhgwZAkdHR3h7e+Pxxx9Hdna2Yp8VK1agQ4cO0Ol0CAwMxOzZsxXPp6SkYPz48XByckKrVq2wYcOG2j1pIqo1DG6IqN6bN28e7rnnHhw/fhyTJ0/GAw88gLNnzwIAcnJyMGLECHh6euLQoUNYs2YN/vrrL0XwsnTpUsyaNQuPP/44Tp48iQ0bNqBly5aK3/Haa6/h/vvvx4kTJzB69GhMnjwZqampdXqeRGQltbIcJxFRFU2ZMkXSaDSSs7Oz4vbWW29JkiRWzZ4xY4bimF69ekkzZ86UJEmSvvzyS8nT01PKzs6Wn9+4caOkVqvl1c+DgoKkV155pdw2AJBeffVV+XF2drYEQPrzzz+tdp5EVHdYc0NENjd48GAsXbpUsc3Ly0u+HxERoXguIiICkZGRAICzZ8+ic+fOcHZ2lp/v27cvDAYDoqKioFKpcP36dQwdOrTCNoSHh8v3nZ2d4ebmhqSkpOqeEhHZEIMbIrI5Z2fnMt1E1uLo6Fil/ezs7BSPVSoVDAZDbTSJiGoZa26IqN7bv39/mcft2rUDALRr1w7Hjx9HTk6O/PyePXugVqvRpk0buLq6IjQ0FNu3b6/TNhOR7TBzQ0Q2V1BQgISEBMU2rVYLHx8fAMCaNWvQo0cP9OvXDz/88AMOHjyIr7/+GgAwefJkLFiwAFOmTMHChQuRnJyMp556Cg899BD8/f0BAAsXLsSMGTPg5+eHUaNGISsrC3v27MFTTz1VtydKRHWCwQ0R2dzmzZsRGBio2NamTRucO3cOgBjJtHr1ajz55JMIDAzETz/9hPbt2wMAnJycsGXLFjz99NO47bbb4OTkhHvuuQcfffSR/FpTpkxBfn4+Pv74Yzz//PPw8fHBvffeW3cnSER1SiVJkmTrRhARlUelUmHdunUYN26crZtCRA0Ea26IiIioUWFwQ0RERI0Ka26IqF5jzzkR3SxmboiIiKhRYXBDREREjQqDGyIiImpUGNwQERFRo8LghoiIiBoVBjdERETUqDC4ISIiokaFwQ0RERE1KgxuiIiIqFH5f4X/r0x8+/3SAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(train_eva_df,'Train','Epoch','Loss',['loss','accuracy'])\n",
    "plot_graph(test_eva_df,'Test','Epoch','Loss',['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8db1e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9828450083732605"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eva_df['accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7560c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss          0\n",
       "accuracy    395\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eva_df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd060757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9721016883850098"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eva_df['accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9601cff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss          0\n",
       "accuracy    350\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eva_df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f71d4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  401\n",
      "152/152 - 6s - loss: 0.1429 - accuracy: 0.9479 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0648 - accuracy: 0.9785\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0982 - accuracy: 0.9657\n",
      "\n",
      "Epoch:  402\n",
      "152/152 - 6s - loss: 0.1342 - accuracy: 0.9476 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0695 - accuracy: 0.9758\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0992 - accuracy: 0.9640\n",
      "\n",
      "Epoch:  403\n",
      "152/152 - 6s - loss: 0.1334 - accuracy: 0.9517 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0637 - accuracy: 0.9765\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0936 - accuracy: 0.9651\n",
      "\n",
      "Epoch:  404\n",
      "152/152 - 6s - loss: 0.1300 - accuracy: 0.9498 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0534 - accuracy: 0.9825\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0823 - accuracy: 0.9690\n",
      "\n",
      "Epoch:  405\n",
      "152/152 - 6s - loss: 0.1270 - accuracy: 0.9501 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0586 - accuracy: 0.9776\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0877 - accuracy: 0.9680\n",
      "\n",
      "Epoch:  406\n",
      "152/152 - 6s - loss: 0.1333 - accuracy: 0.9502 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0574 - accuracy: 0.9806\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0851 - accuracy: 0.9698\n",
      "\n",
      "Epoch:  407\n",
      "152/152 - 6s - loss: 0.1231 - accuracy: 0.9547 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0523 - accuracy: 0.9823\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0772 - accuracy: 0.9719\n",
      "\n",
      "Epoch:  408\n",
      "152/152 - 6s - loss: 0.1277 - accuracy: 0.9507 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0641 - accuracy: 0.9775\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0952 - accuracy: 0.9632\n",
      "\n",
      "Epoch:  409\n",
      "152/152 - 6s - loss: 0.1356 - accuracy: 0.9499 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0629 - accuracy: 0.9784\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0931 - accuracy: 0.9667\n",
      "\n",
      "Epoch:  410\n",
      "152/152 - 6s - loss: 0.1249 - accuracy: 0.9534 - 6s/epoch - 39ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0582 - accuracy: 0.9790\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0929 - accuracy: 0.9634\n",
      "\n",
      "Epoch:  411\n",
      "152/152 - 6s - loss: 0.1348 - accuracy: 0.9480 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0527 - accuracy: 0.9832\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0780 - accuracy: 0.9744\n",
      "\n",
      "Epoch:  412\n",
      "152/152 - 6s - loss: 0.1266 - accuracy: 0.9538 - 6s/epoch - 41ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0779 - accuracy: 0.9697\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1068 - accuracy: 0.9599\n",
      "\n",
      "Epoch:  413\n",
      "152/152 - 6s - loss: 0.1386 - accuracy: 0.9468 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0654 - accuracy: 0.9778\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0909 - accuracy: 0.9680\n",
      "\n",
      "Epoch:  414\n",
      "152/152 - 6s - loss: 0.1332 - accuracy: 0.9484 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0649 - accuracy: 0.9758\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0970 - accuracy: 0.9628\n",
      "\n",
      "Epoch:  415\n",
      "152/152 - 6s - loss: 0.1294 - accuracy: 0.9511 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0530 - accuracy: 0.9811\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0831 - accuracy: 0.9711\n",
      "\n",
      "Epoch:  416\n",
      "152/152 - 7s - loss: 0.1266 - accuracy: 0.9514 - 7s/epoch - 44ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0728 - accuracy: 0.9764\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0985 - accuracy: 0.9645\n",
      "\n",
      "Epoch:  417\n",
      "152/152 - 6s - loss: 0.1340 - accuracy: 0.9493 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0648 - accuracy: 0.9767\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0906 - accuracy: 0.9655\n",
      "\n",
      "Epoch:  418\n",
      "152/152 - 6s - loss: 0.1310 - accuracy: 0.9496 - 6s/epoch - 41ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0549 - accuracy: 0.9822\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0810 - accuracy: 0.9727\n",
      "\n",
      "Epoch:  419\n",
      "152/152 - 6s - loss: 0.1355 - accuracy: 0.9486 - 6s/epoch - 42ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0662 - accuracy: 0.9749\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0972 - accuracy: 0.9642\n",
      "\n",
      "Epoch:  420\n",
      "152/152 - 6s - loss: 0.1289 - accuracy: 0.9497 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0543 - accuracy: 0.9820\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0800 - accuracy: 0.9719\n",
      "\n",
      "Epoch:  421\n",
      "152/152 - 6s - loss: 0.1196 - accuracy: 0.9545 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0553 - accuracy: 0.9821\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0829 - accuracy: 0.9713\n",
      "\n",
      "Epoch:  422\n",
      "152/152 - 6s - loss: 0.1205 - accuracy: 0.9534 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0663 - accuracy: 0.9765\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.1000 - accuracy: 0.9647\n",
      "\n",
      "Epoch:  423\n",
      "152/152 - 6s - loss: 0.1261 - accuracy: 0.9515 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0518 - accuracy: 0.9829\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0781 - accuracy: 0.9709\n",
      "\n",
      "Epoch:  424\n",
      "152/152 - 6s - loss: 0.1304 - accuracy: 0.9489 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0615 - accuracy: 0.9777\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0887 - accuracy: 0.9686\n",
      "\n",
      "Epoch:  425\n",
      "152/152 - 6s - loss: 0.1273 - accuracy: 0.9512 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0539 - accuracy: 0.9830\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0842 - accuracy: 0.9680\n",
      "\n",
      "Epoch:  426\n",
      "152/152 - 6s - loss: 0.1371 - accuracy: 0.9472 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0697 - accuracy: 0.9735\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.1020 - accuracy: 0.9624\n",
      "\n",
      "Epoch:  427\n",
      "152/152 - 6s - loss: 0.1323 - accuracy: 0.9487 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0538 - accuracy: 0.9795\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0837 - accuracy: 0.9649\n",
      "\n",
      "Epoch:  428\n",
      "152/152 - 6s - loss: 0.1258 - accuracy: 0.9529 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0526 - accuracy: 0.9832\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0792 - accuracy: 0.9731\n",
      "\n",
      "Epoch:  429\n",
      "152/152 - 6s - loss: 0.1302 - accuracy: 0.9501 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0466 - accuracy: 0.9843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0774 - accuracy: 0.9709\n",
      "\n",
      "Epoch:  430\n",
      "152/152 - 6s - loss: 0.1210 - accuracy: 0.9546 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0607 - accuracy: 0.9782\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0927 - accuracy: 0.9647\n",
      "\n",
      "Epoch:  431\n",
      "152/152 - 6s - loss: 0.1297 - accuracy: 0.9514 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0508 - accuracy: 0.9832\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0790 - accuracy: 0.9684\n",
      "\n",
      "Epoch:  432\n",
      "152/152 - 6s - loss: 0.1201 - accuracy: 0.9530 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0652 - accuracy: 0.9762\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0917 - accuracy: 0.9645\n",
      "\n",
      "Epoch:  433\n",
      "152/152 - 6s - loss: 0.1341 - accuracy: 0.9510 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0486 - accuracy: 0.9835\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0762 - accuracy: 0.9711\n",
      "\n",
      "Epoch:  434\n",
      "152/152 - 6s - loss: 0.1306 - accuracy: 0.9506 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0516 - accuracy: 0.9822\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0835 - accuracy: 0.9698\n",
      "\n",
      "Epoch:  435\n",
      "152/152 - 6s - loss: 0.1207 - accuracy: 0.9548 - 6s/epoch - 40ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0604 - accuracy: 0.9771\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0963 - accuracy: 0.9630\n",
      "\n",
      "Epoch:  436\n",
      "152/152 - 6s - loss: 0.1187 - accuracy: 0.9561 - 6s/epoch - 41ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0541 - accuracy: 0.9803\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0848 - accuracy: 0.9694\n",
      "\n",
      "Epoch:  437\n",
      "152/152 - 7s - loss: 0.1286 - accuracy: 0.9510 - 7s/epoch - 44ms/step\n",
      "for training\n",
      "605/605 [==============================] - 5s 8ms/step - loss: 0.0561 - accuracy: 0.9807\n",
      "for testing\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 0.0848 - accuracy: 0.9669\n",
      "\n",
      "Epoch:  438\n",
      "152/152 - 6s - loss: 0.1223 - accuracy: 0.9544 - 6s/epoch - 42ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0541 - accuracy: 0.9807\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0870 - accuracy: 0.9676\n",
      "\n",
      "Epoch:  439\n",
      "152/152 - 6s - loss: 0.1260 - accuracy: 0.9520 - 6s/epoch - 42ms/step\n",
      "for training\n",
      "605/605 [==============================] - 5s 7ms/step - loss: 0.0488 - accuracy: 0.9837\n",
      "for testing\n",
      " 22/152 [===>..........................] - ETA: 0s - loss: 0.0949 - accuracy: 0.9673"
     ]
    }
   ],
   "source": [
    "for x in range(400,600):\n",
    "    print(\"\\nEpoch: \",x+1)\n",
    "    history = model.fit(X_train ,y_train ,batch_size=BATCH_SIZE ,epochs=1, verbose=2, shuffle=True)\n",
    "    if history_dataframe.size == 0:\n",
    "        history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    else:\n",
    "        history_dataframe = pd.concat([history_dataframe,pd.DataFrame.from_dict(history.history)],axis=0,ignore_index=True)\n",
    "    \n",
    "    print(\"for training\")\n",
    "    train_eva.append(model.evaluate(X_train,y_train))\n",
    "    print(\"for testing\")\n",
    "    test_eva.append(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c1c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva_df = pd.DataFrame(train_eva,columns=['loss','accuracy'])\n",
    "test_eva_df = pd.DataFrame(test_eva,columns=['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647073ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(train_eva_df,'Train','Epoch','Loss',['loss','accuracy'])\n",
    "plot_graph(test_eva_df,'Test','Epoch','Loss',['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c1e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva_df['accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645878a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva_df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d540b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eva_df['accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e32836",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eva_df.idxmax()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
