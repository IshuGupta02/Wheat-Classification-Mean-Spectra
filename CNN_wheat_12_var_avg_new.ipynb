{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c4fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35daa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6aebd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'wheat_12_var_avg_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "554bc6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class filter_method(Enum):\n",
    "    none = 0\n",
    "    snv = 1\n",
    "    msc = 2\n",
    "    savgol = 3\n",
    "\n",
    "FILT = 1\n",
    "FILTER = filter_method(FILT).name\n",
    "\n",
    "# to be set if filter chosen is savgol\n",
    "WINDOW = 7\n",
    "ORDER = 2\n",
    "DERIVATIVE = 1\n",
    "\n",
    "#will be used for test dataset in msc\n",
    "reference= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76302420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_file_name(file_name):\n",
    "    name = \"./dataset/\"+str(file_name)\n",
    "    if FILT != 0:\n",
    "        name+=\"_FILTER_\"+str(FILTER)\n",
    "    if FILTER == \"savgol\":\n",
    "        name+=\"_WINDOW_\"+str(WINDOW)+\"_ORDER_\"+str(ORDER)+\"_DERIVATIVE_\"+str(DERIVATIVE)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "810bdbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILE_NAME = dataset_file_name(file_name)\n",
    "X_train_file = DATASET_FILE_NAME+\"_train_dataset.npy\"\n",
    "y_train_file = DATASET_FILE_NAME+\"_train_dataset_label.npy\"\n",
    "X_test_file = DATASET_FILE_NAME+\"_test_dataset.npy\"\n",
    "y_test_file = DATASET_FILE_NAME+\"_test_dataset_label.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8dec1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =  np.load(X_train_file)\n",
    "y_train =  np.load(y_train_file)\n",
    "X_test  =  np.load(X_test_file)\n",
    "y_test  =  np.load(y_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58535347",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_set = set(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e8c8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_CLASSES = len(y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e1e570e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19353, 147, 1)\n",
      "(4839, 147, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec820add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Input, Conv1D, Flatten, Dense, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba682707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(input_shape,num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=5, input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=5 ))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d95ace51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(X_train.shape[1:],NUM_OF_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33a0377c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 143, 32)           192       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 28, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 896)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              897000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 4004      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 901,196\n",
      "Trainable params: 901,196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20cd1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva = []\n",
    "test_eva = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fd5eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dataframe = pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "863f63f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  1\n",
      "1210/1210 - 19s - loss: 1.3084 - accuracy: 0.3618 - 19s/epoch - 16ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 1.1442 - accuracy: 0.5193\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 1.1459 - accuracy: 0.5224\n",
      "\n",
      "Epoch:  2\n",
      "1210/1210 - 16s - loss: 0.9679 - accuracy: 0.5825 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.7741 - accuracy: 0.6758\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.7687 - accuracy: 0.6789\n",
      "\n",
      "Epoch:  3\n",
      "1210/1210 - 15s - loss: 0.6839 - accuracy: 0.7198 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.6418 - accuracy: 0.7209\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.6363 - accuracy: 0.7138\n",
      "\n",
      "Epoch:  4\n",
      "1210/1210 - 16s - loss: 0.5737 - accuracy: 0.7655 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.5675 - accuracy: 0.7625\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.5569 - accuracy: 0.7665\n",
      "\n",
      "Epoch:  5\n",
      "1210/1210 - 16s - loss: 0.4967 - accuracy: 0.8054 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.4345 - accuracy: 0.8360\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.4268 - accuracy: 0.8374\n",
      "\n",
      "Epoch:  6\n",
      "1210/1210 - 16s - loss: 0.4314 - accuracy: 0.8378 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.3700 - accuracy: 0.8603\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.3658 - accuracy: 0.8615\n",
      "\n",
      "Epoch:  7\n",
      "1210/1210 - 16s - loss: 0.3833 - accuracy: 0.8558 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.3353 - accuracy: 0.8734\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.3392 - accuracy: 0.8735\n",
      "\n",
      "Epoch:  8\n",
      "1210/1210 - 15s - loss: 0.3338 - accuracy: 0.8755 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.2942 - accuracy: 0.8915\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.2956 - accuracy: 0.8930\n",
      "\n",
      "Epoch:  9\n",
      "1210/1210 - 15s - loss: 0.2995 - accuracy: 0.8883 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.4147 - accuracy: 0.8467\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.4322 - accuracy: 0.8415\n",
      "\n",
      "Epoch:  10\n",
      "1210/1210 - 15s - loss: 0.2694 - accuracy: 0.9013 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.2422 - accuracy: 0.9174\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.2430 - accuracy: 0.9159\n",
      "\n",
      "Epoch:  11\n",
      "1210/1210 - 15s - loss: 0.2457 - accuracy: 0.9112 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.3906 - accuracy: 0.8474\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.3869 - accuracy: 0.8493\n",
      "\n",
      "Epoch:  12\n",
      "1210/1210 - 15s - loss: 0.2234 - accuracy: 0.9219 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.2113 - accuracy: 0.9271\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.2218 - accuracy: 0.9237\n",
      "\n",
      "Epoch:  13\n",
      "1210/1210 - 15s - loss: 0.2173 - accuracy: 0.9198 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1806 - accuracy: 0.9340\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.1806 - accuracy: 0.9368\n",
      "\n",
      "Epoch:  14\n",
      "1210/1210 - 15s - loss: 0.1941 - accuracy: 0.9306 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1746 - accuracy: 0.9383\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1767 - accuracy: 0.9384\n",
      "\n",
      "Epoch:  15\n",
      "1210/1210 - 15s - loss: 0.1784 - accuracy: 0.9329 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1825 - accuracy: 0.9356\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1804 - accuracy: 0.9343\n",
      "\n",
      "Epoch:  16\n",
      "1210/1210 - 16s - loss: 0.1739 - accuracy: 0.9375 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.1339 - accuracy: 0.9548\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1359 - accuracy: 0.9531\n",
      "\n",
      "Epoch:  17\n",
      "1210/1210 - 15s - loss: 0.1614 - accuracy: 0.9418 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.1340 - accuracy: 0.9548\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1374 - accuracy: 0.9504\n",
      "\n",
      "Epoch:  18\n",
      "1210/1210 - 15s - loss: 0.1527 - accuracy: 0.9468 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.1416 - accuracy: 0.9500\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1416 - accuracy: 0.9498\n",
      "\n",
      "Epoch:  19\n",
      "1210/1210 - 15s - loss: 0.1452 - accuracy: 0.9460 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.1367 - accuracy: 0.9506\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1400 - accuracy: 0.9481\n",
      "\n",
      "Epoch:  20\n",
      "1210/1210 - 15s - loss: 0.1457 - accuracy: 0.9474 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.1331 - accuracy: 0.9531\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1314 - accuracy: 0.9564\n",
      "\n",
      "Epoch:  21\n",
      "1210/1210 - 16s - loss: 0.1383 - accuracy: 0.9515 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.1079 - accuracy: 0.9640\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1138 - accuracy: 0.9624\n",
      "\n",
      "Epoch:  22\n",
      "1210/1210 - 15s - loss: 0.1310 - accuracy: 0.9533 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.1497 - accuracy: 0.9434\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1531 - accuracy: 0.9450\n",
      "\n",
      "Epoch:  23\n",
      "1210/1210 - 15s - loss: 0.1301 - accuracy: 0.9541 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1084 - accuracy: 0.9627\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1094 - accuracy: 0.9620\n",
      "\n",
      "Epoch:  24\n",
      "1210/1210 - 15s - loss: 0.1241 - accuracy: 0.9559 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.1167 - accuracy: 0.9561\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1222 - accuracy: 0.9543\n",
      "\n",
      "Epoch:  25\n",
      "1210/1210 - 15s - loss: 0.1218 - accuracy: 0.9563 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0981 - accuracy: 0.9659\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1009 - accuracy: 0.9649\n",
      "\n",
      "Epoch:  26\n",
      "1210/1210 - 15s - loss: 0.1146 - accuracy: 0.9595 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0803 - accuracy: 0.9734\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0844 - accuracy: 0.9721\n",
      "\n",
      "Epoch:  27\n",
      "1210/1210 - 15s - loss: 0.1110 - accuracy: 0.9613 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.1408 - accuracy: 0.9462\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1491 - accuracy: 0.9419\n",
      "\n",
      "Epoch:  28\n",
      "1210/1210 - 15s - loss: 0.1093 - accuracy: 0.9607 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1827 - accuracy: 0.9296\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1836 - accuracy: 0.9310\n",
      "\n",
      "Epoch:  29\n",
      "1210/1210 - 15s - loss: 0.1073 - accuracy: 0.9616 - 15s/epoch - 12ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0930 - accuracy: 0.9672\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0963 - accuracy: 0.9673\n",
      "\n",
      "Epoch:  30\n",
      "1210/1210 - 15s - loss: 0.1070 - accuracy: 0.9629 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0891 - accuracy: 0.9695\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0966 - accuracy: 0.9671\n",
      "\n",
      "Epoch:  31\n",
      "1210/1210 - 15s - loss: 0.1007 - accuracy: 0.9644 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0914 - accuracy: 0.9701\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0935 - accuracy: 0.9696\n",
      "\n",
      "Epoch:  32\n",
      "1210/1210 - 15s - loss: 0.0968 - accuracy: 0.9664 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0810 - accuracy: 0.9726\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0888 - accuracy: 0.9698\n",
      "\n",
      "Epoch:  33\n",
      "1210/1210 - 15s - loss: 0.0961 - accuracy: 0.9663 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0927 - accuracy: 0.9676\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1017 - accuracy: 0.9649\n",
      "\n",
      "Epoch:  34\n",
      "1210/1210 - 15s - loss: 0.0942 - accuracy: 0.9666 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0895 - accuracy: 0.9692\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0931 - accuracy: 0.9655\n",
      "\n",
      "Epoch:  35\n",
      "1210/1210 - 15s - loss: 0.0907 - accuracy: 0.9673 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0602 - accuracy: 0.9807\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0669 - accuracy: 0.9771\n",
      "\n",
      "Epoch:  36\n",
      "1210/1210 - 15s - loss: 0.0844 - accuracy: 0.9708 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0832 - accuracy: 0.9693\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0905 - accuracy: 0.9678\n",
      "\n",
      "Epoch:  37\n",
      "1210/1210 - 15s - loss: 0.0848 - accuracy: 0.9695 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0785 - accuracy: 0.9721\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0824 - accuracy: 0.9725\n",
      "\n",
      "Epoch:  38\n",
      "1210/1210 - 15s - loss: 0.0860 - accuracy: 0.9689 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0798 - accuracy: 0.9713\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0850 - accuracy: 0.9661\n",
      "\n",
      "Epoch:  39\n",
      "1210/1210 - 15s - loss: 0.0818 - accuracy: 0.9719 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0768 - accuracy: 0.9732\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0840 - accuracy: 0.9709\n",
      "\n",
      "Epoch:  40\n",
      "1210/1210 - 15s - loss: 0.0862 - accuracy: 0.9706 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0625 - accuracy: 0.9796\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0689 - accuracy: 0.9771\n",
      "\n",
      "Epoch:  41\n",
      "1210/1210 - 15s - loss: 0.0763 - accuracy: 0.9733 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0640 - accuracy: 0.9788\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0703 - accuracy: 0.9766\n",
      "\n",
      "Epoch:  42\n",
      "1210/1210 - 15s - loss: 0.0744 - accuracy: 0.9745 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0858 - accuracy: 0.9673\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0908 - accuracy: 0.9676\n",
      "\n",
      "Epoch:  43\n",
      "1210/1210 - 15s - loss: 0.0769 - accuracy: 0.9720 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.1060 - accuracy: 0.9615\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1164 - accuracy: 0.9591\n",
      "\n",
      "Epoch:  44\n",
      "1210/1210 - 15s - loss: 0.0704 - accuracy: 0.9756 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0562 - accuracy: 0.9813\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0649 - accuracy: 0.9787\n",
      "\n",
      "Epoch:  45\n",
      "1210/1210 - 15s - loss: 0.0757 - accuracy: 0.9742 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0689 - accuracy: 0.9756\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0754 - accuracy: 0.9735\n",
      "\n",
      "Epoch:  46\n",
      "1210/1210 - 15s - loss: 0.0709 - accuracy: 0.9755 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0627 - accuracy: 0.9789\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0708 - accuracy: 0.9769\n",
      "\n",
      "Epoch:  47\n",
      "1210/1210 - 15s - loss: 0.0690 - accuracy: 0.9747 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0471 - accuracy: 0.9847\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0530 - accuracy: 0.9822\n",
      "\n",
      "Epoch:  48\n",
      "1210/1210 - 15s - loss: 0.0654 - accuracy: 0.9768 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0630 - accuracy: 0.9791\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0742 - accuracy: 0.9746\n",
      "\n",
      "Epoch:  49\n",
      "1210/1210 - 15s - loss: 0.0657 - accuracy: 0.9773 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0683 - accuracy: 0.9744\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0806 - accuracy: 0.9715\n",
      "\n",
      "Epoch:  50\n",
      "1210/1210 - 15s - loss: 0.0658 - accuracy: 0.9765 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0648 - accuracy: 0.9774\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0736 - accuracy: 0.9760\n",
      "\n",
      "Epoch:  51\n",
      "1210/1210 - 15s - loss: 0.0649 - accuracy: 0.9770 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0579 - accuracy: 0.9808\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0672 - accuracy: 0.9775\n",
      "\n",
      "Epoch:  52\n",
      "1210/1210 - 15s - loss: 0.0643 - accuracy: 0.9784 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0519 - accuracy: 0.9826\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0636 - accuracy: 0.9781\n",
      "\n",
      "Epoch:  53\n",
      "1210/1210 - 15s - loss: 0.0590 - accuracy: 0.9794 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0961 - accuracy: 0.9630\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1103 - accuracy: 0.9611\n",
      "\n",
      "Epoch:  54\n",
      "1210/1210 - 15s - loss: 0.0614 - accuracy: 0.9771 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0426 - accuracy: 0.9866\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0519 - accuracy: 0.9831\n",
      "\n",
      "Epoch:  55\n",
      "1210/1210 - 15s - loss: 0.0574 - accuracy: 0.9802 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0359 - accuracy: 0.9890\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0473 - accuracy: 0.9839\n",
      "\n",
      "Epoch:  56\n",
      "1210/1210 - 15s - loss: 0.0577 - accuracy: 0.9791 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0443 - accuracy: 0.9847\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0545 - accuracy: 0.9831\n",
      "\n",
      "Epoch:  57\n",
      "1210/1210 - 15s - loss: 0.0616 - accuracy: 0.9785 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0447 - accuracy: 0.9851\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0542 - accuracy: 0.9804\n",
      "\n",
      "Epoch:  58\n",
      "1210/1210 - 15s - loss: 0.0521 - accuracy: 0.9816 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0375 - accuracy: 0.9877\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0485 - accuracy: 0.9843\n",
      "\n",
      "Epoch:  59\n",
      "1210/1210 - 15s - loss: 0.0584 - accuracy: 0.9805 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.1073 - accuracy: 0.9579\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1136 - accuracy: 0.9618\n",
      "\n",
      "Epoch:  60\n",
      "1210/1210 - 15s - loss: 0.0533 - accuracy: 0.9811 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0648 - accuracy: 0.9761\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0770 - accuracy: 0.9707\n",
      "\n",
      "Epoch:  61\n",
      "1210/1210 - 15s - loss: 0.0551 - accuracy: 0.9801 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0387 - accuracy: 0.9874\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0511 - accuracy: 0.9828\n",
      "\n",
      "Epoch:  62\n",
      "1210/1210 - 15s - loss: 0.0542 - accuracy: 0.9803 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0501 - accuracy: 0.9826\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0632 - accuracy: 0.9797\n",
      "\n",
      "Epoch:  63\n",
      "1210/1210 - 15s - loss: 0.0538 - accuracy: 0.9809 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0471 - accuracy: 0.9846\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0609 - accuracy: 0.9787\n",
      "\n",
      "Epoch:  64\n",
      "1210/1210 - 15s - loss: 0.0524 - accuracy: 0.9820 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0604 - accuracy: 0.9765\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0719 - accuracy: 0.9758\n",
      "\n",
      "Epoch:  65\n",
      "1210/1210 - 15s - loss: 0.0520 - accuracy: 0.9814 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0496 - accuracy: 0.9819\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0642 - accuracy: 0.9783\n",
      "\n",
      "Epoch:  66\n",
      "1210/1210 - 15s - loss: 0.0508 - accuracy: 0.9817 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0528 - accuracy: 0.9805\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0686 - accuracy: 0.9771\n",
      "\n",
      "Epoch:  67\n",
      "1210/1210 - 15s - loss: 0.0504 - accuracy: 0.9817 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0435 - accuracy: 0.9861\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0579 - accuracy: 0.9785\n",
      "\n",
      "Epoch:  68\n",
      "1210/1210 - 15s - loss: 0.0472 - accuracy: 0.9834 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0329 - accuracy: 0.9894\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0455 - accuracy: 0.9833\n",
      "\n",
      "Epoch:  69\n",
      "1210/1210 - 15s - loss: 0.0522 - accuracy: 0.9826 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0498 - accuracy: 0.9819\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0641 - accuracy: 0.9758\n",
      "\n",
      "Epoch:  70\n",
      "1210/1210 - 15s - loss: 0.0489 - accuracy: 0.9836 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0581 - accuracy: 0.9801\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0681 - accuracy: 0.9760\n",
      "\n",
      "Epoch:  71\n",
      "1210/1210 - 15s - loss: 0.0447 - accuracy: 0.9852 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0270 - accuracy: 0.9913\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0401 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  72\n",
      "1210/1210 - 15s - loss: 0.0476 - accuracy: 0.9839 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0594 - accuracy: 0.9792\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0716 - accuracy: 0.9742\n",
      "\n",
      "Epoch:  73\n",
      "1210/1210 - 15s - loss: 0.0456 - accuracy: 0.9847 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0361 - accuracy: 0.9874\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0462 - accuracy: 0.9845\n",
      "\n",
      "Epoch:  74\n",
      "1210/1210 - 15s - loss: 0.0456 - accuracy: 0.9836 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0376 - accuracy: 0.9869\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0546 - accuracy: 0.9833\n",
      "\n",
      "Epoch:  75\n",
      "1210/1210 - 15s - loss: 0.0425 - accuracy: 0.9842 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0407 - accuracy: 0.9853\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0554 - accuracy: 0.9785\n",
      "\n",
      "Epoch:  76\n",
      "1210/1210 - 15s - loss: 0.0446 - accuracy: 0.9845 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0294 - accuracy: 0.9904\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0454 - accuracy: 0.9847\n",
      "\n",
      "Epoch:  77\n",
      "1210/1210 - 15s - loss: 0.0473 - accuracy: 0.9832 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0324 - accuracy: 0.9889\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0466 - accuracy: 0.9845\n",
      "\n",
      "Epoch:  78\n",
      "1210/1210 - 15s - loss: 0.0460 - accuracy: 0.9840 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.1526 - accuracy: 0.9450\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1600 - accuracy: 0.9516\n",
      "\n",
      "Epoch:  79\n",
      "1210/1210 - 15s - loss: 0.0439 - accuracy: 0.9845 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0404 - accuracy: 0.9850\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0584 - accuracy: 0.9806\n",
      "\n",
      "Epoch:  80\n",
      "1210/1210 - 15s - loss: 0.0380 - accuracy: 0.9868 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.1363 - accuracy: 0.9521\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1574 - accuracy: 0.9500\n",
      "\n",
      "Epoch:  81\n",
      "1210/1210 - 16s - loss: 0.0441 - accuracy: 0.9846 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0276 - accuracy: 0.9904\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0457 - accuracy: 0.9828\n",
      "\n",
      "Epoch:  82\n",
      "1210/1210 - 15s - loss: 0.0466 - accuracy: 0.9840 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0468 - accuracy: 0.9825\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0598 - accuracy: 0.9800\n",
      "\n",
      "Epoch:  83\n",
      "1210/1210 - 15s - loss: 0.0446 - accuracy: 0.9840 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0212 - accuracy: 0.9929\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0386 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  84\n",
      "1210/1210 - 15s - loss: 0.0394 - accuracy: 0.9864 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0795 - accuracy: 0.9690\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0942 - accuracy: 0.9665\n",
      "\n",
      "Epoch:  85\n",
      "1210/1210 - 15s - loss: 0.0425 - accuracy: 0.9847 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0314 - accuracy: 0.9894\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0459 - accuracy: 0.9843\n",
      "\n",
      "Epoch:  86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1210/1210 - 15s - loss: 0.0393 - accuracy: 0.9864 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0310 - accuracy: 0.9897\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0478 - accuracy: 0.9833\n",
      "\n",
      "Epoch:  87\n",
      "1210/1210 - 15s - loss: 0.0416 - accuracy: 0.9865 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0491 - accuracy: 0.9839\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0717 - accuracy: 0.9777\n",
      "\n",
      "Epoch:  88\n",
      "1210/1210 - 15s - loss: 0.0383 - accuracy: 0.9871 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0445 - accuracy: 0.9832\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0611 - accuracy: 0.9820\n",
      "\n",
      "Epoch:  89\n",
      "1210/1210 - 16s - loss: 0.0388 - accuracy: 0.9865 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0311 - accuracy: 0.9893\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0479 - accuracy: 0.9847\n",
      "\n",
      "Epoch:  90\n",
      "1210/1210 - 15s - loss: 0.0377 - accuracy: 0.9866 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0331 - accuracy: 0.9887\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0482 - accuracy: 0.9837\n",
      "\n",
      "Epoch:  91\n",
      "1210/1210 - 15s - loss: 0.0417 - accuracy: 0.9850 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0395 - accuracy: 0.9864\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0548 - accuracy: 0.9795\n",
      "\n",
      "Epoch:  92\n",
      "1210/1210 - 15s - loss: 0.0370 - accuracy: 0.9875 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0437 - accuracy: 0.9837\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0632 - accuracy: 0.9791\n",
      "\n",
      "Epoch:  93\n",
      "1210/1210 - 15s - loss: 0.0428 - accuracy: 0.9849 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0250 - accuracy: 0.9915\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0413 - accuracy: 0.9859\n",
      "\n",
      "Epoch:  94\n",
      "1210/1210 - 15s - loss: 0.0358 - accuracy: 0.9876 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0247 - accuracy: 0.9915\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0438 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  95\n",
      "1210/1210 - 15s - loss: 0.0401 - accuracy: 0.9866 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0576 - accuracy: 0.9767\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0718 - accuracy: 0.9752\n",
      "\n",
      "Epoch:  96\n",
      "1210/1210 - 15s - loss: 0.0313 - accuracy: 0.9878 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0331 - accuracy: 0.9877\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0548 - accuracy: 0.9824\n",
      "\n",
      "Epoch:  97\n",
      "1210/1210 - 15s - loss: 0.0383 - accuracy: 0.9867 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0150 - accuracy: 0.9958\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0313 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  98\n",
      "1210/1210 - 14s - loss: 0.0339 - accuracy: 0.9884 - 14s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0176 - accuracy: 0.9945\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0347 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  99\n",
      "1210/1210 - 15s - loss: 0.0349 - accuracy: 0.9879 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0673 - accuracy: 0.9756\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0838 - accuracy: 0.9711\n",
      "\n",
      "Epoch:  100\n",
      "1210/1210 - 15s - loss: 0.0315 - accuracy: 0.9897 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0168 - accuracy: 0.9946\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0325 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  101\n",
      "1210/1210 - 15s - loss: 0.0336 - accuracy: 0.9879 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0213 - accuracy: 0.9928\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0377 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  102\n",
      "1210/1210 - 15s - loss: 0.0359 - accuracy: 0.9868 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0696 - accuracy: 0.9732\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0904 - accuracy: 0.9690\n",
      "\n",
      "Epoch:  103\n",
      "1210/1210 - 15s - loss: 0.0313 - accuracy: 0.9899 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0444 - accuracy: 0.9832\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0607 - accuracy: 0.9797\n",
      "\n",
      "Epoch:  104\n",
      "1210/1210 - 15s - loss: 0.0331 - accuracy: 0.9881 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0226 - accuracy: 0.9925\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0373 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  105\n",
      "1210/1210 - 15s - loss: 0.0344 - accuracy: 0.9888 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0235 - accuracy: 0.9921\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0396 - accuracy: 0.9849\n",
      "\n",
      "Epoch:  106\n",
      "1210/1210 - 14s - loss: 0.0299 - accuracy: 0.9893 - 14s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0959 - accuracy: 0.9635\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1223 - accuracy: 0.9587\n",
      "\n",
      "Epoch:  107\n",
      "1210/1210 - 15s - loss: 0.0306 - accuracy: 0.9897 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0301 - accuracy: 0.9895\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0493 - accuracy: 0.9818\n",
      "\n",
      "Epoch:  108\n",
      "1210/1210 - 15s - loss: 0.0358 - accuracy: 0.9877 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0208 - accuracy: 0.9930\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0366 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  109\n",
      "1210/1210 - 15s - loss: 0.0360 - accuracy: 0.9870 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0884 - accuracy: 0.9669\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1130 - accuracy: 0.9593\n",
      "\n",
      "Epoch:  110\n",
      "1210/1210 - 15s - loss: 0.0301 - accuracy: 0.9896 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0264 - accuracy: 0.9909\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0434 - accuracy: 0.9849\n",
      "\n",
      "Epoch:  111\n",
      "1210/1210 - 15s - loss: 0.0309 - accuracy: 0.9887 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0691 - accuracy: 0.9741\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0821 - accuracy: 0.9729\n",
      "\n",
      "Epoch:  112\n",
      "1210/1210 - 15s - loss: 0.0308 - accuracy: 0.9888 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0182 - accuracy: 0.9942\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0372 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  113\n",
      "1210/1210 - 15s - loss: 0.0324 - accuracy: 0.9891 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0587 - accuracy: 0.9792\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0689 - accuracy: 0.9775\n",
      "\n",
      "Epoch:  114\n",
      "1210/1210 - 15s - loss: 0.0289 - accuracy: 0.9901 - 15s/epoch - 12ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0225 - accuracy: 0.9929\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0394 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  115\n",
      "1210/1210 - 15s - loss: 0.0277 - accuracy: 0.9903 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0585 - accuracy: 0.9782\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0839 - accuracy: 0.9696\n",
      "\n",
      "Epoch:  116\n",
      "1210/1210 - 15s - loss: 0.0285 - accuracy: 0.9896 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0136 - accuracy: 0.9959\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0307 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  117\n",
      "1210/1210 - 15s - loss: 0.0304 - accuracy: 0.9891 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0378 - accuracy: 0.9867\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0571 - accuracy: 0.9831\n",
      "\n",
      "Epoch:  118\n",
      "1210/1210 - 15s - loss: 0.0259 - accuracy: 0.9910 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0227 - accuracy: 0.9918\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0437 - accuracy: 0.9845\n",
      "\n",
      "Epoch:  119\n",
      "1210/1210 - 15s - loss: 0.0315 - accuracy: 0.9884 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0726 - accuracy: 0.9722\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0956 - accuracy: 0.9678\n",
      "\n",
      "Epoch:  120\n",
      "1210/1210 - 15s - loss: 0.0264 - accuracy: 0.9908 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0338 - accuracy: 0.9877\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0548 - accuracy: 0.9820\n",
      "\n",
      "Epoch:  121\n",
      "1210/1210 - 15s - loss: 0.0277 - accuracy: 0.9898 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0198 - accuracy: 0.9931\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0385 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  122\n",
      "1210/1210 - 15s - loss: 0.0321 - accuracy: 0.9891 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0172 - accuracy: 0.9942\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0334 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  123\n",
      "1210/1210 - 16s - loss: 0.0278 - accuracy: 0.9903 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0216 - accuracy: 0.9922\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0446 - accuracy: 0.9870\n",
      "\n",
      "Epoch:  124\n",
      "1210/1210 - 16s - loss: 0.0261 - accuracy: 0.9906 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0217 - accuracy: 0.9920\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0439 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  125\n",
      "1210/1210 - 15s - loss: 0.0308 - accuracy: 0.9897 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0108 - accuracy: 0.9967\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0305 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  126\n",
      "1210/1210 - 15s - loss: 0.0289 - accuracy: 0.9900 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0136 - accuracy: 0.9960\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0325 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  127\n",
      "1210/1210 - 15s - loss: 0.0277 - accuracy: 0.9899 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0137 - accuracy: 0.9959\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  128\n",
      "1210/1210 - 15s - loss: 0.0276 - accuracy: 0.9902 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0228 - accuracy: 0.9912\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0429 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  129\n",
      "1210/1210 - 15s - loss: 0.0275 - accuracy: 0.9905 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0192 - accuracy: 0.9936\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0372 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  130\n",
      "1210/1210 - 15s - loss: 0.0275 - accuracy: 0.9909 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0255 - accuracy: 0.9907\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0515 - accuracy: 0.9853\n",
      "\n",
      "Epoch:  131\n",
      "1210/1210 - 15s - loss: 0.0324 - accuracy: 0.9888 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0129 - accuracy: 0.9959\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0346 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  132\n",
      "1210/1210 - 15s - loss: 0.0289 - accuracy: 0.9900 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0109 - accuracy: 0.9970\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  133\n",
      "1210/1210 - 15s - loss: 0.0211 - accuracy: 0.9924 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0223 - accuracy: 0.9919\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0434 - accuracy: 0.9857\n",
      "\n",
      "Epoch:  134\n",
      "1210/1210 - 15s - loss: 0.0301 - accuracy: 0.9898 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0190 - accuracy: 0.9937\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0388 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  135\n",
      "1210/1210 - 15s - loss: 0.0207 - accuracy: 0.9930 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0160 - accuracy: 0.9950\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0346 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  136\n",
      "1210/1210 - 15s - loss: 0.0276 - accuracy: 0.9902 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.1233 - accuracy: 0.9594\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1478 - accuracy: 0.9585\n",
      "\n",
      "Epoch:  137\n",
      "1210/1210 - 15s - loss: 0.0293 - accuracy: 0.9897 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0212 - accuracy: 0.9929\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0421 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  138\n",
      "1210/1210 - 15s - loss: 0.0229 - accuracy: 0.9917 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0206 - accuracy: 0.9934\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0410 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  139\n",
      "1210/1210 - 15s - loss: 0.0243 - accuracy: 0.9912 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0148 - accuracy: 0.9952\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0399 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  140\n",
      "1210/1210 - 15s - loss: 0.0261 - accuracy: 0.9911 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0097 - accuracy: 0.9969\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0298 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  141\n",
      "1210/1210 - 15s - loss: 0.0287 - accuracy: 0.9901 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0237 - accuracy: 0.9917\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0517 - accuracy: 0.9847\n",
      "\n",
      "Epoch:  142\n",
      "1210/1210 - 15s - loss: 0.0197 - accuracy: 0.9929 - 15s/epoch - 13ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0135 - accuracy: 0.9957\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0372 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  143\n",
      "1210/1210 - 15s - loss: 0.0264 - accuracy: 0.9912 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0107 - accuracy: 0.9967\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0290 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  144\n",
      "1210/1210 - 15s - loss: 0.0230 - accuracy: 0.9923 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0365 - accuracy: 0.9855\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0635 - accuracy: 0.9783\n",
      "\n",
      "Epoch:  145\n",
      "1210/1210 - 15s - loss: 0.0247 - accuracy: 0.9915 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0135 - accuracy: 0.9952\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0382 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  146\n",
      "1210/1210 - 15s - loss: 0.0217 - accuracy: 0.9925 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0153 - accuracy: 0.9950\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0402 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  147\n",
      "1210/1210 - 15s - loss: 0.0264 - accuracy: 0.9915 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0157 - accuracy: 0.9953\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0359 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  148\n",
      "1210/1210 - 15s - loss: 0.0233 - accuracy: 0.9915 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0375 - accuracy: 0.9864\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0636 - accuracy: 0.9791\n",
      "\n",
      "Epoch:  149\n",
      "1210/1210 - 15s - loss: 0.0229 - accuracy: 0.9923 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0297 - accuracy: 0.9891\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0559 - accuracy: 0.9837\n",
      "\n",
      "Epoch:  150\n",
      "1210/1210 - 15s - loss: 0.0229 - accuracy: 0.9919 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0270 - accuracy: 0.9893\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0486 - accuracy: 0.9855\n",
      "\n",
      "Epoch:  151\n",
      "1210/1210 - 15s - loss: 0.0256 - accuracy: 0.9911 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0151 - accuracy: 0.9946\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0356 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  152\n",
      "1210/1210 - 15s - loss: 0.0238 - accuracy: 0.9917 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0249 - accuracy: 0.9904\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0449 - accuracy: 0.9851\n",
      "\n",
      "Epoch:  153\n",
      "1210/1210 - 20s - loss: 0.0228 - accuracy: 0.9919 - 20s/epoch - 16ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0095 - accuracy: 0.9968\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0273 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  154\n",
      "1210/1210 - 21s - loss: 0.0263 - accuracy: 0.9904 - 21s/epoch - 17ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0254 - accuracy: 0.9905\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0449 - accuracy: 0.9857\n",
      "\n",
      "Epoch:  155\n",
      "1210/1210 - 20s - loss: 0.0216 - accuracy: 0.9927 - 20s/epoch - 16ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0801 - accuracy: 0.9683\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0988 - accuracy: 0.9647\n",
      "\n",
      "Epoch:  156\n",
      "1210/1210 - 19s - loss: 0.0198 - accuracy: 0.9932 - 19s/epoch - 16ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0215 - accuracy: 0.9928\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0482 - accuracy: 0.9866\n",
      "\n",
      "Epoch:  157\n",
      "1210/1210 - 23s - loss: 0.0240 - accuracy: 0.9910 - 23s/epoch - 19ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0113 - accuracy: 0.9962\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0297 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  158\n",
      "1210/1210 - 19s - loss: 0.0238 - accuracy: 0.9913 - 19s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0187 - accuracy: 0.9927\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0444 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  159\n",
      "1210/1210 - 18s - loss: 0.0182 - accuracy: 0.9938 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0333 - accuracy: 0.9877\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0587 - accuracy: 0.9828\n",
      "\n",
      "Epoch:  160\n",
      "1210/1210 - 16s - loss: 0.0220 - accuracy: 0.9925 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0087 - accuracy: 0.9976\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0290 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  161\n",
      "1210/1210 - 15s - loss: 0.0200 - accuracy: 0.9930 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0189 - accuracy: 0.9928\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0458 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  162\n",
      "1210/1210 - 16s - loss: 0.0203 - accuracy: 0.9926 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0141 - accuracy: 0.9951\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0343 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  163\n",
      "1210/1210 - 16s - loss: 0.0221 - accuracy: 0.9920 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0071 - accuracy: 0.9981\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0288 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  164\n",
      "1210/1210 - 15s - loss: 0.0230 - accuracy: 0.9920 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0132 - accuracy: 0.9955\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0347 - accuracy: 0.9886\n",
      "\n",
      "Epoch:  165\n",
      "1210/1210 - 15s - loss: 0.0208 - accuracy: 0.9925 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0154 - accuracy: 0.9947\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0331 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  166\n",
      "1210/1210 - 15s - loss: 0.0221 - accuracy: 0.9924 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0080 - accuracy: 0.9975\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0301 - accuracy: 0.9886\n",
      "\n",
      "Epoch:  167\n",
      "1210/1210 - 16s - loss: 0.0205 - accuracy: 0.9934 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0106 - accuracy: 0.9963\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0326 - accuracy: 0.9886\n",
      "\n",
      "Epoch:  168\n",
      "1210/1210 - 16s - loss: 0.0165 - accuracy: 0.9935 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0222 - accuracy: 0.9917\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0491 - accuracy: 0.9870\n",
      "\n",
      "Epoch:  169\n",
      "1210/1210 - 16s - loss: 0.0233 - accuracy: 0.9916 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0081 - accuracy: 0.9975\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0314 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  170\n",
      "1210/1210 - 16s - loss: 0.0237 - accuracy: 0.9914 - 16s/epoch - 13ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0207 - accuracy: 0.9927\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0402 - accuracy: 0.9870\n",
      "\n",
      "Epoch:  171\n",
      "1210/1210 - 16s - loss: 0.0179 - accuracy: 0.9933 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0271 - accuracy: 0.9899\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0546 - accuracy: 0.9835\n",
      "\n",
      "Epoch:  172\n",
      "1210/1210 - 15s - loss: 0.0193 - accuracy: 0.9929 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0060 - accuracy: 0.9981\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0284 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  173\n",
      "1210/1210 - 16s - loss: 0.0187 - accuracy: 0.9936 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0653 - accuracy: 0.9758\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0940 - accuracy: 0.9696\n",
      "\n",
      "Epoch:  174\n",
      "1210/1210 - 15s - loss: 0.0188 - accuracy: 0.9929 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0330 - accuracy: 0.9859\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0557 - accuracy: 0.9820\n",
      "\n",
      "Epoch:  175\n",
      "1210/1210 - 16s - loss: 0.0193 - accuracy: 0.9930 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0189 - accuracy: 0.9925\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0450 - accuracy: 0.9851\n",
      "\n",
      "Epoch:  176\n",
      "1210/1210 - 15s - loss: 0.0206 - accuracy: 0.9935 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0397 - accuracy: 0.9858\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0691 - accuracy: 0.9787\n",
      "\n",
      "Epoch:  177\n",
      "1210/1210 - 15s - loss: 0.0156 - accuracy: 0.9947 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0097 - accuracy: 0.9973\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0319 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  178\n",
      "1210/1210 - 15s - loss: 0.0224 - accuracy: 0.9922 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0874 - accuracy: 0.9704\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1153 - accuracy: 0.9671\n",
      "\n",
      "Epoch:  179\n",
      "1210/1210 - 16s - loss: 0.0166 - accuracy: 0.9943 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0160 - accuracy: 0.9942\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0407 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  180\n",
      "1210/1210 - 15s - loss: 0.0227 - accuracy: 0.9914 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0074 - accuracy: 0.9976\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0355 - accuracy: 0.9886\n",
      "\n",
      "Epoch:  181\n",
      "1210/1210 - 15s - loss: 0.0187 - accuracy: 0.9929 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.1433 - accuracy: 0.9528\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1841 - accuracy: 0.9471\n",
      "\n",
      "Epoch:  182\n",
      "1210/1210 - 15s - loss: 0.0231 - accuracy: 0.9926 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0097 - accuracy: 0.9969\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0339 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  183\n",
      "1210/1210 - 16s - loss: 0.0145 - accuracy: 0.9949 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0079 - accuracy: 0.9970\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0302 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  184\n",
      "1210/1210 - 16s - loss: 0.0177 - accuracy: 0.9933 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0073 - accuracy: 0.9979\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0307 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  185\n",
      "1210/1210 - 16s - loss: 0.0181 - accuracy: 0.9937 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0125 - accuracy: 0.9954\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0386 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  186\n",
      "1210/1210 - 16s - loss: 0.0199 - accuracy: 0.9932 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0082 - accuracy: 0.9974\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0296 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  187\n",
      "1210/1210 - 16s - loss: 0.0154 - accuracy: 0.9947 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0397 - accuracy: 0.9860\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0710 - accuracy: 0.9789\n",
      "\n",
      "Epoch:  188\n",
      "1210/1210 - 15s - loss: 0.0203 - accuracy: 0.9919 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0101 - accuracy: 0.9961\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0322 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  189\n",
      "1210/1210 - 16s - loss: 0.0212 - accuracy: 0.9934 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0094 - accuracy: 0.9973\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0366 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  190\n",
      "1210/1210 - 16s - loss: 0.0136 - accuracy: 0.9957 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0059 - accuracy: 0.9983\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0255 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  191\n",
      "1210/1210 - 15s - loss: 0.0213 - accuracy: 0.9923 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0064 - accuracy: 0.9977\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0312 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  192\n",
      "1210/1210 - 16s - loss: 0.0155 - accuracy: 0.9945 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0043 - accuracy: 0.9989\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0283 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  193\n",
      "1210/1210 - 16s - loss: 0.0158 - accuracy: 0.9942 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0057 - accuracy: 0.9983\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  194\n",
      "1210/1210 - 16s - loss: 0.0185 - accuracy: 0.9931 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0126 - accuracy: 0.9952\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0411 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  195\n",
      "1210/1210 - 16s - loss: 0.0182 - accuracy: 0.9930 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0073 - accuracy: 0.9976\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0322 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  196\n",
      "1210/1210 - 15s - loss: 0.0171 - accuracy: 0.9940 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0382 - accuracy: 0.9860\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0688 - accuracy: 0.9785\n",
      "\n",
      "Epoch:  197\n",
      "1210/1210 - 15s - loss: 0.0173 - accuracy: 0.9946 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0129 - accuracy: 0.9953\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0400 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  198\n",
      "1210/1210 - 15s - loss: 0.0167 - accuracy: 0.9940 - 15s/epoch - 13ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0139 - accuracy: 0.9948\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0416 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  199\n",
      "1210/1210 - 15s - loss: 0.0160 - accuracy: 0.9948 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0070 - accuracy: 0.9979\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0297 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  200\n",
      "1210/1210 - 16s - loss: 0.0167 - accuracy: 0.9941 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0069 - accuracy: 0.9976\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0358 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  201\n",
      "1210/1210 - 15s - loss: 0.0173 - accuracy: 0.9943 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0138 - accuracy: 0.9946\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0427 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  202\n",
      "1210/1210 - 16s - loss: 0.0161 - accuracy: 0.9943 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0352 - accuracy: 0.9849\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0643 - accuracy: 0.9816\n",
      "\n",
      "Epoch:  203\n",
      "1210/1210 - 15s - loss: 0.0177 - accuracy: 0.9936 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0249 - accuracy: 0.9901\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0540 - accuracy: 0.9839\n",
      "\n",
      "Epoch:  204\n",
      "1210/1210 - 16s - loss: 0.0135 - accuracy: 0.9953 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0217 - accuracy: 0.9920\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0563 - accuracy: 0.9853\n",
      "\n",
      "Epoch:  205\n",
      "1210/1210 - 15s - loss: 0.0274 - accuracy: 0.9907 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0102 - accuracy: 0.9966\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0390 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  206\n",
      "1210/1210 - 15s - loss: 0.0155 - accuracy: 0.9945 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0085 - accuracy: 0.9973\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0363 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  207\n",
      "1210/1210 - 16s - loss: 0.0134 - accuracy: 0.9956 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0146 - accuracy: 0.9949\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0369 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  208\n",
      "1210/1210 - 15s - loss: 0.0130 - accuracy: 0.9958 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0427 - accuracy: 0.9836\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0709 - accuracy: 0.9764\n",
      "\n",
      "Epoch:  209\n",
      "1210/1210 - 16s - loss: 0.0200 - accuracy: 0.9935 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0049 - accuracy: 0.9988\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0277 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  210\n",
      "1210/1210 - 15s - loss: 0.0161 - accuracy: 0.9940 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0660 - accuracy: 0.9758\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1076 - accuracy: 0.9622\n",
      "\n",
      "Epoch:  211\n",
      "1210/1210 - 15s - loss: 0.0099 - accuracy: 0.9968 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0087 - accuracy: 0.9971\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0340 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  212\n",
      "1210/1210 - 15s - loss: 0.0203 - accuracy: 0.9925 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0054 - accuracy: 0.9988\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0302 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  213\n",
      "1210/1210 - 15s - loss: 0.0140 - accuracy: 0.9952 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0068 - accuracy: 0.9980\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0326 - accuracy: 0.9886\n",
      "\n",
      "Epoch:  214\n",
      "1210/1210 - 16s - loss: 0.0165 - accuracy: 0.9942 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0212 - accuracy: 0.9917\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0582 - accuracy: 0.9822\n",
      "\n",
      "Epoch:  215\n",
      "1210/1210 - 15s - loss: 0.0175 - accuracy: 0.9939 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0144 - accuracy: 0.9951\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0398 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  216\n",
      "1210/1210 - 16s - loss: 0.0135 - accuracy: 0.9951 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0209 - accuracy: 0.9920\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0471 - accuracy: 0.9870\n",
      "\n",
      "Epoch:  217\n",
      "1210/1210 - 15s - loss: 0.0126 - accuracy: 0.9955 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0434 - accuracy: 0.9848\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0746 - accuracy: 0.9810\n",
      "\n",
      "Epoch:  218\n",
      "1210/1210 - 15s - loss: 0.0171 - accuracy: 0.9944 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0098 - accuracy: 0.9963\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0406 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  219\n",
      "1210/1210 - 15s - loss: 0.0149 - accuracy: 0.9948 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0267 - accuracy: 0.9907\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0593 - accuracy: 0.9841\n",
      "\n",
      "Epoch:  220\n",
      "1210/1210 - 16s - loss: 0.0143 - accuracy: 0.9952 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0091 - accuracy: 0.9970\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0374 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  221\n",
      "1210/1210 - 16s - loss: 0.0188 - accuracy: 0.9934 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0050 - accuracy: 0.9986\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0307 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  222\n",
      "1210/1210 - 16s - loss: 0.0143 - accuracy: 0.9948 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0112 - accuracy: 0.9959\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0391 - accuracy: 0.9886\n",
      "\n",
      "Epoch:  223\n",
      "1210/1210 - 16s - loss: 0.0126 - accuracy: 0.9951 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0044 - accuracy: 0.9988\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0265 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  224\n",
      "1210/1210 - 16s - loss: 0.0147 - accuracy: 0.9946 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0119 - accuracy: 0.9958\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0360 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  225\n",
      "1210/1210 - 16s - loss: 0.0126 - accuracy: 0.9957 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0287 - accuracy: 0.9887\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0534 - accuracy: 0.9824\n",
      "\n",
      "Epoch:  226\n",
      "1210/1210 - 15s - loss: 0.0178 - accuracy: 0.9941 - 15s/epoch - 13ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0330 - accuracy: 0.9885\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0663 - accuracy: 0.9814\n",
      "\n",
      "Epoch:  227\n",
      "1210/1210 - 15s - loss: 0.0144 - accuracy: 0.9946 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0413 - accuracy: 0.9855\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0817 - accuracy: 0.9777\n",
      "\n",
      "Epoch:  228\n",
      "1210/1210 - 16s - loss: 0.0148 - accuracy: 0.9945 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0067 - accuracy: 0.9981\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0307 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  229\n",
      "1210/1210 - 15s - loss: 0.0117 - accuracy: 0.9960 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0052 - accuracy: 0.9984\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  230\n",
      "1210/1210 - 16s - loss: 0.0130 - accuracy: 0.9956 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0134 - accuracy: 0.9954\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0403 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  231\n",
      "1210/1210 - 16s - loss: 0.0191 - accuracy: 0.9941 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0072 - accuracy: 0.9978\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0302 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  232\n",
      "1210/1210 - 16s - loss: 0.0102 - accuracy: 0.9964 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0043 - accuracy: 0.9989\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  233\n",
      "1210/1210 - 16s - loss: 0.0153 - accuracy: 0.9950 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0057 - accuracy: 0.9988\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0291 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  234\n",
      "1210/1210 - 15s - loss: 0.0094 - accuracy: 0.9967 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0107 - accuracy: 0.9957\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0363 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  235\n",
      "1210/1210 - 17s - loss: 0.0172 - accuracy: 0.9941 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.0076 - accuracy: 0.9976\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0364 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  236\n",
      "1210/1210 - 17s - loss: 0.0130 - accuracy: 0.9958 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0067 - accuracy: 0.9976\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0300 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  237\n",
      "1210/1210 - 18s - loss: 0.0136 - accuracy: 0.9954 - 18s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0294 - accuracy: 0.9893\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0633 - accuracy: 0.9814\n",
      "\n",
      "Epoch:  238\n",
      "1210/1210 - 17s - loss: 0.0125 - accuracy: 0.9954 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0140 - accuracy: 0.9948\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0460 - accuracy: 0.9857\n",
      "\n",
      "Epoch:  239\n",
      "1210/1210 - 18s - loss: 0.0150 - accuracy: 0.9947 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0186 - accuracy: 0.9933\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0580 - accuracy: 0.9841\n",
      "\n",
      "Epoch:  240\n",
      "1210/1210 - 17s - loss: 0.0123 - accuracy: 0.9955 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0063 - accuracy: 0.9981\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  241\n",
      "1210/1210 - 16s - loss: 0.0113 - accuracy: 0.9962 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0123 - accuracy: 0.9955\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0416 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  242\n",
      "1210/1210 - 16s - loss: 0.0161 - accuracy: 0.9945 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0113 - accuracy: 0.9962\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0304 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  243\n",
      "1210/1210 - 16s - loss: 0.0146 - accuracy: 0.9949 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0150 - accuracy: 0.9944\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0417 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  244\n",
      "1210/1210 - 16s - loss: 0.0113 - accuracy: 0.9960 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0049 - accuracy: 0.9982\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0272 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  245\n",
      "1210/1210 - 16s - loss: 0.0147 - accuracy: 0.9951 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0054 - accuracy: 0.9980\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0276 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  246\n",
      "1210/1210 - 16s - loss: 0.0124 - accuracy: 0.9953 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0085 - accuracy: 0.9967\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0332 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  247\n",
      "1210/1210 - 16s - loss: 0.0117 - accuracy: 0.9955 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0209 - accuracy: 0.9916\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0521 - accuracy: 0.9845\n",
      "\n",
      "Epoch:  248\n",
      "1210/1210 - 15s - loss: 0.0177 - accuracy: 0.9943 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0038 - accuracy: 0.9990\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0296 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  249\n",
      "1210/1210 - 16s - loss: 0.0116 - accuracy: 0.9962 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0086 - accuracy: 0.9969\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0346 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  250\n",
      "1210/1210 - 16s - loss: 0.0101 - accuracy: 0.9962 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0364 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  251\n",
      "1210/1210 - 16s - loss: 0.0183 - accuracy: 0.9933 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0056 - accuracy: 0.9984\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0307 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  252\n",
      "1210/1210 - 16s - loss: 0.0133 - accuracy: 0.9956 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0036 - accuracy: 0.9989\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0265 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  253\n",
      "1210/1210 - 17s - loss: 0.0115 - accuracy: 0.9956 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0113 - accuracy: 0.9962\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0301 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  254\n",
      "1210/1210 - 17s - loss: 0.0126 - accuracy: 0.9956 - 17s/epoch - 14ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0077 - accuracy: 0.9978\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0363 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  255\n",
      "1210/1210 - 17s - loss: 0.0127 - accuracy: 0.9952 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0037 - accuracy: 0.9990\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0244 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  256\n",
      "1210/1210 - 16s - loss: 0.0107 - accuracy: 0.9960 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0055 - accuracy: 0.9986\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  257\n",
      "1210/1210 - 16s - loss: 0.0150 - accuracy: 0.9951 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0037 - accuracy: 0.9991\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0249 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  258\n",
      "1210/1210 - 16s - loss: 0.0128 - accuracy: 0.9955 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0026 - accuracy: 0.9997\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0272 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  259\n",
      "1210/1210 - 17s - loss: 0.0106 - accuracy: 0.9963 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  260\n",
      "1210/1210 - 16s - loss: 0.0180 - accuracy: 0.9943 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0065 - accuracy: 0.9977\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0346 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  261\n",
      "1210/1210 - 17s - loss: 0.0119 - accuracy: 0.9955 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0022 - accuracy: 0.9998\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0262 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  262\n",
      "1210/1210 - 16s - loss: 0.0135 - accuracy: 0.9950 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0029 - accuracy: 0.9994\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0276 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  263\n",
      "1210/1210 - 16s - loss: 0.0093 - accuracy: 0.9971 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0054 - accuracy: 0.9980\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0331 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  264\n",
      "1210/1210 - 16s - loss: 0.0089 - accuracy: 0.9970 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0035 - accuracy: 0.9990\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0282 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  265\n",
      "1210/1210 - 16s - loss: 0.0151 - accuracy: 0.9953 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0253 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  266\n",
      "1210/1210 - 17s - loss: 0.0125 - accuracy: 0.9960 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0032 - accuracy: 0.9992\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0280 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  267\n",
      "1210/1210 - 17s - loss: 0.0047 - accuracy: 0.9986 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0099 - accuracy: 0.9962\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0441 - accuracy: 0.9870\n",
      "\n",
      "Epoch:  268\n",
      "1210/1210 - 16s - loss: 0.0154 - accuracy: 0.9946 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0054 - accuracy: 0.9983\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0280 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  269\n",
      "1210/1210 - 17s - loss: 0.0107 - accuracy: 0.9967 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0213 - accuracy: 0.9922\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0519 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  270\n",
      "1210/1210 - 17s - loss: 0.0132 - accuracy: 0.9950 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0109 - accuracy: 0.9958\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0403 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  271\n",
      "1210/1210 - 16s - loss: 0.0130 - accuracy: 0.9953 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0023 - accuracy: 0.9994\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0246 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  272\n",
      "1210/1210 - 16s - loss: 0.0098 - accuracy: 0.9966 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0034 - accuracy: 0.9989\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  273\n",
      "1210/1210 - 17s - loss: 0.0116 - accuracy: 0.9958 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0035 - accuracy: 0.9990\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0281 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  274\n",
      "1210/1210 - 17s - loss: 0.0098 - accuracy: 0.9967 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0033 - accuracy: 0.9992\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0280 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  275\n",
      "1210/1210 - 17s - loss: 0.0124 - accuracy: 0.9954 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0118 - accuracy: 0.9952\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0464 - accuracy: 0.9866\n",
      "\n",
      "Epoch:  276\n",
      "1210/1210 - 17s - loss: 0.0108 - accuracy: 0.9963 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0030 - accuracy: 0.9991\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  277\n",
      "1210/1210 - 17s - loss: 0.0140 - accuracy: 0.9949 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0297 - accuracy: 0.9895\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0652 - accuracy: 0.9783\n",
      "\n",
      "Epoch:  278\n",
      "1210/1210 - 17s - loss: 0.0070 - accuracy: 0.9977 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0227 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  279\n",
      "1210/1210 - 16s - loss: 0.0149 - accuracy: 0.9959 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0132 - accuracy: 0.9952\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0396 - accuracy: 0.9870\n",
      "\n",
      "Epoch:  280\n",
      "1210/1210 - 16s - loss: 0.0077 - accuracy: 0.9970 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0018 - accuracy: 0.9997\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0241 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  281\n",
      "1210/1210 - 17s - loss: 0.0130 - accuracy: 0.9958 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0039 - accuracy: 0.9984\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0330 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  282\n",
      "1210/1210 - 19s - loss: 0.0150 - accuracy: 0.9952 - 19s/epoch - 15ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0256 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  283\n",
      "1210/1210 - 17s - loss: 0.0080 - accuracy: 0.9972 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0308 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  284\n",
      "1210/1210 - 16s - loss: 0.0094 - accuracy: 0.9964 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0023 - accuracy: 0.9996\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0278 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  285\n",
      "1210/1210 - 17s - loss: 0.0156 - accuracy: 0.9943 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0044 - accuracy: 0.9987\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0307 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  286\n",
      "1210/1210 - 17s - loss: 0.0081 - accuracy: 0.9970 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0037 - accuracy: 0.9988\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0313 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  287\n",
      "1210/1210 - 17s - loss: 0.0127 - accuracy: 0.9955 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0222 - accuracy: 0.9918\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0576 - accuracy: 0.9857\n",
      "\n",
      "Epoch:  288\n",
      "1210/1210 - 16s - loss: 0.0104 - accuracy: 0.9962 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0067 - accuracy: 0.9975\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0350 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  289\n",
      "1210/1210 - 16s - loss: 0.0080 - accuracy: 0.9971 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  290\n",
      "1210/1210 - 16s - loss: 0.0131 - accuracy: 0.9958 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0042 - accuracy: 0.9988\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0324 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  291\n",
      "1210/1210 - 17s - loss: 0.0088 - accuracy: 0.9970 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0039 - accuracy: 0.9989\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0371 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  292\n",
      "1210/1210 - 17s - loss: 0.0134 - accuracy: 0.9959 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0070 - accuracy: 0.9977\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0359 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  293\n",
      "1210/1210 - 16s - loss: 0.0124 - accuracy: 0.9960 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0038 - accuracy: 0.9989\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0314 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  294\n",
      "1210/1210 - 16s - loss: 0.0100 - accuracy: 0.9963 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0467 - accuracy: 0.9828\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0891 - accuracy: 0.9752\n",
      "\n",
      "Epoch:  295\n",
      "1210/1210 - 16s - loss: 0.0149 - accuracy: 0.9941 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0025 - accuracy: 0.9994\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0292 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  296\n",
      "1210/1210 - 16s - loss: 0.0079 - accuracy: 0.9974 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0261 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  297\n",
      "1210/1210 - 16s - loss: 0.0107 - accuracy: 0.9960 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0275 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  298\n",
      "1210/1210 - 16s - loss: 0.0085 - accuracy: 0.9971 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0046 - accuracy: 0.9983\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0324 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  299\n",
      "1210/1210 - 17s - loss: 0.0107 - accuracy: 0.9964 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0315 - accuracy: 0.9885\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0711 - accuracy: 0.9814\n",
      "\n",
      "Epoch:  300\n",
      "1210/1210 - 16s - loss: 0.0043 - accuracy: 0.9986 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  301\n",
      "1210/1210 - 16s - loss: 0.0151 - accuracy: 0.9956 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0023 - accuracy: 0.9995\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0278 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  302\n",
      "1210/1210 - 16s - loss: 0.0092 - accuracy: 0.9965 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0067 - accuracy: 0.9975\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0346 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  303\n",
      "1210/1210 - 17s - loss: 0.0135 - accuracy: 0.9958 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0044 - accuracy: 0.9983\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0368 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  304\n",
      "1210/1210 - 16s - loss: 0.0078 - accuracy: 0.9967 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0288 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  305\n",
      "1210/1210 - 17s - loss: 0.0143 - accuracy: 0.9953 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0018 - accuracy: 0.9998\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0265 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  306\n",
      "1210/1210 - 21s - loss: 0.0097 - accuracy: 0.9963 - 21s/epoch - 17ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0060 - accuracy: 0.9979\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0296 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  307\n",
      "1210/1210 - 19s - loss: 0.0107 - accuracy: 0.9967 - 19s/epoch - 16ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0262 - accuracy: 0.9894\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0620 - accuracy: 0.9837\n",
      "\n",
      "Epoch:  308\n",
      "1210/1210 - 18s - loss: 0.0149 - accuracy: 0.9950 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1272 - accuracy: 0.9693\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1770 - accuracy: 0.9616\n",
      "\n",
      "Epoch:  309\n",
      "1210/1210 - 17s - loss: 0.0126 - accuracy: 0.9963 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0017 - accuracy: 0.9995\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  310\n",
      "1210/1210 - 16s - loss: 0.0072 - accuracy: 0.9974 - 16s/epoch - 13ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0194 - accuracy: 0.9929\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0564 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  311\n",
      "1210/1210 - 16s - loss: 0.0077 - accuracy: 0.9974 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0137 - accuracy: 0.9949\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0536 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  312\n",
      "1210/1210 - 16s - loss: 0.0169 - accuracy: 0.9951 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0104 - accuracy: 0.9957\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0425 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  313\n",
      "1210/1210 - 16s - loss: 0.0076 - accuracy: 0.9969 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0272 - accuracy: 0.9911\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0541 - accuracy: 0.9833\n",
      "\n",
      "Epoch:  314\n",
      "1210/1210 - 16s - loss: 0.0074 - accuracy: 0.9977 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0329 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  315\n",
      "1210/1210 - 16s - loss: 0.0131 - accuracy: 0.9958 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0047 - accuracy: 0.9986\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0295 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  316\n",
      "1210/1210 - 16s - loss: 0.0092 - accuracy: 0.9966 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0364 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  317\n",
      "1210/1210 - 16s - loss: 0.0090 - accuracy: 0.9972 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0054 - accuracy: 0.9983\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0398 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  318\n",
      "1210/1210 - 16s - loss: 0.0133 - accuracy: 0.9958 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0022 - accuracy: 0.9993\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  319\n",
      "1210/1210 - 16s - loss: 0.0082 - accuracy: 0.9975 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 0.9989\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0309 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  320\n",
      "1210/1210 - 16s - loss: 0.0130 - accuracy: 0.9952 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0094 - accuracy: 0.9960\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0369 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  321\n",
      "1210/1210 - 16s - loss: 0.0094 - accuracy: 0.9967 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0069 - accuracy: 0.9972\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0427 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  322\n",
      "1210/1210 - 16s - loss: 0.0116 - accuracy: 0.9955 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0019 - accuracy: 0.9997\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0279 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  323\n",
      "1210/1210 - 16s - loss: 0.0044 - accuracy: 0.9984 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0062 - accuracy: 0.9976\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0382 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  324\n",
      "1210/1210 - 16s - loss: 0.0128 - accuracy: 0.9959 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0092 - accuracy: 0.9962\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0419 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  325\n",
      "1210/1210 - 16s - loss: 0.0153 - accuracy: 0.9952 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0050 - accuracy: 0.9982\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0320 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  326\n",
      "1210/1210 - 17s - loss: 0.0050 - accuracy: 0.9983 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0295 - accuracy: 0.9898\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0600 - accuracy: 0.9816\n",
      "\n",
      "Epoch:  327\n",
      "1210/1210 - 16s - loss: 0.0079 - accuracy: 0.9976 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0039 - accuracy: 0.9989\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0302 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  328\n",
      "1210/1210 - 16s - loss: 0.0167 - accuracy: 0.9957 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0294 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  329\n",
      "1210/1210 - 16s - loss: 0.0083 - accuracy: 0.9971 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0373 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  330\n",
      "1210/1210 - 16s - loss: 0.0083 - accuracy: 0.9972 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0079 - accuracy: 0.9972\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0392 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  331\n",
      "1210/1210 - 17s - loss: 0.0073 - accuracy: 0.9979 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0475 - accuracy: 0.9826\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0860 - accuracy: 0.9752\n",
      "\n",
      "Epoch:  332\n",
      "1210/1210 - 17s - loss: 0.0079 - accuracy: 0.9972 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0045 - accuracy: 0.9983\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0332 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  333\n",
      "1210/1210 - 16s - loss: 0.0134 - accuracy: 0.9956 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0059 - accuracy: 0.9977\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0340 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  334\n",
      "1210/1210 - 16s - loss: 0.0091 - accuracy: 0.9969 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0250 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  335\n",
      "1210/1210 - 16s - loss: 0.0102 - accuracy: 0.9966 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0025 - accuracy: 0.9990\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  336\n",
      "1210/1210 - 16s - loss: 0.0107 - accuracy: 0.9961 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0023 - accuracy: 0.9994\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0268 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  337\n",
      "1210/1210 - 16s - loss: 0.0091 - accuracy: 0.9971 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0069 - accuracy: 0.9974\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0381 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  338\n",
      "1210/1210 - 16s - loss: 0.0088 - accuracy: 0.9968 - 16s/epoch - 13ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0266 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  339\n",
      "1210/1210 - 16s - loss: 0.0112 - accuracy: 0.9964 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 9.8070e-04 - accuracy: 1.0000\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0259 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  340\n",
      "1210/1210 - 16s - loss: 0.0051 - accuracy: 0.9981 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0165 - accuracy: 0.9940\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0495 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  341\n",
      "1210/1210 - 16s - loss: 0.0140 - accuracy: 0.9952 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0025 - accuracy: 0.9994\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0275 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  342\n",
      "1210/1210 - 16s - loss: 0.0078 - accuracy: 0.9971 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0232 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  343\n",
      "1210/1210 - 16s - loss: 0.0122 - accuracy: 0.9956 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0012 - accuracy: 0.9999\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0232 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  344\n",
      "1210/1210 - 16s - loss: 0.0094 - accuracy: 0.9965 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0026 - accuracy: 0.9992\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0277 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  345\n",
      "1210/1210 - 16s - loss: 0.0056 - accuracy: 0.9981 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0010 - accuracy: 0.9999\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0230 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  346\n",
      "1210/1210 - 16s - loss: 0.0147 - accuracy: 0.9950 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0032 - accuracy: 0.9989\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0308 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  347\n",
      "1210/1210 - 16s - loss: 0.0042 - accuracy: 0.9987 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0379 - accuracy: 0.9886\n",
      "\n",
      "Epoch:  348\n",
      "1210/1210 - 16s - loss: 0.0145 - accuracy: 0.9946 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0047 - accuracy: 0.9986\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0296 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  349\n",
      "1210/1210 - 16s - loss: 0.0034 - accuracy: 0.9989 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0297 - accuracy: 0.9903\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0658 - accuracy: 0.9833\n",
      "\n",
      "Epoch:  350\n",
      "1210/1210 - 16s - loss: 0.0125 - accuracy: 0.9960 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0078 - accuracy: 0.9969\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0384 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  351\n",
      "1210/1210 - 16s - loss: 0.0106 - accuracy: 0.9964 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0026 - accuracy: 0.9991\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0269 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  352\n",
      "1210/1210 - 16s - loss: 0.0098 - accuracy: 0.9965 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0025 - accuracy: 0.9991\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0285 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  353\n",
      "1210/1210 - 16s - loss: 0.0104 - accuracy: 0.9964 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0013 - accuracy: 0.9998\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  354\n",
      "1210/1210 - 16s - loss: 0.0114 - accuracy: 0.9964 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0076 - accuracy: 0.9978\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  355\n",
      "1210/1210 - 16s - loss: 0.0076 - accuracy: 0.9976 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 8.5558e-04 - accuracy: 0.9998\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  356\n",
      "1210/1210 - 16s - loss: 0.0102 - accuracy: 0.9965 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0141 - accuracy: 0.9953\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0405 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  357\n",
      "1210/1210 - 16s - loss: 0.0113 - accuracy: 0.9964 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0245 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  358\n",
      "1210/1210 - 16s - loss: 0.0123 - accuracy: 0.9962 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  359\n",
      "1210/1210 - 16s - loss: 0.0103 - accuracy: 0.9963 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0327 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  360\n",
      "1210/1210 - 16s - loss: 0.0087 - accuracy: 0.9968 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0031 - accuracy: 0.9989\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0317 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  361\n",
      "1210/1210 - 16s - loss: 0.0064 - accuracy: 0.9976 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0242 - accuracy: 0.9908\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0653 - accuracy: 0.9837\n",
      "\n",
      "Epoch:  362\n",
      "1210/1210 - 16s - loss: 0.0064 - accuracy: 0.9979 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0130 - accuracy: 0.9948\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0467 - accuracy: 0.9859\n",
      "\n",
      "Epoch:  363\n",
      "1210/1210 - 16s - loss: 0.0126 - accuracy: 0.9956 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  364\n",
      "1210/1210 - 16s - loss: 0.0034 - accuracy: 0.9990 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0049 - accuracy: 0.9982\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0394 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  365\n",
      "1210/1210 - 16s - loss: 0.0113 - accuracy: 0.9959 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0383 - accuracy: 0.9889\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0717 - accuracy: 0.9828\n",
      "\n",
      "Epoch:  366\n",
      "1210/1210 - 16s - loss: 0.0096 - accuracy: 0.9964 - 16s/epoch - 14ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0282 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  367\n",
      "1210/1210 - 17s - loss: 0.0094 - accuracy: 0.9970 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0197 - accuracy: 0.9918\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0607 - accuracy: 0.9839\n",
      "\n",
      "Epoch:  368\n",
      "1210/1210 - 17s - loss: 0.0098 - accuracy: 0.9963 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0050 - accuracy: 0.9982\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0408 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  369\n",
      "1210/1210 - 16s - loss: 0.0016 - accuracy: 0.9997 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0022 - accuracy: 0.9994\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0329 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  370\n",
      "1210/1210 - 16s - loss: 0.0095 - accuracy: 0.9972 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0210 - accuracy: 0.9921\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0588 - accuracy: 0.9857\n",
      "\n",
      "Epoch:  371\n",
      "1210/1210 - 16s - loss: 0.0125 - accuracy: 0.9962 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0280 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  372\n",
      "1210/1210 - 16s - loss: 0.0055 - accuracy: 0.9981 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0102 - accuracy: 0.9959\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0437 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  373\n",
      "1210/1210 - 16s - loss: 0.0087 - accuracy: 0.9968 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0247 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  374\n",
      "1210/1210 - 16s - loss: 0.0071 - accuracy: 0.9974 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0433 - accuracy: 0.9862\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0852 - accuracy: 0.9804\n",
      "\n",
      "Epoch:  375\n",
      "1210/1210 - 16s - loss: 0.0090 - accuracy: 0.9968 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0029 - accuracy: 0.9994\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0346 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  376\n",
      "1210/1210 - 16s - loss: 0.0090 - accuracy: 0.9966 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  377\n",
      "1210/1210 - 16s - loss: 0.0078 - accuracy: 0.9974 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0625 - accuracy: 0.9796\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1069 - accuracy: 0.9719\n",
      "\n",
      "Epoch:  378\n",
      "1210/1210 - 16s - loss: 0.0063 - accuracy: 0.9980 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0356 - accuracy: 0.9891\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0789 - accuracy: 0.9818\n",
      "\n",
      "Epoch:  379\n",
      "1210/1210 - 16s - loss: 0.0121 - accuracy: 0.9953 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0043 - accuracy: 0.9986\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0325 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  380\n",
      "1210/1210 - 16s - loss: 0.0108 - accuracy: 0.9964 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 6.3139e-04 - accuracy: 1.0000\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0253 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  381\n",
      "1210/1210 - 16s - loss: 0.0048 - accuracy: 0.9984 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0176 - accuracy: 0.9936\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0560 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  382\n",
      "1210/1210 - 16s - loss: 0.0072 - accuracy: 0.9982 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0233 - accuracy: 0.9921\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0578 - accuracy: 0.9835\n",
      "\n",
      "Epoch:  383\n",
      "1210/1210 - 16s - loss: 0.0102 - accuracy: 0.9969 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 9.9197e-04 - accuracy: 0.9998\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0249 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  384\n",
      "1210/1210 - 16s - loss: 0.0097 - accuracy: 0.9966 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0060 - accuracy: 0.9977\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0447 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  385\n",
      "1210/1210 - 16s - loss: 0.0057 - accuracy: 0.9983 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0325 - accuracy: 0.9881\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0771 - accuracy: 0.9808\n",
      "\n",
      "Epoch:  386\n",
      "1210/1210 - 16s - loss: 0.0085 - accuracy: 0.9971 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0238 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  387\n",
      "1210/1210 - 16s - loss: 0.0109 - accuracy: 0.9965 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0261 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  388\n",
      "1210/1210 - 16s - loss: 0.0037 - accuracy: 0.9984 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0019 - accuracy: 0.9995\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0311 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  389\n",
      "1210/1210 - 16s - loss: 0.0101 - accuracy: 0.9962 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0410 - accuracy: 0.9849\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0761 - accuracy: 0.9804\n",
      "\n",
      "Epoch:  390\n",
      "1210/1210 - 16s - loss: 0.0128 - accuracy: 0.9958 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0022 - accuracy: 0.9995\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0283 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  391\n",
      "1210/1210 - 16s - loss: 0.0032 - accuracy: 0.9990 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0305 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  392\n",
      "1210/1210 - 16s - loss: 0.0135 - accuracy: 0.9951 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0115 - accuracy: 0.9949\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0479 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  393\n",
      "1210/1210 - 16s - loss: 0.0062 - accuracy: 0.9977 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0291 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  394\n",
      "1210/1210 - 16s - loss: 0.0046 - accuracy: 0.9985 - 16s/epoch - 13ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0086 - accuracy: 0.9966\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0395 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  395\n",
      "1210/1210 - 16s - loss: 0.0124 - accuracy: 0.9961 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 6.2572e-04 - accuracy: 0.9999\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0240 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  396\n",
      "1210/1210 - 16s - loss: 0.0133 - accuracy: 0.9961 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0239 - accuracy: 0.9917\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0601 - accuracy: 0.9870\n",
      "\n",
      "Epoch:  397\n",
      "1210/1210 - 16s - loss: 0.0033 - accuracy: 0.9991 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0272 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  398\n",
      "1210/1210 - 16s - loss: 0.0095 - accuracy: 0.9966 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0022 - accuracy: 0.9994\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0313 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  399\n",
      "1210/1210 - 16s - loss: 0.0065 - accuracy: 0.9982 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0013 - accuracy: 0.9998\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0242 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  400\n",
      "1210/1210 - 16s - loss: 0.0087 - accuracy: 0.9978 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0091 - accuracy: 0.9964\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0418 - accuracy: 0.9899\n"
     ]
    }
   ],
   "source": [
    "for x in range(400):\n",
    "    print(\"\\nEpoch: \",x+1)\n",
    "    history = model.fit(X_train ,y_train ,batch_size=BATCH_SIZE ,epochs=1, verbose=2, shuffle=True)\n",
    "    if history_dataframe.size == 0:\n",
    "        history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    else:\n",
    "        history_dataframe = pd.concat([history_dataframe,pd.DataFrame.from_dict(history.history)],axis=0,ignore_index=True)\n",
    "    \n",
    "    print(\"for training\")\n",
    "    train_eva.append(model.evaluate(X_train,y_train))\n",
    "    print(\"for testing\")\n",
    "    test_eva.append(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ec37c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.308394</td>\n",
       "      <td>0.361753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.967880</td>\n",
       "      <td>0.582494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.683898</td>\n",
       "      <td>0.719785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.573747</td>\n",
       "      <td>0.765463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.496719</td>\n",
       "      <td>0.805353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.013268</td>\n",
       "      <td>0.996073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.003287</td>\n",
       "      <td>0.999122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.009484</td>\n",
       "      <td>0.996590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.006508</td>\n",
       "      <td>0.998191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.008653</td>\n",
       "      <td>0.997778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy\n",
       "0    1.308394  0.361753\n",
       "1    0.967880  0.582494\n",
       "2    0.683898  0.719785\n",
       "3    0.573747  0.765463\n",
       "4    0.496719  0.805353\n",
       "..        ...       ...\n",
       "395  0.013268  0.996073\n",
       "396  0.003287  0.999122\n",
       "397  0.009484  0.996590\n",
       "398  0.006508  0.998191\n",
       "399  0.008653  0.997778\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c8463e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva_df = pd.DataFrame(train_eva,columns=['loss','accuracy'])\n",
    "test_eva_df = pd.DataFrame(test_eva,columns=['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cc95506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(df,title,xlabel,ylabel,values=['loss'],legends=[]):\n",
    "    \n",
    "    for value in values:\n",
    "        epoch_count = range(1, len(df.index) + 1)\n",
    "        plt.plot(epoch_count, df[value].tolist())\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    if legends==[]:\n",
    "        legends = values\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35c781fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(train_eva_df,'Train','Epoch','Loss',['loss','accuracy'])\n",
    "plot_graph(test_eva_df,'Test','Epoch','Loss',['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8db1e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eva_df['accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7560c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss          0\n",
       "accuracy    338\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eva_df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd060757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9933870434761047"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eva_df['accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9601cff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss          0\n",
       "accuracy    354\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eva_df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f71d4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
