{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c4fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35daa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6aebd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'wheat_12_var_avg_new.csv'\n",
    "\n",
    "def dir(file_name):\n",
    "    return '../data/'+file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a19daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_X_Y(dataframe):\n",
    "    return (dataframe.drop('classes', axis =1), dataframe.loc[:,'classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "554bc6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class filter_method(Enum):\n",
    "    none = 0\n",
    "    snv = 1\n",
    "    msc = 2\n",
    "    savgol = 3\n",
    "\n",
    "FILT = 1\n",
    "FILTER = filter_method(FILT).name\n",
    "\n",
    "# to be set if filter chosen is savgol\n",
    "WINDOW = 7\n",
    "ORDER = 2\n",
    "DERIVATIVE = 1\n",
    "\n",
    "#will be used for test dataset in msc\n",
    "reference= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c20231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def create_test_train(X, y, test_size = 0.2, shuffle = True):\n",
    "    return train_test_split(X,y, test_size = test_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e9301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Normal Variate\n",
    "def snv(input_data):\n",
    "  \n",
    "    # Define a new array and populate it with the corrected data  \n",
    "    output_data = np.zeros_like(input_data)\n",
    "    for i in range(input_data.shape[0]):\n",
    " \n",
    "        # Apply correction\n",
    "        output_data[i,:] = (input_data[i,:] - np.mean(input_data[i,:])) / np.std(input_data[i,:])\n",
    " \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d925acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicative scatter correction\n",
    "def msc(input_data, reference=None):\n",
    "#     print(reference)\n",
    "    ''' Perform Multiplicative scatter correction'''\n",
    "\n",
    "    # Baseline correction\n",
    "    for i in range(input_data.shape[0]):\n",
    "        input_data[i,:] -= input_data[i,:].mean()\n",
    "\n",
    "    # Get the reference spectrum. If not given, estimate from the mean    \n",
    "    if reference is None:    \n",
    "        # Calculate mean\n",
    "        matm = np.mean(input_data, axis=0)\n",
    "    else:\n",
    "        matm = reference\n",
    "\n",
    "    # Define a new data matrix and populate it with the corrected data    \n",
    "    output_data = np.zeros_like(input_data)\n",
    "    for i in range(input_data.shape[0]):\n",
    "        # Run regression\n",
    "        fit = np.polyfit(matm, input_data[i,:], 1, full=True)\n",
    "        # Apply correction\n",
    "        output_data[i,:] = (input_data[i,:] - fit[0][1]) / fit[0][0] \n",
    "\n",
    "    return (output_data, matm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b5090be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter, general_gaussian\n",
    "def savgol(input_data):\n",
    "    w = WINDOW\n",
    "    p = ORDER\n",
    "    d = DERIVATIVE\n",
    "    \n",
    "    output_data = savgol_filter(np.array(input_data), w, polyorder = p, deriv=d)\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b68affd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X,y, type=\"train\"):\n",
    "    if FILTER == \"snv\":\n",
    "        return {\"X\": snv(np.array(X)), \"y\": y}\n",
    "    elif FILTER == \"msc\":\n",
    "        msc_output = msc(np.array(X), reference = reference if type==\"test\" else None)\n",
    "        X = msc_output[0]\n",
    "        ref = msc_output[1]\n",
    "        return {\n",
    "            \"X\": X,\n",
    "            \"y\": y,\n",
    "            \"ref\": ref\n",
    "        }\n",
    "    elif FILTER == \"savgol\":\n",
    "        return {\n",
    "            \"X\": savgol(X),\n",
    "            \"y\": y\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"X\":X,\n",
    "            \"y\":y\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8dec1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(dir(file_name))\n",
    "X,y = seperate_X_Y(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58535347",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_set = set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e8c8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_CLASSES = len(y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd357e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = create_test_train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f79eb839",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_results = preprocess_data(X_train_raw,y_train_raw)\n",
    "X_train, y_train = preprocessed_results[\"X\"], preprocessed_results[\"y\"]\n",
    "\n",
    "if FILTER == \"msc\":\n",
    "    reference = preprocessed_results[\"ref\"]\n",
    "    \n",
    "preprocessed_results_test = preprocess_data(X_test_raw, y_test_raw, type=\"test\")\n",
    "X_test, y_test = preprocessed_results_test[\"X\"], preprocessed_results_test[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e1e570e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19353, 147, 1)\n",
      "(4839, 147, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec820add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Input, Conv1D, Flatten, Dense, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba682707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(input_shape,num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=5, input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=5 ))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d95ace51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(X_train.shape[1:],NUM_OF_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33a0377c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 143, 32)           192       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 28, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 896)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              897000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 4004      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 901,196\n",
      "Trainable params: 901,196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20cd1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva = []\n",
    "test_eva = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fd5eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dataframe = pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "863f63f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  1\n",
      "1210/1210 - 22s - loss: 1.2818 - accuracy: 0.3885 - 22s/epoch - 18ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 1.0617 - accuracy: 0.5686\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 1.0615 - accuracy: 0.5648\n",
      "\n",
      "Epoch:  2\n",
      "1210/1210 - 17s - loss: 0.8513 - accuracy: 0.6474 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.7888 - accuracy: 0.6419\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.8000 - accuracy: 0.6390\n",
      "\n",
      "Epoch:  3\n",
      "1210/1210 - 17s - loss: 0.6106 - accuracy: 0.7515 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.5143 - accuracy: 0.7986\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.5294 - accuracy: 0.7936\n",
      "\n",
      "Epoch:  4\n",
      "1210/1210 - 17s - loss: 0.5107 - accuracy: 0.7946 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.4592 - accuracy: 0.8244\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4751 - accuracy: 0.8177\n",
      "\n",
      "Epoch:  5\n",
      "1210/1210 - 17s - loss: 0.4298 - accuracy: 0.8320 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.3676 - accuracy: 0.8636\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.3803 - accuracy: 0.8580\n",
      "\n",
      "Epoch:  6\n",
      "1210/1210 - 17s - loss: 0.3710 - accuracy: 0.8583 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.4966 - accuracy: 0.7998\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5071 - accuracy: 0.7907\n",
      "\n",
      "Epoch:  7\n",
      "1210/1210 - 17s - loss: 0.3221 - accuracy: 0.8793 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.2804 - accuracy: 0.8998\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.2867 - accuracy: 0.8985\n",
      "\n",
      "Epoch:  8\n",
      "1210/1210 - 17s - loss: 0.2808 - accuracy: 0.8973 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.2696 - accuracy: 0.9032\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.2785 - accuracy: 0.8996\n",
      "\n",
      "Epoch:  9\n",
      "1210/1210 - 17s - loss: 0.2490 - accuracy: 0.9092 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.2219 - accuracy: 0.9216\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.2268 - accuracy: 0.9192\n",
      "\n",
      "Epoch:  10\n",
      "1210/1210 - 17s - loss: 0.2250 - accuracy: 0.9205 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1981 - accuracy: 0.9296\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.2111 - accuracy: 0.9266\n",
      "\n",
      "Epoch:  11\n",
      "1210/1210 - 17s - loss: 0.2080 - accuracy: 0.9245 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.1876 - accuracy: 0.9338\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1949 - accuracy: 0.9312\n",
      "\n",
      "Epoch:  12\n",
      "1210/1210 - 17s - loss: 0.1875 - accuracy: 0.9342 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1786 - accuracy: 0.9353\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1885 - accuracy: 0.9322\n",
      "\n",
      "Epoch:  13\n",
      "1210/1210 - 17s - loss: 0.1787 - accuracy: 0.9374 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1587 - accuracy: 0.9425\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.1700 - accuracy: 0.9401\n",
      "\n",
      "Epoch:  14\n",
      "1210/1210 - 16s - loss: 0.1642 - accuracy: 0.9401 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1690 - accuracy: 0.9372\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1843 - accuracy: 0.9328\n",
      "\n",
      "Epoch:  15\n",
      "1210/1210 - 16s - loss: 0.1618 - accuracy: 0.9407 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.2641 - accuracy: 0.8914\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.2809 - accuracy: 0.8876\n",
      "\n",
      "Epoch:  16\n",
      "1210/1210 - 16s - loss: 0.1476 - accuracy: 0.9473 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1129 - accuracy: 0.9628\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1233 - accuracy: 0.9593\n",
      "\n",
      "Epoch:  17\n",
      "1210/1210 - 16s - loss: 0.1460 - accuracy: 0.9471 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.1122 - accuracy: 0.9637\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.1225 - accuracy: 0.9616\n",
      "\n",
      "Epoch:  18\n",
      "1210/1210 - 17s - loss: 0.1365 - accuracy: 0.9506 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1188 - accuracy: 0.9582\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1248 - accuracy: 0.9552\n",
      "\n",
      "Epoch:  19\n",
      "1210/1210 - 17s - loss: 0.1296 - accuracy: 0.9555 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.1227 - accuracy: 0.9578\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1322 - accuracy: 0.9560\n",
      "\n",
      "Epoch:  20\n",
      "1210/1210 - 17s - loss: 0.1240 - accuracy: 0.9554 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.1063 - accuracy: 0.9639\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1158 - accuracy: 0.9622\n",
      "\n",
      "Epoch:  21\n",
      "1210/1210 - 17s - loss: 0.1208 - accuracy: 0.9578 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1037 - accuracy: 0.9613\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1123 - accuracy: 0.9599\n",
      "\n",
      "Epoch:  22\n",
      "1210/1210 - 17s - loss: 0.1156 - accuracy: 0.9587 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0872 - accuracy: 0.9713\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0967 - accuracy: 0.9684\n",
      "\n",
      "Epoch:  23\n",
      "1210/1210 - 17s - loss: 0.1120 - accuracy: 0.9611 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1090 - accuracy: 0.9594\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1247 - accuracy: 0.9566\n",
      "\n",
      "Epoch:  24\n",
      "1210/1210 - 17s - loss: 0.1080 - accuracy: 0.9616 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0980 - accuracy: 0.9666\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1107 - accuracy: 0.9609\n",
      "\n",
      "Epoch:  25\n",
      "1210/1210 - 17s - loss: 0.1060 - accuracy: 0.9633 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1054 - accuracy: 0.9628\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1216 - accuracy: 0.9562\n",
      "\n",
      "Epoch:  26\n",
      "1210/1210 - 17s - loss: 0.0982 - accuracy: 0.9662 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1063 - accuracy: 0.9588\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1171 - accuracy: 0.9576\n",
      "\n",
      "Epoch:  27\n",
      "1210/1210 - 17s - loss: 0.0956 - accuracy: 0.9667 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0894 - accuracy: 0.9685\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0984 - accuracy: 0.9638\n",
      "\n",
      "Epoch:  28\n",
      "1210/1210 - 17s - loss: 0.0969 - accuracy: 0.9647 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0763 - accuracy: 0.9730\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0880 - accuracy: 0.9678\n",
      "\n",
      "Epoch:  29\n",
      "1210/1210 - 17s - loss: 0.0984 - accuracy: 0.9637 - 17s/epoch - 14ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0842 - accuracy: 0.9729\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0968 - accuracy: 0.9661\n",
      "\n",
      "Epoch:  30\n",
      "1210/1210 - 17s - loss: 0.0937 - accuracy: 0.9681 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0977 - accuracy: 0.9651\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1126 - accuracy: 0.9597\n",
      "\n",
      "Epoch:  31\n",
      "1210/1210 - 17s - loss: 0.0910 - accuracy: 0.9672 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0901 - accuracy: 0.9683\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1023 - accuracy: 0.9665\n",
      "\n",
      "Epoch:  32\n",
      "1210/1210 - 17s - loss: 0.0896 - accuracy: 0.9687 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0763 - accuracy: 0.9746\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0910 - accuracy: 0.9684\n",
      "\n",
      "Epoch:  33\n",
      "1210/1210 - 17s - loss: 0.0847 - accuracy: 0.9708 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0688 - accuracy: 0.9767\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0798 - accuracy: 0.9754\n",
      "\n",
      "Epoch:  34\n",
      "1210/1210 - 16s - loss: 0.0834 - accuracy: 0.9702 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0933 - accuracy: 0.9655\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1050 - accuracy: 0.9605\n",
      "\n",
      "Epoch:  35\n",
      "1210/1210 - 17s - loss: 0.0835 - accuracy: 0.9702 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0568 - accuracy: 0.9812\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0695 - accuracy: 0.9758\n",
      "\n",
      "Epoch:  36\n",
      "1210/1210 - 17s - loss: 0.0818 - accuracy: 0.9702 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0704 - accuracy: 0.9746\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0867 - accuracy: 0.9692\n",
      "\n",
      "Epoch:  37\n",
      "1210/1210 - 17s - loss: 0.0780 - accuracy: 0.9718 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0734 - accuracy: 0.9745\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0910 - accuracy: 0.9684\n",
      "\n",
      "Epoch:  38\n",
      "1210/1210 - 18s - loss: 0.0817 - accuracy: 0.9714 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 5s 8ms/step - loss: 0.0652 - accuracy: 0.9786\n",
      "for testing\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 0.0742 - accuracy: 0.9744\n",
      "\n",
      "Epoch:  39\n",
      "1210/1210 - 21s - loss: 0.0773 - accuracy: 0.9732 - 21s/epoch - 17ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0855 - accuracy: 0.9701\n",
      "for testing\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 0.1022 - accuracy: 0.9667\n",
      "\n",
      "Epoch:  40\n",
      "1210/1210 - 19s - loss: 0.0742 - accuracy: 0.9744 - 19s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0502 - accuracy: 0.9840\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0626 - accuracy: 0.9785\n",
      "\n",
      "Epoch:  41\n",
      "1210/1210 - 17s - loss: 0.0696 - accuracy: 0.9759 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0582 - accuracy: 0.9802\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0662 - accuracy: 0.9769\n",
      "\n",
      "Epoch:  42\n",
      "1210/1210 - 17s - loss: 0.0754 - accuracy: 0.9728 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0804 - accuracy: 0.9704\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0917 - accuracy: 0.9700\n",
      "\n",
      "Epoch:  43\n",
      "1210/1210 - 17s - loss: 0.0709 - accuracy: 0.9757 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0464 - accuracy: 0.9844\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0599 - accuracy: 0.9783\n",
      "\n",
      "Epoch:  44\n",
      "1210/1210 - 17s - loss: 0.0755 - accuracy: 0.9728 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0780 - accuracy: 0.9722\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0940 - accuracy: 0.9671\n",
      "\n",
      "Epoch:  45\n",
      "1210/1210 - 18s - loss: 0.0681 - accuracy: 0.9753 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0518 - accuracy: 0.9825\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0661 - accuracy: 0.9773\n",
      "\n",
      "Epoch:  46\n",
      "1210/1210 - 17s - loss: 0.0626 - accuracy: 0.9777 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1302 - accuracy: 0.9519\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1416 - accuracy: 0.9504\n",
      "\n",
      "Epoch:  47\n",
      "1210/1210 - 17s - loss: 0.0684 - accuracy: 0.9764 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0410 - accuracy: 0.9863\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0513 - accuracy: 0.9841\n",
      "\n",
      "Epoch:  48\n",
      "1210/1210 - 17s - loss: 0.0634 - accuracy: 0.9775 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0412 - accuracy: 0.9868\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0523 - accuracy: 0.9833\n",
      "\n",
      "Epoch:  49\n",
      "1210/1210 - 17s - loss: 0.0644 - accuracy: 0.9771 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0634 - accuracy: 0.9770\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0763 - accuracy: 0.9717\n",
      "\n",
      "Epoch:  50\n",
      "1210/1210 - 17s - loss: 0.0618 - accuracy: 0.9769 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0865 - accuracy: 0.9679\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0970 - accuracy: 0.9638\n",
      "\n",
      "Epoch:  51\n",
      "1210/1210 - 17s - loss: 0.0621 - accuracy: 0.9781 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0678 - accuracy: 0.9763\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0741 - accuracy: 0.9740\n",
      "\n",
      "Epoch:  52\n",
      "1210/1210 - 17s - loss: 0.0595 - accuracy: 0.9794 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0481 - accuracy: 0.9829\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0585 - accuracy: 0.9793\n",
      "\n",
      "Epoch:  53\n",
      "1210/1210 - 17s - loss: 0.0614 - accuracy: 0.9780 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0522 - accuracy: 0.9828\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0605 - accuracy: 0.9795\n",
      "\n",
      "Epoch:  54\n",
      "1210/1210 - 17s - loss: 0.0565 - accuracy: 0.9803 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0549 - accuracy: 0.9810\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0679 - accuracy: 0.9775\n",
      "\n",
      "Epoch:  55\n",
      "1210/1210 - 17s - loss: 0.0579 - accuracy: 0.9794 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0825 - accuracy: 0.9695\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0965 - accuracy: 0.9647\n",
      "\n",
      "Epoch:  56\n",
      "1210/1210 - 17s - loss: 0.0548 - accuracy: 0.9810 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1120 - accuracy: 0.9595\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1408 - accuracy: 0.9535\n",
      "\n",
      "Epoch:  57\n",
      "1210/1210 - 17s - loss: 0.0599 - accuracy: 0.9800 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0446 - accuracy: 0.9842\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0593 - accuracy: 0.9785\n",
      "\n",
      "Epoch:  58\n",
      "1210/1210 - 17s - loss: 0.0564 - accuracy: 0.9791 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0341 - accuracy: 0.9888\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0458 - accuracy: 0.9853\n",
      "\n",
      "Epoch:  59\n",
      "1210/1210 - 17s - loss: 0.0549 - accuracy: 0.9808 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0559 - accuracy: 0.9796\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0718 - accuracy: 0.9762\n",
      "\n",
      "Epoch:  60\n",
      "1210/1210 - 17s - loss: 0.0556 - accuracy: 0.9806 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0406 - accuracy: 0.9867\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0528 - accuracy: 0.9833\n",
      "\n",
      "Epoch:  61\n",
      "1210/1210 - 17s - loss: 0.0504 - accuracy: 0.9812 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0539 - accuracy: 0.9806\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0731 - accuracy: 0.9733\n",
      "\n",
      "Epoch:  62\n",
      "1210/1210 - 19s - loss: 0.0537 - accuracy: 0.9809 - 19s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0314 - accuracy: 0.9893\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0455 - accuracy: 0.9855\n",
      "\n",
      "Epoch:  63\n",
      "1210/1210 - 18s - loss: 0.0561 - accuracy: 0.9810 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0483 - accuracy: 0.9840\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0552 - accuracy: 0.9795\n",
      "\n",
      "Epoch:  64\n",
      "1210/1210 - 18s - loss: 0.0491 - accuracy: 0.9823 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0519 - accuracy: 0.9826\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0605 - accuracy: 0.9795\n",
      "\n",
      "Epoch:  65\n",
      "1210/1210 - 18s - loss: 0.0531 - accuracy: 0.9822 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0373 - accuracy: 0.9870\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0496 - accuracy: 0.9839\n",
      "\n",
      "Epoch:  66\n",
      "1210/1210 - 18s - loss: 0.0531 - accuracy: 0.9813 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0445 - accuracy: 0.9845\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0523 - accuracy: 0.9818\n",
      "\n",
      "Epoch:  67\n",
      "1210/1210 - 17s - loss: 0.0532 - accuracy: 0.9799 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0571 - accuracy: 0.9791\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0757 - accuracy: 0.9746\n",
      "\n",
      "Epoch:  68\n",
      "1210/1210 - 16s - loss: 0.0475 - accuracy: 0.9843 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0361 - accuracy: 0.9879\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0486 - accuracy: 0.9839\n",
      "\n",
      "Epoch:  69\n",
      "1210/1210 - 17s - loss: 0.0556 - accuracy: 0.9809 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0654 - accuracy: 0.9764\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0779 - accuracy: 0.9733\n",
      "\n",
      "Epoch:  70\n",
      "1210/1210 - 17s - loss: 0.0434 - accuracy: 0.9850 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0389 - accuracy: 0.9858\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0537 - accuracy: 0.9808\n",
      "\n",
      "Epoch:  71\n",
      "1210/1210 - 16s - loss: 0.0465 - accuracy: 0.9846 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0435 - accuracy: 0.9844\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0633 - accuracy: 0.9791\n",
      "\n",
      "Epoch:  72\n",
      "1210/1210 - 16s - loss: 0.0510 - accuracy: 0.9818 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0377 - accuracy: 0.9869\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0520 - accuracy: 0.9814\n",
      "\n",
      "Epoch:  73\n",
      "1210/1210 - 17s - loss: 0.0516 - accuracy: 0.9805 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0669 - accuracy: 0.9758\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0809 - accuracy: 0.9702\n",
      "\n",
      "Epoch:  74\n",
      "1210/1210 - 17s - loss: 0.0421 - accuracy: 0.9852 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1294 - accuracy: 0.9581\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1478 - accuracy: 0.9556\n",
      "\n",
      "Epoch:  75\n",
      "1210/1210 - 17s - loss: 0.0505 - accuracy: 0.9818 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0317 - accuracy: 0.9886\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0478 - accuracy: 0.9851\n",
      "\n",
      "Epoch:  76\n",
      "1210/1210 - 17s - loss: 0.0430 - accuracy: 0.9847 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0387 - accuracy: 0.9863\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0565 - accuracy: 0.9797\n",
      "\n",
      "Epoch:  77\n",
      "1210/1210 - 17s - loss: 0.0496 - accuracy: 0.9827 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1260 - accuracy: 0.9585\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1515 - accuracy: 0.9502\n",
      "\n",
      "Epoch:  78\n",
      "1210/1210 - 17s - loss: 0.0465 - accuracy: 0.9840 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0256 - accuracy: 0.9921\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0393 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  79\n",
      "1210/1210 - 17s - loss: 0.0406 - accuracy: 0.9862 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0538 - accuracy: 0.9815\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0694 - accuracy: 0.9766\n",
      "\n",
      "Epoch:  80\n",
      "1210/1210 - 17s - loss: 0.0492 - accuracy: 0.9819 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0229 - accuracy: 0.9931\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0377 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  81\n",
      "1210/1210 - 17s - loss: 0.0442 - accuracy: 0.9849 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0741 - accuracy: 0.9731\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0899 - accuracy: 0.9678\n",
      "\n",
      "Epoch:  82\n",
      "1210/1210 - 17s - loss: 0.0416 - accuracy: 0.9865 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0422 - accuracy: 0.9852\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0583 - accuracy: 0.9812\n",
      "\n",
      "Epoch:  83\n",
      "1210/1210 - 17s - loss: 0.0436 - accuracy: 0.9855 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0266 - accuracy: 0.9917\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0376 - accuracy: 0.9870\n",
      "\n",
      "Epoch:  84\n",
      "1210/1210 - 17s - loss: 0.0400 - accuracy: 0.9867 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0657 - accuracy: 0.9758\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0828 - accuracy: 0.9702\n",
      "\n",
      "Epoch:  85\n",
      "1210/1210 - 17s - loss: 0.0418 - accuracy: 0.9854 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0364 - accuracy: 0.9863\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0505 - accuracy: 0.9816\n",
      "\n",
      "Epoch:  86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1210/1210 - 17s - loss: 0.0414 - accuracy: 0.9859 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0280 - accuracy: 0.9901\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0363 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  87\n",
      "1210/1210 - 17s - loss: 0.0445 - accuracy: 0.9840 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0451 - accuracy: 0.9842\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0551 - accuracy: 0.9802\n",
      "\n",
      "Epoch:  88\n",
      "1210/1210 - 17s - loss: 0.0391 - accuracy: 0.9859 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0364 - accuracy: 0.9867\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0539 - accuracy: 0.9835\n",
      "\n",
      "Epoch:  89\n",
      "1210/1210 - 17s - loss: 0.0419 - accuracy: 0.9848 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0457 - accuracy: 0.9835\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0652 - accuracy: 0.9789\n",
      "\n",
      "Epoch:  90\n",
      "1210/1210 - 17s - loss: 0.0442 - accuracy: 0.9845 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0270 - accuracy: 0.9907\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0393 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  91\n",
      "1210/1210 - 17s - loss: 0.0355 - accuracy: 0.9873 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0488 - accuracy: 0.9813\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0653 - accuracy: 0.9783\n",
      "\n",
      "Epoch:  92\n",
      "1210/1210 - 17s - loss: 0.0427 - accuracy: 0.9849 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0386 - accuracy: 0.9859\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0599 - accuracy: 0.9800\n",
      "\n",
      "Epoch:  93\n",
      "1210/1210 - 17s - loss: 0.0386 - accuracy: 0.9854 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0277 - accuracy: 0.9903\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0374 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  94\n",
      "1210/1210 - 17s - loss: 0.0407 - accuracy: 0.9850 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0221 - accuracy: 0.9926\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0369 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  95\n",
      "1210/1210 - 17s - loss: 0.0352 - accuracy: 0.9879 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0357 - accuracy: 0.9875\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0448 - accuracy: 0.9835\n",
      "\n",
      "Epoch:  96\n",
      "1210/1210 - 17s - loss: 0.0404 - accuracy: 0.9851 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0434 - accuracy: 0.9843\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0600 - accuracy: 0.9791\n",
      "\n",
      "Epoch:  97\n",
      "1210/1210 - 17s - loss: 0.0345 - accuracy: 0.9884 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0266 - accuracy: 0.9906\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0360 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  98\n",
      "1210/1210 - 17s - loss: 0.0418 - accuracy: 0.9856 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0302 - accuracy: 0.9889\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0439 - accuracy: 0.9859\n",
      "\n",
      "Epoch:  99\n",
      "1210/1210 - 17s - loss: 0.0338 - accuracy: 0.9886 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0301 - accuracy: 0.9891\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9849\n",
      "\n",
      "Epoch:  100\n",
      "1210/1210 - 17s - loss: 0.0375 - accuracy: 0.9868 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0212 - accuracy: 0.9930\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0346 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  101\n",
      "1210/1210 - 17s - loss: 0.0370 - accuracy: 0.9867 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0227 - accuracy: 0.9925\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0339 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  102\n",
      "1210/1210 - 17s - loss: 0.0374 - accuracy: 0.9868 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0197 - accuracy: 0.9934\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  103\n",
      "1210/1210 - 17s - loss: 0.0363 - accuracy: 0.9872 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0450 - accuracy: 0.9838\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0643 - accuracy: 0.9812\n",
      "\n",
      "Epoch:  104\n",
      "1210/1210 - 17s - loss: 0.0386 - accuracy: 0.9864 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0381 - accuracy: 0.9855\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0595 - accuracy: 0.9806\n",
      "\n",
      "Epoch:  105\n",
      "1210/1210 - 17s - loss: 0.0371 - accuracy: 0.9867 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0325 - accuracy: 0.9883\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0511 - accuracy: 0.9818\n",
      "\n",
      "Epoch:  106\n",
      "1210/1210 - 17s - loss: 0.0341 - accuracy: 0.9883 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.0209 - accuracy: 0.9931\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0322 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  107\n",
      "1210/1210 - 21s - loss: 0.0359 - accuracy: 0.9863 - 21s/epoch - 17ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 7ms/step - loss: 0.0216 - accuracy: 0.9924\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0408 - accuracy: 0.9870\n",
      "\n",
      "Epoch:  108\n",
      "1210/1210 - 22s - loss: 0.0368 - accuracy: 0.9873 - 22s/epoch - 18ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0649 - accuracy: 0.9746\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0915 - accuracy: 0.9676\n",
      "\n",
      "Epoch:  109\n",
      "1210/1210 - 18s - loss: 0.0328 - accuracy: 0.9882 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0200 - accuracy: 0.9932\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0366 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  110\n",
      "1210/1210 - 16s - loss: 0.0327 - accuracy: 0.9887 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0327 - accuracy: 0.9880\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0433 - accuracy: 0.9862\n",
      "\n",
      "Epoch:  111\n",
      "1210/1210 - 16s - loss: 0.0366 - accuracy: 0.9865 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0394 - accuracy: 0.9849\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0555 - accuracy: 0.9820\n",
      "\n",
      "Epoch:  112\n",
      "1210/1210 - 20s - loss: 0.0302 - accuracy: 0.9891 - 20s/epoch - 17ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0289 - accuracy: 0.9888\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0497 - accuracy: 0.9837\n",
      "\n",
      "Epoch:  113\n",
      "1210/1210 - 19s - loss: 0.0336 - accuracy: 0.9882 - 19s/epoch - 16ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0204 - accuracy: 0.9931\n",
      "for testing\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  114\n",
      "1210/1210 - 20s - loss: 0.0320 - accuracy: 0.9889 - 20s/epoch - 16ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0281 - accuracy: 0.9899\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0403 - accuracy: 0.9857\n",
      "\n",
      "Epoch:  115\n",
      "1210/1210 - 19s - loss: 0.0322 - accuracy: 0.9883 - 19s/epoch - 16ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.1300 - accuracy: 0.9523\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.1691 - accuracy: 0.9450\n",
      "\n",
      "Epoch:  116\n",
      "1210/1210 - 20s - loss: 0.0308 - accuracy: 0.9887 - 20s/epoch - 17ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.0192 - accuracy: 0.9932\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0313 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  117\n",
      "1210/1210 - 19s - loss: 0.0323 - accuracy: 0.9886 - 19s/epoch - 16ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0317 - accuracy: 0.9884\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0474 - accuracy: 0.9826\n",
      "\n",
      "Epoch:  118\n",
      "1210/1210 - 21s - loss: 0.0332 - accuracy: 0.9881 - 21s/epoch - 18ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0299 - accuracy: 0.9890\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0505 - accuracy: 0.9835\n",
      "\n",
      "Epoch:  119\n",
      "1210/1210 - 18s - loss: 0.0329 - accuracy: 0.9884 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0451 - accuracy: 0.9827\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0671 - accuracy: 0.9769\n",
      "\n",
      "Epoch:  120\n",
      "1210/1210 - 16s - loss: 0.0304 - accuracy: 0.9890 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0241 - accuracy: 0.9910\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0413 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  121\n",
      "1210/1210 - 16s - loss: 0.0302 - accuracy: 0.9888 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0751 - accuracy: 0.9725\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0956 - accuracy: 0.9684\n",
      "\n",
      "Epoch:  122\n",
      "1210/1210 - 16s - loss: 0.0329 - accuracy: 0.9874 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0174 - accuracy: 0.9942\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0293 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  123\n",
      "1210/1210 - 15s - loss: 0.0290 - accuracy: 0.9893 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0167 - accuracy: 0.9942\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0294 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  124\n",
      "1210/1210 - 15s - loss: 0.0342 - accuracy: 0.9877 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0154 - accuracy: 0.9948\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0285 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  125\n",
      "1210/1210 - 15s - loss: 0.0304 - accuracy: 0.9891 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.1103 - accuracy: 0.9599\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1257 - accuracy: 0.9572\n",
      "\n",
      "Epoch:  126\n",
      "1210/1210 - 15s - loss: 0.0326 - accuracy: 0.9884 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0215 - accuracy: 0.9922\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0340 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  127\n",
      "1210/1210 - 15s - loss: 0.0274 - accuracy: 0.9902 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0222 - accuracy: 0.9922\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0394 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  128\n",
      "1210/1210 - 15s - loss: 0.0329 - accuracy: 0.9887 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0187 - accuracy: 0.9941\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0307 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  129\n",
      "1210/1210 - 15s - loss: 0.0272 - accuracy: 0.9899 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0221 - accuracy: 0.9913\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0419 - accuracy: 0.9862\n",
      "\n",
      "Epoch:  130\n",
      "1210/1210 - 15s - loss: 0.0267 - accuracy: 0.9909 - 15s/epoch - 12ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0177 - accuracy: 0.9941\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0310 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  131\n",
      "1210/1210 - 15s - loss: 0.0284 - accuracy: 0.9898 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0592 - accuracy: 0.9780\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0862 - accuracy: 0.9729\n",
      "\n",
      "Epoch:  132\n",
      "1210/1210 - 15s - loss: 0.0322 - accuracy: 0.9884 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0295 - accuracy: 0.9897\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0439 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  133\n",
      "1210/1210 - 15s - loss: 0.0268 - accuracy: 0.9894 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0227 - accuracy: 0.9917\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0423 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  134\n",
      "1210/1210 - 16s - loss: 0.0242 - accuracy: 0.9926 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0210 - accuracy: 0.9927\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0416 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  135\n",
      "1210/1210 - 17s - loss: 0.0264 - accuracy: 0.9904 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0502 - accuracy: 0.9823\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0641 - accuracy: 0.9802\n",
      "\n",
      "Epoch:  136\n",
      "1210/1210 - 16s - loss: 0.0311 - accuracy: 0.9887 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0242 - accuracy: 0.9910\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0437 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  137\n",
      "1210/1210 - 16s - loss: 0.0306 - accuracy: 0.9895 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0181 - accuracy: 0.9939\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0356 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  138\n",
      "1210/1210 - 16s - loss: 0.0282 - accuracy: 0.9898 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0112 - accuracy: 0.9963\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0264 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  139\n",
      "1210/1210 - 16s - loss: 0.0292 - accuracy: 0.9898 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0845 - accuracy: 0.9670\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.1183 - accuracy: 0.9616\n",
      "\n",
      "Epoch:  140\n",
      "1210/1210 - 16s - loss: 0.0215 - accuracy: 0.9928 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0143 - accuracy: 0.9952\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0332 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  141\n",
      "1210/1210 - 16s - loss: 0.0274 - accuracy: 0.9899 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0190 - accuracy: 0.9934\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0335 - accuracy: 0.9886\n",
      "\n",
      "Epoch:  142\n",
      "1210/1210 - 16s - loss: 0.0262 - accuracy: 0.9908 - 16s/epoch - 13ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0342 - accuracy: 0.9869\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0496 - accuracy: 0.9828\n",
      "\n",
      "Epoch:  143\n",
      "1210/1210 - 17s - loss: 0.0262 - accuracy: 0.9910 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0163 - accuracy: 0.9941\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0363 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  144\n",
      "1210/1210 - 19s - loss: 0.0251 - accuracy: 0.9915 - 19s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0609 - accuracy: 0.9769\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0810 - accuracy: 0.9733\n",
      "\n",
      "Epoch:  145\n",
      "1210/1210 - 19s - loss: 0.0261 - accuracy: 0.9898 - 19s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0117 - accuracy: 0.9956\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0257 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  146\n",
      "1210/1210 - 17s - loss: 0.0243 - accuracy: 0.9909 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0693 - accuracy: 0.9760\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.1012 - accuracy: 0.9731\n",
      "\n",
      "Epoch:  147\n",
      "1210/1210 - 18s - loss: 0.0277 - accuracy: 0.9893 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0173 - accuracy: 0.9935\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0336 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  148\n",
      "1210/1210 - 18s - loss: 0.0233 - accuracy: 0.9916 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0125 - accuracy: 0.9958\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0273 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  149\n",
      "1210/1210 - 18s - loss: 0.0279 - accuracy: 0.9894 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.0432 - accuracy: 0.9849\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0651 - accuracy: 0.9831\n",
      "\n",
      "Epoch:  150\n",
      "1210/1210 - 18s - loss: 0.0229 - accuracy: 0.9918 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0370 - accuracy: 0.9862\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0581 - accuracy: 0.9814\n",
      "\n",
      "Epoch:  151\n",
      "1210/1210 - 19s - loss: 0.0260 - accuracy: 0.9913 - 19s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0160 - accuracy: 0.9937\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0366 - accuracy: 0.9886\n",
      "\n",
      "Epoch:  152\n",
      "1210/1210 - 18s - loss: 0.0242 - accuracy: 0.9912 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0203 - accuracy: 0.9925\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0366 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  153\n",
      "1210/1210 - 18s - loss: 0.0261 - accuracy: 0.9903 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0505 - accuracy: 0.9822\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0662 - accuracy: 0.9802\n",
      "\n",
      "Epoch:  154\n",
      "1210/1210 - 18s - loss: 0.0235 - accuracy: 0.9919 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0220 - accuracy: 0.9921\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0367 - accuracy: 0.9866\n",
      "\n",
      "Epoch:  155\n",
      "1210/1210 - 18s - loss: 0.0247 - accuracy: 0.9910 - 18s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0186 - accuracy: 0.9936\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0312 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  156\n",
      "1210/1210 - 18s - loss: 0.0245 - accuracy: 0.9919 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0234 - accuracy: 0.9918\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0359 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  157\n",
      "1210/1210 - 17s - loss: 0.0247 - accuracy: 0.9909 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0192 - accuracy: 0.9931\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0381 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  158\n",
      "1210/1210 - 18s - loss: 0.0250 - accuracy: 0.9917 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0245 - accuracy: 0.9907\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0434 - accuracy: 0.9862\n",
      "\n",
      "Epoch:  159\n",
      "1210/1210 - 17s - loss: 0.0273 - accuracy: 0.9908 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0122 - accuracy: 0.9961\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0311 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  160\n",
      "1210/1210 - 17s - loss: 0.0228 - accuracy: 0.9917 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0253 - accuracy: 0.9910\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0400 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  161\n",
      "1210/1210 - 16s - loss: 0.0217 - accuracy: 0.9915 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0258 - accuracy: 0.9912\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0395 - accuracy: 0.9866\n",
      "\n",
      "Epoch:  162\n",
      "1210/1210 - 18s - loss: 0.0261 - accuracy: 0.9908 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0218 - accuracy: 0.9911\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0390 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  163\n",
      "1210/1210 - 18s - loss: 0.0232 - accuracy: 0.9909 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0192 - accuracy: 0.9931\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0317 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  164\n",
      "1210/1210 - 18s - loss: 0.0211 - accuracy: 0.9925 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0774 - accuracy: 0.9711\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.1005 - accuracy: 0.9676\n",
      "\n",
      "Epoch:  165\n",
      "1210/1210 - 17s - loss: 0.0247 - accuracy: 0.9908 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0229 - accuracy: 0.9918\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0351 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  166\n",
      "1210/1210 - 17s - loss: 0.0211 - accuracy: 0.9928 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.0149 - accuracy: 0.9952\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0330 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  167\n",
      "1210/1210 - 18s - loss: 0.0282 - accuracy: 0.9893 - 18s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0198 - accuracy: 0.9926\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0406 - accuracy: 0.9886\n",
      "\n",
      "Epoch:  168\n",
      "1210/1210 - 16s - loss: 0.0223 - accuracy: 0.9918 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0155 - accuracy: 0.9947\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0308 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  169\n",
      "1210/1210 - 18s - loss: 0.0223 - accuracy: 0.9912 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0109 - accuracy: 0.9965\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0276 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  170\n",
      "1210/1210 - 16s - loss: 0.0269 - accuracy: 0.9908 - 16s/epoch - 13ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0128 - accuracy: 0.9955\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0257 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  171\n",
      "1210/1210 - 17s - loss: 0.0172 - accuracy: 0.9936 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0072 - accuracy: 0.9979\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0272 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  172\n",
      "1210/1210 - 15s - loss: 0.0208 - accuracy: 0.9929 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0319 - accuracy: 0.9881\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0486 - accuracy: 0.9853\n",
      "\n",
      "Epoch:  173\n",
      "1210/1210 - 16s - loss: 0.0233 - accuracy: 0.9917 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0081 - accuracy: 0.9973\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0252 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  174\n",
      "1210/1210 - 15s - loss: 0.0167 - accuracy: 0.9944 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0105 - accuracy: 0.9964\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0301 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  175\n",
      "1210/1210 - 17s - loss: 0.0230 - accuracy: 0.9924 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0157 - accuracy: 0.9944\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0296 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  176\n",
      "1210/1210 - 16s - loss: 0.0191 - accuracy: 0.9939 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0227 - accuracy: 0.9921\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0518 - accuracy: 0.9845\n",
      "\n",
      "Epoch:  177\n",
      "1210/1210 - 16s - loss: 0.0238 - accuracy: 0.9910 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0204 - accuracy: 0.9925\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0420 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  178\n",
      "1210/1210 - 16s - loss: 0.0232 - accuracy: 0.9919 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0189 - accuracy: 0.9930\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0404 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  179\n",
      "1210/1210 - 17s - loss: 0.0195 - accuracy: 0.9924 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0304 - accuracy: 0.9879\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0593 - accuracy: 0.9822\n",
      "\n",
      "Epoch:  180\n",
      "1210/1210 - 16s - loss: 0.0200 - accuracy: 0.9939 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0188 - accuracy: 0.9935\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0413 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  181\n",
      "1210/1210 - 15s - loss: 0.0178 - accuracy: 0.9931 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0306 - accuracy: 0.9884\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0466 - accuracy: 0.9855\n",
      "\n",
      "Epoch:  182\n",
      "1210/1210 - 16s - loss: 0.0244 - accuracy: 0.9910 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0236 - accuracy: 0.9905\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0449 - accuracy: 0.9855\n",
      "\n",
      "Epoch:  183\n",
      "1210/1210 - 15s - loss: 0.0201 - accuracy: 0.9927 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 2s 4ms/step - loss: 0.0149 - accuracy: 0.9945\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0314 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  184\n",
      "1210/1210 - 16s - loss: 0.0197 - accuracy: 0.9929 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0182 - accuracy: 0.9931\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0359 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  185\n",
      "1210/1210 - 16s - loss: 0.0186 - accuracy: 0.9935 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0069 - accuracy: 0.9978\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0254 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  186\n",
      "1210/1210 - 15s - loss: 0.0240 - accuracy: 0.9912 - 15s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0131 - accuracy: 0.9955\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0255 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  187\n",
      "1210/1210 - 17s - loss: 0.0176 - accuracy: 0.9936 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0271 - accuracy: 0.9899\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0505 - accuracy: 0.9839\n",
      "\n",
      "Epoch:  188\n",
      "1210/1210 - 16s - loss: 0.0213 - accuracy: 0.9921 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0226 - accuracy: 0.9909\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0453 - accuracy: 0.9870\n",
      "\n",
      "Epoch:  189\n",
      "1210/1210 - 16s - loss: 0.0235 - accuracy: 0.9919 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0297 - accuracy: 0.9881\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0486 - accuracy: 0.9835\n",
      "\n",
      "Epoch:  190\n",
      "1210/1210 - 16s - loss: 0.0189 - accuracy: 0.9939 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0212 - accuracy: 0.9924\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0513 - accuracy: 0.9859\n",
      "\n",
      "Epoch:  191\n",
      "1210/1210 - 17s - loss: 0.0162 - accuracy: 0.9943 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0200 - accuracy: 0.9926\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0433 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  192\n",
      "1210/1210 - 17s - loss: 0.0227 - accuracy: 0.9916 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0085 - accuracy: 0.9972\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0236 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  193\n",
      "1210/1210 - 16s - loss: 0.0163 - accuracy: 0.9943 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0257 - accuracy: 0.9901\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0464 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  194\n",
      "1210/1210 - 16s - loss: 0.0201 - accuracy: 0.9926 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0231 - accuracy: 0.9918\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0380 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  195\n",
      "1210/1210 - 16s - loss: 0.0179 - accuracy: 0.9940 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0203 - accuracy: 0.9927\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0379 - accuracy: 0.9866\n",
      "\n",
      "Epoch:  196\n",
      "1210/1210 - 17s - loss: 0.0207 - accuracy: 0.9925 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0083 - accuracy: 0.9977\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0269 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  197\n",
      "1210/1210 - 17s - loss: 0.0185 - accuracy: 0.9935 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0247 - accuracy: 0.9905\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0456 - accuracy: 0.9843\n",
      "\n",
      "Epoch:  198\n",
      "1210/1210 - 17s - loss: 0.0168 - accuracy: 0.9932 - 17s/epoch - 14ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0092 - accuracy: 0.9968\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0264 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  199\n",
      "1210/1210 - 16s - loss: 0.0202 - accuracy: 0.9926 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0365 - accuracy: 0.9868\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0636 - accuracy: 0.9816\n",
      "\n",
      "Epoch:  200\n",
      "1210/1210 - 16s - loss: 0.0201 - accuracy: 0.9926 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0085 - accuracy: 0.9968\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0273 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  201\n",
      "1210/1210 - 17s - loss: 0.0172 - accuracy: 0.9935 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0172 - accuracy: 0.9931\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0353 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  202\n",
      "1210/1210 - 16s - loss: 0.0182 - accuracy: 0.9934 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0306 - accuracy: 0.9876\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0556 - accuracy: 0.9818\n",
      "\n",
      "Epoch:  203\n",
      "1210/1210 - 16s - loss: 0.0180 - accuracy: 0.9937 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0082 - accuracy: 0.9977\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0261 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  204\n",
      "1210/1210 - 16s - loss: 0.0173 - accuracy: 0.9937 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0090 - accuracy: 0.9972\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0243 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  205\n",
      "1210/1210 - 16s - loss: 0.0192 - accuracy: 0.9930 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0085 - accuracy: 0.9970\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0310 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  206\n",
      "1210/1210 - 16s - loss: 0.0231 - accuracy: 0.9913 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0200 - accuracy: 0.9927\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0478 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  207\n",
      "1210/1210 - 17s - loss: 0.0152 - accuracy: 0.9948 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0144 - accuracy: 0.9949\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0368 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  208\n",
      "1210/1210 - 16s - loss: 0.0180 - accuracy: 0.9935 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0173 - accuracy: 0.9940\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0363 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  209\n",
      "1210/1210 - 17s - loss: 0.0176 - accuracy: 0.9940 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0455 - accuracy: 0.9825\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0658 - accuracy: 0.9791\n",
      "\n",
      "Epoch:  210\n",
      "1210/1210 - 17s - loss: 0.0122 - accuracy: 0.9953 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0049 - accuracy: 0.9985\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0247 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  211\n",
      "1210/1210 - 17s - loss: 0.0213 - accuracy: 0.9924 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0229 - accuracy: 0.9915\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0443 - accuracy: 0.9855\n",
      "\n",
      "Epoch:  212\n",
      "1210/1210 - 17s - loss: 0.0198 - accuracy: 0.9926 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0114 - accuracy: 0.9966\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0279 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  213\n",
      "1210/1210 - 17s - loss: 0.0161 - accuracy: 0.9951 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0124 - accuracy: 0.9955\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0297 - accuracy: 0.9905\n",
      "\n",
      "Epoch:  214\n",
      "1210/1210 - 16s - loss: 0.0158 - accuracy: 0.9953 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0263 - accuracy: 0.9905\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0471 - accuracy: 0.9862\n",
      "\n",
      "Epoch:  215\n",
      "1210/1210 - 16s - loss: 0.0199 - accuracy: 0.9936 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0071 - accuracy: 0.9977\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0291 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  216\n",
      "1210/1210 - 16s - loss: 0.0155 - accuracy: 0.9944 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0085 - accuracy: 0.9971\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0267 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  217\n",
      "1210/1210 - 16s - loss: 0.0139 - accuracy: 0.9955 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0055 - accuracy: 0.9988\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0229 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  218\n",
      "1210/1210 - 16s - loss: 0.0191 - accuracy: 0.9931 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0078 - accuracy: 0.9977\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0262 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  219\n",
      "1210/1210 - 16s - loss: 0.0140 - accuracy: 0.9953 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0150 - accuracy: 0.9938\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0338 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  220\n",
      "1210/1210 - 16s - loss: 0.0183 - accuracy: 0.9935 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0291 - accuracy: 0.9891\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0509 - accuracy: 0.9826\n",
      "\n",
      "Epoch:  221\n",
      "1210/1210 - 17s - loss: 0.0130 - accuracy: 0.9956 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0255 - accuracy: 0.9906\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0527 - accuracy: 0.9833\n",
      "\n",
      "Epoch:  222\n",
      "1210/1210 - 17s - loss: 0.0149 - accuracy: 0.9947 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0126 - accuracy: 0.9956\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0377 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  223\n",
      "1210/1210 - 16s - loss: 0.0242 - accuracy: 0.9914 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0092 - accuracy: 0.9968\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0285 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  224\n",
      "1210/1210 - 16s - loss: 0.0135 - accuracy: 0.9951 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0234 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  225\n",
      "1210/1210 - 16s - loss: 0.0136 - accuracy: 0.9955 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0092 - accuracy: 0.9965\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0315 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  226\n",
      "1210/1210 - 17s - loss: 0.0209 - accuracy: 0.9921 - 17s/epoch - 14ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0212 - accuracy: 0.9917\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0466 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  227\n",
      "1210/1210 - 17s - loss: 0.0141 - accuracy: 0.9950 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0126 - accuracy: 0.9951\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0364 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  228\n",
      "1210/1210 - 17s - loss: 0.0191 - accuracy: 0.9939 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0071 - accuracy: 0.9981\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0296 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  229\n",
      "1210/1210 - 18s - loss: 0.0121 - accuracy: 0.9959 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0112 - accuracy: 0.9955\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0344 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  230\n",
      "1210/1210 - 17s - loss: 0.0228 - accuracy: 0.9917 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0125 - accuracy: 0.9951\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0279 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  231\n",
      "1210/1210 - 18s - loss: 0.0131 - accuracy: 0.9951 - 18s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0269 - accuracy: 0.9944\n",
      "\n",
      "Epoch:  232\n",
      "1210/1210 - 17s - loss: 0.0164 - accuracy: 0.9937 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0178 - accuracy: 0.9931\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0441 - accuracy: 0.9886\n",
      "\n",
      "Epoch:  233\n",
      "1210/1210 - 19s - loss: 0.0140 - accuracy: 0.9955 - 19s/epoch - 16ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0194 - accuracy: 0.9925\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0472 - accuracy: 0.9855\n",
      "\n",
      "Epoch:  234\n",
      "1210/1210 - 18s - loss: 0.0170 - accuracy: 0.9939 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0367 - accuracy: 0.9875\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0587 - accuracy: 0.9820\n",
      "\n",
      "Epoch:  235\n",
      "1210/1210 - 17s - loss: 0.0132 - accuracy: 0.9952 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0837 - accuracy: 0.9737\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.1121 - accuracy: 0.9694\n",
      "\n",
      "Epoch:  236\n",
      "1210/1210 - 19s - loss: 0.0149 - accuracy: 0.9945 - 19s/epoch - 16ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0088 - accuracy: 0.9968\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0314 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  237\n",
      "1210/1210 - 16s - loss: 0.0154 - accuracy: 0.9944 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0138 - accuracy: 0.9947\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0354 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  238\n",
      "1210/1210 - 17s - loss: 0.0149 - accuracy: 0.9948 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0229 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  239\n",
      "1210/1210 - 17s - loss: 0.0178 - accuracy: 0.9935 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0048 - accuracy: 0.9988\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0267 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  240\n",
      "1210/1210 - 17s - loss: 0.0089 - accuracy: 0.9968 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0080 - accuracy: 0.9972\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0276 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  241\n",
      "1210/1210 - 16s - loss: 0.0160 - accuracy: 0.9946 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0053 - accuracy: 0.9983\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0281 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  242\n",
      "1210/1210 - 16s - loss: 0.0174 - accuracy: 0.9945 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0070 - accuracy: 0.9977\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0249 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  243\n",
      "1210/1210 - 16s - loss: 0.0156 - accuracy: 0.9946 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0384 - accuracy: 0.9865\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0676 - accuracy: 0.9826\n",
      "\n",
      "Epoch:  244\n",
      "1210/1210 - 16s - loss: 0.0142 - accuracy: 0.9947 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0099 - accuracy: 0.9957\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0277 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  245\n",
      "1210/1210 - 16s - loss: 0.0194 - accuracy: 0.9932 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0469 - accuracy: 0.9837\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0754 - accuracy: 0.9797\n",
      "\n",
      "Epoch:  246\n",
      "1210/1210 - 16s - loss: 0.0154 - accuracy: 0.9943 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0285 - accuracy: 0.9893\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0668 - accuracy: 0.9822\n",
      "\n",
      "Epoch:  247\n",
      "1210/1210 - 17s - loss: 0.0154 - accuracy: 0.9953 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0063 - accuracy: 0.9979\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0281 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  248\n",
      "1210/1210 - 16s - loss: 0.0127 - accuracy: 0.9956 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0089 - accuracy: 0.9970\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0317 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  249\n",
      "1210/1210 - 18s - loss: 0.0169 - accuracy: 0.9939 - 18s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0273 - accuracy: 0.9890\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0518 - accuracy: 0.9845\n",
      "\n",
      "Epoch:  250\n",
      "1210/1210 - 19s - loss: 0.0103 - accuracy: 0.9957 - 19s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0427 - accuracy: 0.9835\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0768 - accuracy: 0.9781\n",
      "\n",
      "Epoch:  251\n",
      "1210/1210 - 19s - loss: 0.0165 - accuracy: 0.9941 - 19s/epoch - 16ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0201 - accuracy: 0.9924\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0464 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  252\n",
      "1210/1210 - 18s - loss: 0.0138 - accuracy: 0.9950 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0579 - accuracy: 0.9809\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0905 - accuracy: 0.9758\n",
      "\n",
      "Epoch:  253\n",
      "1210/1210 - 17s - loss: 0.0136 - accuracy: 0.9957 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0031 - accuracy: 0.9992\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0225 - accuracy: 0.9942\n",
      "\n",
      "Epoch:  254\n",
      "1210/1210 - 18s - loss: 0.0160 - accuracy: 0.9946 - 18s/epoch - 15ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0054 - accuracy: 0.9980\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0262 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  255\n",
      "1210/1210 - 17s - loss: 0.0168 - accuracy: 0.9942 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0250 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  256\n",
      "1210/1210 - 17s - loss: 0.0177 - accuracy: 0.9941 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0056 - accuracy: 0.9979\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0252 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  257\n",
      "1210/1210 - 17s - loss: 0.0075 - accuracy: 0.9972 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0049 - accuracy: 0.9987\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0267 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  258\n",
      "1210/1210 - 17s - loss: 0.0181 - accuracy: 0.9936 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0031 - accuracy: 0.9992\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0191 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  259\n",
      "1210/1210 - 17s - loss: 0.0109 - accuracy: 0.9967 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0106 - accuracy: 0.9959\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  260\n",
      "1210/1210 - 17s - loss: 0.0134 - accuracy: 0.9955 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0108 - accuracy: 0.9958\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0353 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  261\n",
      "1210/1210 - 17s - loss: 0.0166 - accuracy: 0.9946 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0205 - accuracy: 0.9925\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0421 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  262\n",
      "1210/1210 - 16s - loss: 0.0098 - accuracy: 0.9966 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0291 - accuracy: 0.9875\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0631 - accuracy: 0.9824\n",
      "\n",
      "Epoch:  263\n",
      "1210/1210 - 17s - loss: 0.0157 - accuracy: 0.9940 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0044 - accuracy: 0.9988\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0275 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  264\n",
      "1210/1210 - 17s - loss: 0.0123 - accuracy: 0.9960 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0020 - accuracy: 0.9997\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9938\n",
      "\n",
      "Epoch:  265\n",
      "1210/1210 - 17s - loss: 0.0170 - accuracy: 0.9935 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0086 - accuracy: 0.9969\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0317 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  266\n",
      "1210/1210 - 17s - loss: 0.0108 - accuracy: 0.9963 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0044 - accuracy: 0.9988\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  267\n",
      "1210/1210 - 17s - loss: 0.0143 - accuracy: 0.9950 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0129 - accuracy: 0.9949\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0474 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  268\n",
      "1210/1210 - 18s - loss: 0.0137 - accuracy: 0.9956 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0034 - accuracy: 0.9991\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0272 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  269\n",
      "1210/1210 - 17s - loss: 0.0136 - accuracy: 0.9951 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0027 - accuracy: 0.9992\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0238 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  270\n",
      "1210/1210 - 17s - loss: 0.0151 - accuracy: 0.9948 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0129 - accuracy: 0.9945\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0350 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  271\n",
      "1210/1210 - 17s - loss: 0.0095 - accuracy: 0.9965 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0070 - accuracy: 0.9976\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0333 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  272\n",
      "1210/1210 - 17s - loss: 0.0160 - accuracy: 0.9936 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0174 - accuracy: 0.9937\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0413 - accuracy: 0.9886\n",
      "\n",
      "Epoch:  273\n",
      "1210/1210 - 17s - loss: 0.0090 - accuracy: 0.9972 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0147 - accuracy: 0.9950\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0442 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  274\n",
      "1210/1210 - 17s - loss: 0.0161 - accuracy: 0.9948 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0047 - accuracy: 0.9988\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0234 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  275\n",
      "1210/1210 - 17s - loss: 0.0089 - accuracy: 0.9966 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0114 - accuracy: 0.9957\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0402 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  276\n",
      "1210/1210 - 17s - loss: 0.0129 - accuracy: 0.9954 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0212 - accuracy: 0.9921\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0629 - accuracy: 0.9837\n",
      "\n",
      "Epoch:  277\n",
      "1210/1210 - 17s - loss: 0.0137 - accuracy: 0.9959 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0019 - accuracy: 0.9996\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0219 - accuracy: 0.9940\n",
      "\n",
      "Epoch:  278\n",
      "1210/1210 - 18s - loss: 0.0149 - accuracy: 0.9944 - 18s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0134 - accuracy: 0.9949\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0380 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  279\n",
      "1210/1210 - 16s - loss: 0.0105 - accuracy: 0.9964 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0986 - accuracy: 0.9699\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.1444 - accuracy: 0.9620\n",
      "\n",
      "Epoch:  280\n",
      "1210/1210 - 17s - loss: 0.0128 - accuracy: 0.9951 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0071 - accuracy: 0.9974\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0339 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  281\n",
      "1210/1210 - 17s - loss: 0.0137 - accuracy: 0.9950 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.0424 - accuracy: 0.9845\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0713 - accuracy: 0.9804\n",
      "\n",
      "Epoch:  282\n",
      "1210/1210 - 18s - loss: 0.0090 - accuracy: 0.9971 - 18s/epoch - 15ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0149 - accuracy: 0.9944\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0372 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  283\n",
      "1210/1210 - 17s - loss: 0.0117 - accuracy: 0.9956 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0102 - accuracy: 0.9962\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0362 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  284\n",
      "1210/1210 - 17s - loss: 0.0154 - accuracy: 0.9943 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0050 - accuracy: 0.9987\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0294 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  285\n",
      "1210/1210 - 17s - loss: 0.0124 - accuracy: 0.9960 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0114 - accuracy: 0.9955\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0337 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  286\n",
      "1210/1210 - 18s - loss: 0.0114 - accuracy: 0.9963 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.0626 - accuracy: 0.9770\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.1021 - accuracy: 0.9698\n",
      "\n",
      "Epoch:  287\n",
      "1210/1210 - 17s - loss: 0.0188 - accuracy: 0.9937 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0217 - accuracy: 0.9917\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0498 - accuracy: 0.9843\n",
      "\n",
      "Epoch:  288\n",
      "1210/1210 - 17s - loss: 0.0101 - accuracy: 0.9964 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0142 - accuracy: 0.9944\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0317 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  289\n",
      "1210/1210 - 17s - loss: 0.0113 - accuracy: 0.9961 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0069 - accuracy: 0.9973\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0316 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  290\n",
      "1210/1210 - 17s - loss: 0.0147 - accuracy: 0.9950 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0033 - accuracy: 0.9991\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0222 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  291\n",
      "1210/1210 - 17s - loss: 0.0077 - accuracy: 0.9974 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0051 - accuracy: 0.9984\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0276 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  292\n",
      "1210/1210 - 18s - loss: 0.0118 - accuracy: 0.9958 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0029 - accuracy: 0.9992\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0224 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  293\n",
      "1210/1210 - 17s - loss: 0.0134 - accuracy: 0.9952 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0085 - accuracy: 0.9969\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0362 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  294\n",
      "1210/1210 - 16s - loss: 0.0104 - accuracy: 0.9963 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0167 - accuracy: 0.9930\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0415 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  295\n",
      "1210/1210 - 17s - loss: 0.0165 - accuracy: 0.9948 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0170 - accuracy: 0.9939\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0398 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  296\n",
      "1210/1210 - 17s - loss: 0.0136 - accuracy: 0.9949 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.0091 - accuracy: 0.9967\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0309 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  297\n",
      "1210/1210 - 17s - loss: 0.0096 - accuracy: 0.9967 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0077 - accuracy: 0.9970\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0375 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  298\n",
      "1210/1210 - 17s - loss: 0.0154 - accuracy: 0.9946 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0105 - accuracy: 0.9962\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0304 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  299\n",
      "1210/1210 - 16s - loss: 0.0118 - accuracy: 0.9959 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0066 - accuracy: 0.9976\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0326 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  300\n",
      "1210/1210 - 17s - loss: 0.0114 - accuracy: 0.9961 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0277 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  301\n",
      "1210/1210 - 17s - loss: 0.0113 - accuracy: 0.9965 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0136 - accuracy: 0.9947\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0387 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  302\n",
      "1210/1210 - 17s - loss: 0.0136 - accuracy: 0.9954 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0033 - accuracy: 0.9992\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0232 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  303\n",
      "1210/1210 - 17s - loss: 0.0102 - accuracy: 0.9964 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0171 - accuracy: 0.9929\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0453 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  304\n",
      "1210/1210 - 18s - loss: 0.0138 - accuracy: 0.9954 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0043 - accuracy: 0.9987\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0338 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  305\n",
      "1210/1210 - 18s - loss: 0.0123 - accuracy: 0.9961 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0341 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  306\n",
      "1210/1210 - 18s - loss: 0.0073 - accuracy: 0.9976 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0100 - accuracy: 0.9960\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0438 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  307\n",
      "1210/1210 - 18s - loss: 0.0202 - accuracy: 0.9941 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0238 - accuracy: 0.9948\n",
      "\n",
      "Epoch:  308\n",
      "1210/1210 - 19s - loss: 0.0072 - accuracy: 0.9971 - 19s/epoch - 16ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0085 - accuracy: 0.9970\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0304 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  309\n",
      "1210/1210 - 17s - loss: 0.0187 - accuracy: 0.9947 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0260 - accuracy: 0.9938\n",
      "\n",
      "Epoch:  310\n",
      "1210/1210 - 17s - loss: 0.0069 - accuracy: 0.9979 - 17s/epoch - 14ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0036 - accuracy: 0.9989\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0284 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  311\n",
      "1210/1210 - 18s - loss: 0.0145 - accuracy: 0.9951 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0143 - accuracy: 0.9948\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0447 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  312\n",
      "1210/1210 - 18s - loss: 0.0133 - accuracy: 0.9952 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0166 - accuracy: 0.9940\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0528 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  313\n",
      "1210/1210 - 18s - loss: 0.0091 - accuracy: 0.9967 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0050 - accuracy: 0.9985\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0319 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  314\n",
      "1210/1210 - 17s - loss: 0.0120 - accuracy: 0.9957 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0019 - accuracy: 0.9997\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0222 - accuracy: 0.9955\n",
      "\n",
      "Epoch:  315\n",
      "1210/1210 - 18s - loss: 0.0091 - accuracy: 0.9967 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.0152 - accuracy: 0.9945\n",
      "for testing\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.0420 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  316\n",
      "1210/1210 - 19s - loss: 0.0145 - accuracy: 0.9949 - 19s/epoch - 16ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0087 - accuracy: 0.9968\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0339 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  317\n",
      "1210/1210 - 18s - loss: 0.0098 - accuracy: 0.9964 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0036 - accuracy: 0.9993\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0264 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  318\n",
      "1210/1210 - 18s - loss: 0.0091 - accuracy: 0.9970 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0020 - accuracy: 0.9996\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0223 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  319\n",
      "1210/1210 - 17s - loss: 0.0155 - accuracy: 0.9948 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0023 - accuracy: 0.9994\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0217 - accuracy: 0.9946\n",
      "\n",
      "Epoch:  320\n",
      "1210/1210 - 17s - loss: 0.0105 - accuracy: 0.9966 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0231 - accuracy: 0.9944\n",
      "\n",
      "Epoch:  321\n",
      "1210/1210 - 17s - loss: 0.0093 - accuracy: 0.9964 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0020 - accuracy: 0.9995\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0213 - accuracy: 0.9948\n",
      "\n",
      "Epoch:  322\n",
      "1210/1210 - 17s - loss: 0.0097 - accuracy: 0.9967 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0154 - accuracy: 0.9942\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0396 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  323\n",
      "1210/1210 - 17s - loss: 0.0097 - accuracy: 0.9965 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0086 - accuracy: 0.9965\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0401 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  324\n",
      "1210/1210 - 17s - loss: 0.0145 - accuracy: 0.9951 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.1084 - accuracy: 0.9666\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.1457 - accuracy: 0.9605\n",
      "\n",
      "Epoch:  325\n",
      "1210/1210 - 16s - loss: 0.0090 - accuracy: 0.9968 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0010 - accuracy: 0.9999\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0218 - accuracy: 0.9942\n",
      "\n",
      "Epoch:  326\n",
      "1210/1210 - 16s - loss: 0.0118 - accuracy: 0.9959 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0248 - accuracy: 0.9919\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0497 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  327\n",
      "1210/1210 - 17s - loss: 0.0132 - accuracy: 0.9957 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0035 - accuracy: 0.9990\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0272 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  328\n",
      "1210/1210 - 17s - loss: 0.0090 - accuracy: 0.9967 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0076 - accuracy: 0.9974\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0433 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  329\n",
      "1210/1210 - 17s - loss: 0.0153 - accuracy: 0.9949 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0021 - accuracy: 0.9996\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0249 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  330\n",
      "1210/1210 - 17s - loss: 0.0064 - accuracy: 0.9979 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0221 - accuracy: 0.9944\n",
      "\n",
      "Epoch:  331\n",
      "1210/1210 - 17s - loss: 0.0142 - accuracy: 0.9957 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0185 - accuracy: 0.9925\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0428 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  332\n",
      "1210/1210 - 18s - loss: 0.0103 - accuracy: 0.9963 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0273 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  333\n",
      "1210/1210 - 17s - loss: 0.0097 - accuracy: 0.9966 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0116 - accuracy: 0.9956\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0346 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  334\n",
      "1210/1210 - 17s - loss: 0.0115 - accuracy: 0.9960 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0229 - accuracy: 0.9938\n",
      "\n",
      "Epoch:  335\n",
      "1210/1210 - 16s - loss: 0.0076 - accuracy: 0.9974 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.2799 - accuracy: 0.9292\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.3662 - accuracy: 0.9219\n",
      "\n",
      "Epoch:  336\n",
      "1210/1210 - 16s - loss: 0.0146 - accuracy: 0.9950 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0336 - accuracy: 0.9881\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0723 - accuracy: 0.9839\n",
      "\n",
      "Epoch:  337\n",
      "1210/1210 - 16s - loss: 0.0088 - accuracy: 0.9967 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0109 - accuracy: 0.9960\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0507 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  338\n",
      "1210/1210 - 16s - loss: 0.0111 - accuracy: 0.9963 - 16s/epoch - 14ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0071 - accuracy: 0.9972\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0324 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  339\n",
      "1210/1210 - 16s - loss: 0.0132 - accuracy: 0.9956 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0018 - accuracy: 0.9997\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0235 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  340\n",
      "1210/1210 - 16s - loss: 0.0086 - accuracy: 0.9972 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0019 - accuracy: 0.9995\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0228 - accuracy: 0.9944\n",
      "\n",
      "Epoch:  341\n",
      "1210/1210 - 16s - loss: 0.0101 - accuracy: 0.9966 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0032 - accuracy: 0.9990\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0243 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  342\n",
      "1210/1210 - 16s - loss: 0.0101 - accuracy: 0.9967 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0148 - accuracy: 0.9937\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0426 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  343\n",
      "1210/1210 - 16s - loss: 0.0070 - accuracy: 0.9976 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0340 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  344\n",
      "1210/1210 - 16s - loss: 0.0119 - accuracy: 0.9953 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 8.8630e-04 - accuracy: 0.9998\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0233 - accuracy: 0.9942\n",
      "\n",
      "Epoch:  345\n",
      "1210/1210 - 17s - loss: 0.0104 - accuracy: 0.9963 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0033 - accuracy: 0.9992\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0334 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  346\n",
      "1210/1210 - 17s - loss: 0.0123 - accuracy: 0.9958 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0387 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  347\n",
      "1210/1210 - 17s - loss: 0.0148 - accuracy: 0.9949 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.1829 - accuracy: 0.9498\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.2403 - accuracy: 0.9415\n",
      "\n",
      "Epoch:  348\n",
      "1210/1210 - 16s - loss: 0.0071 - accuracy: 0.9975 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0033 - accuracy: 0.9991\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0269 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  349\n",
      "1210/1210 - 16s - loss: 0.0064 - accuracy: 0.9975 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0034 - accuracy: 0.9990\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0276 - accuracy: 0.9944\n",
      "\n",
      "Epoch:  350\n",
      "1210/1210 - 16s - loss: 0.0193 - accuracy: 0.9937 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0083 - accuracy: 0.9965\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0360 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  351\n",
      "1210/1210 - 16s - loss: 0.0057 - accuracy: 0.9978 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0254 - accuracy: 0.9942\n",
      "\n",
      "Epoch:  352\n",
      "1210/1210 - 16s - loss: 0.0126 - accuracy: 0.9953 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0020 - accuracy: 0.9994\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0284 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  353\n",
      "1210/1210 - 16s - loss: 0.0082 - accuracy: 0.9971 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0095 - accuracy: 0.9963\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0349 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  354\n",
      "1210/1210 - 16s - loss: 0.0148 - accuracy: 0.9953 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0143 - accuracy: 0.9943\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0507 - accuracy: 0.9845\n",
      "\n",
      "Epoch:  355\n",
      "1210/1210 - 16s - loss: 0.0062 - accuracy: 0.9982 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0240 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  356\n",
      "1210/1210 - 16s - loss: 0.0110 - accuracy: 0.9967 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0015 - accuracy: 0.9999\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0277 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  357\n",
      "1210/1210 - 17s - loss: 0.0112 - accuracy: 0.9967 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0020 - accuracy: 0.9994\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0269 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  358\n",
      "1210/1210 - 18s - loss: 0.0084 - accuracy: 0.9970 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0314 - accuracy: 0.9889\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0681 - accuracy: 0.9800\n",
      "\n",
      "Epoch:  359\n",
      "1210/1210 - 16s - loss: 0.0098 - accuracy: 0.9966 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0343 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  360\n",
      "1210/1210 - 17s - loss: 0.0072 - accuracy: 0.9975 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0062 - accuracy: 0.9976\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0260 - accuracy: 0.9942\n",
      "\n",
      "Epoch:  361\n",
      "1210/1210 - 19s - loss: 0.0093 - accuracy: 0.9962 - 19s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 6ms/step - loss: 0.0063 - accuracy: 0.9980\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0318 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  362\n",
      "1210/1210 - 19s - loss: 0.0098 - accuracy: 0.9964 - 19s/epoch - 16ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0332 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  363\n",
      "1210/1210 - 17s - loss: 0.0133 - accuracy: 0.9952 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0019 - accuracy: 0.9997\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0241 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  364\n",
      "1210/1210 - 17s - loss: 0.0069 - accuracy: 0.9976 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0070 - accuracy: 0.9972\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0393 - accuracy: 0.9899\n",
      "\n",
      "Epoch:  365\n",
      "1210/1210 - 17s - loss: 0.0149 - accuracy: 0.9951 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0037 - accuracy: 0.9988\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0284 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  366\n",
      "1210/1210 - 17s - loss: 0.0082 - accuracy: 0.9974 - 17s/epoch - 14ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0322 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  367\n",
      "1210/1210 - 17s - loss: 0.0138 - accuracy: 0.9954 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0032 - accuracy: 0.9991\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0288 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  368\n",
      "1210/1210 - 17s - loss: 0.0059 - accuracy: 0.9980 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0079 - accuracy: 0.9971\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0285 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  369\n",
      "1210/1210 - 17s - loss: 0.0155 - accuracy: 0.9946 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0052 - accuracy: 0.9980\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0382 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  370\n",
      "1210/1210 - 18s - loss: 0.0095 - accuracy: 0.9964 - 18s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0024 - accuracy: 0.9995\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0302 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  371\n",
      "1210/1210 - 18s - loss: 0.0092 - accuracy: 0.9967 - 18s/epoch - 15ms/step\n",
      "for training\n",
      "605/605 [==============================] - 4s 6ms/step - loss: 0.0039 - accuracy: 0.9991\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0312 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  372\n",
      "1210/1210 - 17s - loss: 0.0107 - accuracy: 0.9961 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0041 - accuracy: 0.9983\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0303 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  373\n",
      "1210/1210 - 17s - loss: 0.0121 - accuracy: 0.9962 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0310 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  374\n",
      "1210/1210 - 17s - loss: 0.0105 - accuracy: 0.9965 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0029 - accuracy: 0.9992\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0234 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  375\n",
      "1210/1210 - 17s - loss: 0.0049 - accuracy: 0.9984 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0449 - accuracy: 0.9857\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0769 - accuracy: 0.9808\n",
      "\n",
      "Epoch:  376\n",
      "1210/1210 - 16s - loss: 0.0093 - accuracy: 0.9968 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0040 - accuracy: 0.9989\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0328 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  377\n",
      "1210/1210 - 17s - loss: 0.0115 - accuracy: 0.9962 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0050 - accuracy: 0.9981\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0316 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  378\n",
      "1210/1210 - 17s - loss: 0.0084 - accuracy: 0.9971 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0032 - accuracy: 0.9989\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0315 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  379\n",
      "1210/1210 - 17s - loss: 0.0151 - accuracy: 0.9950 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0303 - accuracy: 0.9884\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0707 - accuracy: 0.9793\n",
      "\n",
      "Epoch:  380\n",
      "1210/1210 - 16s - loss: 0.0069 - accuracy: 0.9974 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0013 - accuracy: 0.9998\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0209 - accuracy: 0.9942\n",
      "\n",
      "Epoch:  381\n",
      "1210/1210 - 17s - loss: 0.0094 - accuracy: 0.9967 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0368 - accuracy: 0.9873\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0643 - accuracy: 0.9835\n",
      "\n",
      "Epoch:  382\n",
      "1210/1210 - 17s - loss: 0.0096 - accuracy: 0.9966 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0046 - accuracy: 0.9985\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0383 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  383\n",
      "1210/1210 - 16s - loss: 0.0065 - accuracy: 0.9976 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 8.0604e-04 - accuracy: 0.9999\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0224 - accuracy: 0.9938\n",
      "\n",
      "Epoch:  384\n",
      "1210/1210 - 16s - loss: 0.0086 - accuracy: 0.9970 - 16s/epoch - 13ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0237 - accuracy: 0.9942\n",
      "\n",
      "Epoch:  385\n",
      "1210/1210 - 17s - loss: 0.0064 - accuracy: 0.9976 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0143 - accuracy: 0.9947\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0476 - accuracy: 0.9886\n",
      "\n",
      "Epoch:  386\n",
      "1210/1210 - 16s - loss: 0.0170 - accuracy: 0.9936 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0038 - accuracy: 0.9988\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0359 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  387\n",
      "1210/1210 - 17s - loss: 0.0097 - accuracy: 0.9975 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0164 - accuracy: 0.9947\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0450 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  388\n",
      "1210/1210 - 17s - loss: 0.0083 - accuracy: 0.9970 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0029 - accuracy: 0.9990\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0252 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  389\n",
      "1210/1210 - 17s - loss: 0.0060 - accuracy: 0.9981 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0013 - accuracy: 0.9999\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0246 - accuracy: 0.9940\n",
      "\n",
      "Epoch:  390\n",
      "1210/1210 - 17s - loss: 0.0105 - accuracy: 0.9963 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0465 - accuracy: 0.9864\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0876 - accuracy: 0.9771\n",
      "\n",
      "Epoch:  391\n",
      "1210/1210 - 17s - loss: 0.0083 - accuracy: 0.9976 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0291 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  392\n",
      "1210/1210 - 16s - loss: 0.0135 - accuracy: 0.9958 - 16s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0162 - accuracy: 0.9946\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0563 - accuracy: 0.9853\n",
      "\n",
      "Epoch:  393\n",
      "1210/1210 - 17s - loss: 0.0029 - accuracy: 0.9992 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0312 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  394\n",
      "1210/1210 - 16s - loss: 0.0116 - accuracy: 0.9961 - 16s/epoch - 14ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 3s 4ms/step - loss: 9.6032e-04 - accuracy: 0.9999\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0228 - accuracy: 0.9944\n",
      "\n",
      "Epoch:  395\n",
      "1210/1210 - 17s - loss: 0.0140 - accuracy: 0.9965 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0012 - accuracy: 0.9999\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0273 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  396\n",
      "1210/1210 - 17s - loss: 0.0053 - accuracy: 0.9983 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0220 - accuracy: 0.9938\n",
      "\n",
      "Epoch:  397\n",
      "1210/1210 - 17s - loss: 0.0091 - accuracy: 0.9967 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0018 - accuracy: 0.9997\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0304 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  398\n",
      "1210/1210 - 17s - loss: 0.0066 - accuracy: 0.9980 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0024 - accuracy: 0.9992\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0275 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  399\n",
      "1210/1210 - 17s - loss: 0.0079 - accuracy: 0.9978 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.0023 - accuracy: 0.9995\n",
      "for testing\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.0233 - accuracy: 0.9942\n",
      "\n",
      "Epoch:  400\n",
      "1210/1210 - 17s - loss: 0.0120 - accuracy: 0.9959 - 17s/epoch - 14ms/step\n",
      "for training\n",
      "605/605 [==============================] - 3s 4ms/step - loss: 0.0019 - accuracy: 0.9995\n",
      "for testing\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.0225 - accuracy: 0.9944\n"
     ]
    }
   ],
   "source": [
    "for x in range(400):\n",
    "    print(\"\\nEpoch: \",x+1)\n",
    "    history = model.fit(X_train ,y_train ,batch_size=BATCH_SIZE ,epochs=1, verbose=2, shuffle=True)\n",
    "    if history_dataframe.size == 0:\n",
    "        history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    else:\n",
    "        history_dataframe = pd.concat([history_dataframe,pd.DataFrame.from_dict(history.history)],axis=0,ignore_index=True)\n",
    "    \n",
    "    print(\"for training\")\n",
    "    train_eva.append(model.evaluate(X_train,y_train))\n",
    "    print(\"for testing\")\n",
    "    test_eva.append(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ec37c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.281798</td>\n",
       "      <td>0.388467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.851255</td>\n",
       "      <td>0.647445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.610582</td>\n",
       "      <td>0.751511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.510676</td>\n",
       "      <td>0.794605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.429842</td>\n",
       "      <td>0.831964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.005344</td>\n",
       "      <td>0.998347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.009082</td>\n",
       "      <td>0.996745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.006634</td>\n",
       "      <td>0.997985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.007894</td>\n",
       "      <td>0.997830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.012044</td>\n",
       "      <td>0.995866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy\n",
       "0    1.281798  0.388467\n",
       "1    0.851255  0.647445\n",
       "2    0.610582  0.751511\n",
       "3    0.510676  0.794605\n",
       "4    0.429842  0.831964\n",
       "..        ...       ...\n",
       "395  0.005344  0.998347\n",
       "396  0.009082  0.996745\n",
       "397  0.006634  0.997985\n",
       "398  0.007894  0.997830\n",
       "399  0.012044  0.995866\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c8463e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva_df = pd.DataFrame(train_eva,columns=['loss','accuracy'])\n",
    "test_eva_df = pd.DataFrame(test_eva,columns=['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cc95506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(df,title,xlabel,ylabel,values=['loss'],legends=[]):\n",
    "    \n",
    "    for value in values:\n",
    "        epoch_count = range(1, len(df.index) + 1)\n",
    "        plt.plot(epoch_count, df[value].tolist())\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    if legends==[]:\n",
    "        legends = values\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35c781fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAACK9UlEQVR4nO3dd3hTZfsH8G+S7tJJF4VC2XvJLENAkOHEiYiKqLjQV0XfV3GAG18Hoq8oKuJEQfwpDhAEBGTvsvcqqy1t6W6TJjm/P56ck5wkbdOSZpTv57p6tU1OkufkJOfc537u5zkaSZIkEBEREdUTWm83gIiIiMidGNwQERFRvcLghoiIiOoVBjdERERUrzC4ISIionqFwQ0RERHVKwxuiIiIqF5hcENERET1CoMbIiIiqlcY3BAREVG9wuCGiHyKRqNx6Wf16tWX/FqlpaV4+eWX3fJcROQ7ArzdACIiW99++63q/2+++QbLly93uL19+/aX/FqlpaV45ZVXAACDBw++5OcjIt/A4IaIfMpdd92l+n/Tpk1Yvny5w+1ERJVhtxQR+R2z2YyZM2eiY8eOCAkJQWJiIh566CFcvHhRtdy2bdswYsQIxMXFITQ0FM2bN8d9990HADh58iTi4+MBAK+88orS3fXyyy97enWIyM2YuSEiv/PQQw/hq6++woQJE/Cvf/0LJ06cwEcffYSdO3di/fr1CAwMRHZ2NoYPH474+Hg899xziI6OxsmTJ/Hzzz8DAOLj4/HJJ5/gkUcewU033YSbb74ZANClSxdvrhoRuQGDGyLyK+vWrcOcOXMwb9483HnnncrtQ4YMwciRI7Fw4ULceeed2LBhAy5evIi//voLPXv2VJZ7/fXXAQDh4eG49dZb8cgjj6BLly7s9iKqR9gtRUR+ZeHChYiKisLVV1+NnJwc5adHjx5o0KABVq1aBQCIjo4GAPzxxx+oqKjwYouJyNMY3BCRXzly5AgKCgqQkJCA+Ph41U9xcTGys7MBAIMGDcItt9yCV155BXFxcbjxxhvx5ZdfQq/Xe3kNiKiusVuKiPyK2WxGQkIC5s2b5/R+uUhYo9Hgp59+wqZNm/D7779j2bJluO+++/Dee+9h06ZNaNCggSebTUQexOCGiPxKy5YtsWLFCvTv3x+hoaHVLt+3b1/07dsXb7zxBr7//nuMGzcO8+fPxwMPPACNRuOBFhORp7Fbioj8yu233w6TyYTXXnvN4T6j0Yj8/HwAwMWLFyFJkur+bt26AYDSNRUWFgYAymOIqH5g5oaI/MqgQYPw0EMPYfr06UhPT8fw4cMRGBiII0eOYOHChfjggw9w66234uuvv8bHH3+Mm266CS1btkRRURE+//xzREZG4pprrgEAhIaGokOHDliwYAHatGmD2NhYdOrUCZ06dfLyWhLRpWBwQ0R+Z/bs2ejRowc+/fRTPP/88wgICEBqairuuusu9O/fH4AIgrZs2YL58+cjKysLUVFR6N27N+bNm4fmzZsrzzVnzhw8/vjjeOqpp2AwGDBt2jQGN0R+TiPZ522JiIiI/BhrboiIiKheYXBDRERE9QqDGyIiIqpXGNwQERFRvcLghoiIiOoVBjdERERUr1x289yYzWacO3cOERERnHqdiIjIT0iShKKiIiQnJ0OrrTo3c9kFN+fOnUNKSoq3m0FERES1cPr0aTRp0qTKZS674CYiIgKAeHMiIyO93BoiIiJyRWFhIVJSUpTjeFUuu+BG7oqKjIxkcENERORnXCkpYUExERER1SsMboiIiKheYXBDRERE9cplV3PjKpPJhIqKCm83g2ogMDAQOp3O280gIiIvY3BjR5IkZGZmIj8/39tNoVqIjo5GUlIS5zAiIrqMMbixIwc2CQkJCAsL40HST0iShNLSUmRnZwMAGjVq5OUWERGRtzC4sWEymZTApmHDht5uDtVQaGgoACA7OxsJCQnsoiIiukyxoNiGXGMTFhbm5ZZQbcnbjvVSRESXLwY3TrAryn9x2xEREYMbIiIiqlcY3NQTgwcPxpNPPuntZhAREXkdgxsiIiKqVzhayk3MkgSjSQIABAUwZiQiIvIWHoXdpMxgwsHMQhzPKfZ2U3Dx4kXcc889iImJQVhYGEaNGoUjR44o9586dQrXX389YmJiEB4ejo4dO2LJkiXKY8eNG4f4+HiEhoaidevW+PLLL721KkRERDXGzE01JElCWYWp2uXKKoworzDBbJZQajC65bVDA3W1Gv1z77334siRI/jtt98QGRmJZ599Ftdccw3279+PwMBATJo0CQaDAf/88w/Cw8Oxf/9+NGjQAADw0ksvYf/+/fjzzz8RFxeHo0ePoqyszC3rQ0RE5AkMbqpRVmFCh6nLvPLa+18dgbCgmm0iOahZv349+vXrBwCYN28eUlJSsGjRItx2223IyMjALbfcgs6dOwMAWrRooTw+IyMD3bt3R8+ePQEAqamp7lkZIiIiD2G3VD1z4MABBAQEoE+fPsptDRs2RNu2bXHgwAEAwL/+9S+8/vrr6N+/P6ZNm4bdu3cryz7yyCOYP38+unXrhv/85z/YsGGDx9eBiIjoUjBzU43QQB32vzqi2uXKK0w4ml2MAK0W7RpFuO2168IDDzyAESNGYPHixfjrr78wffp0vPfee3j88ccxatQonDp1CkuWLMHy5csxdOhQTJo0Ce+++26dtIWIiMjdmLmphkajQVhQgEs/IYE6BAdqXV6+up/a1Nu0b98eRqMRmzdvVm7Lzc3FoUOH0KFDB+W2lJQUPPzww/j555/x9NNP4/PPP1fui4+Px/jx4/Hdd99h5syZ+Oyzzy7tTSQiIvIgZm7cxFcm/W/dujVuvPFGTJw4EZ9++ikiIiLw3HPPoXHjxrjxxhsBAE8++SRGjRqFNm3a4OLFi1i1ahXat28PAJg6dSp69OiBjh07Qq/X448//lDuIyIi8gfM3LiLJbqRJO82AwC+/PJL9OjRA9dddx3S0tIgSRKWLFmCwMBAAOLq55MmTUL79u0xcuRItGnTBh9//DEAICgoCFOmTEGXLl1w5ZVXQqfTYf78+d5cHSIiohrRSJIvHI49p7CwEFFRUSgoKEBkZKTqvvLycpw4cQLNmzdHSEhIjZ7XYDThYGYRtBoNOjWOcmeTqQYuZRsSEZHvqur4bY+ZGzfRWFI3l1WkSERE5IMY3LiL0i3F8IaIiMibGNy4iW1BMQMcIiIi72FwQ0RERPUKgxs3sZ2ShokbIiIi72Fw4zbW6IaxDRERkfcwuHET9WTCDG+IiIi8xavBzT///IPrr78eycnJ0Gg0WLRoUbWPWb16Na644goEBwejVatW+Oqrr+q8na5QFxR7rRlERESXPa8GNyUlJejatStmzZrl0vInTpzAtddeiyFDhiA9PR1PPvkkHnjgASxbtqyOW0pERET+wqvXlho1ahRGjRrl8vKzZ89G8+bN8d577wEQF4lct24d3n//fYwYUf2Vu+uSRiOm8ZPATikiIiJv8quam40bN2LYsGGq20aMGIGNGzd6qUV2LIU37JYiIiLyHr+6KnhmZiYSExNVtyUmJqKwsBBlZWUIDQ11eIxer4der1f+LywsrLP2yZkb5m6EiooK5WKdREREnuJXmZvamD59OqKiopSflJSUOn9Nb4U2S5cuxYABAxAdHY2GDRviuuuuw7Fjx5T7z5w5g7FjxyI2Nhbh4eHo2bMnNm/erNz/+++/o1evXggJCUFcXBxuuukm5T5nBd/R0dFKQffJkyeh0WiwYMECDBo0CCEhIZg3bx5yc3MxduxYNG7cGGFhYejcuTN++OEH1fOYzWa8/fbbaNWqFYKDg9G0aVO88cYbAICrrroKjz32mGr5CxcuICgoCCtXrnTH20b1mdksfmqj4CxwLh0wlDi/P+8EoC9yfp/JCOz5Cbh4qvLnzz1W+eNtSZLzdTCbgQN/ADlHrctJElBRBpTmOS5fUQac2S5e115pXvXv06kNzp/XlfYXXxDvSfZBwGhw/XH2SnKBVW8CmXuBC4eBnCPq5TI2A19dB5xcp37MznnA8qnAipeBJf8BCs9b7z+3Uzyf2QyYTeK2C4eBzZ8CBWesz1+SY32vbRWcAbZ/Dez9P+tnpSQH2LcIyDtuXa4oE9j5HbD/V/F+7F6ofj/1RdYf+XnKC4HdPwKF58T/+aeBsouVv0+leYC+2Pq/oVT9GhXl1nXMOQqcsvR6mCqAoyuAHd8ARVnW5Y16scyJterXMZvEZ2/v/wHndwGnt4jnKM0T78Wad8RzeZFfZW6SkpKQlZWlui0rKwuRkZFOszYAMGXKFEyePFn5v7CwsGYBjiQBFaUuLao1lkIyS4BeC5h1rr9GZQLD7MeYV6mkpASTJ09Gly5dUFxcjKlTp+Kmm25Ceno6SktLMWjQIDRu3Bi//fYbkpKSsGPHDpgtO7TFixfjpptuwgsvvIBvvvkGBoMBS5YsqXGTn3vuObz33nvo3r07QkJCUF5ejh49euDZZ59FZGQkFi9ejLvvvhstW7ZE7969AYht9Pnnn+P999/HgAEDcP78eRw8eBAA8MADD+Cxxx7De++9h+DgYADAd999h8aNG+Oqq66qcfvqhNksdjjhDateTpKAC4cAYxkQEArEtQa0Out9+kKx09g4C+h6h7jfmcJzwJbPgE63AEmdHe8vLwA2/A/ocS8Q1QTI3AMENQBimzt/vopyoOg8EJkMBAS7vNoAxI54/6+i/Zs+BiIbA/FtgUN/Ah1HA21GAim9q3+e87uBH+8R78cV9wD9n1Dfn3cc+GMy0P0uoPOt4rZTG4GsveJ92L8IaH8jsPpNoO01QKuhQPoPwMpXgdIcoNudwPDXgeAIEbSExgC/PCjW/Zq3xXMldQISOwG7fgAOLgEOLQEgAeEJwIQ/gbhW4nWz9gOLHhY79aimwD2LgIYtxQ7++Bqgy23AqunA7vlARDLw2FYguIF47LmdwNY5QOlF4NBiQBcENGwttn1pLhDdDBg5HdjxNXD1a4A2AJg9ANBogYFPA30ftr4n6fOA3yyBf2IncfDUFwGSGTBXAK2HA30fAVoMEc//UW+gOFMs3zRNvFb3u4DV04FT68X7OOQFQBcIRDcF0r8Htn0JDHtZBEbzbgESOgIPrrYcgIuBmGbiQL3zW2Dvz0Cv+4GeE6xtzNgE/PUicGarWBezEUi+Arjr/4CwWODkeuD0ZvH+ndoIFFqCiVZDgS1zgMBQoNUwYN/PQEwqcOQv8bwbPwYqSsS6NukFjF0g3r/vbwfK84HfzgE97wO2zQXynARzJ9cCbUYALQYD394MSCag9Qjg2N9AYkfgfLpY7s//AAEh4r3KtQQ2T+0DIhuJIOD3fwGHl0E5pY1sAgx+VgRSchCS2BkY+hLwy8NAmSXQCGso2hsQAoywfGY/7iu2EyA+p3f+CCx6RHz2tYHiNfMzxGP7PCz2Jed2ABdPArEtxHbe8Y14j8NiRRCpLxRtu/NHYNd84MBvYjv0vF8EWvoCYPRsYN0MIOeweO2YVPETGAZcOGgN0AY+Ld7PIS8AuxeIbWorIERsO5Olp6RJb/Fd9hKN5CMXQtJoNPjll18wevToSpd59tlnsWTJEuzZs0e57c4770ReXh6WLl3q0utUdcn08vJynDhxAs2bN0dISIi40VACvJlc4/Vxi+fPAUHhtX54Tk4O4uPjsWfPHmzYsAHPPPMMTp48idjYWIdl+/XrhxYtWuC7775z+lzOtk90dDRmzpyJe++9FydPnkTz5s0xc+ZMPPHEE06fQ3bdddehXbt2ePfdd1FUVIT4+Hh89NFHeOCBBxyWLS8vR3JyMmZ/8C5uHzMGCAhB1+7dcfPNt2DatGli56bRii9VWR7KjcCJs9liGwYHix1daIx4suNrxIG+UVeg+UCxg9w6B7hxFtCoi/i7yLLzb9YPaH+9+PvICmDpsyJY6PsosOQZcdAaOFkcjP96EdjwEXDdDKDDaOCzwWLHec074vFmkzg4HFoC/DzRunJtRgKpA8ROpSgLOLZS7JgAsaO99l1xcCg6Lw42HW8Cjq0C/u8BccBuM1IciIoygS5jxE4r/Xsgob04OHYdK157z4/iPXhil9hBb/lcvM6QF4CSC8APd4gdbXg8cMcPYoe56wdg6FSg+WCxo1/7ngikutwOLPk3cHYH0LgHkLUPKDpX5fbG8NfFgeb0ZnEgDwgRAVhcK7FNVr0JnN5k+2kDnkgX73FAkDgj/GK4aFdAiHg+o16875CA4Cixk26QZD14T1gKfH2d9f0ERCAS00wc2JK6AJm7Hdua1Fl8RuzFtREH9dyjwFfXi9eTNUgCWl8tDvDO9J0EjHxT/L3gLuDA71W/X7LWw4Hmg4C/XrDe9vB6IChMBI/ndgJ7Flb/PJ1uAZr1BxZPrn5ZQHyOUgcAx1dbbwuJEtsMEJ+L/b+K4G7Qs8A/74rgABDfxXELgZZDxYF51w8OTw9AHDw73iyCcHOFa+2qiu22dya+vfjOF2eJtsvkIKMm7l8u9iFfXWs9wKf0EVkV2+9CZGPx3ZRM4vubn1H5c9q+v7LAcBHAyb8vhS7YGnRUJqiBCFhdFRwJNEgU+yJorIFbQkegSQ+gYSvHk5RLVNXx255XMzfFxcU4etSa5jtx4gTS09MRGxuLpk2bYsqUKTh79iy++Uaktx5++GF89NFH+M9//oP77rsPf//9N3788UcsXrzYW6vgU44cOYKpU6di8+bNyMnJUbIyGRkZSE9PR/fu3Z0GNgCQnp6OiRMnqm+U05dydsEFPTu0FIGGRgNIEkwFZ/Hm+5/ix58X4ezZszAYDNDr9QgLCwMkCQcOHIBer8fQoUPVT2QyAuX5CAmNwd133oG5c+fg9qHdsWP/cezduw+//fKLSP0WnBEHLI1W7DyMGkCy1Pmsng6s+S9wx/ciSPzmRsv6BADj/wCWTRH/fzlSnKXYZug2zwYe2wbENBdnb3nHxMH09GbrwenMVnGg3fA/8f8fT4kdXP4pkVm54h5xsFz6HLD1CyC5u1hO3lmdXC9SwbYHYNmRZcD/Vqt3SEdXirMt+Szx6ErrgcH2LOrMFvF794/Wg07ZRXHWteNb65lszmEg9zhgKBLvX8kF4Aubgv3vbhGZBWO5+P/QEmD/b0D2PsvrLxe/o1LEcvZnyG1GAYf/FO/bXy+K2xokitcqOg807QdkbLSuT8PWIiNQnAl80NVyhvoIsPMb64HBWC6CS1tyoGF7cPtypPid2AkYOg2YPxYoyBA/gPPABrAGNv3+JYLDsIbAZ4PEe7Xhf8DhpeL1UvoC170P/HQfcOGAJbDRiAxE7lERmLW8Ckj/Dtg0SwSXVz4DZB+wvtZVL4rAI/eY+Hzu/1V87mTHV4tuCVvr3hddLrbret37IjANiQaiU0Q7zEbxXNvmiq6Dvf8nlh08Behwo8g2/POu2PaxLYGmfUUmCBCPtQ1sAPWBd8NH1gPZmv+K30ldxHtkLAdWvCK6J3b9IL5r3cYBV/4bMBlEkP/DHSLbsG6G9TljW4osSnw78f3ZOAuqDv7YFkDn20R2rOd9wL5fREaw5VXAl6Os70dMc6DtKJFFDAgFhr8mAv8QmwPhho+sAaN9YJPURXxv24wQWb1fHhTf27g24nsMiG3yy8PiOxcSBdy7RGT9sg+Kz4qxXARuN38m3sd5t4r9AiA+/+2vB078A9w6Fzi4WOyn5Pf36tdERib9O2tAc/8ysS4l2WIb//yg+P70GC9Owhq2Bo6vEidrbUcCvSaKjE1AiHi/Fj1s3Y9c9z7w9xuWgMSGLkjs7w7/KfZjgMiIxbURPyumwcF171uzqGaz2G5mowhqatDjUFe8Gtxs27YNQ4YMUf6Xu4/Gjx+Pr776CufPn0dGhjXabd68ORYvXoynnnoKH3zwAZo0aYI5c+bU7TDwwDCRQXHBwcwiVJjMaBUfjtAgN7y1gWE1Wvz6669Hs2bN8PnnnyM5ORlmsxmdOnWCwWCotNtO5nC/ySB2xJIZCI2FRqNxuNp5RYXNGZclEAqXioGC06KvNygc77z9Dj6Y/S1mvv8+OjeLRXiQBk+++iEMZSXA+XSESpYvnSSJM3RJEmfrxVniy1yaiwfGj0O3vp/izLksfPn9QlzVvxeaJUaJ1wHUfcQwi4Dnu+eAM/+Im9Z/qM6AmY3iwK1amVIgKALodZ/YIZ3fBSx7QRx8bA/atmfdR5aJH1tbPrf+PXsA0KibNcV9dpv4PeJ1sQMx2NRbBEcByd2AE2tstoHdmZacGWg51JLlqeaMVw5sZCteVv9/fpf4ndIXGPMtsPhpkbYGRNfBuR1iR60NFK8lma2BzdgFYmcWkSS6DYLCxVnqzM7is/PASpHZmTtSnZUpttlWGRvE7ya9Rcq7xWDRLTB/rLi9NBdY9br4OzQGSHtMHJCDwsW6GQ3Vn9F2vg1oMxwY9Taw7HmRWTv8p+NZ8u3fiq6ZzbPFwXP4a9b7RrwhgpjV08X/wZHi/WqQILpXvhwpumZu/UIEdCUXRLCh1Yoz9tVvivUoz7fW4Dy5R9wHiAM3IA7Mmz+FclA3Gazv3Z0/ii6XvT85rmOrYdbnsnXNOyKQ+epa623tbxCZvYT2IjO063ug90PioBvdVLQlPE4cKMvygJs+BT7qqX5eObCRhUSLbEZpLvB+BxE4Ln5a3Df4ORHY2Hp4HbDqDXGiENlEBAFyt52s94MicPjxHtEtMuFP8VmTdbjB+veDq4G1M0RQed1MkRVKaC+yKfFtHd+Xfo+JzMvX16lvj24K3PUz0CBe/dyyfYvE9ljzX3ECoQ0EbvtKBDYAkNAOuHuR+L73ekBkVRskWB5s2aahMcC171mfM7GTqGWSv/e9J4qAJN2SQY9qKpbRaKzdog/9I/63DSB63Ct+7EU0An5/QuxLtIEi6MrcC2z7Qr1cs36i26vHBLFN4tuI9xEQAb99cBPXRmSSZVpt5d3eXuLV4Gbw4MEOB0xbzmYfHjx4MHbu3FmHrbKj0bjcNSQFmiBpzZCCwgF3BDc1kJubi0OHDuHzzz/HwIEDAQDr1lmL6rp06YI5c+YgLy/Pmr2pKBO/A0PRpUtnrFz+FyZMsPSXG8rEwQwAyvIQHx+P8+fPi+6A4iwcOXIUpaWl1iIz2x2efDZkLMP6rem4ccQg3HV1VwCiePjw4cPo0Ebs0FsnBCM0JAQrF32LB+64UZzVJ7QXBwIAqChF5xZJ6Nm1Az7//md8/8tSfPTGs9bAxvI6DvJPWP9WDq4a4OG1wMIJQO4Ryxtzh0jBn9kqagWSu4udyxdXi4Pg4T/Fcq2utmYqAHEQuHhSvEdBEUCnm0VXkG3AAlgDG1uNe6hTwJGNxcEOGhE8fD8GKDwr7hvwlDjz/Liv+D+mudihvmVTN9Z6hOgbz6+keHXkW+JgJWcthrwIbP9K1DcAwA3/EzvhMd8CxdkiyxPfVqyf3D65WwgQXQBtRzq+TkSSONiXFwJNLAfE0R+L+oPWV4uz86+vE+t57XsioAxrKHa4gZZu4DYjRFdMeQEQGi2yFFf+W6S3A0PFzjcoXGQTzSaR7dj5ragVOroCSB0odvL/d794vk43i9+97heP1WqBla8Ba9+1rPtH4sDeZrg4YPZ52LpTl3W8Wbx/cnA67GXrQSuqMTBpqzh4hERZ3gebEZ2DnxX1E8umABs/ErcFhokDiL3IRiITccyuUL5JL/G+tL3GUgdkIzBMZM4qkzpAZAOWvySyIgntrfcldhCZR6Wtz1n/bmlTz3bnQmDhvcCwaSLAsy9o7Xyr2H6RyUBorNgX6AtF0NP/Scc2hUZbu2wrE9NM/B7/W9XLASIouX6m+rbqaj2a9bPWAAFAt7uA0dVMJisfB+TM6KD/qN8nAGiWJn5kcpd4Zf9rNCKDs+QZsX0DQ0VQFhAiTizajnLMgmhrMA4oKEy05/hqoMUg8d63GGQNbiKSxXdN/hxoNOK7YCu+vcgcGctEsDXgCVHfU4OMvjf4VUGxr1M+gl6oYoqJiUHDhg3x2WefoVGjRsjIyMBzz/5H3Gk0YOyNI/Dmm0kYPXo0pk+fjkbxsdi5ZjGSE+OQNmAwpj05EUNvvgctmybjjmsHwwgdlixdhmcn3QsAuOrKfvjoo4+Q1jYRJkM5nn3jAwQGBliDkEpGUbRu3hQ/LV6JDVt3ISY6AjPmLEBWTp4S3IQEB+LZSePxn9dmIEinRf9eXXHh4DnsS9+G+8dYzjj1hXhg7Gg89uJ/ER4WiptGDnH6WgiNBYoLRIAkC4qwBhydbxXdRGO+BT6/Shxcu94BtBwCXHG39TEpvcVBLv17Ecx1uEGc+b/XVpxNA0C/x8WOIXu/KMo8uVYEN8pz9BFnTfsXObazYStxnxxgRSZbdxRJnUVqXA5umvUXB6T21wOHlor6oJBIceCQ3/uEdsCNH4kz3Lkj4fABTB0oMhYb/ifS0X0fFsXKC8eLepD4NtZlGyRYD9y2B/n4ttbgxvYAaa/5lXbr2hK4Y571/zssXRX2O1CZVmc9oMnF/LYnF7ZF27pAoOsY8VOUKYqH+zws3sOSCyKAtM1oyAeF9teL4CY0VnQ96Wx2g87OPjUaYOx8sY3lrIetwBBrcOZM2qMiSDtk6T5v2KryA9TNn4vMR+5RccCLbQlc/6G4b9jLjsFNRWn1XQD9HhfrldChdt0FbYYDz58Vj931gzq4CQwXWQpA3N+oi7VLq1k/sY18kVYnvoPySZJtVqgy9tklZ9kye/bBTEi04zLhceKERRYYIoKa/b+KzOOl6jtJjP7q97j4P3WgCFY0GuDRDSJArmoggS5AbNfTm0X3pby9fRyDGzeS9xveqNDWarWYP38+/vWvf6FTp05o26YNPpz2Lwy+dSJQnIWg0vP465d5ePrF13HNqJEwGk3o0KY5Zr3xHFB+EYN7dcDCT/+L12bOwVvv/w+RDcJxZd8rlOd/b9rTmPDEixh4w91ITozHB2+9gu0THxfDDk1G6xlQoLp768UnHsDxzHyMuOsxhIWF48GJD2D0iDIUFFkL1156ciICQiIw9b3ZOJeZjUaJCXj4bnW30djRI/HktHcx9sYRCAmRv4gasfOUA47QGCA4DijSAbd+BWSsFjuJla+JYsKelrP5hPai5ibnkOgKcWbUf0XGQzJbA4/4dtZajbi2QGp/awYjPF79+NbDxVlr7jEgy6ZANaqpOFhHJquDG1u2B3B5pNEtc8XZcHic5XlSrMFNdFNrUJLQXgRcsqAIcZtWZy1qBcRIppSDru3UAZGGliV0cO0xzrS7xvVla5A1RUSSyBLJ+j5S+bLJ3YAx34mDm87FXWCDeGsWqDZaDbUGN7bvpb3whiLYTh0o3ufk7uLsGxAB5og3RfCQd0J8fjrdUvlzyTQaa3F8bck7t5hUUcgMiAzZqLfVB8Yku+DGl0U2tgY3kY2qXz7ILrgJrrqgVXmMRmftIg6Ndq1tN34MDHvFmsG6FG2GA0/b1HqFxQL3/gFA4xh8Vab99SK46Tj60tvjIQxu3MoyQ3FdPb1cqFuJYcOGYf9+y4EtPwMozYV0dodyf7NoHX76aBoAm/5Tmy/ezdcMxc3X2BX2hsUCpXlIjg3Hsm9nApDEwTQ0BvkDrxCPLc9HakoypPO7RQCgLxJdBoVnEJucikW//aF+ztJcMc9EaDRQcgHakEi88Po7eGHaq6J7xYmcvHyU6w24/+F/WW8MCrMWPQPizEpvEJmbpE5AqqVr5M75jk/YpIf4qYpGI94fWWIna3AT3069rH1wE9ZQHDgnLBFByJyrRdGjPLzbNqCJbKx+bPNBonBYo7N2dQQEAQFx1mWimliDpuhU6+0trxLBjdyNltq/8vSxKzt0me36Jl5CcOMrLvVgX1OtbL5XrgSUugCx7eylTRI/JTlimHZvD59F22bzops5nvHbTk3g68FNVGNA7t2OcGFErENwE1H9YzSWAEIu4HWWuXH6WmFAkBsCm8rI3cau6jsJ6Hpn9dNd+BAGN25k7Zaqg/CmLB+4eEKcsYfHqe8rFoW3CI0VZ5hFWa5PttWwlSiYdTZiBxBf6Ipyy0giSRxwQ2NEABHcQPTXlli+uLpgkUkJi7UUBgdbzzpthTUUP5Ikzn7kZQJCRNW+nImBKFrOvViAF9+ehb69e+KKPv2tdSy6ICAsQgRywZHq7qi6kNjR0v44xy+5s+AGsHQhRYqd/tFMa4FjhE1gYZ+56XybCNqa9Kq8LVE2AZFtenzICyLAaTFYdGFU9Rw1YVuYWVW3FDlnGxQ0bHnpzxceBwz6d/XLuZsquHHSLdOom/XvpK513ZpLY/u9cyXgtM8ihriQuQHUwY2rmRJfo9X6VWADMLhxr7rolpIk8YwXLQWyBafVwU1prrU+o+ic+N/ZfAa6YFHrYCwXfayGIhEcBIWJAMdUITIM9kMjtYHiwC0Xq4bYBBHBESK4kQt6bc/iNJrqv/z2y2g04jnlNgSGYv2G7Rhy20S0adEMP/24wHomVGaZ1yQgWLTxEuYDclmLweI9bOmk5ic01jLfjqUIO8xuR9DjXtENJvehqzI3dsGNRgN0G1t1W6JsClKjbQpKg8KsWQJ3Zieim4mAzFguCgyp5u5fLoqeu3tvYrNLVl1wE99GjKQLj3O9y89bbIu67b+DztjX3LiSuQHUAY2r3VJ0yXz80+df3DKy31AiZqANCBEHsIIzjnMSXDwp0ptB4eJ+wNq9JAc2EY1ENiPnkPi/Qbw1u2CZ8E4Zah4YKn6CwsXzXjxp7SPWBYovdcEZcZvtQdu+z7mms9s6ExRuDW50QRg8sJ+1a00+qEY3BaLMItAAXD+DulRJnYAndjs/+9JqRUanJFv8bx/ctL9O/MhUmRsnI2eqI4+QCU9wqHOqE7oAMYTXbHSejaPqpfR2bbZmX2Yb3FQ2SsvZSDpfJGc/NTrHzKszDt1SUa69ju3+wtVuKbpkDG7cSCkorm3qpqJcXCsFkhgmrNU5BjaAGK1QdlEc3CWzCFLi2ojiVTkj0yABgMY63NH2i6nROB58AfF6IZEioDHaBDcarTgjM+rVZysBwdYhi4B43Utl205tgPiRAzb5TFCjrfsuqMpENa78vvD4yoMbe5FVdEu5ovEV4r2xHXZa1+y7Q+nyE5Uiipw1OjGE3p/FWroHY5q5Nqy5NjU3gDpb46/dUn6IwY0Ttb8ixSUWFJv06kfLE55pdJYviEYd7Mh1MlFNRMASnSIyLA0SrAf/2BZiNFONzu5tclByQW1AiPixFxJtnR3UHZkb2wDJvoBaU/0OyKtXE7E9+Fe3E4tqCjHaK8j1EUu2YlsATx+2FhwTeYJWB0xcJf72gVloL0liB+Cmz6yT41XHtus7IEQU+buC3VJeweDGRmCgmJOhtLS02hl9nbF+1Wt5gJVH/gSEihlhzUbxJWrYyjLk2ShuD4kSmRtJEoGM/KULCHYsVqxNLYoqoKhmBxYS6d7gRqOxXCcmS6ybXE/kSlsgth1g3ZYeJae2Q6KrrzdoEA+M/kSc/dV2LhA/K/CjesLfgxpbXce4vqxtzY2rWRuA3VJewuDGhk6nQ3R0NLKzRddCWFgYNDX4IpuMekhGE/TlWpRrzDVvQLkeMFpGJEU2FtfrCAgCKkziBwDCLF0Y4TZBS3l5zV+rKlKgaIcrzy1pgaCGYodnMAKoZNRVTQRGAzHRgEkDmHQutUWSJJSWliI7OxvR0dHQ6bwwe6Yc3FTXJSWrrmiYiHyHbbeUK3PcyJi58QoGN3aSkkQXgRzg1EROkR7lRjOMBYEIq83lF/SFYsh3UCmQ74YgobbMJqCsRGR9Sk5Uv7yiBleUrUlbSotcbkt0dLSyDT1O7pZyNbghIv8RxMyNP2FwY0ej0aBRo0ZISEhQXxjSBZ/8tAvbT13Ec6Pa4ermtTjAbvlM/HS8BRgypeaPr7dc6xMPDAz0TsZGFm2ZdCuqFqOfiMi32Xbx12SEphzQBIa7XqdDl4zBTSV0Ol2ND5SFFRqcLTJBLwUgJKSKa83Y2vENsOYd4PavgLIsoPg0oDMBrj6efEeHGwD9DHGVZiKqX2rbLSVfZZyjDT2KwY0b6Sz1OSazi/U2FWXAipfFvC5/TbVOzR9Ug5Qn+Y6AYHH1aSKqf4JrGdw06iZmDm/k4zM21zMMbtxIq5WDGxcWNlUAG2dZJ6w7tc46C7AnZtslIiLXBYRYZyGvSc2NRgMM+k/dtYucYnDjRgFaFzM3hlLgq2uBc5aZd0NjxNBu+Qq19tN8ExGRd2k0IquuL/DcrOhUa16a5rV+smZuqpnnZvFkEdgERwJ9HwX6Pa6+334mTCIi8j45q16TzA15BYMbN1IyN1XFNme2A7t+EOnNsT8AI6errzMEMLghIvJFcla9JjU35BUMbtzIpYLidTPE7y53AKkDxN/286KwW4qIyPcwc+M3WHPjRtUWFBecAQ4uFn8PeNJ6u31ww4JiIiLf0/FmoLwAaNbP2y2hajC4cSO5W8pc2cUbz+4AIImhgfFtrbeHxaqX41BwIiLf0/9f4od8Hrul3EjO3BgrK7rJ2id+J3VS387MDRERkdswuHEjpeamssxN1l7xO6Gj+nb74jTW3BAREdUagxs30lU3z42cuUm0C240GjF6ShbIzA0REVFtMbhxI11VBcX6YuCi5arW9sENAOiCrX9ruVmIiIhqi0dRN6q0oLgsH1gwTvzdINH5BdQCgh1vIyIiohpjcONGlRYU71kIHF8t/m4x2PmDGdwQERG5BYMbN5ILih0yN+UF4ndsS+DGWZU8mMENERGROzC4cSNdZdeWMurF75ZXAbpA5w8OCKrDlhEREV0+GNy4kRzcGB2Cm3Lxu6quJ07nTURE5BYMbtxIDm7MlQU3gaGVP/j6D4HQWGDUO3XUOiIiossDL7/gRpeUuWnUBfjPcTHnDREREdUaMzduVGlBsVxzExBS9RMwsCEiIrpkDG7cqPKCYjlzU01wQ0RERJeMwY0bVRrcVDC4ISIi8hQGN26kZeaGiIjI6xjcuJF8+QWHq4LLNTeBDG6IiIjqGoMbN5ILih0zN2XiNzM3REREdY5Dwd3IoVsq7wRwZLn18gu8fhQREVGdY3DjRgH2wc0n/YCKUpsFmLkhIiKqa+yWciOHzI1tYAMwuCEiIvIABjduVGlBsbIAgxsiIqK6xuDGjbS2BcXOAhzW3BAREdU5BjdupJrEz1DsuEBVF84kIiIit2Bw40Zyt5RZkoCSC04WYOaGiIiorjG4cSO5oNhokoBiZ8ENa26IiIjqGoMbN1JdFdwhc6MBdEGebxQREdFlhsGNG8k1N0azk+AmIASwBD9ERERUdxjcuJEc3JjNElCSo76T9TZEREQeweDGjXS289yUZKvv5EgpIiIij2Bw40Y624Jih24pZm6IiIg8gcGNG6kLiu26pbSBXmgRERHR5YfBjRupJvErylTfaTZ6oUVERESXHwY3biQHN5LJCFw8qb6TwQ0REZFHeD24mTVrFlJTUxESEoI+ffpgy5YtVS4/c+ZMtG3bFqGhoUhJScFTTz2F8vJyD7W2ajrLu5kgXQDMFYDOps7GZPBOo4iIiC4zXg1uFixYgMmTJ2PatGnYsWMHunbtihEjRiA7O9vp8t9//z2ee+45TJs2DQcOHMAXX3yBBQsW4Pnnn/dwy53TacXb2cR8TtwQ29x6JzM3REREHuHV4GbGjBmYOHEiJkyYgA4dOmD27NkICwvD3LlznS6/YcMG9O/fH3feeSdSU1MxfPhwjB07ttpsj6fIBcUp0nlxQ2xL650mBjdERESe4LXgxmAwYPv27Rg2bJi1MVothg0bho0bNzp9TL9+/bB9+3YlmDl+/DiWLFmCa665ptLX0ev1KCwsVP3UFUviBk1hCW4atrDeyW4pIiIijwjw1gvn5OTAZDIhMTFRdXtiYiIOHjzo9DF33nkncnJyMGDAAEiSBKPRiIcffrjKbqnp06fjlVdecWvbKxNgiW6awUnmht1SREREHuH1guKaWL16Nd588018/PHH2LFjB37++WcsXrwYr732WqWPmTJlCgoKCpSf06dP11n75MxNM41lGHhD2+Cmos5el4iIiKy8lrmJi4uDTqdDVlaW6vasrCwkJSU5fcxLL72Eu+++Gw888AAAoHPnzigpKcGDDz6IF154AVqtY6wWHByM4GDPzA4sZ26SkCduiErxyOsSERGRldcyN0FBQejRowdWrlyp3GY2m7Fy5UqkpaU5fUxpaalDAKPT6QAAkiTVXWNdJBcUB8LSBRUYCvR9VPw95AUvtYqIiOjy4rXMDQBMnjwZ48ePR8+ePdG7d2/MnDkTJSUlmDBhAgDgnnvuQePGjTF9+nQAwPXXX48ZM2age/fu6NOnD44ePYqXXnoJ119/vRLkeJNWC2hhhk5jCbR0QcDw14Er7gHi23m3cURERJcJrwY3Y8aMwYULFzB16lRkZmaiW7duWLp0qVJknJGRocrUvPjii9BoNHjxxRdx9uxZxMfH4/rrr8cbb7zhrVVQCdBqrVkbANAFAlodkNDee40iIiK6zGgkX+jP8aDCwkJERUWhoKAAkZGRbn1uvdGEHi/+jL0hoiYIL2QBgSFufQ0iIqLLUU2O3341WsrX6TQax8wNEREReRSDGzfSaTUIhAkAIGl0okuKiIiIPIrBjRtpNBoEayyZG12QdxtDRER0mWJw42YhWjMAQGKXFBERkVcwuHGzYK3I3Egarw5EIyIiumwxuHGzYI2l5obdUkRERF7B4MbNQrSW4EbLbikiIiJvYHDjZkrmhsENERGRVzC4cbMgS3BjZkExERGRVzC4cbNguVtKw+CGiIjIGxjcuFmwZYZiM7uliIiIvILBjZsFs6CYiIjIqxjcuFmQhpkbIiIib2Jw42aBGjFDsVnLSfyIiIi8gcGNm8nXljKzoJiIiMgrGNy4WZDlquAmZm6IiIi8gsGNmwUxc0NERORVDG7cLMgyFNzE4IaIiMgrGNy4WYBG7pZicENEROQNDG7cTJnET6PzckuIiIguTwxu3CxALihmtxQREZFXMLhxM9bcEBEReReDGzcL1MjBDYeCExEReQODGzeTu6WMzNwQERF5BYMbNwtUuqVYUExEROQNDG7cTA5ujGDmhoiIyBsY3LhZgFQBADCy5oaIiMgrGNy4mTVzw+CGiIjIGxjcuJm1oJjBDRERkTcwuHGzAImZGyIiIm9icONmAbDU3LCgmIiIyCsY3LiZnLmp4FBwIiIir2Bw42Y6DgUnIiLyKgY3bqZkbsDMDRERkTcwuHEznRLcsKCYiIjIGxjcuJnOMokfgxsiIiLvYHDjZkq3lMRuKSIiIm9gcONm1swNC4qJiIi8gcGNm2lZc0NERORVDG7cTM7cGDhaioiIyCsY3LiZziwyNwaJmRsiIiJvYHDjTmYTtJYLZxokvrVERETewCOwO5kqlD8NEguKiYiIvIHBjTuZrcENZygmIiLyDgY37mSTudFznhsiIiKvYHDjThVl4pekg4k1N0RERF7BI7A7GUoAACUIgcksebkxRERElycGN+5kKAYgghsjgxsiIiKvYHDjTpbMTakUArPE4IaIiMgbGNy4k9ItFczMDRERkZcwuHEnS7dUqRQCM4MbIiIir2Bw404sKCYiIvI6BjfuJNfcMLghIiLyGq8HN7NmzUJqaipCQkLQp08fbNmypcrl8/PzMWnSJDRq1AjBwcFo06YNlixZ4qHWVkPO3EjBMLGgmIiIyCu8eunqBQsWYPLkyZg9ezb69OmDmTNnYsSIETh06BASEhIcljcYDLj66quRkJCAn376CY0bN8apU6cQHR3t+cY7YygCwMwNERGRN3k1uJkxYwYmTpyICRMmAABmz56NxYsXY+7cuXjuuecclp87dy7y8vKwYcMGBAaKC1OmpqZ6sslVU2puQhncEBEReYnXuqUMBgO2b9+OYcOGWRuj1WLYsGHYuHGj08f89ttvSEtLw6RJk5CYmIhOnTrhzTffhMlk8lSzq2bbLcXghoiIyCu8lrnJycmByWRCYmKi6vbExEQcPHjQ6WOOHz+Ov//+G+PGjcOSJUtw9OhRPProo6ioqMC0adOcPkav10Ov1yv/FxYWum8l7MlDwdktRURE5DVeLyiuCbPZjISEBHz22Wfo0aMHxowZgxdeeAGzZ8+u9DHTp09HVFSU8pOSklJ3DVQyNyEsKCYiIvISrwU3cXFx0Ol0yMrKUt2elZWFpKQkp49p1KgR2rRpA51Op9zWvn17ZGZmwmAwOH3MlClTUFBQoPycPn3afSthz2YoOCfxIyIi8g6vBTdBQUHo0aMHVq5cqdxmNpuxcuVKpKWlOX1M//79cfToUZjNZuW2w4cPo1GjRggKCnL6mODgYERGRqp+6ozNJH68/AIREZF3eLVbavLkyfj888/x9ddf48CBA3jkkUdQUlKijJ665557MGXKFGX5Rx55BHl5eXjiiSdw+PBhLF68GG+++SYmTZrkrVVQUy6/wIJiIiIib/HqUPAxY8bgwoULmDp1KjIzM9GtWzcsXbpUKTLOyMiAVmuNv1JSUrBs2TI89dRT6NKlCxo3bownnngCzz77rLdWQc0mc8OrghMREXmHRpIur6NwYWEhoqKiUFBQ4P4uqteTAGMZBuhnQt8gBVtfGFb9Y4iIiKhaNTl+ezVzU6+YTYCxDIC4KriG3VJEREReUauam9OnT+PMmTPK/1u2bMGTTz6Jzz77zG0N8zuWLimABcVERETeVKvg5s4778SqVasAAJmZmbj66quxZcsWvPDCC3j11Vfd2kC/YQluJI0OegRyKDgREZGX1Cq42bt3L3r37g0A+PHHH9GpUyds2LAB8+bNw1dffeXO9vkPObgJDAeg4SR+REREXlKr4KaiogLBwcEAgBUrVuCGG24AALRr1w7nz593X+v8iWUYuBQUDgDsliIiIvKSWgU3HTt2xOzZs7F27VosX74cI0eOBACcO3cODRs2dGsD/YYqcwN2SxEREXlJrYKb//73v/j0008xePBgjB07Fl27dgUgrtotd1dddpr2BZ49hfwxiwCA3VJEREReUquh4IMHD0ZOTg4KCwsRExOj3P7ggw8iLCzMbY3zK1odEBoNrVmsvySJ7I1Wq/Fyw4iIiC4vtcrclJWVQa/XK4HNqVOnMHPmTBw6dAgJCQlubaC/0WmswQyzN0RERJ5Xq+DmxhtvxDfffAMAyM/PR58+ffDee+9h9OjR+OSTT9zaQH+j09kEN6y7ISIi8rhaBTc7duzAwIEDAQA//fQTEhMTcerUKXzzzTf48MMP3dpAf6PK3DC4ISIi8rhaBTelpaWIiIgAAPz111+4+eabodVq0bdvX5w6dcqtDfQ3Ntf5ZLcUERGRF9QquGnVqhUWLVqE06dPY9myZRg+fDgAIDs72/0Xo/QzATbRjcnE4IaIiMjTahXcTJ06Fc888wxSU1PRu3dvpKWlARBZnO7du7u1gf7GdnAUMzdERESeV6uh4LfeeisGDBiA8+fPK3PcAMDQoUNx0003ua1x/kij0UCrAcwSJ/IjIiLyhloFNwCQlJSEpKQk5ergTZo0uXwn8LMToNXCYDLzEgxEREReUKtuKbPZjFdffRVRUVFo1qwZmjVrhujoaLz22mswm83ubqPfCbAMB68w8b0gIiLytFplbl544QV88cUXeOutt9C/f38AwLp16/Dyyy+jvLwcb7zxhlsb6W8iQgJQajChqNzo7aYQERFddmoV3Hz99deYM2eOcjVwAOjSpQsaN26MRx999LIPbiJDApFVqEdhWYW3m0JERHTZqVW3VF5eHtq1a+dwe7t27ZCXl3fJjfJ3UaGBAIACBjdEREQeV6vgpmvXrvjoo48cbv/oo4/QpUuXS26Uv4u0BDeF5QxuiIiIPK1W3VJvv/02rr32WqxYsUKZ42bjxo04ffo0lixZ4tYG+iNmboiIiLynVpmbQYMG4fDhw7jpppuQn5+P/Px83Hzzzdi3bx++/fZbd7fR70SGiJixsMyIEr0Ry/dnobzC5OVWERERXR40kuS+aXR37dqFK664AiaT7x7ICwsLERUVhYKCgjq7VMSMvw7hw7+P4u6+zZBZWI7l+7MwpmcK/nsru+yIiIhqoybH71plbqhqtjU3y/dnAQAWbDvtzSYRERFdNhjc1IFI1twQERF5DYObOhAZwuCGiIjIW2o0Wurmm2+u8v78/PxLaUu9IY+Wsp3ET2d7uXAiIiKqMzUKbqKioqq9/5577rmkBtUHkaHibS0os15+QadhcENEROQJNQpuvvzyy7pqR70S5WQSPy07AImIiDyCh9w6IBcUG4zWq4Izc0NEROQZDG7qQIOgANiX2GhZc0NEROQRDG7qgFarQYRlxJSMBcVERESeweCmjsh1NzJ2SxEREXkGg5s6Eh6srtVmtxQREZFnMLipIyGB6reWmRsiIiLPYHBTR0IDdar/WXNDRETkGQxu6kiIXXDDeW6IiIg8g4fcOuKQuWG3FBERkUcwuKkjwXY1NywoJiIi8gwGN3WEmRsiIiLvYHBTR+xrblhQTERE5BkMbuqIfeaGiIiIPIPBTR2xn+fGLEleagkREdHlhcFNHbHvljKaGdwQERF5AoObOmIf3JgY3BAREXkEg5s64pC5MTG4ISIi8gQGN3XEvqDYaDZ7qSVERESXFwY3dcS+oJjdUkRERJ7B4KaOOGZuGNwQERF5AoObOhJsX1DMmhsiIiKPYHBTR5i5ISIi8g4GN3WENTdERETeweCmjoQGcbQUERGRN/hEcDNr1iykpqYiJCQEffr0wZYtW1x63Pz586HRaDB69Oi6bWAthASogxuzBJiZvSEiIqpzXg9uFixYgMmTJ2PatGnYsWMHunbtihEjRiA7O7vKx508eRLPPPMMBg4c6KGW1ox95gYATLy+FBERUZ3zenAzY8YMTJw4ERMmTECHDh0we/ZshIWFYe7cuZU+xmQyYdy4cXjllVfQokULD7bWdcEBjm8t626IiIjqnleDG4PBgO3bt2PYsGHKbVqtFsOGDcPGjRsrfdyrr76KhIQE3H///dW+hl6vR2FhoerHEzQajcNtHDFFRERU97wa3OTk5MBkMiExMVF1e2JiIjIzM50+Zt26dfjiiy/w+eefu/Qa06dPR1RUlPKTkpJyye2uLc51Q0REVPe83i1VE0VFRbj77rvx+eefIy4uzqXHTJkyBQUFBcrP6dOn67iVleOIKSIioroX4M0Xj4uLg06nQ1ZWlur2rKwsJCUlOSx/7NgxnDx5Etdff71ym9kSMAQEBODQoUNo2bKl6jHBwcEIDg6ug9bXHGtuiIiI6p5XMzdBQUHo0aMHVq5cqdxmNpuxcuVKpKWlOSzfrl077NmzB+np6crPDTfcgCFDhiA9Pd2rXU6uqGBwQ0REVOe8mrkBgMmTJ2P8+PHo2bMnevfujZkzZ6KkpAQTJkwAANxzzz1o3Lgxpk+fjpCQEHTq1En1+OjoaABwuN0XseaGiIio7nk9uBkzZgwuXLiAqVOnIjMzE926dcPSpUuVIuOMjAxotX5VGlQp1twQERHVPY0kXV4zyxUWFiIqKgoFBQWIjIys09dqPmUxbN/d5U9didaJEXX6mkRERPVRTY7f9SMl4qP+fnowXrquAyJCRIKM89wQERHVPQY3dah5XDjuH9AcDYJFcMPRUkRERHWPwY0H6LRitmJmboiI/NtlVsnhtxjceECAJbgxsaCYiMhvfbz6KPq/9TfO5Zd5uylUDQY3HqBkbjgUnIjIb63Yn4VzBeXYfSbf202hajC48YAAy1B21twQEfkv+fzUxCS8z2Nw4wGsuSEi8n9yvQ3nLPN9DG48IEAn19wwuCEi8lfyPtzMomKfx+DGA5i5ISLyf2Z2S/kNBjcewNFSRET+zyxnbnii6vMY3HgAMzdERP7PZOmOMrFbyucxuPEAebQUh4ITEfkvudaG9ZO+j8GNBzBzQ0Tk/8wsKPYbDG48IFDHmhsiIn9nYubGbzC48QBmboiI/J98fsrgxvcxuPEAzlBMROT/5O4odkv5PgY3HsBrSxER+T9rQbGXG0LVYnDjAdZ5bhjcEBH5KzmoYebG9zG48QDW3BAR+T8OBfcfDG48IICjpYiI/B6DG//B4MYDmLkhIvJ/vHCm/2Bw4wEcLUVE5P8k5cKZ3Jf7OgY3HsDMDRGR/5ODGl5byvcxuPEAjpYiIvJ/clDDq4L7PgY3HsB5boiI/J/EeW78BoMbD7BmbviNICLyV0q3FPflPo/BjQfoLAXFrLkhIvJPkiRB3oWz5sb3MbjxAHmeG3ZLERH5J9t4ht1Svo/BjQcEcLQUEZFfs83WsKDY9zG48YBAnXibL5YavNwSIiKqDduJ+9gt5fsY3HhA3xYNAQD/HL6AzIJyp8vojSb8sCUD5/LLPNk0IiJygW0NMTM3vo/BjQd0SI5E7+axMJolzNt8yuky/1t5FFN+3oPr/rfOw60jIqLqmJi58SsMbjxkbO8UAMA/R3Kc3r/yYDYAIK+EXVdERL5G1S3FzI3PY3DjIU1iwgAABZXU3XDeBCIi32XbFcULZ/o+BjceEh0aCADIL6twej9HUhER+S6zaig499e+jsGNh0RZgpvCsgqnxWgsUCMi8l22AQ3nufF9DG48JNIS3JgloEhvdLifBWpERL7LtiuK3VK+j8GNh4QE6hASKN7uQiddUybOXkxE5LNYUOxfGNx4kNw1VeAkuGHNDRGR7zKxoNivMLjxIDm4yS91DG74ZSEi8l0SC4r9CoMbD4oODQLAzA0Rkb9RFxRzf+3rGNx4UGQV3VKsuSEi8l0mFhT7FQY3HhQdJs914ziRH0dLERH5LokFxX6FwY0HsaCYiMg/2c5tU9NE+5rDF3D8QrF7G0RVYnDjQUpw46SgmGcCRES+S11z4/osfqdySzB+7hY8/sPOumgWVYLBjQfJ3VJOa25svjgSu6iIiHyKep4b1x+XUyzKEHKLeVFkT2Jw40FVdUvZYhcVEZFvUc1QXIN9tHziauTFkT2KwY0HRVYxz42tCl64hIjIp6gunFmD7LrRsj/nSatnMbjxoOhKMjdGu2CmgsPCiYh8imqG4hoEKnJQw+k+PIvBjQc1iQkDAJwrKENRuTXAKTfaBzfM3BAR+RJVzU1NMjdmZm68gcGNB8VHBCMlNhSSBOw6XaDcXmYwqZZjcENE5FvMtZyh2GjJ2HBErGcxuPGw7ikxAICdGReV28or1MGNkelLIiKfYrrEguIKFhR7FIMbD+veNBoAsPN0vnKb3qgObgzM3BAR+RSplgXFFZbgRpJqFhTRpfGJ4GbWrFlITU1FSEgI+vTpgy1btlS67Oeff46BAwciJiYGMTExGDZsWJXL+5ruTa2ZG3k+mzIDa26IiHyZehK/mjzOujDrbjzH68HNggULMHnyZEybNg07duxA165dMWLECGRnZztdfvXq1Rg7dixWrVqFjRs3IiUlBcOHD8fZs2c93PLa6dAoEkEBWlwsrcDJ3FIAQLmR3VJERL6sthfOtB39yrobz/F6cDNjxgxMnDgREyZMQIcOHTB79myEhYVh7ty5TpefN28eHn30UXTr1g3t2rXDnDlzYDabsXLlSg+3vHaCArTo3DgKgLXuxr7mht1SRES+pbYXzrRdlhP5eY5XgxuDwYDt27dj2LBhym1arRbDhg3Dxo0bXXqO0tJSVFRUIDY2tq6a6XbdU6IBADsswY3DaCkjvwBERL7E9pyzRvPc2DyQWXnPCfDmi+fk5MBkMiExMVF1e2JiIg4ePOjSczz77LNITk5WBUi29Ho99Hq98n9hYWHtG+wmou7mBHZm5ANwnOeG/bJERL6l9vPcSE7/prrl9W6pS/HWW29h/vz5+OWXXxASEuJ0menTpyMqKkr5SUlJ8XArHV3RLBoAcDCzCCV6I7uliIh83KXOc1PTx9Gl8WpwExcXB51Oh6ysLNXtWVlZSEpKqvKx7777Lt566y389ddf6NKlS6XLTZkyBQUFBcrP6dOn3dL2S9EoKhRNY8NgMkv4fnMG9BXsliIi8mW1LSg2subGK7wa3AQFBaFHjx6qYmC5ODgtLa3Sx7399tt47bXXsHTpUvTs2bPK1wgODkZkZKTqxxc8dlUrAMD//j6CrEK96j5eW4qIyLeoLpxZy5obZm48x+vdUpMnT8bnn3+Or7/+GgcOHMAjjzyCkpISTJgwAQBwzz33YMqUKcry//3vf/HSSy9h7ty5SE1NRWZmJjIzM1FcXOytVaiVW65ogpbx4SgsN2LpvkzVfYzuiYh8i223lFlSj56qim3mhieunuPVgmIAGDNmDC5cuICpU6ciMzMT3bp1w9KlS5Ui44yMDGi11hjsk08+gcFgwK233qp6nmnTpuHll1/2ZNMviU6rQb+WcTh2oQRHs9WBmYHdUkREPsU+62IySwjQaWr0OGZuPMfrwQ0APPbYY3jsscec3rd69WrV/ydPnqz7BnlIh2TnXWSM7omIfIt9nY1Jklw6gFaoZijmiauneL1b6nLWoVGk0//5BSAi8i32wY2ru2kTR0t5BYMbL2qbFKH6v1VCAwDsliIi8jX2cYmrc91wnhvvYHDjRSGBOuXviJAABAWIzcFuKf9kMJrx844zOF9Q5u2mEJGbOau5cYVtJp4zFHsOgxsvG9u7KQDgpes6INBSnGbkJH5+acWBLEz+cRfeXnrI200hIjdz7JZyMbgxcZ4bb/CJguLL2dTrOmBMrxR0bRKFvWcLAAAVDG78Uk6xmK8ot8Tg5ZYQkbvZBzO16ZZizY3nMLjxstAgHbpZLqQZqBOJNANTl35JrpUyGE3VLElE/sZ+t+x65sZ2tBT37Z7CbikfIgc37JbyT3pLcMOaKaL6x37Svlplbrhv8BgGNz5Errlht5R/smZuuP2I6pvaFhSbeG0pr2Bw40PYLeUov9SAB77ehqV7z3u7KdWSr+bO4JSo/rHP1Lgap1SYOBTcGxjc+BB2Swn7zxXigxVHUGYwYe2RHKw4kIW56096u1nVYuaGqP6y74VytVvKZOaFM72BBcU+hN1SwjUfrgUgUrgpMWEAAH2F7xfpKsHNZb79qH5bdyQHWg3Qr1Wct5tyScorTLhrzmb0bdEQz4xoW+3ytZ/nxiZzw6y8xzBz40PkzI23C1LLDCbMWH4Y+84VuLT8sQvFOJlT4vZ27D1bgHLLyCO9H2RD5KCUmRuqr8orTLjv6624/+ttfn8SdjCzCNtOXcSP2067tLzDPDeuFhTz8gteweDGh1hrbry70/hg5RF8uPIIrv1wXbXLluiNGPreGgx+d7Xbv7gBOi3KDP4T3BiMrLmh+q1Yb4TBaEZZhQmlBt/Pplal3JINdnV/6zDPTS1mKK5gQbHHMLjxIb4yQ/Gu0/kuL3su33qpgVKD0a3tCNBqUF4h3gt/6JbSM3ND9ZztSYbez+dz0tewRs6+xqY23VLM3HgOgxsfYt8ttf1UHn7c6lrK1J1cTbcC4kxOVubmMzmdVoOyCn/M3HAHRvVTuc1Jhr7C97+TVSmv4b7FPi6pTbcUa248hwXFPsS2W6qgrAK3fLIRANAyIRw9msV6rB01iG2QX1qh/O2ONLXtRFmBOm2Nd0DeZFtQLEkSNBqNl1tE5F62AY0/fCerIrffZJZgMkvQaav+vta+W4qZG29g5saH2HZLfbfplHL79lMXlb9LDcY6/4LUJHOTZ3MdJXcEN2U2Z4Y6rcYmuPH9FLhtetuV7M2qQ9nYciKvLptE5FblNt9Df/hOVsU2C+VK15T9ftf1zA0vv+ANDG58iJy52ZGRj49XHVVu33VajFraf64QnV/+C2/9eQClBqPbu4FktQ1uyiouvebGtptLA+sOqMIk+fxZj21hYnVFioXlFZj49Tbc/9VWh2ndiXxVfczcAK4FN/a7H1e7mFQzFHOwgcewW8qHxEcEK3+X2AQu6ZYC38/+OQaTWcLna0/gl53nEBakwy+P9kPDBsH2T3VJahJD5JW6N3NTXG4NbvRGs2qnYzCaERqku+TXqCuqzI3RDFSxWQpKK2A0SyjSG6E3mhESWPP1MprMCNDx/IQ8R5W58fOaG9tBCiILFVjl8vYnfbW5thQzN57DPaMP6ZgciS/v7YWJA5tj+s2dsWvacGg0wNn8MmQXlSM0yBqL5hTrkZFXiicXpLv9zN/2+ap77otu7pYq0Vufo7zCpOqm8vU0uCoQq+YMzXZdymsxEiyrsBw9Xl+BlxbtrfFjiWpLnbnx7e9jdVTF0S5lbmp3+QXbbI2vZ5/rE2ZufIhGo8GQdgkY0i5Bua11QgMczirGF2tPILuw3OExa4/k4NiFYrRKiAAAHM0uRmrDsEs6o7f9/lWXVci17ZZyQ3BTpLcWKJcbzXZnV759pqjqlqqmreU2B4myChOia/ha+88VoqCsAhuO5dTwkeRNFSaz0v3sj/RG//k+Vkdfg5MRwMkMxczc+DT//ZZdJh4Y2AIA8Ok/x7HyYLbqvqAAsfn2nSsEACzefR7DZqzBO8sOXdJr2n6Jq8sq1HXmxp+GntYkc2ObkapNUCg/vtzH3xOyev2P/ej+6nKcynX/bN6eYvsdrE3G0ZfUtKDYMXNTm9FS/L56CoMbH3d7zxTc2y/V4fagAC1u79kEALD/vAhuVh7IAgD8tP3MJaU/bQ/MZdXswNQ1N+4oKLZmbvRGs+rg7etpcL1qtFR1mRvbIK7mOzw5IHL3xIlUd+asO4FivRGz1xzzdlNqrd5mblwJbuwWcXkouMl2v8DMjacwuPEDg9vGq/7/9O4eWPbkleiYHAVAdFEAwI4MMWQ8t8SArSfFEONP1xzD5AXpLp9lAEBpDSbmu+jmbqlivW2mxr7mxrd3pgaj62eC9t1SNSU/xt+nwL8cBWj9d7dbXo9GS9W05sZhhuJadEux5sZz/Pdbdhnp3jRG+VujAUZ0TELzuHB0aBQJQAQ3eSUGnMwtVZZbujcTZrOE6X8exM87z2KzzXwqYoLADZi77oTT17MdqVXVgddklpBfZjOJnxvS1CU2gZVDt5SPZ24Mptpmbmq+XraTGzoLXPVGE2avOYbDWUU1fu7KHL9QjCNufL7LVb2puXHyuTWZJTzy3Xa899eldY17Qs2Hgl96txRrbjzHf79ll5GoUOsQRdvvV9ukCOi0GuSWGLB0byYAKLNsLt2biXMF1us+2QYNX6w9ju2nLuLVP/Y7fT3bDIx8EC0zmHDW5jpSAJBfalC1xy2Zm3Lb4MbstzU31Z0JXmrNje374iwAXXUwG2/9eRBvLz1Y4+d2xmSWcOvsjRg9a73f11p4g22wK0/W6Y+qy9xsPZmHP/dm4n9/H3W4z9eoam5M1X+mHWYorsUkfqy58RwGN34iMsRxYFtIoA6tExoAAD5fexwAcF2XRmgQHIDMwnL8tuucsmxuiV75O9PJqCtAfAn3ni1Q19wYxN8Tv9mGgf/9W1UMedGm3gZwV82NTXBjNPlNGtxoMqtGmdn3re/IuIgHvt6Gkzni/bM96y2vRUaqrJrgRh7FllNscLivNkoMRuSVGFBiMKlGyJFrimyC9uqm+fdl1dXc2AZxvh4E1zRzY18u40oXk9ksqfYLzNx4DoMbP/H9xL5ok9gAX9/XW3X71R0SAQAnLAfNYe0TcZVlKPns1dbCxexCPcxmCbtO56t2tAajGTszLuL/tp/B64sP4Lr/rVM9f1mFCSazhC0n82CWgJ0Z+cp95wvUQZJbJvGzCW5KDSZVoOXtbilJkvBr+lmno13sR0fZ7yxv/ngDVhzIwr/m7wRgV3NTm9FShqofX2qpXbJ9Py+FbeavxE3PeTkpsOm+dddV4921bWuiJlcFt11nX3TJ89y4kLmxD2Z44UzPYXDjJzo1jsJfTw3CoDbq4uJruzRS/o4ND8LwjokY1SkJAFBoE8RkFZXj6YW7cOOs9fjT0oUFiIzOTR9vwNMLd+GrDScdXre8woRTuSXKDvnYhWLlvrMX1d1U7uiWsj1w2h8E5B3QrFVHMXLmP6piZk/YfCIPT8xPx/O/7HG4z76tldXcyEHoJdfcGKvO3JRYsmjuCkRsn8c2OCbXFLi5Nm3e5lPoNG0Zfk0/e8nPVRPVdRPbTuXg68GNvgbdyICzC2dW/xoOc+P4aeZGkiScLyirfkEfwuDGz7VNjEDL+HAAwK09miA4QIdBbeMRHKDetN9tysAvOx13hGcuVv2BLasw4XCWNaA5fsGatZBrcOQusxI3d0vZk3em7yw7hIOZRUpXnKfIwdz5fMduPfvgprKzc7lLoqrgpNRgxOQF6Vi+P6vStpTbBJLOMmbybe46u7cdxeaNjIG/sz3Qu+Mk4IVfxMzUT8xPv+TnqonqMje2QbCvBze22dO6Kig22tXY2P/vL2avOY606X9j8e7z3m6Kyxjc+DmNRoNXbuiE0d2S8dCVYsK/sKAADGwdX80jhZ0ZF6u8v7zCpBpxY5u5kQOj1olidmT3DAWvIrix25nmFhuQX2rA63/sxwHLXD91SR4ZVljuuNO2P/OrbBI/nUYEN+puJfWyX6w9gZ93nsXEb7ZV2hbbgMi+1sloMisHmRK90S2X57A9aBUzc1NjqsyNH89NVG3mxmbdCkp9O7jR12DqBsAxU+NKQbF9N5S/Zm7kudQ8sZ91FwY39cCA1nGYeUd31QU0h1tqcaqz/VTVwU2ZQR3cnMgpUc5Y5EyGXNRcm5ob++6bqrpR9Eaz6kBdYjBi+pKDmLPuBEZ9sLbGr11TBZYC6oKyCoeAobqaG5nWSebGvqD4XIHzgm9bZZV0a/2wJQMdpy3DX5asj1mq3Tw69opZc3NJClXBjftqx4ICPLsLr64rx/Zzku/jmZuaXuHc4cKZLmVupCr/9xfFlhO6Iicndr6KwU09dVX7BIfbwoJ00NgN1Nh+Kr/K5ymzy9zojWalO0r+LWduXN1pF+uNWHP4Anadzkfnl5fhgxVHlPuyi/SVPk5vNKteo8xgwq4zVbffneSz7wqT5DCrsKs1N3LmpryKoeC2Q4Ury7qUVzjvlpry8x7ojWZcsHkf3dGNZJutKWJwU2MFNQxuJElSnUjIlu3LVF0sNdjDc+ZUN++UP3VL1TRzU7uCYrtuKS8UFB/KLMLjP+zEcZuse03J+5BCP8raMripp+IaBOPPJwbij8cHKLc1iQlFnE12BxBXF69KcblRKYKVa2uO55SgwmRWCszkzI2cIdAbxeR732w8iTMXSx2e891lhzB+7hbcOGs9yivMeH/FYQBix5hvSWUHOdlp6ytMqh1mflmFQ21RXbI9E7Xvmqqq5sY20JFHAVd1jR7bocKVHQjLajDayrbIs7ZsuxvYLVVzNc3cLNmTiSHvrsYrv+9T3f7Qt9vx7aZTyv8+l7kp95/gRlVz48I8N7UpDrYPZrxRczNuzmb8vusc7v+68m7u6siDCJi5IZ/QvlEkOjWOUv5PigrFe7d1BeD6XBtHLxSjwiQhOECL/q3iAIgZkTMLymGWRBDSrGEYAFFL8PHqo+g0bRnu/mIzpv66D/d+udXhOfecLXC4TZIkJRMUERKAuAZBDsvsP1+kemxmQTmCA6xXLK9uVuBLlW9TQ2C/47bvlrJti+3oIo1cc1PFPDW2O8S8SkaElbs4izTgnmBE1S3lxzUj3qIuKK7+/ft+iwhgvt54SsmGOPt8ezy4sQkI1h7JwdUz1qhOkGwLzwt9PLipbeZG3nW6sr+x74byRs2NvH3kk1QA+OjvI/jo7yOVPcSBvA9j5oZ8Uu/UGFzZJh5bXhiKt2/p4tJj5OtWpTYMR49m4jIQ209dVAKR5OgQhAWJjE55hRlvLz2ECpOErSdFLc/RbMdUqLP0aE6xQanhaRwdipBAncMyKw5k4aFvtyv/ZxWWQ4J1Z3Ghki4tdxTUAuoDlP2Ou7LMzfZTefj0H+t8Q3KWpqqh4LZnR5VNmFdWSbeUM866pcxmCbvP5Ls8d1B9GwpeUFbh0XmTXO2WWnvkAp7+cZdqVnJ5Mk77qRcAz08IaF8fdiS7GJuO5yr/+0u3lMksqSbadG0ouPidHB0KoPqRpuJ17EdLubYv+nbjSdz40TrkVpNZr42LJQa8+9dhvPvXYZe3kdIt5cPb1B6Dm8vA3Ht7YlyfpnhgoBhNlRARgriI4GoeJcg1MKlxYco1rnZmXFSGBLZJjEBYkGMgUpmLJQZcdDKKYum+TGw4lgNAdJ8FOwlu7BnNkip4sp1U8LN/jmHkzH/wy84z6P7acvy47bTLbQSAX9PP4qO/j6jOtApq0i1lkiBJEm75ZCM+XWMdsi7Xq6gvn6B+rO3ZUZ5lZultJ/MwY/lh5WzRWc1OZUFcid6I53/Zgzs/36Qs+/vuc7jho/WY8ddhp49xfA7fHgpeZjDh/7afcelgcLHEgCteW47bZm/0QMsE289LVd2Is1Ydxf/tOIMle6xzUS3ZI75rJ51MHunqCMUD5wtrHWxIkoTTeaUwmyWnI6Qybb53qtFSPnwgtA9sXZuhWHy/2lpqDJ2duNmzn6nc1czNS7/uw64zBXVyGQvb2eqX7DmPqb/urXKuLUmSlO+8P53YOM7pT/XOVe0ScVU79egp226fYe0TkX46HznFetxyRRPkluiREBGMH7edUZZJjQtHp8aRCNJpkVtiUPr9J/RvjtBqApHC8gocyiyCySxVmka3LZJsHB3q8hT/toGSvJOtMJnx5hJxTaWnFuwCAPznp93o27whmlq60ApKK1BQVqH8b0uSJGX+kGK9Cc+NagdAXEtLWacy9ZfcYSi40ewwg7N8u8FoVvX3l9sdoGwPCrmWyye8/Ps+7D1biI7JkRjRMclpt1ZlQUd+WQW+35wBAPhk9VFMHt4W+ywZub3nHLsInSlWDQX3vYPWTzvO4KVFe3FPWjO8emOnKpf958gFmMwSdp8pgCRJSldhXbKfxK+y13WWfcyyXC4lI8+xfs2VQHNHxkXc/PEGdEyOxOJ/DaxJswGIzNET89PxyOCWTrNd2ZUUr+eX+u5lOqobEOCMfPLQJikCKw9m44gLwY19MGMf7FSnLi51cqHI+pxTfhYTkiZGhmDSkFZOly+vMCvrwZob8nltEiPQOzUW13ZphI/u7I7k6BAAQP9WDfHVhN7o1zJOtXyLuHAEB+jQsXGkctsVTaPRt0UstFoNQgIr/ygt3ZOJ22ZvxN1fbFalsCvTJCYMIQGuZ4NkcoHzFpsroNuaucKapbj904248p1VTi+lYLtDmb3mGA5lFsFsllQHKFdqbnadznfajhK9scpJ/GxTv3klBpjNEo5YJlKU55lwlrm5WOJ8x5Nhs47fbc5AqcGodHE46+qorM3Wv2vXnWM0mXHjR+tw6ycbXL6isqtOWeoJTuY6BgD2bLMd9kFqXbH9vJjMUqXzIDmrsZIDnpM5juumN5pVF2Z05setImspB7Q1JR8AP1l9zGnmJsvmWnX+0i1lH6TpXaifkQ/wbRLFAIoLRfpq5/JxrLlxPYhydfmass3cyPacqfwkxzagKdIbff6aYTIGN5epQJ0WPz6chll3XoGQQB0mDmyBwW3jMaStGEJuX/OS2lDMgixf/qF9o0i8fWtX5eyzaaxjBkT2n//bDUCctdh20VSmcUxolcFSZTILyjFn7XGMm7PZ6f1yliK/1IBDluHtfx/Mdvo8tr7acALFBqPqAniFZRX4cOURPPztdpTojU5rbtIrGaZerDdWWRBcaFdzcza/TMkMHc4qgtFkVp0ByjUceZWcKZ+wOeDnlRiw+USeUjN1rqDcpUDD9oy8tkPBj2QXY9eZAmw7dRGnnGQhLoWcPcguFOvz+A878exPu50ua1sAm+NkR+9uF0sMLl2qxGSWnM4Nc7G0AhUms9NAHKg+2LQPrGrKtkbI2UVeVd1Sqssv+G4XRm0yN/JXLiI4EMlR4mTw6IWiKh4Bh8DTlZob24DbYLy0kwCH+biMZuQ4yQ5WlQG0/b5LEtDupaWY/ueBS2qXJzC4IQDA9V2T8dWE3ogJF91VoXZ1NM3jRHDz2JBW+OPxAfjj8QFoZRkCDsAh01MZV87mku0KijvbjPiqyt5zBXh9ceVfupM5pTCazKqJC52duZ/LVx+IFu08hwy7jMCZi2WYsfwwlu7LxDvLDjmd56ayzE2x3ohym+Xtz4Rs25RbbFDNCn0os0j1WNvHV3atrZM56oPi0axiZR0NRrNLqW/VDMV618/IC0or8Orv+3HsQrFqdtO9TkbM2T5Grp05c7EUC7edrvbgI2c3cor1OHqhGL/vOocF2047/bydtdm+uS5eNT2/1IAXF+3B1TPWVHmW68zfB7NhlsQJgTzFgbOi4oulBlRW+55XYnBacwMAxdWMvrLdvpdaoOqsW6WybqlCJ5Nd1pVP1xzDsBlrHE5MKmP/nXOloFheF51Wg5aWfV91dTeujpY6klWkfFZtA+5L7dqzD+LySw3IcfKZr+qExdloyzWHLlxSuzyBwQ05FRtmrclpFBWCeEsBcoBOi06NoxxGafRr2VD5u3lcOLQaa0AEAMPsJhWUU7sDW8fhpu6N8eqNHVWPt504cGzvpg7t62kZuWVr03Frd1Tv5rHK34E6DYICtDCYzDhzsQzbbIIbZwcMuVZmRMdEtElsgLIKk0NBslzkCQDfbTqlai8ArDl8ATtsrqBuq8QutWv7t8FoVmVy8kr0OGZzPa+TuaUOO7xSgxHv/XUIE75yHHYPOAY3+88Xqg5IZ/Or75pSFRRXUVS4ePd5fLPxpPL/jOWHMHf9CQybsUYZeQdUXutjNJlxzYdrMeTd1fh20ymM+mAt/v3TbmUupMpcsBy0c0sMqm1hG8RtOJoDo8mMszbXBrM/2JcZTE4PyC/9ug/fbcrAkexifGczz4wrVhwQs0Vf3T5BOWlwdgkGZ11SDYJFWWRmQbnTmhug+qH+tqMTbbe7ySw5nYfKlisFy1mF5ZAkUUCvuvCtyeyW2bGrk1diwPQ/D+JodjF+2u7awAH7YOafwxdw7Ydrq+xykQMTjQbKiZ3tdfeccZjnxklwuOl4Lq5+/x889v0OAOrPQWaha8FaZeyD+7xSg9O5zWy/BydySlTZY2dZnZO5JR4LXGuLwQ051alxJF69sSNeuq4Dfnm0f7VFl31aWIObG7om4/j0a3F7zxTltieHtcGAVnEID9Jh5phuuKl7EwBAh0aReH9MN9yTloq1/xmCFZMHISo0UBluGRMWiKQox5FdvWyCF/surGu7NMLce3sp/6fEhqFlvNgZHbtQjG0nrUHQ8ZwSXCjS43ReqfJllYObRlGhSjfcuqM5qtewPdMxmiWsPKi+yGVuiQEGoxldmzhmnez7rVU1IHYFe3klBtXByWSWHGonCsoqqhxVIbdVHtW29oj6rMs+U+VMsQs1NwajGU/9mI6pv+7DacuBWG6rJAGrDlm7AD9dcxwD3/4bs1YdVXWLncsvx9n8MhSWG/HSor3K6Ix5m04hp1iPsZ9tUs3PsedMAf679KBykJYkYP1Ra12X3B00e80x3DlnM97565BqfU/llSLbcgBZujcT7acuxUKbQnrxnBLW22z/rafUNV3PLNyF22ZvcBoIbD2Zp6z3sA6JyjZwlrmxzyIF6bRIsXT3bj2ZhwqThHAnIxOr6lLIK1GfqWcXWQ+Wn/5zDAP+uwp/2gTqMoPRjJxivWpulMqUGkwo0htF/Y9NAAA4rxOqiU3Hc7HI5oK/zg6oP2zJUP7OKnQtM+UsiNl3rlC1ne3JH1OdVoP2SaL2cH81dUzypH3y++FsEr85lgsArz0iXts20Mgu1F9SEOEQ3BQ7D27O5ZehwmTG0ewiDHl3Ne7+Ygt2nc7HlhN5TouIyyvMVc4m7wsY3JBTGo0G96Sl4v4BzZFk6V+uSlRoIFItI4+GWrI08rw4Gg3QMTkS39zXG9tevBqjuzfGPWnN8O5tXfHI4JbKc6TEhilnRNOu74i7+jbF0ievRIDW8WPaxaarKjHSmlkCRMDUIDgADS1dbE1jw5Qrp287dRG7TluzBrtO56PXGysw8O1VSoAgFyYnR4egQ7LYidleDd2WvI6n88RjAmwyWqkNw7DgoTSHx1wsMajqd8oso2eK9UbMWXtCtezhrGLM25yhum2H3cVOK8sQ2UuzBKD2aWnbepB3lx3CiPf/UQ74MtshvgaT2emomVO5JUr30VFLQGZbo3HM7j08nVeGd5YdwkKbs237TNoNXZORHBWCwnIjHvt+BzYez8W7fx1Wilhf+2M/Pll9TJV+tz1AnbNsyxnLRebn0zXHVev71p8HMeTd1ThfUIbFloP8kr3qg/2Zi2Wqs+njF0qUA1BusR4/bT+DrScv4o/d51SPyy3WY/zcLSivMKNvi1h0So6yydw4vn/2mZuosEBlVKO8Tm2SInBvv1TVclVd6+uIXUYx2+bgv/KACLrWHFYHu0ezizD8/TXo++ZKVUBalezCclU7ejUTJx+VZegOZxU5ZDvtSZKEOz7bhCcXpGPT8Vz8uec82r60FEv3ZqqWW7DV+vk5nCVGZc7fklFl0F5ZN9RXG07img/WKp/llxbtxUpL5k0OwnUajbJf2HeuQBV8/LUvE2/9eVD5HsiZGnmAhLNuqQs238fyCpPq+2kwmZ1OneEqZ5mbC066pcyS2A8s3y+2967T+bhx1nrc/unGSjOG9hlhX8Pghtzm50f74/fHBqBLk2gAomto7r09se7Zq6DRaKDVapSde3hwAG7t0QTRYY4zEQMi7fv66M5IjAxxehVu28flFOnRxyaT06GR2PHIw7ybxYahhSVz88nqYzCYzEqwY+vbTadgNJlx3tJtkRQVig6N1JkX26HsMWGBuK9/c9X94cHW2RX6NG/odDJC+zN0swS8sfgA3li8H7PXHFOeu2lsmCqtP7C1qGv6fpM62HFVr+axcDbnm9wt9c/hC/ho1VEcyirCtN/2YfSs9Rg/dwum/bpXNTszAHy86hjavPinKpCwHRp74oK4LtKx7Op3gKsOWg+uctFsQkQwZtzeFTPHdMO4vs0AqLsdX/5tHy6WGLDPycHTdmd8Nr/M4YBi31VSYjBh0/Fc7LEUgO89qz5gybNid24cpVxqRK7bsq3fWrZPnb3bevIiSg0mNI8Lx5f39oZWq1EyN86yPHl2xc1aDRBvuVyKnDlslxSBadd3wI6Xrla6ZqsKblbbBS7y2bbJLCk1UAczrUFGeYUJd83ZgpO5pTCaJVVWROZs6oesQr2S0QsL0qGzJWPpLLOx50wBrvlgLYa//w8m/5ju9IC//miOKgO36mA2Hpm3AwajGS/aTBuRXaTurjuSXYw/dp/Dcz/vwUPfbnea9TiXX4aJ3zi/FMHaIznYf74Qv+w8i+82ncK3m04ply2Q57nRaDRokxiBQJ0GheVGZTI/SZLw4LfbMXvNMXy1QZykyJmsYEt22b4Gx2yWcMImM3vmYqnD/sG+juj3XeecbpdjF4odMlL2wc3FEoPTgmJAfG+c1ahtOeH84sruHhTgbgxuyG1iw4OUnZrsqnaJaGzpYqot29odZwJ0WnRLiVb+l8+q2iWJybZaJ0Y4BDP2czpEhgTgQpEe647mKGf7yVEhaBEfrgpo+tp0vz0yuCV6pqprf1rYvE73pqJNs++6AkPbJSjBibO08Jx1J/DDFusZaGJkCFZMHoSZY7rh9p5NMGlIS7x1SxfotJpaj1ZqHB2KZg2t7ZOzTGculuHHbacxad4O5b4/92Yi/XQ+1hy+gK83OtaYfLDyiMOB5ohN/cHxnGKcLyxHWYUJGg1wT1ozBAdoMbJjEl64pj1u69EEP0zsC0AU3M5Zexyn80qVodw3dE3GzVc0gVarcVpQ/ufeTHR/bTlKqqkJOXuxzKULBq49nKO8dk6xQZVyly/O2rlJFHqmiiB6s2W6Adv6rTWHs1FQai2i3XNWPK5P81glqA8LDLC0/7xDgGNf2G0yS0pGUi7kbZMYAY1Gg9jwICWQrqxbKrdYj683nAQgipkB67Dtk7klSvboSJaY6iC7sBzzNmeo6jyczcLrbNLOSd/vwJFsESSFBwegk2XKCPvC8QqTGf/+aZdykP95x1mMnrUeHacuVTKS20/lYdyczbjrC+uoxy/WqTOasnRL1rJpbBg0GpH9WmUZAbnnbIEqIJb9sCVDyazItX/29p0rxOmL6iBZHvmk04oavjaWyfzkrlfbz8z/bRddaQczxX3hllncTSYJe88W4LtNpyBJEo7nlKgm7czIK3UYqp1l05VYWF6Bx3/YiSk/71EV6K89cgFD31uDJ+bvVD3Wfkbh3BLn3VKAqLU5keP4Xdl+yvE9BFDp6D1fweCGfF7H5Ch8eW8vrJg8CLf2aIIuTaLQo1kMvhjfEwkRwfhwbHcMbitqYwJ1GiRYDgiTr26Ld2/rilt7NEGf5g2VKe2bNQzDdV2SlWzPo4Nb4qbujQEAk+btUDIZjaJDEajTqrId/xnRFkEBWgTqRLddYqS6y25sL2vxszyj88hOjfDFvb2U+gk57VzVzM5n88sQFKDF6O6N8fatXfHvEe3QODoUIzsmKcvYXj3cFXENgpWACwBGWJ5rzeFs/Oen3SjSGxEdFqh6zNTrOqguYmp/za8TOSXKzvKoTRBxIqdEGUnSMr4BXr2xEw6+NhKz7+6BiVe2wDu3dUWv1BiEB+lgMJnx+uIDeGHRXmWH2cwmoG3XKKJG62nrXH4Zdrkwuulnm7oOQH1Q3m3pxuzaJAqD2ogA9Y/d52AyS6r6rQqThGs+XIt2Ly3F77vOYbfldW0DfvkM/sdtZ/Ch3bV97M/YjWbJ4UK3bZOs70WDaoKbd/86jFKDCV2aROHO3qL+LbtIj/IKEzbbHPRLDCasO5qDK99Zhdf+2A8AShezzLbWJ8Vm2gf5unL5pRV4+LvtSrs6Jot13nbqoqqLc93RHBzMLEJ0WCBu6JoMQAQhJQYTXvxlL37afgbfOAmmbTMe+aUGJTjZaRmRmNaiIVJiRFt+323tVvxinePUE/K2Hd0tGe/c2tXhfkBknM7bFJ73f+tvJfiV9wcdbbqmbH8DwKGsIvyafhYfrxKZ2DG9xPtfbjThuv+tw4uL9uL33eexzq7+7XRemUOQez6/HDszLuL1P/bjwxXWz8yinWeRfjofkiRhniWbu2xfFo5mWzNx9pmY33adq7RLbveZAqc1UpV1i7kyp5Q3cYZi8gtD2ok6nndvs+6MhrZPxJYXrDMvL5rUH9GhgUrxc3xEMG7tIQqXk6J02Pz8UGTklSIxMgRBAVq8e1tXbDmRh5u6N8bxnBL8vvu8UvcQERygBEndUqKx6Xge4iOC0alxFJY+MRCRoYFKl1PH5EjsO1eI/q0aKqlrAKqh8oD1YPR/O0TBanCAFu0bRWJHxkWHIcCVTXM+rk9TpTYkvkEwsov0MJolhAXp8PvjA3Ayp6TSq//GRwTjlRs6YniHJIQF6ZDWsiGK9Eb8Y+m6uKtvU7xyQye0fH4JACA6LBD3DWiOC8V6fLJa7KQn9G+Od/86pGrvd5tO4clhbVT1HeuP5irdCq0sXYL2RekBOi3aJkUoNUP/HL6g1EnZHlzjGwQjNjxI2TZL/jUQf+49X2URdauEBjiaXYxz+eVKRuCBAc0xslMSjueUQAPg35XMgwMAe88WYmj7RJzOK8UWSwDTo1ksmsaGISYsEFmFeizdm6l0WT19dRu8t/ywEhhP/jEdWsv6dmkcrTyvbRfSwm2n8exIMfu1JEkONTcmk4S4CHUw2S7JOolmeLDO4Tll64/mKF0XU0a1V7p2swvLMX7uFiXzJHv3r0NK3VJkSABeuq6D8jnSaoBBbeOVS0J0bxqNovIKHLtQgp8e7ofjF4ox5rNNSnapWcMwtIgLR0igFuUVZvR+cyV+frQfrmgag43HxGdiRIck3DeguXLdLECM4ntm4S6HdbFnNEu4cdZ63D+guZK56dY0GrklemTklaq6uVYcyMaxC8XKgALAmmm5O62Z025jQJxcOBvRBgBaS3TTqXEUftx2Blstn499Z9VdcP/+aTcMJjMGt43HbT2bWC6fYm3bT9vP4JAls6PTamAySyJzYzlZaBobhoy8Ujz/yx6n7fj0n+P49J/juLZLIyzdZ61DGjbjH8SGByGuQZDDaC5ntYNXNI3Gjox87Mi4qNQp/XtEW2QWlKuuQG/P9rn+PpiF+VtO4+nhbVUBuDcxuKF6w7ZrypmQQJ2SSgbEGah8FtoqoQG2vjAMhzKLsPtMPlonRiDQkrF486bO+GjVUTw5tA0AKPU7svfHdMPCbacxaUgrGM0S3l9+GKM6JTkMl7fPioQG6vDjQ2nQG0147Y/9+GHLaTx0ZQt8se4Enr+mvdN1sO0WO1dQjgUP9sWpvFJc0TQGLeMbqHbiADCkbTxWWeakiI8IRkRIIEZ2smZ/3hjdCTd9vB6tEhpg6nUdodNq8OzIdnjvr0P4eNwVAIB/XdUaxy8Uo01iBCYNaYXBbeNxNLsYReVGvLhoL2auOILcYgOOV1JgWNXObtKQVnj2/3Yr2Sz5rDXVpvtMo9GgXVIENhzLhcYyxcCIjklVBjcvXtse9365FZmF5fjJMvqpf6s49EyNRc/UWBzKdF7M2iQmFGculuHrjSfRJSUKaw6JSzUMbB2nBKujuzfGl+tPYpJl6G6LuHA8OqQVftt1Tqk7EgcxCUGWAE52Z59m2HeuEHqjGTnFBkz5eTf2ny/CkawihyJjk6TO3AxqE4/YcGuw0yBYfJ5+TT+HAa3jkRITiuX7syABSnHzXX2bIq1lQ+y0BHj2WaygAC0MRrOSZRrbOwUTB7ZAw3Dr6zaKClVla7o3jcGzI9uhzGBCTHgQ4iOCMa5PU8zbnAGNRgwGCNBp8eDAFvjQso2e+XEXIkIDlbmf+raMRdukCAxpG49Nx/PQq3msEmTbe/OmzuiWEo34iGA88t12bDt1EQfsAqFuKdEoNZiwwlIkrdEA/VvGYd3RHHyx7gTevKkzADEfUnaRHhqNCBSrGvFTWcZCZwlah7RNgEazD5uO5yEjt1QJmuRgQc4uPTCghdNBEfL6NokJxfi0VLyx5ICq++2xIa2UCVCrIl/nz/YEIK/EoAqW70lrBp1Wgz/3ZKKovAL9WsVh+X5RIza0fSJ2ZOQrI+MCdRo8dGULZOSVVhrcaDRitvQn5u9EeHAAVh7IQlahHn/tz8KPD6WppuLwFgY3RBY6rRgFIdfsyFrEN8CM27tV+rg2iRF44doOyv+bnx/qdOj8rVc0wem8MhSUGXAkqxijuzeGTqtBWFAAXr2xEx4d3AopsWF4enjbSq/BpdVqMKx9IlYcyELH5Ej0adFQNQwfEFkPOWX84nUdsOrQGjSODkVkiOPXPSU2DJufHwYNrGekjwxuiYkDmyPAEtyFBunw6d09lcd0TI5Cx+QoSJKEs/ll+GT1MWUnGB0WqCo+njSkpcPoHltD2ydi24tX45PVx/DfpeJ6YAFaDRrZjdBrawlukqNCERqkU7oEbMmBSdvECAxqE69kDgwmM7o0iVK6LgGogoReqTHYduoiRndrjCmj2uGeuVtwMLMID36zTclQPXSldVTf3X2b4duNp5SukvH9UqHTajBr3BX4c08mUmJDMflHceDtlhKt2pa39miCW65ojFtnb8T2UxdVdVayrinR2HU6H6/c0BGdG0chISIYbZMilGBT1sCSuTmSXYzRs9Y7fX8fHCja3SKugfJ+AEDD8CAMa5+Ipg3D8M6yQ8ryzwxvi4Z2XWGhQTo0CLJ+drqnRCMkUKfKevx7RFsE6rS4oVuyUiM3eXhbDGqbgFs+2eAQ+Ka1EN17n97dE2UVJoQH6bDzdD6yCsvx5HyR9ZIvUWH7nYx3csHfns1i0CYxAg0bBCndagDw2FWtsO5oDn7cehpXd0hESkwovrV0ebWIC0d4cACCnRTQJkWGqOqO5ABQJmfkUmLDMKBVHNYeycGk73coU0hMGtIKk77fgfIKM+IaBCOtZUPojSbl/Q8O0Kq6hl6y6/oFRPCQ1rIh+jSPxeYTeQgO0OLuvs0wxxL8DGwdh+xCPW7r2QQ/bT+DwrIKvHRdBzRsEAyNRkyJ8Mfuc0oXX3hwAJ4d2Q7TrhfziZXojeg4bZnyXjSPC1eCm6axYQjQadGsYbjqM/Ovq1rhZG4pHryyBWauOIwVB7Lxa7p6hCAAPPjtNrx1c2f0So11+Cx5EoMbIjerbE6ghMgQTL+5s9P7Am3mNKkssJF9dGd3zFl7XJWBsfXp3T0x9de9mHx1G7SMb4C1/xmCoABtpe2yzzABUAKbqmg0IsvTr2VDfL3hFKLDAvHAwOb4ZcdZrDiQhS/G90JqNcXgslt7NMFvu84ht1iPm65o7PD6XSx1K3JhrEajwZp/D0ZGXimax4Xjx21ncE9aM5zLL0OL+AbQaDT494h2eHfZIeiNJjw3sp1q/RuGB6F5XDgMRjO+vb8PNBog2DJc99fH+uOpBelKN8zNVzRG/1bWALJFfANMHt4Gby89hIjgANxi6fpskxihZAZ7NIvBlhN56NNcHXjKbR/SNl4ZafXajR3RJjECbyw5gJM5JfhifE9UmMxoFCUK8TdOGep0G4VUUbMFiFGD8ojBqLBAzLrzCjzy3Q5oNMBvjw9A4+hQ6I0mbD2Zh9WHLqBfy4aqg1FUaCAKyiowvEOiqnC7SYzjAIHosCC8fENHh9uvaBqtdLnYkqeXCArQKp/3XpZi7b4tGqJUb8KV76wCANVggKHtE/Hn3kwkRgZjVKdGiAkLwkODWkCn1SAhwhoQR4cGok/zWIzuloxF6ecw4Uv1BJdyTZDt+7r0yYEwmiQcu1CsXDi3c+MovD+mKwJ1Wgx6ZzUAwGzTJ3tn76ZYeyRH6Z4MDtCiZ2osrmqXgCV7MnFdl0bKCcx39/fBqdxS9GkRi/VHc/DpP8fx/Kj2GNYhEWfzy6DViJGTjw5uiQGt4pASG4bpN3fGe38dxiODWyIyJBBfrD+B5KhQfD2ht3Iy8sDAFg7vu3g/Y5Tgxv7yOGFBOgTqNKgwSYgND0L3ptFKcCN/hnVaDW65ookyFcWITknK+3ZX32ZKlkx2T1oz7D5TgPTT+Xj4ux1oEhOKdc9e5bRtnqCRfH2aQTcrLCxEVFQUCgoKEBnpePZHRL6nwmTGwm1nMLB1nKqLpDr5pQZcLK1wOuJOHjbrrO5CbzThnaWHEBMehEcGtVQOJDKTWcK3G0+ibVIk0lo6BjDVuVhiwGt/7Mf13ZKV67lJkgS90VxpHYi94xeK8Z+fduOO3k0xulsyJIiReGnT/wYAPDSoBaaMUndvHrtQDKNJUnWVVZjMWLLnPHqlxiqTZ8rLrjyQhQn9m+Ncfhmu+9863NErRZWldMWv6Wfx9tJDeGhQCyzcdgbj+jTFHU5mHbe3aOdZBOg0uK5LsnKbySxh8Z7zuLJ1nNNpJLafysO/F+7GS9d3wJC2CdAbTXhqQTqW7s2ERqNBTFgQcor1mDmmG0Z3bwyTWcLV769BkE6LJf8aqGznH7eexozlh/HksNZKW3/afgZ7zxZg6nUdlOXMZgmfrz2OrScvIj4iGPf2S0XbpAicLyjDD5szcP/AFspAhupsPZmHuAbBVY4OPZpdhNCgAJdHoGbklmLJ3vOY0D9VCd5lQ99bjeM5JVj/7FXILtLjuf/bjS5NovD4Va1V37H8UgMqTJIqa2Y2S3ht8X6EBOqQU6THhmO5WPhwGoIDtJi54gg2Hc9Fp8ZReH9MN5fa6aqaHL8Z3BAR1SMfrjyCxbvP4+v7ers0AaerTGbJaQbJH5RXmGAySwjUaZFVWI4mMaFKJq/CZIZWo/HbdautU7klyC7SKxkzd6uLzwuDmyowuCEiIvI/NTl++8Q8N7NmzUJqaipCQkLQp08fbNmypcrlFy5ciHbt2iEkJASdO3fGkiVLPNRSIiIi8nVeD24WLFiAyZMnY9q0adixYwe6du2KESNGIDvb+TVNNmzYgLFjx+L+++/Hzp07MXr0aIwePRp79+51ujwRERFdXrzeLdWnTx/06tULH330EQDAbDYjJSUFjz/+OJ577jmH5ceMGYOSkhL88ccfym19+/ZFt27dMHv27Gpfj91SRERE/sdvuqUMBgO2b9+OYcOGKbdptVoMGzYMGzdudPqYjRs3qpYHgBEjRlS6vF6vR2FhoeqHiIiI6i+vBjc5OTkwmUxITExU3Z6YmIjMzEynj8nMzKzR8tOnT0dUVJTyk5KS4p7GExERkU/yes1NXZsyZQoKCgqUn9OnHWcEJSIiovrDqzMUx8XFQafTISsrS3V7VlYWkpKcz76alJRUo+WDg4MRHOy9KaCJiIjIs7yauQkKCkKPHj2wcuVK5Taz2YyVK1ciLS3N6WPS0tJUywPA8uXLK12eiIiILi9ev7bU5MmTMX78ePTs2RO9e/fGzJkzUVJSggkTJgAA7rnnHjRu3BjTp08HADzxxBMYNGgQ3nvvPVx77bWYP38+tm3bhs8++8ybq0FEREQ+wuvBzZgxY3DhwgVMnToVmZmZ6NatG5YuXaoUDWdkZEBrc7n4fv364fvvv8eLL76I559/Hq1bt8aiRYvQqVMnb60CERER+RCvz3PjaZznhoiIyP/4zTw3RERERO7G4IaIiIjqFQY3REREVK94vaDY0+QSI16GgYiIyH/Ix21XSoUvu+CmqKgIAHgZBiIiIj9UVFSEqKioKpe57EZLmc1mnDt3DhEREdBoNG573sLCQqSkpOD06dP1chRWfV8/oP6vY31fP6D+r2N9Xz+g/q9jfV8/oO7WUZIkFBUVITk5WTVFjDOXXeZGq9WiSZMmdfb8kZGR9fYDC9T/9QPq/zrW9/UD6v861vf1A+r/Otb39QPqZh2ry9jIWFBMRERE9QqDGyIiIqpXGNy4SXBwMKZNm1Zvr0Be39cPqP/rWN/XD6j/61jf1w+o/+tY39cP8I11vOwKiomIiKh+Y+aGiIiI6hUGN0RERFSvMLghIiKieoXBDREREdUrDG7cYNasWUhNTUVISAj69OmDLVu2eLtJtfbyyy9Do9Goftq1a6fcX15ejkmTJqFhw4Zo0KABbrnlFmRlZXmxxVX7559/cP311yM5ORkajQaLFi1S3S9JEqZOnYpGjRohNDQUw4YNw5EjR1TL5OXlYdy4cYiMjER0dDTuv/9+FBcXe3AtqlbdOt57770O23TkyJGqZXx5HadPn45evXohIiICCQkJGD16NA4dOqRaxpXPZUZGBq699lqEhYUhISEB//73v2E0Gj25Kk65sn6DBw922IYPP/ywahlfXT8A+OSTT9ClSxdlUre0tDT8+eefyv3+vP2A6tfP37efvbfeegsajQZPPvmkcpvPbUOJLsn8+fOloKAgae7cudK+ffukiRMnStHR0VJWVpa3m1Yr06ZNkzp27CidP39e+blw4YJy/8MPPyylpKRIK1eulLZt2yb17dtX6tevnxdbXLUlS5ZIL7zwgvTzzz9LAKRffvlFdf9bb70lRUVFSYsWLZJ27dol3XDDDVLz5s2lsrIyZZmRI0dKXbt2lTZt2iStXbtWatWqlTR27FgPr0nlqlvH8ePHSyNHjlRt07y8PNUyvryOI0aMkL788ktp7969Unp6unTNNddITZs2lYqLi5VlqvtcGo1GqVOnTtKwYcOknTt3SkuWLJHi4uKkKVOmeGOVVFxZv0GDBkkTJ05UbcOCggLlfl9eP0mSpN9++01avHixdPjwYenQoUPS888/LwUGBkp79+6VJMm/t58kVb9+/r79bG3ZskVKTU2VunTpIj3xxBPK7b62DRncXKLevXtLkyZNUv43mUxScnKyNH36dC+2qvamTZsmde3a1el9+fn5UmBgoLRw4ULltgMHDkgApI0bN3qohbVnf+A3m81SUlKS9M477yi35efnS8HBwdIPP/wgSZIk7d+/XwIgbd26VVnmzz//lDQajXT27FmPtd1VlQU3N954Y6WP8bd1zM7OlgBIa9askSTJtc/lkiVLJK1WK2VmZirLfPLJJ1JkZKSk1+s9uwLVsF8/SRIHR9sDiT1/Wj9ZTEyMNGfOnHq3/WTy+klS/dl+RUVFUuvWraXly5er1skXtyG7pS6BwWDA9u3bMWzYMOU2rVaLYcOGYePGjV5s2aU5cuQIkpOT0aJFC4wbNw4ZGRkAgO3bt6OiokK1vu3atUPTpk39cn1PnDiBzMxM1fpERUWhT58+yvps3LgR0dHR6Nmzp7LMsGHDoNVqsXnzZo+3ubZWr16NhIQEtG3bFo888ghyc3OV+/xtHQsKCgAAsbGxAFz7XG7cuBGdO3dGYmKissyIESNQWFiIffv2ebD11bNfP9m8efMQFxeHTp06YcqUKSgtLVXu86f1M5lMmD9/PkpKSpCWllbvtp/9+snqw/abNGkSrr32WtW2AnzzO3jZXTjTnXJycmAymVQbCwASExNx8OBBL7Xq0vTp0wdfffUV2rZti/Pnz+OVV17BwIEDsXfvXmRmZiIoKAjR0dGqxyQmJiIzM9M7Db4EcpudbT/5vszMTCQkJKjuDwgIQGxsrN+s88iRI3HzzTejefPmOHbsGJ5//nmMGjUKGzduhE6n86t1NJvNePLJJ9G/f3906tQJAFz6XGZmZjrdzvJ9vsLZ+gHAnXfeiWbNmiE5ORm7d+/Gs88+i0OHDuHnn38G4B/rt2fPHqSlpaG8vBwNGjTAL7/8gg4dOiA9Pb1ebL/K1g+oH9tv/vz52LFjB7Zu3epwny9+BxnckMqoUaOUv7t06YI+ffqgWbNm+PHHHxEaGurFllFt3XHHHcrfnTt3RpcuXdCyZUusXr0aQ4cO9WLLam7SpEnYu3cv1q1b5+2m1InK1u/BBx9U/u7cuTMaNWqEoUOH4tixY2jZsqWnm1krbdu2RXp6OgoKCvDTTz9h/PjxWLNmjbeb5TaVrV+HDh38fvudPn0aTzzxBJYvX46QkBBvN8cl7Ja6BHFxcdDpdA4V4VlZWUhKSvJSq9wrOjoabdq0wdGjR5GUlASDwYD8/HzVMv66vnKbq9p+SUlJyM7OVt1vNBqRl5fnl+sMAC1atEBcXByOHj0KwH/W8bHHHsMff/yBVatWoUmTJsrtrnwuk5KSnG5n+T5fUNn6OdOnTx8AUG1DX1+/oKAgtGrVCj169MD06dPRtWtXfPDBB/Vm+1W2fs742/bbvn07srOzccUVVyAgIAABAQFYs2YNPvzwQwQEBCAxMdHntiGDm0sQFBSEHj16YOXKlcptZrMZK1euVPW1+rPi4mIcO3YMjRo1Qo8ePRAYGKha30OHDiEjI8Mv17d58+ZISkpSrU9hYSE2b96srE9aWhry8/Oxfft2ZZm///4bZrNZ2UH5mzNnziA3NxeNGjUC4PvrKEkSHnvsMfzyyy/4+++/0bx5c9X9rnwu09LSsGfPHlUQt3z5ckRGRipdB95S3fo5k56eDgCqbeir61cZs9kMvV7v99uvMvL6OeNv22/o0KHYs2cP0tPTlZ+ePXti3Lhxyt8+tw3dXqJ8mZk/f74UHBwsffXVV9L+/fulBx98UIqOjlZVhPuTp59+Wlq9erV04sQJaf369dKwYcOkuLg4KTs7W5IkMdyvadOm0t9//y1t27ZNSktLk9LS0rzc6soVFRVJO3fulHbu3CkBkGbMmCHt3LlTOnXqlCRJYih4dHS09Ouvv0q7d++WbrzxRqdDwbt37y5t3rxZWrdundS6dWufGSYtSVWvY1FRkfTMM89IGzdulE6cOCGtWLFCuuKKK6TWrVtL5eXlynP48jo+8sgjUlRUlLR69WrVUNrS0lJlmeo+l/Iw1OHDh0vp6enS0qVLpfj4eJ8Yalvd+h09elR69dVXpW3btkknTpyQfv31V6lFixbSlVdeqTyHL6+fJEnSc889J61Zs0Y6ceKEtHv3bum5556TNBqN9Ndff0mS5N/bT5KqXr/6sP2csR8B5mvbkMGNG/zvf/+TmjZtKgUFBUm9e/eWNm3a5O0m1dqYMWOkRo0aSUFBQVLjxo2lMWPGSEePHlXuLysrkx599FEpJiZGCgsLk2666Sbp/PnzXmxx1VatWiUBcPgZP368JEliOPhLL70kJSYmSsHBwdLQoUOlQ4cOqZ4jNzdXGjt2rNSgQQMpMjJSmjBhglRUVOSFtXGuqnUsLS2Vhg8fLsXHx0uBgYFSs2bNpIkTJzoE3768js7WDYD05ZdfKsu48rk8efKkNGrUKCk0NFSKi4uTnn76aamiosLDa+OouvXLyMiQrrzySik2NlYKDg6WWrVqJf373/9WzZMiSb67fpIkSffdd5/UrFkzKSgoSIqPj5eGDh2qBDaS5N/bT5KqXr/6sP2csQ9ufG0baiRJktyfDyIiIiLyDtbcEBERUb3C4IaIiIjqFQY3REREVK8wuCEiIqJ6hcENERER1SsMboiIiKheYXBDRERE9QqDGyK67Gk0GixatMjbzSAiN2FwQ0Rede+990Kj0Tj8jBw50ttNIyI/FeDtBhARjRw5El9++aXqtuDgYC+1hoj8HTM3ROR1wcHBSEpKUv3ExMQAEF1Gn3zyCUaNGoXQ0FC0aNECP/30k+rxe/bswVVXXYXQ0FA0bNgQDz74IIqLi1XLzJ07Fx07dkRwcDAaNWqExx57THV/Tk4ObrrpJoSFhaF169b47bff6naliajOMLghIp/30ksv4ZZbbsGuXbswbtw43HHHHThw4AAAoKSkBCNGjEBMTAy2bt2KhQsXYsWKFarg5ZNPPsGkSZPw4IMPYs+ePfjtt9/QqlUr1Wu88soruP3227F7925cc801GDduHPLy8jy6nkTkJnVyOU4iIheNHz9e0ul0Unh4uOrnjTfekCRJXDX74YcfVj2mT58+0iOPPCJJkiR99tlnUkxMjFRcXKzcv3jxYkmr1SpXP09OTpZeeOGFStsAQHrxxReV/4uLiyUA0p9//um29SQiz2HNDRF53ZAhQ/DJJ5+obouNjVX+TktLU92XlpaG9PR0AMCBAwfQtWtXhIeHK/f3798fZrMZhw4dgkajwblz5zB06NAq29ClSxfl7/DwcERGRiI7O7u2q0REXsTghoi8Ljw83KGbyF1CQ0NdWi4wMFD1v0ajgdlsrosmEVEdY80NEfm8TZs2Ofzfvn17AED79u2xa9culJSUKPevX78eWq0Wbdu2RUREBFJTU7Fy5UqPtpmIvIeZGyLyOr1ej8zMTNVtAQEBiIuLAwAsXLgQPXv2xIABAzBv3jxs2bIFX3zxBQBg3LhxmDZtGsaPH4+XX34ZFy5cwOOPP467774biYmJAICXX34ZDz/8MBISEjBq1CgUFRVh/fr1ePzxxz27okTkEQxuiMjrli5dikaNGqlua9u2LQ4ePAhAjGSaP38+Hn30UTRq1Ag//PADOnToAAAICwvDsmXL8MQTT6BXr14ICwvDLbfcghkzZijPNX78eJSXl+P999/HM888g7i4ONx6662eW0Ei8iiNJEmStxtBRFQZjUaDX375BaNHj/Z2U4jIT7DmhoiIiOoVBjdERERUr7Dmhoh8GnvOiaimmLkhIiKieoXBDREREdUrDG6IiIioXmFwQ0RERPUKgxsiIiKqVxjcEBERUb3C4IaIiIjqFQY3REREVK8wuCEiIqJ65f8BQB3Dyw5mSCkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(train_eva_df,'Train','Epoch','Loss',['loss','accuracy'])\n",
    "plot_graph(test_eva_df,'Test','Epoch','Loss',['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8db1e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999483227729797"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eva_df['accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7560c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss          0\n",
       "accuracy    382\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eva_df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd060757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9954535961151123"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eva_df['accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9601cff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss          0\n",
       "accuracy    313\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eva_df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f71d4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
