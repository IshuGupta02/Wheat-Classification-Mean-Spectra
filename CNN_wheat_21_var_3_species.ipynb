{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c4fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b98a174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6aebd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'wheat_21_var_3_species.csv'\n",
    "\n",
    "def dir(file_name):\n",
    "    return '../data/'+file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a19daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_X_Y(dataframe):\n",
    "    return (dataframe.drop('classes', axis =1), dataframe.loc[:,'classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "554bc6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class filter_method(Enum):\n",
    "    none = 0\n",
    "    snv = 1\n",
    "    msc = 2\n",
    "    savgol = 3\n",
    "\n",
    "FILT = 1\n",
    "FILTER = filter_method(FILT).name\n",
    "\n",
    "# to be set if filter chosen is savgol\n",
    "WINDOW = 7\n",
    "ORDER = 2\n",
    "DERIVATIVE = 1\n",
    "\n",
    "#will be used for test dataset in msc\n",
    "reference= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c20231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def create_test_train(X, y, test_size = 0.2, shuffle = True):\n",
    "    return train_test_split(X,y, test_size = test_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e9301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Normal Variate\n",
    "def snv(input_data):\n",
    "  \n",
    "    # Define a new array and populate it with the corrected data  \n",
    "    output_data = np.zeros_like(input_data)\n",
    "    for i in range(input_data.shape[0]):\n",
    " \n",
    "        # Apply correction\n",
    "        output_data[i,:] = (input_data[i,:] - np.mean(input_data[i,:])) / np.std(input_data[i,:])\n",
    " \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d925acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicative scatter correction\n",
    "def msc(input_data, reference=None):\n",
    "#     print(reference)\n",
    "    ''' Perform Multiplicative scatter correction'''\n",
    "\n",
    "    # Baseline correction\n",
    "    for i in range(input_data.shape[0]):\n",
    "        input_data[i,:] -= input_data[i,:].mean()\n",
    "\n",
    "    # Get the reference spectrum. If not given, estimate from the mean    \n",
    "    if reference is None:    \n",
    "        # Calculate mean\n",
    "        matm = np.mean(input_data, axis=0)\n",
    "    else:\n",
    "        matm = reference\n",
    "\n",
    "    # Define a new data matrix and populate it with the corrected data    \n",
    "    output_data = np.zeros_like(input_data)\n",
    "    for i in range(input_data.shape[0]):\n",
    "        # Run regression\n",
    "        fit = np.polyfit(matm, input_data[i,:], 1, full=True)\n",
    "        # Apply correction\n",
    "        output_data[i,:] = (input_data[i,:] - fit[0][1]) / fit[0][0] \n",
    "\n",
    "    return (output_data, matm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b5090be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter, general_gaussian\n",
    "def savgol(input_data):\n",
    "    w = WINDOW\n",
    "    p = ORDER\n",
    "    d = DERIVATIVE\n",
    "    \n",
    "    output_data = savgol_filter(np.array(input_data), w, polyorder = p, deriv=d)\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b68affd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X,y, type=\"train\"):\n",
    "    if FILTER == \"snv\":\n",
    "        return {\"X\": snv(np.array(X)), \"y\": y}\n",
    "    elif FILTER == \"msc\":\n",
    "        msc_output = msc(np.array(X), reference = reference if type==\"test\" else None)\n",
    "        X = msc_output[0]\n",
    "        ref = msc_output[1]\n",
    "        return {\n",
    "            \"X\": X,\n",
    "            \"y\": y,\n",
    "            \"ref\": ref\n",
    "        }\n",
    "    elif FILTER == \"savgol\":\n",
    "        return {\n",
    "            \"X\": savgol(X),\n",
    "            \"y\": y\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"X\":X,\n",
    "            \"y\":y\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8dec1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(dir(file_name))\n",
    "X,y = seperate_X_Y(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03e24565",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_set = set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e8c8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_CLASSES = len(y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e545c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = create_test_train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f79eb839",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_results = preprocess_data(X_train_raw,y_train_raw)\n",
    "X_train, y_train = preprocessed_results[\"X\"], preprocessed_results[\"y\"]\n",
    "\n",
    "if FILTER == \"msc\":\n",
    "    reference = preprocessed_results[\"ref\"]\n",
    "    \n",
    "preprocessed_results_test = preprocess_data(X_test_raw, y_test_raw, type=\"test\")\n",
    "X_test, y_test = preprocessed_results_test[\"X\"], preprocessed_results_test[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89f78cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33868, 147, 1)\n",
      "(8468, 147, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55a78e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Input, Conv1D, Flatten, Dense, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba682707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(input_shape,num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=5, input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=5 ))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6a3400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(X_train.shape[1:],NUM_OF_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2a7d43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 143, 32)           192       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 28, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 896)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              897000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 3003      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 900,195\n",
      "Trainable params: 900,195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34d6bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva = []\n",
    "test_eva = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fd5eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dataframe = pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "863f63f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  1\n",
      "2117/2117 - 29s - loss: 0.8709 - accuracy: 0.5744 - 29s/epoch - 14ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.5459 - accuracy: 0.7690\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.5400 - accuracy: 0.7722\n",
      "\n",
      "Epoch:  2\n",
      "2117/2117 - 26s - loss: 0.4424 - accuracy: 0.8173 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.3211 - accuracy: 0.8781\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.3173 - accuracy: 0.8781\n",
      "\n",
      "Epoch:  3\n",
      "2117/2117 - 26s - loss: 0.2879 - accuracy: 0.8888 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2352 - accuracy: 0.9114\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.2333 - accuracy: 0.9118\n",
      "\n",
      "Epoch:  4\n",
      "2117/2117 - 27s - loss: 0.2423 - accuracy: 0.9060 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2069 - accuracy: 0.9218\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9219\n",
      "\n",
      "Epoch:  5\n",
      "2117/2117 - 26s - loss: 0.2191 - accuracy: 0.9156 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1818 - accuracy: 0.9321\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1799 - accuracy: 0.9312\n",
      "\n",
      "Epoch:  6\n",
      "2117/2117 - 26s - loss: 0.1982 - accuracy: 0.9236 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1695 - accuracy: 0.9360\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1695 - accuracy: 0.9333\n",
      "\n",
      "Epoch:  7\n",
      "2117/2117 - 26s - loss: 0.1846 - accuracy: 0.9280 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1467 - accuracy: 0.9467\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1447 - accuracy: 0.9467\n",
      "\n",
      "Epoch:  8\n",
      "2117/2117 - 26s - loss: 0.1734 - accuracy: 0.9326 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1617 - accuracy: 0.9383\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1631 - accuracy: 0.9355\n",
      "\n",
      "Epoch:  9\n",
      "2117/2117 - 26s - loss: 0.1672 - accuracy: 0.9360 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1237 - accuracy: 0.9567\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1225 - accuracy: 0.9562\n",
      "\n",
      "Epoch:  10\n",
      "2117/2117 - 26s - loss: 0.1541 - accuracy: 0.9418 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1595 - accuracy: 0.9373\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1580 - accuracy: 0.9369\n",
      "\n",
      "Epoch:  11\n",
      "2117/2117 - 26s - loss: 0.1485 - accuracy: 0.9430 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1446 - accuracy: 0.9429\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1458 - accuracy: 0.9444\n",
      "\n",
      "Epoch:  12\n",
      "2117/2117 - 28s - loss: 0.1376 - accuracy: 0.9474 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1026 - accuracy: 0.9641\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1039 - accuracy: 0.9620\n",
      "\n",
      "Epoch:  13\n",
      "2117/2117 - 26s - loss: 0.1299 - accuracy: 0.9507 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1181 - accuracy: 0.9561\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1165 - accuracy: 0.9563\n",
      "\n",
      "Epoch:  14\n",
      "2117/2117 - 27s - loss: 0.1329 - accuracy: 0.9487 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1686 - accuracy: 0.9305\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1737 - accuracy: 0.9316\n",
      "\n",
      "Epoch:  15\n",
      "2117/2117 - 26s - loss: 0.1193 - accuracy: 0.9551 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0983 - accuracy: 0.9657\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1010 - accuracy: 0.9656\n",
      "\n",
      "Epoch:  16\n",
      "2117/2117 - 26s - loss: 0.1090 - accuracy: 0.9596 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0802 - accuracy: 0.9720\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0831 - accuracy: 0.9708\n",
      "\n",
      "Epoch:  17\n",
      "2117/2117 - 26s - loss: 0.1064 - accuracy: 0.9602 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1191 - accuracy: 0.9548\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1220 - accuracy: 0.9537\n",
      "\n",
      "Epoch:  18\n",
      "2117/2117 - 26s - loss: 0.1052 - accuracy: 0.9604 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0648 - accuracy: 0.9780\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0665 - accuracy: 0.9771\n",
      "\n",
      "Epoch:  19\n",
      "2117/2117 - 26s - loss: 0.0975 - accuracy: 0.9636 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0773 - accuracy: 0.9708\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0823 - accuracy: 0.9689\n",
      "\n",
      "Epoch:  20\n",
      "2117/2117 - 26s - loss: 0.0925 - accuracy: 0.9656 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0715 - accuracy: 0.9750\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0759 - accuracy: 0.9740\n",
      "\n",
      "Epoch:  21\n",
      "2117/2117 - 26s - loss: 0.0868 - accuracy: 0.9683 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0706 - accuracy: 0.9756\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0708 - accuracy: 0.9756\n",
      "\n",
      "Epoch:  22\n",
      "2117/2117 - 26s - loss: 0.0826 - accuracy: 0.9701 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0720 - accuracy: 0.9732\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0725 - accuracy: 0.9747\n",
      "\n",
      "Epoch:  23\n",
      "2117/2117 - 27s - loss: 0.0774 - accuracy: 0.9713 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0702 - accuracy: 0.9746\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0741 - accuracy: 0.9744\n",
      "\n",
      "Epoch:  24\n",
      "2117/2117 - 26s - loss: 0.0807 - accuracy: 0.9694 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1392 - accuracy: 0.9456\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1334 - accuracy: 0.9492\n",
      "\n",
      "Epoch:  25\n",
      "2117/2117 - 26s - loss: 0.0739 - accuracy: 0.9730 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1535 - accuracy: 0.9368\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1512 - accuracy: 0.9384\n",
      "\n",
      "Epoch:  26\n",
      "2117/2117 - 26s - loss: 0.0733 - accuracy: 0.9736 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0490 - accuracy: 0.9833\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0539 - accuracy: 0.9836\n",
      "\n",
      "Epoch:  27\n",
      "2117/2117 - 26s - loss: 0.0692 - accuracy: 0.9742 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0469 - accuracy: 0.9846\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0504 - accuracy: 0.9831\n",
      "\n",
      "Epoch:  28\n",
      "2117/2117 - 26s - loss: 0.0671 - accuracy: 0.9751 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1784 - accuracy: 0.9288\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1688 - accuracy: 0.9339\n",
      "\n",
      "Epoch:  29\n",
      "2117/2117 - 27s - loss: 0.0712 - accuracy: 0.9741 - 27s/epoch - 13ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1005 - accuracy: 0.9610\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0980 - accuracy: 0.9633\n",
      "\n",
      "Epoch:  30\n",
      "2117/2117 - 26s - loss: 0.0624 - accuracy: 0.9776 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0456 - accuracy: 0.9848\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0515 - accuracy: 0.9817\n",
      "\n",
      "Epoch:  31\n",
      "2117/2117 - 26s - loss: 0.0641 - accuracy: 0.9771 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0509 - accuracy: 0.9806\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0547 - accuracy: 0.9808\n",
      "\n",
      "Epoch:  32\n",
      "2117/2117 - 26s - loss: 0.0603 - accuracy: 0.9780 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0737 - accuracy: 0.9743\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0807 - accuracy: 0.9733\n",
      "\n",
      "Epoch:  33\n",
      "2117/2117 - 27s - loss: 0.0574 - accuracy: 0.9791 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0995 - accuracy: 0.9630\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0995 - accuracy: 0.9648\n",
      "\n",
      "Epoch:  34\n",
      "2117/2117 - 26s - loss: 0.0567 - accuracy: 0.9789 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0805 - accuracy: 0.9705\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0871 - accuracy: 0.9702\n",
      "\n",
      "Epoch:  35\n",
      "2117/2117 - 26s - loss: 0.0548 - accuracy: 0.9801 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0626 - accuracy: 0.9764\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0639 - accuracy: 0.9789\n",
      "\n",
      "Epoch:  36\n",
      "2117/2117 - 27s - loss: 0.0557 - accuracy: 0.9789 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0945 - accuracy: 0.9652\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0992 - accuracy: 0.9637\n",
      "\n",
      "Epoch:  37\n",
      "2117/2117 - 25s - loss: 0.0523 - accuracy: 0.9816 - 25s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0433 - accuracy: 0.9846\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0487 - accuracy: 0.9855\n",
      "\n",
      "Epoch:  38\n",
      "2117/2117 - 25s - loss: 0.0541 - accuracy: 0.9804 - 25s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0278 - accuracy: 0.9914\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0326 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  39\n",
      "2117/2117 - 26s - loss: 0.0512 - accuracy: 0.9816 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0475 - accuracy: 0.9825\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0553 - accuracy: 0.9800\n",
      "\n",
      "Epoch:  40\n",
      "2117/2117 - 26s - loss: 0.0486 - accuracy: 0.9816 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0738 - accuracy: 0.9720\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0783 - accuracy: 0.9727\n",
      "\n",
      "Epoch:  41\n",
      "2117/2117 - 26s - loss: 0.0510 - accuracy: 0.9808 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0395 - accuracy: 0.9856\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0464 - accuracy: 0.9829\n",
      "\n",
      "Epoch:  42\n",
      "2117/2117 - 27s - loss: 0.0524 - accuracy: 0.9811 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0385 - accuracy: 0.9865\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0425 - accuracy: 0.9862\n",
      "\n",
      "Epoch:  43\n",
      "2117/2117 - 26s - loss: 0.0476 - accuracy: 0.9824 - 26s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0466 - accuracy: 0.9833\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0492 - accuracy: 0.9824\n",
      "\n",
      "Epoch:  44\n",
      "2117/2117 - 26s - loss: 0.0505 - accuracy: 0.9815 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0374 - accuracy: 0.9870\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0446 - accuracy: 0.9855\n",
      "\n",
      "Epoch:  45\n",
      "2117/2117 - 27s - loss: 0.0482 - accuracy: 0.9824 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0805 - accuracy: 0.9682\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0800 - accuracy: 0.9689\n",
      "\n",
      "Epoch:  46\n",
      "2117/2117 - 26s - loss: 0.0486 - accuracy: 0.9827 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0257 - accuracy: 0.9915\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0335 - accuracy: 0.9887\n",
      "\n",
      "Epoch:  47\n",
      "2117/2117 - 26s - loss: 0.0467 - accuracy: 0.9829 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1206 - accuracy: 0.9556\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1259 - accuracy: 0.9558\n",
      "\n",
      "Epoch:  48\n",
      "2117/2117 - 26s - loss: 0.0459 - accuracy: 0.9833 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0386 - accuracy: 0.9863\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0467 - accuracy: 0.9837\n",
      "\n",
      "Epoch:  49\n",
      "2117/2117 - 26s - loss: 0.0493 - accuracy: 0.9818 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0274 - accuracy: 0.9905\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0344 - accuracy: 0.9889\n",
      "\n",
      "Epoch:  50\n",
      "2117/2117 - 26s - loss: 0.0415 - accuracy: 0.9855 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0453 - accuracy: 0.9835\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0513 - accuracy: 0.9826\n",
      "\n",
      "Epoch:  51\n",
      "2117/2117 - 27s - loss: 0.0457 - accuracy: 0.9836 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0234 - accuracy: 0.9921\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  52\n",
      "2117/2117 - 26s - loss: 0.0420 - accuracy: 0.9840 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0437 - accuracy: 0.9842\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0521 - accuracy: 0.9832\n",
      "\n",
      "Epoch:  53\n",
      "2117/2117 - 26s - loss: 0.0447 - accuracy: 0.9837 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0692 - accuracy: 0.9728\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0778 - accuracy: 0.9715\n",
      "\n",
      "Epoch:  54\n",
      "2117/2117 - 26s - loss: 0.0422 - accuracy: 0.9845 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0224 - accuracy: 0.9927\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0313 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  55\n",
      "2117/2117 - 26s - loss: 0.0429 - accuracy: 0.9840 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0758 - accuracy: 0.9707\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0826 - accuracy: 0.9711\n",
      "\n",
      "Epoch:  56\n",
      "2117/2117 - 27s - loss: 0.0402 - accuracy: 0.9857 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0314 - accuracy: 0.9885\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0405 - accuracy: 0.9865\n",
      "\n",
      "Epoch:  57\n",
      "2117/2117 - 26s - loss: 0.0404 - accuracy: 0.9851 - 26s/epoch - 12ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0301 - accuracy: 0.9897\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0351 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  58\n",
      "2117/2117 - 28s - loss: 0.0378 - accuracy: 0.9864 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0255 - accuracy: 0.9916\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0316 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  59\n",
      "2117/2117 - 26s - loss: 0.0410 - accuracy: 0.9849 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0383 - accuracy: 0.9855\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0473 - accuracy: 0.9831\n",
      "\n",
      "Epoch:  60\n",
      "2117/2117 - 26s - loss: 0.0375 - accuracy: 0.9863 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1200 - accuracy: 0.9552\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1275 - accuracy: 0.9562\n",
      "\n",
      "Epoch:  61\n",
      "2117/2117 - 27s - loss: 0.0375 - accuracy: 0.9864 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0243 - accuracy: 0.9919\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0312 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  62\n",
      "2117/2117 - 26s - loss: 0.0375 - accuracy: 0.9859 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0449 - accuracy: 0.9835\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0549 - accuracy: 0.9810\n",
      "\n",
      "Epoch:  63\n",
      "2117/2117 - 26s - loss: 0.0407 - accuracy: 0.9846 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0208 - accuracy: 0.9929\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0286 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  64\n",
      "2117/2117 - 26s - loss: 0.0370 - accuracy: 0.9869 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0283 - accuracy: 0.9895\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0355 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  65\n",
      "2117/2117 - 26s - loss: 0.0362 - accuracy: 0.9866 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0298 - accuracy: 0.9890\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0398 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  66\n",
      "2117/2117 - 26s - loss: 0.0365 - accuracy: 0.9865 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0235 - accuracy: 0.9917\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0327 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  67\n",
      "2117/2117 - 27s - loss: 0.0365 - accuracy: 0.9865 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0191 - accuracy: 0.9938\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0283 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  68\n",
      "2117/2117 - 26s - loss: 0.0353 - accuracy: 0.9871 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0320 - accuracy: 0.9879\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0425 - accuracy: 0.9857\n",
      "\n",
      "Epoch:  69\n",
      "2117/2117 - 26s - loss: 0.0364 - accuracy: 0.9866 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0181 - accuracy: 0.9937\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0273 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  70\n",
      "2117/2117 - 26s - loss: 0.0337 - accuracy: 0.9880 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0229 - accuracy: 0.9916\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0332 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  71\n",
      "2117/2117 - 27s - loss: 0.0349 - accuracy: 0.9874 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0279 - accuracy: 0.9900\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0325 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  72\n",
      "2117/2117 - 26s - loss: 0.0356 - accuracy: 0.9872 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0428 - accuracy: 0.9836\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0545 - accuracy: 0.9816\n",
      "\n",
      "Epoch:  73\n",
      "2117/2117 - 26s - loss: 0.0375 - accuracy: 0.9860 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0390 - accuracy: 0.9856\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0493 - accuracy: 0.9823\n",
      "\n",
      "Epoch:  74\n",
      "2117/2117 - 26s - loss: 0.0316 - accuracy: 0.9882 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0270 - accuracy: 0.9896\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0378 - accuracy: 0.9867\n",
      "\n",
      "Epoch:  75\n",
      "2117/2117 - 26s - loss: 0.0340 - accuracy: 0.9867 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0225 - accuracy: 0.9916\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0320 - accuracy: 0.9902\n",
      "\n",
      "Epoch:  76\n",
      "2117/2117 - 26s - loss: 0.0343 - accuracy: 0.9878 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0218 - accuracy: 0.9920\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  77\n",
      "2117/2117 - 26s - loss: 0.0313 - accuracy: 0.9887 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0690 - accuracy: 0.9737\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0746 - accuracy: 0.9724\n",
      "\n",
      "Epoch:  78\n",
      "2117/2117 - 26s - loss: 0.0324 - accuracy: 0.9880 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0243 - accuracy: 0.9913\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0343 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  79\n",
      "2117/2117 - 26s - loss: 0.0352 - accuracy: 0.9868 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0606 - accuracy: 0.9773\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0719 - accuracy: 0.9761\n",
      "\n",
      "Epoch:  80\n",
      "2117/2117 - 27s - loss: 0.0315 - accuracy: 0.9889 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0197 - accuracy: 0.9936\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  81\n",
      "2117/2117 - 26s - loss: 0.0329 - accuracy: 0.9878 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0265 - accuracy: 0.9902\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0366 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  82\n",
      "2117/2117 - 26s - loss: 0.0282 - accuracy: 0.9908 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0152 - accuracy: 0.9949\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0246 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  83\n",
      "2117/2117 - 26s - loss: 0.0337 - accuracy: 0.9885 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0225 - accuracy: 0.9920\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0348 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  84\n",
      "2117/2117 - 26s - loss: 0.0282 - accuracy: 0.9902 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0334 - accuracy: 0.9876\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9851\n",
      "\n",
      "Epoch:  85\n",
      "2117/2117 - 26s - loss: 0.0287 - accuracy: 0.9892 - 26s/epoch - 12ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0284 - accuracy: 0.9888\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0369 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  86\n",
      "2117/2117 - 26s - loss: 0.0325 - accuracy: 0.9882 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0223 - accuracy: 0.9919\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0336 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  87\n",
      "2117/2117 - 26s - loss: 0.0289 - accuracy: 0.9894 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0406 - accuracy: 0.9859\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0530 - accuracy: 0.9835\n",
      "\n",
      "Epoch:  88\n",
      "2117/2117 - 28s - loss: 0.0292 - accuracy: 0.9887 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0317 - accuracy: 0.9889\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0381 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  89\n",
      "2117/2117 - 26s - loss: 0.0299 - accuracy: 0.9897 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0155 - accuracy: 0.9950\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0257 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  90\n",
      "2117/2117 - 26s - loss: 0.0297 - accuracy: 0.9894 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0153 - accuracy: 0.9947\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0268 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  91\n",
      "2117/2117 - 26s - loss: 0.0282 - accuracy: 0.9902 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0161 - accuracy: 0.9948\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0255 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  92\n",
      "2117/2117 - 26s - loss: 0.0265 - accuracy: 0.9903 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0180 - accuracy: 0.9937\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0266 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  93\n",
      "2117/2117 - 26s - loss: 0.0289 - accuracy: 0.9898 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0162 - accuracy: 0.9947\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0273 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  94\n",
      "2117/2117 - 26s - loss: 0.0270 - accuracy: 0.9903 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0174 - accuracy: 0.9941\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0254 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  95\n",
      "2117/2117 - 26s - loss: 0.0294 - accuracy: 0.9892 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0151 - accuracy: 0.9947\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0277 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  96\n",
      "2117/2117 - 26s - loss: 0.0272 - accuracy: 0.9903 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0608 - accuracy: 0.9760\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0684 - accuracy: 0.9776\n",
      "\n",
      "Epoch:  97\n",
      "2117/2117 - 26s - loss: 0.0272 - accuracy: 0.9898 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0295 - accuracy: 0.9891\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0416 - accuracy: 0.9862\n",
      "\n",
      "Epoch:  98\n",
      "2117/2117 - 26s - loss: 0.0284 - accuracy: 0.9896 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0156 - accuracy: 0.9945\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0273 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  99\n",
      "2117/2117 - 28s - loss: 0.0269 - accuracy: 0.9901 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0275 - accuracy: 0.9895\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0413 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  100\n",
      "2117/2117 - 26s - loss: 0.0273 - accuracy: 0.9903 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0310 - accuracy: 0.9885\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0430 - accuracy: 0.9850\n",
      "\n",
      "Epoch:  101\n",
      "2117/2117 - 26s - loss: 0.0280 - accuracy: 0.9900 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0221 - accuracy: 0.9917\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0348 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  102\n",
      "2117/2117 - 26s - loss: 0.0264 - accuracy: 0.9902 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0257 - accuracy: 0.9902\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0339 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  103\n",
      "2117/2117 - 26s - loss: 0.0276 - accuracy: 0.9902 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0423 - accuracy: 0.9840\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0539 - accuracy: 0.9800\n",
      "\n",
      "Epoch:  104\n",
      "2117/2117 - 26s - loss: 0.0261 - accuracy: 0.9905 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0172 - accuracy: 0.9943\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0296 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  105\n",
      "2117/2117 - 26s - loss: 0.0251 - accuracy: 0.9913 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0205 - accuracy: 0.9922\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0328 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  106\n",
      "2117/2117 - 26s - loss: 0.0271 - accuracy: 0.9904 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0163 - accuracy: 0.9942\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0270 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  107\n",
      "2117/2117 - 26s - loss: 0.0253 - accuracy: 0.9911 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0115 - accuracy: 0.9966\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0229 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  108\n",
      "2117/2117 - 26s - loss: 0.0254 - accuracy: 0.9909 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0147 - accuracy: 0.9946\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0286 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  109\n",
      "2117/2117 - 26s - loss: 0.0269 - accuracy: 0.9902 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0290 - accuracy: 0.9896\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0409 - accuracy: 0.9865\n",
      "\n",
      "Epoch:  110\n",
      "2117/2117 - 28s - loss: 0.0231 - accuracy: 0.9920 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0137 - accuracy: 0.9956\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0270 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  111\n",
      "2117/2117 - 26s - loss: 0.0249 - accuracy: 0.9907 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0683 - accuracy: 0.9755\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0899 - accuracy: 0.9726\n",
      "\n",
      "Epoch:  112\n",
      "2117/2117 - 26s - loss: 0.0238 - accuracy: 0.9916 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0121 - accuracy: 0.9955\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0243 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  113\n",
      "2117/2117 - 26s - loss: 0.0258 - accuracy: 0.9906 - 26s/epoch - 12ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0703 - accuracy: 0.9750\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0809 - accuracy: 0.9744\n",
      "\n",
      "Epoch:  114\n",
      "2117/2117 - 26s - loss: 0.0229 - accuracy: 0.9918 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0304 - accuracy: 0.9888\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0437 - accuracy: 0.9861\n",
      "\n",
      "Epoch:  115\n",
      "2117/2117 - 26s - loss: 0.0231 - accuracy: 0.9914 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0488 - accuracy: 0.9818\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0619 - accuracy: 0.9791\n",
      "\n",
      "Epoch:  116\n",
      "2117/2117 - 26s - loss: 0.0252 - accuracy: 0.9907 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0247 - accuracy: 0.9908\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0335 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  117\n",
      "2117/2117 - 26s - loss: 0.0214 - accuracy: 0.9928 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0150 - accuracy: 0.9949\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0275 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  118\n",
      "2117/2117 - 27s - loss: 0.0262 - accuracy: 0.9900 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0194 - accuracy: 0.9928\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0291 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  119\n",
      "2117/2117 - 26s - loss: 0.0247 - accuracy: 0.9908 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0340 - accuracy: 0.9872\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0430 - accuracy: 0.9850\n",
      "\n",
      "Epoch:  120\n",
      "2117/2117 - 26s - loss: 0.0237 - accuracy: 0.9917 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0138 - accuracy: 0.9950\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0257 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  121\n",
      "2117/2117 - 26s - loss: 0.0222 - accuracy: 0.9920 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0160 - accuracy: 0.9937\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0319 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  122\n",
      "2117/2117 - 27s - loss: 0.0222 - accuracy: 0.9922 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0101 - accuracy: 0.9965\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0230 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  123\n",
      "2117/2117 - 26s - loss: 0.0224 - accuracy: 0.9920 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0298 - accuracy: 0.9894\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9875\n",
      "\n",
      "Epoch:  124\n",
      "2117/2117 - 26s - loss: 0.0252 - accuracy: 0.9908 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0178 - accuracy: 0.9937\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0309 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  125\n",
      "2117/2117 - 26s - loss: 0.0240 - accuracy: 0.9907 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0190 - accuracy: 0.9925\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0339 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  126\n",
      "2117/2117 - 26s - loss: 0.0263 - accuracy: 0.9905 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0114 - accuracy: 0.9961\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0254 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  127\n",
      "2117/2117 - 26s - loss: 0.0219 - accuracy: 0.9922 - 26s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0172 - accuracy: 0.9935\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0353 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  128\n",
      "2117/2117 - 27s - loss: 0.0239 - accuracy: 0.9914 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0128 - accuracy: 0.9954\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0267 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  129\n",
      "2117/2117 - 26s - loss: 0.0188 - accuracy: 0.9924 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0183 - accuracy: 0.9932\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0320 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  130\n",
      "2117/2117 - 26s - loss: 0.0218 - accuracy: 0.9922 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0081 - accuracy: 0.9972\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0210 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  131\n",
      "2117/2117 - 26s - loss: 0.0221 - accuracy: 0.9918 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0399 - accuracy: 0.9856\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0555 - accuracy: 0.9800\n",
      "\n",
      "Epoch:  132\n",
      "2117/2117 - 26s - loss: 0.0238 - accuracy: 0.9912 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0193 - accuracy: 0.9928\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0304 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  133\n",
      "2117/2117 - 26s - loss: 0.0213 - accuracy: 0.9922 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0156 - accuracy: 0.9939\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  134\n",
      "2117/2117 - 26s - loss: 0.0190 - accuracy: 0.9934 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0107 - accuracy: 0.9964\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0243 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  135\n",
      "2117/2117 - 26s - loss: 0.0202 - accuracy: 0.9922 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0159 - accuracy: 0.9939\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0322 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  136\n",
      "2117/2117 - 26s - loss: 0.0205 - accuracy: 0.9922 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0140 - accuracy: 0.9946\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0311 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  137\n",
      "2117/2117 - 27s - loss: 0.0202 - accuracy: 0.9927 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0120 - accuracy: 0.9957\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  138\n",
      "2117/2117 - 26s - loss: 0.0212 - accuracy: 0.9925 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0114 - accuracy: 0.9956\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  139\n",
      "2117/2117 - 26s - loss: 0.0215 - accuracy: 0.9916 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0261 - accuracy: 0.9902\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0342 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  140\n",
      "2117/2117 - 26s - loss: 0.0203 - accuracy: 0.9926 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0154 - accuracy: 0.9945\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0294 - accuracy: 0.9904\n",
      "\n",
      "Epoch:  141\n",
      "2117/2117 - 26s - loss: 0.0211 - accuracy: 0.9924 - 26s/epoch - 12ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0505 - accuracy: 0.9822\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0682 - accuracy: 0.9765\n",
      "\n",
      "Epoch:  142\n",
      "2117/2117 - 26s - loss: 0.0183 - accuracy: 0.9932 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0180 - accuracy: 0.9931\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0334 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  143\n",
      "2117/2117 - 27s - loss: 0.0195 - accuracy: 0.9927 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0129 - accuracy: 0.9953\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0247 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  144\n",
      "2117/2117 - 26s - loss: 0.0209 - accuracy: 0.9922 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0146 - accuracy: 0.9947\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0277 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  145\n",
      "2117/2117 - 26s - loss: 0.0210 - accuracy: 0.9923 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0440 - accuracy: 0.9836\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0604 - accuracy: 0.9813\n",
      "\n",
      "Epoch:  146\n",
      "2117/2117 - 27s - loss: 0.0197 - accuracy: 0.9932 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0217 - accuracy: 0.9917\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0357 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  147\n",
      "2117/2117 - 27s - loss: 0.0196 - accuracy: 0.9932 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0107 - accuracy: 0.9963\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0246 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  148\n",
      "2117/2117 - 26s - loss: 0.0196 - accuracy: 0.9926 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0094 - accuracy: 0.9965\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0231 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  149\n",
      "2117/2117 - 26s - loss: 0.0213 - accuracy: 0.9926 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0147 - accuracy: 0.9942\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0263 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  150\n",
      "2117/2117 - 27s - loss: 0.0194 - accuracy: 0.9931 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0071 - accuracy: 0.9978\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0201 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  151\n",
      "2117/2117 - 26s - loss: 0.0202 - accuracy: 0.9929 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0169 - accuracy: 0.9933\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0311 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  152\n",
      "2117/2117 - 27s - loss: 0.0190 - accuracy: 0.9931 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0093 - accuracy: 0.9970\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0229 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  153\n",
      "2117/2117 - 26s - loss: 0.0228 - accuracy: 0.9921 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0086 - accuracy: 0.9971\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0233 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  154\n",
      "2117/2117 - 26s - loss: 0.0168 - accuracy: 0.9937 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0169 - accuracy: 0.9931\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0287 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  155\n",
      "2117/2117 - 27s - loss: 0.0187 - accuracy: 0.9930 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0108 - accuracy: 0.9957\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0242 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  156\n",
      "2117/2117 - 27s - loss: 0.0190 - accuracy: 0.9934 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0103 - accuracy: 0.9962\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0272 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  157\n",
      "2117/2117 - 26s - loss: 0.0195 - accuracy: 0.9926 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0239 - accuracy: 0.9907\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0396 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  158\n",
      "2117/2117 - 26s - loss: 0.0178 - accuracy: 0.9934 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0155 - accuracy: 0.9939\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0365 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  159\n",
      "2117/2117 - 27s - loss: 0.0173 - accuracy: 0.9939 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0070 - accuracy: 0.9979\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0202 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  160\n",
      "2117/2117 - 26s - loss: 0.0203 - accuracy: 0.9923 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0356 - accuracy: 0.9875\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0499 - accuracy: 0.9848\n",
      "\n",
      "Epoch:  161\n",
      "2117/2117 - 26s - loss: 0.0187 - accuracy: 0.9936 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0373 - accuracy: 0.9856\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0508 - accuracy: 0.9826\n",
      "\n",
      "Epoch:  162\n",
      "2117/2117 - 26s - loss: 0.0209 - accuracy: 0.9928 - 26s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0134 - accuracy: 0.9949\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0333 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  163\n",
      "2117/2117 - 28s - loss: 0.0164 - accuracy: 0.9942 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0139 - accuracy: 0.9944\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0312 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  164\n",
      "2117/2117 - 27s - loss: 0.0188 - accuracy: 0.9930 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0245 - accuracy: 0.9911\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0346 - accuracy: 0.9887\n",
      "\n",
      "Epoch:  165\n",
      "2117/2117 - 27s - loss: 0.0176 - accuracy: 0.9941 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0128 - accuracy: 0.9947\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0343 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  166\n",
      "2117/2117 - 26s - loss: 0.0166 - accuracy: 0.9940 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0073 - accuracy: 0.9977\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0232 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  167\n",
      "2117/2117 - 26s - loss: 0.0193 - accuracy: 0.9929 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0629 - accuracy: 0.9784\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0795 - accuracy: 0.9763\n",
      "\n",
      "Epoch:  168\n",
      "2117/2117 - 27s - loss: 0.0181 - accuracy: 0.9938 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0091 - accuracy: 0.9970\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0229 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  169\n",
      "2117/2117 - 26s - loss: 0.0183 - accuracy: 0.9936 - 26s/epoch - 12ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0074 - accuracy: 0.9976\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0248 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  170\n",
      "2117/2117 - 26s - loss: 0.0174 - accuracy: 0.9934 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0345 - accuracy: 0.9869\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0538 - accuracy: 0.9838\n",
      "\n",
      "Epoch:  171\n",
      "2117/2117 - 27s - loss: 0.0185 - accuracy: 0.9938 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0084 - accuracy: 0.9968\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0261 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  172\n",
      "2117/2117 - 26s - loss: 0.0165 - accuracy: 0.9942 - 26s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0086 - accuracy: 0.9971\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0282 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  173\n",
      "2117/2117 - 26s - loss: 0.0166 - accuracy: 0.9942 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0065 - accuracy: 0.9979\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0227 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  174\n",
      "2117/2117 - 27s - loss: 0.0174 - accuracy: 0.9939 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0380 - accuracy: 0.9869\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0542 - accuracy: 0.9854\n",
      "\n",
      "Epoch:  175\n",
      "2117/2117 - 27s - loss: 0.0135 - accuracy: 0.9950 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0102 - accuracy: 0.9962\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  176\n",
      "2117/2117 - 26s - loss: 0.0167 - accuracy: 0.9942 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0083 - accuracy: 0.9973\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0224 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  177\n",
      "2117/2117 - 26s - loss: 0.0158 - accuracy: 0.9949 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0111 - accuracy: 0.9960\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0276 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  178\n",
      "2117/2117 - 26s - loss: 0.0140 - accuracy: 0.9948 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0140 - accuracy: 0.9946\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0317 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  179\n",
      "2117/2117 - 27s - loss: 0.0168 - accuracy: 0.9941 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0076 - accuracy: 0.9973\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0234 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  180\n",
      "2117/2117 - 26s - loss: 0.0141 - accuracy: 0.9950 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0339 - accuracy: 0.9881\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0560 - accuracy: 0.9862\n",
      "\n",
      "Epoch:  181\n",
      "2117/2117 - 27s - loss: 0.0201 - accuracy: 0.9929 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0089 - accuracy: 0.9965\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0217 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  182\n",
      "2117/2117 - 26s - loss: 0.0138 - accuracy: 0.9951 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0104 - accuracy: 0.9965\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0262 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  183\n",
      "2117/2117 - 26s - loss: 0.0151 - accuracy: 0.9945 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0085 - accuracy: 0.9971\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0234 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  184\n",
      "2117/2117 - 29s - loss: 0.0153 - accuracy: 0.9944 - 29s/epoch - 14ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0089 - accuracy: 0.9966\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0235 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  185\n",
      "2117/2117 - 27s - loss: 0.0164 - accuracy: 0.9939 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0063 - accuracy: 0.9980\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0226 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  186\n",
      "2117/2117 - 27s - loss: 0.0138 - accuracy: 0.9953 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0224 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  187\n",
      "2117/2117 - 26s - loss: 0.0165 - accuracy: 0.9943 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0227 - accuracy: 0.9913\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0385 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  188\n",
      "2117/2117 - 27s - loss: 0.0183 - accuracy: 0.9937 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0063 - accuracy: 0.9979\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0223 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  189\n",
      "2117/2117 - 26s - loss: 0.0152 - accuracy: 0.9942 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0073 - accuracy: 0.9974\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0217 - accuracy: 0.9940\n",
      "\n",
      "Epoch:  190\n",
      "2117/2117 - 26s - loss: 0.0170 - accuracy: 0.9940 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0095 - accuracy: 0.9964\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0230 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  191\n",
      "2117/2117 - 26s - loss: 0.0159 - accuracy: 0.9939 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0077 - accuracy: 0.9974\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0204 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  192\n",
      "2117/2117 - 27s - loss: 0.0148 - accuracy: 0.9944 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0209 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  193\n",
      "2117/2117 - 27s - loss: 0.0160 - accuracy: 0.9947 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0880 - accuracy: 0.9710\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1052 - accuracy: 0.9713\n",
      "\n",
      "Epoch:  194\n",
      "2117/2117 - 27s - loss: 0.0169 - accuracy: 0.9937 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0455 - accuracy: 0.9830\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0711 - accuracy: 0.9779\n",
      "\n",
      "Epoch:  195\n",
      "2117/2117 - 29s - loss: 0.0129 - accuracy: 0.9959 - 29s/epoch - 14ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0078 - accuracy: 0.9976\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  196\n",
      "2117/2117 - 27s - loss: 0.0158 - accuracy: 0.9942 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0189 - accuracy: 0.9931\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0456 - accuracy: 0.9863\n",
      "\n",
      "Epoch:  197\n",
      "2117/2117 - 26s - loss: 0.0133 - accuracy: 0.9952 - 26s/epoch - 12ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0058 - accuracy: 0.9980\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0206 - accuracy: 0.9942\n",
      "\n",
      "Epoch:  198\n",
      "2117/2117 - 26s - loss: 0.0151 - accuracy: 0.9946 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0209 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  199\n",
      "2117/2117 - 27s - loss: 0.0147 - accuracy: 0.9948 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0045 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0207 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  200\n",
      "2117/2117 - 27s - loss: 0.0149 - accuracy: 0.9947 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0179 - accuracy: 0.9930\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0336 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  201\n",
      "2117/2117 - 26s - loss: 0.0141 - accuracy: 0.9952 - 26s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0086 - accuracy: 0.9968\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0268 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  202\n",
      "2117/2117 - 27s - loss: 0.0144 - accuracy: 0.9944 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0079 - accuracy: 0.9976\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0244 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  203\n",
      "2117/2117 - 27s - loss: 0.0148 - accuracy: 0.9945 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0144 - accuracy: 0.9945\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0303 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  204\n",
      "2117/2117 - 27s - loss: 0.0120 - accuracy: 0.9952 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0143 - accuracy: 0.9947\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0365 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  205\n",
      "2117/2117 - 27s - loss: 0.0123 - accuracy: 0.9956 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0050 - accuracy: 0.9984\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0226 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  206\n",
      "2117/2117 - 26s - loss: 0.0158 - accuracy: 0.9944 - 26s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0176 - accuracy: 0.9934\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0382 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  207\n",
      "2117/2117 - 27s - loss: 0.0143 - accuracy: 0.9947 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1123 - accuracy: 0.9639\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1351 - accuracy: 0.9611\n",
      "\n",
      "Epoch:  208\n",
      "2117/2117 - 28s - loss: 0.0132 - accuracy: 0.9947 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0285 - accuracy: 0.9890\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0533 - accuracy: 0.9841\n",
      "\n",
      "Epoch:  209\n",
      "2117/2117 - 28s - loss: 0.0144 - accuracy: 0.9945 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0066 - accuracy: 0.9978\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0217 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  210\n",
      "2117/2117 - 27s - loss: 0.0124 - accuracy: 0.9956 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0105 - accuracy: 0.9962\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  211\n",
      "2117/2117 - 27s - loss: 0.0166 - accuracy: 0.9944 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0046 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0189 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  212\n",
      "2117/2117 - 27s - loss: 0.0143 - accuracy: 0.9947 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0202 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  213\n",
      "2117/2117 - 27s - loss: 0.0131 - accuracy: 0.9957 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0076 - accuracy: 0.9975\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  214\n",
      "2117/2117 - 27s - loss: 0.0148 - accuracy: 0.9950 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0052 - accuracy: 0.9984\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0207 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  215\n",
      "2117/2117 - 27s - loss: 0.0120 - accuracy: 0.9952 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0045 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0208 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  216\n",
      "2117/2117 - 27s - loss: 0.0125 - accuracy: 0.9957 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0131 - accuracy: 0.9955\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0318 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  217\n",
      "2117/2117 - 27s - loss: 0.0141 - accuracy: 0.9950 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0053 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0202 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  218\n",
      "2117/2117 - 27s - loss: 0.0132 - accuracy: 0.9951 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0066 - accuracy: 0.9978\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  219\n",
      "2117/2117 - 27s - loss: 0.0133 - accuracy: 0.9950 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0479 - accuracy: 0.9825\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0696 - accuracy: 0.9800\n",
      "\n",
      "Epoch:  220\n",
      "2117/2117 - 27s - loss: 0.0130 - accuracy: 0.9954 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0136 - accuracy: 0.9952\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0304 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  221\n",
      "2117/2117 - 27s - loss: 0.0141 - accuracy: 0.9950 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0070 - accuracy: 0.9975\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  222\n",
      "2117/2117 - 27s - loss: 0.0137 - accuracy: 0.9954 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0035 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0175 - accuracy: 0.9944\n",
      "\n",
      "Epoch:  223\n",
      "2117/2117 - 27s - loss: 0.0114 - accuracy: 0.9957 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0054 - accuracy: 0.9983\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0204 - accuracy: 0.9940\n",
      "\n",
      "Epoch:  224\n",
      "2117/2117 - 27s - loss: 0.0139 - accuracy: 0.9950 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0044 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0174 - accuracy: 0.9948\n",
      "\n",
      "Epoch:  225\n",
      "2117/2117 - 27s - loss: 0.0122 - accuracy: 0.9958 - 27s/epoch - 13ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0052 - accuracy: 0.9985\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0220 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  226\n",
      "2117/2117 - 27s - loss: 0.0111 - accuracy: 0.9963 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0078 - accuracy: 0.9969\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0250 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  227\n",
      "2117/2117 - 27s - loss: 0.0135 - accuracy: 0.9950 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0213 - accuracy: 0.9922\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0379 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  228\n",
      "2117/2117 - 27s - loss: 0.0110 - accuracy: 0.9964 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0356 - accuracy: 0.9864\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0507 - accuracy: 0.9829\n",
      "\n",
      "Epoch:  229\n",
      "2117/2117 - 27s - loss: 0.0139 - accuracy: 0.9951 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0079 - accuracy: 0.9972\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0243 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  230\n",
      "2117/2117 - 27s - loss: 0.0130 - accuracy: 0.9954 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0171 - accuracy: 0.9937\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0404 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  231\n",
      "2117/2117 - 27s - loss: 0.0111 - accuracy: 0.9961 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0072 - accuracy: 0.9976\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0251 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  232\n",
      "2117/2117 - 27s - loss: 0.0127 - accuracy: 0.9957 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0103 - accuracy: 0.9961\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0298 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  233\n",
      "2117/2117 - 27s - loss: 0.0113 - accuracy: 0.9960 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0196 - accuracy: 0.9921\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0383 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  234\n",
      "2117/2117 - 27s - loss: 0.0133 - accuracy: 0.9946 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0059 - accuracy: 0.9981\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0238 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  235\n",
      "2117/2117 - 27s - loss: 0.0113 - accuracy: 0.9959 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0047 - accuracy: 0.9985\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0203 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  236\n",
      "2117/2117 - 27s - loss: 0.0130 - accuracy: 0.9953 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0350 - accuracy: 0.9858\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0574 - accuracy: 0.9837\n",
      "\n",
      "Epoch:  237\n",
      "2117/2117 - 25s - loss: 0.0108 - accuracy: 0.9960 - 25s/epoch - 12ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0136 - accuracy: 0.9950\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0332 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  238\n",
      "2117/2117 - 27s - loss: 0.0115 - accuracy: 0.9957 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0040 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0214 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  239\n",
      "2117/2117 - 27s - loss: 0.0113 - accuracy: 0.9958 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0069 - accuracy: 0.9978\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0283 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  240\n",
      "2117/2117 - 27s - loss: 0.0111 - accuracy: 0.9960 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0137 - accuracy: 0.9952\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0363 - accuracy: 0.9894\n",
      "\n",
      "Epoch:  241\n",
      "2117/2117 - 27s - loss: 0.0115 - accuracy: 0.9962 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0054 - accuracy: 0.9981\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0245 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  242\n",
      "2117/2117 - 27s - loss: 0.0115 - accuracy: 0.9962 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0059 - accuracy: 0.9979\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0228 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  243\n",
      "2117/2117 - 27s - loss: 0.0124 - accuracy: 0.9959 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0184 - accuracy: 0.9949\n",
      "\n",
      "Epoch:  244\n",
      "2117/2117 - 27s - loss: 0.0134 - accuracy: 0.9951 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0290 - accuracy: 0.9887\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0495 - accuracy: 0.9848\n",
      "\n",
      "Epoch:  245\n",
      "2117/2117 - 27s - loss: 0.0118 - accuracy: 0.9957 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0302 - accuracy: 0.9880\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0477 - accuracy: 0.9867\n",
      "\n",
      "Epoch:  246\n",
      "2117/2117 - 27s - loss: 0.0111 - accuracy: 0.9959 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0203 - accuracy: 0.9946\n",
      "\n",
      "Epoch:  247\n",
      "2117/2117 - 27s - loss: 0.0141 - accuracy: 0.9953 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0242 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  248\n",
      "2117/2117 - 27s - loss: 0.0104 - accuracy: 0.9960 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0058 - accuracy: 0.9976\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0264 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  249\n",
      "2117/2117 - 27s - loss: 0.0105 - accuracy: 0.9963 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0067 - accuracy: 0.9974\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  250\n",
      "2117/2117 - 27s - loss: 0.0109 - accuracy: 0.9963 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0028 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0212 - accuracy: 0.9941\n",
      "\n",
      "Epoch:  251\n",
      "2117/2117 - 27s - loss: 0.0138 - accuracy: 0.9953 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0099 - accuracy: 0.9963\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0309 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  252\n",
      "2117/2117 - 27s - loss: 0.0111 - accuracy: 0.9961 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0357 - accuracy: 0.9861\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0592 - accuracy: 0.9826\n",
      "\n",
      "Epoch:  253\n",
      "2117/2117 - 27s - loss: 0.0109 - accuracy: 0.9963 - 27s/epoch - 13ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0140 - accuracy: 0.9944\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0406 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  254\n",
      "2117/2117 - 27s - loss: 0.0113 - accuracy: 0.9963 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0153 - accuracy: 0.9948\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0323 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  255\n",
      "2117/2117 - 27s - loss: 0.0110 - accuracy: 0.9962 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0092 - accuracy: 0.9965\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0248 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  256\n",
      "2117/2117 - 27s - loss: 0.0110 - accuracy: 0.9960 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0024 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0189 - accuracy: 0.9944\n",
      "\n",
      "Epoch:  257\n",
      "2117/2117 - 27s - loss: 0.0101 - accuracy: 0.9963 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0063 - accuracy: 0.9980\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0240 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  258\n",
      "2117/2117 - 27s - loss: 0.0107 - accuracy: 0.9963 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0043 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0217 - accuracy: 0.9941\n",
      "\n",
      "Epoch:  259\n",
      "2117/2117 - 27s - loss: 0.0120 - accuracy: 0.9960 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0205 - accuracy: 0.9944\n",
      "\n",
      "Epoch:  260\n",
      "2117/2117 - 27s - loss: 0.0104 - accuracy: 0.9959 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0100 - accuracy: 0.9964\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0287 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  261\n",
      "2117/2117 - 27s - loss: 0.0123 - accuracy: 0.9953 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0040 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0225 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  262\n",
      "2117/2117 - 27s - loss: 0.0091 - accuracy: 0.9966 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0196 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  263\n",
      "2117/2117 - 27s - loss: 0.0119 - accuracy: 0.9955 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0117 - accuracy: 0.9958\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0307 - accuracy: 0.9904\n",
      "\n",
      "Epoch:  264\n",
      "2117/2117 - 27s - loss: 0.0111 - accuracy: 0.9959 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0080 - accuracy: 0.9973\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0242 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  265\n",
      "2117/2117 - 27s - loss: 0.0093 - accuracy: 0.9965 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0447 - accuracy: 0.9827\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0733 - accuracy: 0.9808\n",
      "\n",
      "Epoch:  266\n",
      "2117/2117 - 27s - loss: 0.0138 - accuracy: 0.9951 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0028 - accuracy: 0.9990\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0207 - accuracy: 0.9941\n",
      "\n",
      "Epoch:  267\n",
      "2117/2117 - 27s - loss: 0.0092 - accuracy: 0.9969 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0036 - accuracy: 0.9989\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0215 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  268\n",
      "2117/2117 - 27s - loss: 0.0119 - accuracy: 0.9960 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0053 - accuracy: 0.9981\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0252 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  269\n",
      "2117/2117 - 27s - loss: 0.0107 - accuracy: 0.9962 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0283 - accuracy: 0.9904\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0527 - accuracy: 0.9844\n",
      "\n",
      "Epoch:  270\n",
      "2117/2117 - 28s - loss: 0.0112 - accuracy: 0.9964 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0075 - accuracy: 0.9972\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0275 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  271\n",
      "2117/2117 - 28s - loss: 0.0113 - accuracy: 0.9963 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0033 - accuracy: 0.9989\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0230 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  272\n",
      "2117/2117 - 27s - loss: 0.0082 - accuracy: 0.9971 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0072 - accuracy: 0.9970\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0301 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  273\n",
      "2117/2117 - 27s - loss: 0.0108 - accuracy: 0.9964 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0020 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0221 - accuracy: 0.9937\n",
      "\n",
      "Epoch:  274\n",
      "2117/2117 - 27s - loss: 0.0121 - accuracy: 0.9960 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0040 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0227 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  275\n",
      "2117/2117 - 27s - loss: 0.0116 - accuracy: 0.9961 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0081 - accuracy: 0.9970\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0317 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  276\n",
      "2117/2117 - 27s - loss: 0.0100 - accuracy: 0.9967 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0118 - accuracy: 0.9955\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0316 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  277\n",
      "2117/2117 - 27s - loss: 0.0097 - accuracy: 0.9966 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0199 - accuracy: 0.9952\n",
      "\n",
      "Epoch:  278\n",
      "2117/2117 - 27s - loss: 0.0102 - accuracy: 0.9965 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0104 - accuracy: 0.9961\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0317 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  279\n",
      "2117/2117 - 27s - loss: 0.0095 - accuracy: 0.9965 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0067 - accuracy: 0.9977\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0256 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  280\n",
      "2117/2117 - 27s - loss: 0.0115 - accuracy: 0.9960 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0026 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0193 - accuracy: 0.9944\n",
      "\n",
      "Epoch:  281\n",
      "2117/2117 - 27s - loss: 0.0099 - accuracy: 0.9962 - 27s/epoch - 13ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0405 - accuracy: 0.9862\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0591 - accuracy: 0.9836\n",
      "\n",
      "Epoch:  282\n",
      "2117/2117 - 27s - loss: 0.0102 - accuracy: 0.9964 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0228 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  283\n",
      "2117/2117 - 27s - loss: 0.0101 - accuracy: 0.9961 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0033 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0195 - accuracy: 0.9940\n",
      "\n",
      "Epoch:  284\n",
      "2117/2117 - 28s - loss: 0.0100 - accuracy: 0.9963 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0051 - accuracy: 0.9981\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  285\n",
      "2117/2117 - 27s - loss: 0.0086 - accuracy: 0.9968 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0024 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0228 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  286\n",
      "2117/2117 - 27s - loss: 0.0108 - accuracy: 0.9963 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0075 - accuracy: 0.9971\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0296 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  287\n",
      "2117/2117 - 27s - loss: 0.0081 - accuracy: 0.9968 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0027 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0252 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  288\n",
      "2117/2117 - 27s - loss: 0.0104 - accuracy: 0.9964 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0098 - accuracy: 0.9966\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0288 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  289\n",
      "2117/2117 - 27s - loss: 0.0085 - accuracy: 0.9968 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0046 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0232 - accuracy: 0.9937\n",
      "\n",
      "Epoch:  290\n",
      "2117/2117 - 27s - loss: 0.0095 - accuracy: 0.9971 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0062 - accuracy: 0.9977\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0273 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  291\n",
      "2117/2117 - 27s - loss: 0.0114 - accuracy: 0.9963 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0032 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0199 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  292\n",
      "2117/2117 - 27s - loss: 0.0093 - accuracy: 0.9964 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0060 - accuracy: 0.9978\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  293\n",
      "2117/2117 - 27s - loss: 0.0086 - accuracy: 0.9970 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0177 - accuracy: 0.9944\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0444 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  294\n",
      "2117/2117 - 27s - loss: 0.0074 - accuracy: 0.9972 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0032 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0239 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  295\n",
      "2117/2117 - 27s - loss: 0.0125 - accuracy: 0.9957 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0243 - accuracy: 0.9937\n",
      "\n",
      "Epoch:  296\n",
      "2117/2117 - 27s - loss: 0.0117 - accuracy: 0.9960 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0030 - accuracy: 0.9990\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0230 - accuracy: 0.9937\n",
      "\n",
      "Epoch:  297\n",
      "2117/2117 - 27s - loss: 0.0096 - accuracy: 0.9971 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0025 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0204 - accuracy: 0.9943\n",
      "\n",
      "Epoch:  298\n",
      "2117/2117 - 27s - loss: 0.0096 - accuracy: 0.9969 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0187 - accuracy: 0.9935\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0436 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  299\n",
      "2117/2117 - 27s - loss: 0.0106 - accuracy: 0.9965 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0591 - accuracy: 0.9800\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0817 - accuracy: 0.9767\n",
      "\n",
      "Epoch:  300\n",
      "2117/2117 - 27s - loss: 0.0092 - accuracy: 0.9965 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0130 - accuracy: 0.9943\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0365 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  301\n",
      "2117/2117 - 27s - loss: 0.0091 - accuracy: 0.9965 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0209 - accuracy: 0.9940\n",
      "\n",
      "Epoch:  302\n",
      "2117/2117 - 27s - loss: 0.0089 - accuracy: 0.9973 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0168 - accuracy: 0.9938\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0405 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  303\n",
      "2117/2117 - 27s - loss: 0.0107 - accuracy: 0.9965 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0027 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0218 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  304\n",
      "2117/2117 - 27s - loss: 0.0115 - accuracy: 0.9961 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0068 - accuracy: 0.9973\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0245 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  305\n",
      "2117/2117 - 27s - loss: 0.0075 - accuracy: 0.9974 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0059 - accuracy: 0.9976\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  306\n",
      "2117/2117 - 27s - loss: 0.0088 - accuracy: 0.9969 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0042 - accuracy: 0.9984\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  307\n",
      "2117/2117 - 28s - loss: 0.0100 - accuracy: 0.9963 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0017 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0229 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  308\n",
      "2117/2117 - 27s - loss: 0.0068 - accuracy: 0.9978 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0024 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0258 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  309\n",
      "2117/2117 - 27s - loss: 0.0112 - accuracy: 0.9959 - 27s/epoch - 13ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0040 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0206 - accuracy: 0.9944\n",
      "\n",
      "Epoch:  310\n",
      "2117/2117 - 27s - loss: 0.0048 - accuracy: 0.9984 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0022 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0206 - accuracy: 0.9943\n",
      "\n",
      "Epoch:  311\n",
      "2117/2117 - 27s - loss: 0.0125 - accuracy: 0.9957 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0047 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0283 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  312\n",
      "2117/2117 - 27s - loss: 0.0082 - accuracy: 0.9972 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0152 - accuracy: 0.9940\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0424 - accuracy: 0.9867\n",
      "\n",
      "Epoch:  313\n",
      "2117/2117 - 28s - loss: 0.0094 - accuracy: 0.9968 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0231 - accuracy: 0.9917\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0467 - accuracy: 0.9875\n",
      "\n",
      "Epoch:  314\n",
      "2117/2117 - 27s - loss: 0.0085 - accuracy: 0.9968 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0207 - accuracy: 0.9922\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0515 - accuracy: 0.9865\n",
      "\n",
      "Epoch:  315\n",
      "2117/2117 - 27s - loss: 0.0112 - accuracy: 0.9963 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0027 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0216 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  316\n",
      "2117/2117 - 28s - loss: 0.0068 - accuracy: 0.9977 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0042 - accuracy: 0.9984\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0237 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  317\n",
      "2117/2117 - 29s - loss: 0.0085 - accuracy: 0.9968 - 29s/epoch - 14ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0043 - accuracy: 0.9983\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  318\n",
      "2117/2117 - 27s - loss: 0.0103 - accuracy: 0.9965 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0023 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0211 - accuracy: 0.9942\n",
      "\n",
      "Epoch:  319\n",
      "2117/2117 - 27s - loss: 0.0069 - accuracy: 0.9975 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0083 - accuracy: 0.9968\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0301 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  320\n",
      "2117/2117 - 27s - loss: 0.0119 - accuracy: 0.9958 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9940\n",
      "\n",
      "Epoch:  321\n",
      "2117/2117 - 27s - loss: 0.0091 - accuracy: 0.9968 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0191 - accuracy: 0.9944\n",
      "\n",
      "Epoch:  322\n",
      "2117/2117 - 28s - loss: 0.0077 - accuracy: 0.9974 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0048 - accuracy: 0.9980\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0258 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  323\n",
      "2117/2117 - 27s - loss: 0.0071 - accuracy: 0.9976 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0239 - accuracy: 0.9944\n",
      "\n",
      "Epoch:  324\n",
      "2117/2117 - 27s - loss: 0.0096 - accuracy: 0.9969 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0061 - accuracy: 0.9977\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0259 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  325\n",
      "2117/2117 - 27s - loss: 0.0086 - accuracy: 0.9971 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0026 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0256 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  326\n",
      "2117/2117 - 27s - loss: 0.0110 - accuracy: 0.9963 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0254 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  327\n",
      "2117/2117 - 27s - loss: 0.0049 - accuracy: 0.9985 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0019 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0234 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  328\n",
      "2117/2117 - 27s - loss: 0.0116 - accuracy: 0.9962 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0172 - accuracy: 0.9954\n",
      "\n",
      "Epoch:  329\n",
      "2117/2117 - 27s - loss: 0.0104 - accuracy: 0.9965 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0053 - accuracy: 0.9981\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0230 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  330\n",
      "2117/2117 - 27s - loss: 0.0076 - accuracy: 0.9969 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0020 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0202 - accuracy: 0.9949\n",
      "\n",
      "Epoch:  331\n",
      "2117/2117 - 27s - loss: 0.0082 - accuracy: 0.9972 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0062 - accuracy: 0.9976\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0293 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  332\n",
      "2117/2117 - 27s - loss: 0.0087 - accuracy: 0.9970 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0213 - accuracy: 0.9940\n",
      "\n",
      "Epoch:  333\n",
      "2117/2117 - 27s - loss: 0.0108 - accuracy: 0.9963 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0025 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0252 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  334\n",
      "2117/2117 - 27s - loss: 0.0056 - accuracy: 0.9980 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9948\n",
      "\n",
      "Epoch:  335\n",
      "2117/2117 - 27s - loss: 0.0088 - accuracy: 0.9969 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0029 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0251 - accuracy: 0.9941\n",
      "\n",
      "Epoch:  336\n",
      "2117/2117 - 27s - loss: 0.0085 - accuracy: 0.9970 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0179 - accuracy: 0.9929\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0466 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  337\n",
      "2117/2117 - 27s - loss: 0.0086 - accuracy: 0.9973 - 27s/epoch - 13ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0040 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0243 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  338\n",
      "2117/2117 - 27s - loss: 0.0101 - accuracy: 0.9967 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0243 - accuracy: 0.9947\n",
      "\n",
      "Epoch:  339\n",
      "2117/2117 - 27s - loss: 0.0080 - accuracy: 0.9975 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0017 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0235 - accuracy: 0.9937\n",
      "\n",
      "Epoch:  340\n",
      "2117/2117 - 27s - loss: 0.0070 - accuracy: 0.9978 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0020 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0223 - accuracy: 0.9943\n",
      "\n",
      "Epoch:  341\n",
      "2117/2117 - 27s - loss: 0.0098 - accuracy: 0.9966 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0258 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  342\n",
      "2117/2117 - 27s - loss: 0.0094 - accuracy: 0.9966 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0066 - accuracy: 0.9976\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  343\n",
      "2117/2117 - 27s - loss: 0.0069 - accuracy: 0.9977 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 8.9272e-04 - accuracy: 0.9999\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0198 - accuracy: 0.9953\n",
      "\n",
      "Epoch:  344\n",
      "2117/2117 - 27s - loss: 0.0093 - accuracy: 0.9968 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0039 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0264 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  345\n",
      "2117/2117 - 27s - loss: 0.0089 - accuracy: 0.9969 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0017 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0227 - accuracy: 0.9948\n",
      "\n",
      "Epoch:  346\n",
      "2117/2117 - 27s - loss: 0.0096 - accuracy: 0.9963 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0056 - accuracy: 0.9977\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0341 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  347\n",
      "2117/2117 - 27s - loss: 0.0088 - accuracy: 0.9970 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0037 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0273 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  348\n",
      "2117/2117 - 27s - loss: 0.0065 - accuracy: 0.9975 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0248 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  349\n",
      "2117/2117 - 27s - loss: 0.0077 - accuracy: 0.9974 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0078 - accuracy: 0.9971\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0310 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  350\n",
      "2117/2117 - 27s - loss: 0.0085 - accuracy: 0.9972 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0011 - accuracy: 0.9999\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0210 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  351\n",
      "2117/2117 - 27s - loss: 0.0091 - accuracy: 0.9968 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0044 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0322 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  352\n",
      "2117/2117 - 27s - loss: 0.0078 - accuracy: 0.9972 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0034 - accuracy: 0.9990\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0291 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  353\n",
      "2117/2117 - 27s - loss: 0.0082 - accuracy: 0.9969 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0041 - accuracy: 0.9984\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0267 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  354\n",
      "2117/2117 - 27s - loss: 0.0089 - accuracy: 0.9972 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0220 - accuracy: 0.9946\n",
      "\n",
      "Epoch:  355\n",
      "2117/2117 - 27s - loss: 0.0085 - accuracy: 0.9972 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0207 - accuracy: 0.9926\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0450 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  356\n",
      "2117/2117 - 27s - loss: 0.0066 - accuracy: 0.9975 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0107 - accuracy: 0.9957\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0387 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  357\n",
      "2117/2117 - 27s - loss: 0.0094 - accuracy: 0.9970 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 8.5368e-04 - accuracy: 0.9999\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0215 - accuracy: 0.9947\n",
      "\n",
      "Epoch:  358\n",
      "2117/2117 - 27s - loss: 0.0058 - accuracy: 0.9980 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 9.3801e-04 - accuracy: 0.9998\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0187 - accuracy: 0.9948\n",
      "\n",
      "Epoch:  359\n",
      "2117/2117 - 27s - loss: 0.0065 - accuracy: 0.9979 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0086 - accuracy: 0.9969\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0380 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  360\n",
      "2117/2117 - 27s - loss: 0.0074 - accuracy: 0.9975 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0191 - accuracy: 0.9934\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0517 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  361\n",
      "2117/2117 - 27s - loss: 0.0097 - accuracy: 0.9966 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0025 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0249 - accuracy: 0.9942\n",
      "\n",
      "Epoch:  362\n",
      "2117/2117 - 27s - loss: 0.0073 - accuracy: 0.9977 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0220 - accuracy: 0.9948\n",
      "\n",
      "Epoch:  363\n",
      "2117/2117 - 27s - loss: 0.0089 - accuracy: 0.9968 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0209 - accuracy: 0.9948\n",
      "\n",
      "Epoch:  364\n",
      "2117/2117 - 27s - loss: 0.0079 - accuracy: 0.9971 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  365\n",
      "2117/2117 - 27s - loss: 0.0074 - accuracy: 0.9979 - 27s/epoch - 13ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0094 - accuracy: 0.9962\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0294 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  366\n",
      "2117/2117 - 27s - loss: 0.0087 - accuracy: 0.9969 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0023 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  367\n",
      "2117/2117 - 27s - loss: 0.0061 - accuracy: 0.9979 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0022 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0211 - accuracy: 0.9937\n",
      "\n",
      "Epoch:  368\n",
      "2117/2117 - 27s - loss: 0.0093 - accuracy: 0.9974 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0031 - accuracy: 0.9990\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0254 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  369\n",
      "2117/2117 - 27s - loss: 0.0079 - accuracy: 0.9972 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0055 - accuracy: 0.9978\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0283 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  370\n",
      "2117/2117 - 27s - loss: 0.0068 - accuracy: 0.9976 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0072 - accuracy: 0.9970\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0325 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  371\n",
      "2117/2117 - 28s - loss: 0.0098 - accuracy: 0.9971 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0061 - accuracy: 0.9979\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0331 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  372\n",
      "2117/2117 - 27s - loss: 0.0065 - accuracy: 0.9975 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0138 - accuracy: 0.9950\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0422 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  373\n",
      "2117/2117 - 27s - loss: 0.0063 - accuracy: 0.9982 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0091 - accuracy: 0.9968\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0334 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  374\n",
      "2117/2117 - 27s - loss: 0.0089 - accuracy: 0.9970 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0125 - accuracy: 0.9949\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0375 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  375\n",
      "2117/2117 - 28s - loss: 0.0107 - accuracy: 0.9965 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0026 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0196 - accuracy: 0.9944\n",
      "\n",
      "Epoch:  376\n",
      "2117/2117 - 27s - loss: 0.0077 - accuracy: 0.9976 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0279 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  377\n",
      "2117/2117 - 28s - loss: 0.0091 - accuracy: 0.9970 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0228 - accuracy: 0.9947\n",
      "\n",
      "Epoch:  378\n",
      "2117/2117 - 28s - loss: 0.0067 - accuracy: 0.9975 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0266 - accuracy: 0.9946\n",
      "\n",
      "Epoch:  379\n",
      "2117/2117 - 27s - loss: 0.0054 - accuracy: 0.9980 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0067 - accuracy: 0.9972\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0302 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  380\n",
      "2117/2117 - 27s - loss: 0.0113 - accuracy: 0.9963 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0013 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0236 - accuracy: 0.9950\n",
      "\n",
      "Epoch:  381\n",
      "2117/2117 - 27s - loss: 0.0087 - accuracy: 0.9971 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0232 - accuracy: 0.9943\n",
      "\n",
      "Epoch:  382\n",
      "2117/2117 - 27s - loss: 0.0075 - accuracy: 0.9981 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 6.3032e-04 - accuracy: 0.9999\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0198 - accuracy: 0.9954\n",
      "\n",
      "Epoch:  383\n",
      "2117/2117 - 27s - loss: 0.0112 - accuracy: 0.9966 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0132 - accuracy: 0.9951\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0437 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  384\n",
      "2117/2117 - 27s - loss: 0.0042 - accuracy: 0.9986 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0018 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0245 - accuracy: 0.9943\n",
      "\n",
      "Epoch:  385\n",
      "2117/2117 - 27s - loss: 0.0109 - accuracy: 0.9963 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0039 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  386\n",
      "2117/2117 - 28s - loss: 0.0067 - accuracy: 0.9979 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0021 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0224 - accuracy: 0.9944\n",
      "\n",
      "Epoch:  387\n",
      "2117/2117 - 27s - loss: 0.0062 - accuracy: 0.9981 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 6.7577e-04 - accuracy: 0.9999\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0216 - accuracy: 0.9944\n",
      "\n",
      "Epoch:  388\n",
      "2117/2117 - 28s - loss: 0.0087 - accuracy: 0.9971 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0190 - accuracy: 0.9934\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0436 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  389\n",
      "2117/2117 - 28s - loss: 0.0059 - accuracy: 0.9979 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 5.5383e-04 - accuracy: 1.0000\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0208 - accuracy: 0.9948\n",
      "\n",
      "Epoch:  390\n",
      "2117/2117 - 27s - loss: 0.0095 - accuracy: 0.9971 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0206 - accuracy: 0.9948\n",
      "\n",
      "Epoch:  391\n",
      "2117/2117 - 27s - loss: 0.0058 - accuracy: 0.9980 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0068 - accuracy: 0.9974\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0256 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  392\n",
      "2117/2117 - 27s - loss: 0.0084 - accuracy: 0.9969 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0015 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0243 - accuracy: 0.9946\n",
      "\n",
      "Epoch:  393\n",
      "2117/2117 - 27s - loss: 0.0085 - accuracy: 0.9974 - 27s/epoch - 13ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0239 - accuracy: 0.9913\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0536 - accuracy: 0.9850\n",
      "\n",
      "Epoch:  394\n",
      "2117/2117 - 28s - loss: 0.0057 - accuracy: 0.9984 - 28s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0511 - accuracy: 0.9802\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0850 - accuracy: 0.9782\n",
      "\n",
      "Epoch:  395\n",
      "2117/2117 - 27s - loss: 0.0065 - accuracy: 0.9977 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0320 - accuracy: 0.9884\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0742 - accuracy: 0.9854\n",
      "\n",
      "Epoch:  396\n",
      "2117/2117 - 27s - loss: 0.0078 - accuracy: 0.9975 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0080 - accuracy: 0.9975\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0351 - accuracy: 0.9904\n",
      "\n",
      "Epoch:  397\n",
      "2117/2117 - 27s - loss: 0.0110 - accuracy: 0.9970 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0027 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0257 - accuracy: 0.9937\n",
      "\n",
      "Epoch:  398\n",
      "2117/2117 - 27s - loss: 0.0021 - accuracy: 0.9992 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0021 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0239 - accuracy: 0.9942\n",
      "\n",
      "Epoch:  399\n",
      "2117/2117 - 27s - loss: 0.0098 - accuracy: 0.9968 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0068 - accuracy: 0.9976\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0333 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  400\n",
      "2117/2117 - 27s - loss: 0.0055 - accuracy: 0.9984 - 27s/epoch - 13ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0211 - accuracy: 0.9943\n"
     ]
    }
   ],
   "source": [
    "for x in range(400):\n",
    "    print(\"\\nEpoch: \",x+1)\n",
    "    history = model.fit(X_train ,y_train ,batch_size=BATCH_SIZE ,epochs=1, verbose=2, shuffle=True)\n",
    "    if history_dataframe.size == 0:\n",
    "        history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    else:\n",
    "        history_dataframe = pd.concat([history_dataframe,pd.DataFrame.from_dict(history.history)],axis=0,ignore_index=True)\n",
    "    \n",
    "    print(\"for training\")\n",
    "    train_eva.append(model.evaluate(X_train,y_train))\n",
    "    print(\"for testing\")\n",
    "    test_eva.append(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ec37c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.870918</td>\n",
       "      <td>0.574377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.442385</td>\n",
       "      <td>0.817291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287906</td>\n",
       "      <td>0.888774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.242319</td>\n",
       "      <td>0.906017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.219126</td>\n",
       "      <td>0.915584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.997520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.010959</td>\n",
       "      <td>0.996988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.999203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.009844</td>\n",
       "      <td>0.996752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.005540</td>\n",
       "      <td>0.998435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy\n",
       "0    0.870918  0.574377\n",
       "1    0.442385  0.817291\n",
       "2    0.287906  0.888774\n",
       "3    0.242319  0.906017\n",
       "4    0.219126  0.915584\n",
       "..        ...       ...\n",
       "395  0.007820  0.997520\n",
       "396  0.010959  0.996988\n",
       "397  0.002052  0.999203\n",
       "398  0.009844  0.996752\n",
       "399  0.005540  0.998435\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c8463e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva_df = pd.DataFrame(train_eva,columns=['loss','accuracy'])\n",
    "test_eva_df = pd.DataFrame(test_eva,columns=['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "708b9560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(df,title,xlabel,ylabel,values=['loss'],legends=[]):\n",
    "    \n",
    "    for value in values:\n",
    "        epoch_count = range(1, len(df.index) + 1)\n",
    "        plt.plot(epoch_count, df[value].tolist())\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    if legends==[]:\n",
    "        legends = values\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35c781fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(train_eva_df,'Train','Epoch','Loss',['loss','accuracy'])\n",
    "plot_graph(test_eva_df,'Test','Epoch','Loss',['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bab450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
