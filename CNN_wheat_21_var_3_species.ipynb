{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c4fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b98a174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6aebd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'wheat_21_var_3_species.csv'\n",
    "\n",
    "def dir(file_name):\n",
    "    return '../data/'+file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a19daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_X_Y(dataframe):\n",
    "    return (dataframe.drop('classes', axis =1), dataframe.loc[:,'classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "554bc6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class filter_method(Enum):\n",
    "    none = 0\n",
    "    snv = 1\n",
    "    msc = 2\n",
    "    savgol = 3\n",
    "\n",
    "FILT = 3\n",
    "FILTER = filter_method(FILT).name\n",
    "\n",
    "# to be set if filter chosen is savgol\n",
    "WINDOW = 7\n",
    "ORDER = 2\n",
    "DERIVATIVE = 1\n",
    "\n",
    "#will be used for test dataset in msc\n",
    "reference= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c20231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def create_test_train(X, y, test_size = 0.2, shuffle = True):\n",
    "    return train_test_split(X,y, test_size = test_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e9301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Normal Variate\n",
    "def snv(input_data):\n",
    "  \n",
    "    # Define a new array and populate it with the corrected data  \n",
    "    output_data = np.zeros_like(input_data)\n",
    "    for i in range(input_data.shape[0]):\n",
    " \n",
    "        # Apply correction\n",
    "        output_data[i,:] = (input_data[i,:] - np.mean(input_data[i,:])) / np.std(input_data[i,:])\n",
    " \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d925acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicative scatter correction\n",
    "def msc(input_data, reference=None):\n",
    "#     print(reference)\n",
    "    ''' Perform Multiplicative scatter correction'''\n",
    "\n",
    "    # Baseline correction\n",
    "    for i in range(input_data.shape[0]):\n",
    "        input_data[i,:] -= input_data[i,:].mean()\n",
    "\n",
    "    # Get the reference spectrum. If not given, estimate from the mean    \n",
    "    if reference is None:    \n",
    "        # Calculate mean\n",
    "        matm = np.mean(input_data, axis=0)\n",
    "    else:\n",
    "        matm = reference\n",
    "\n",
    "    # Define a new data matrix and populate it with the corrected data    \n",
    "    output_data = np.zeros_like(input_data)\n",
    "    for i in range(input_data.shape[0]):\n",
    "        # Run regression\n",
    "        fit = np.polyfit(matm, input_data[i,:], 1, full=True)\n",
    "        # Apply correction\n",
    "        output_data[i,:] = (input_data[i,:] - fit[0][1]) / fit[0][0] \n",
    "\n",
    "    return (output_data, matm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b5090be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter, general_gaussian\n",
    "def savgol(input_data):\n",
    "    w = WINDOW\n",
    "    p = ORDER\n",
    "    d = DERIVATIVE\n",
    "    \n",
    "    output_data = savgol_filter(np.array(input_data), w, polyorder = p, deriv=d)\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b68affd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X,y, type=\"train\"):\n",
    "    if FILTER == \"snv\":\n",
    "        return {\"X\": snv(np.array(X)), \"y\": y}\n",
    "    elif FILTER == \"msc\":\n",
    "        msc_output = msc(np.array(X), reference = reference if type==\"test\" else None)\n",
    "        X = msc_output[0]\n",
    "        ref = msc_output[1]\n",
    "        return {\n",
    "            \"X\": X,\n",
    "            \"y\": y,\n",
    "            \"ref\": ref\n",
    "        }\n",
    "    elif FILTER == \"savgol\":\n",
    "        return {\n",
    "            \"X\": savgol(X),\n",
    "            \"y\": y\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"X\":X,\n",
    "            \"y\":y\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8dec1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(dir(file_name))\n",
    "X,y = seperate_X_Y(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03e24565",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_set = set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e8c8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_CLASSES = len(y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e545c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = create_test_train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f79eb839",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_results = preprocess_data(X_train_raw,y_train_raw)\n",
    "X_train, y_train = preprocessed_results[\"X\"], preprocessed_results[\"y\"]\n",
    "\n",
    "if FILTER == \"msc\":\n",
    "    reference = preprocessed_results[\"ref\"]\n",
    "    \n",
    "preprocessed_results_test = preprocess_data(X_test_raw, y_test_raw, type=\"test\")\n",
    "X_test, y_test = preprocessed_results_test[\"X\"], preprocessed_results_test[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89f78cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33868, 147, 1)\n",
      "(8468, 147, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55a78e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Input, Conv1D, Flatten, Dense, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba682707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(input_shape,num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=5, input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=5 ))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6a3400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(X_train.shape[1:],NUM_OF_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2a7d43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 143, 32)           192       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 28, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 896)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              897000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 3003      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 900,195\n",
      "Trainable params: 900,195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34d6bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva = []\n",
    "test_eva = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fd5eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dataframe = pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "863f63f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  1\n",
      "265/265 - 6s - loss: 1.0421 - accuracy: 0.4385 - 6s/epoch - 24ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.9784 - accuracy: 0.4950\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.9805 - accuracy: 0.4932\n",
      "\n",
      "Epoch:  2\n",
      "265/265 - 5s - loss: 0.9371 - accuracy: 0.5339 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.8751 - accuracy: 0.5650\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.8826 - accuracy: 0.5596\n",
      "\n",
      "Epoch:  3\n",
      "265/265 - 5s - loss: 0.8072 - accuracy: 0.6428 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.7296 - accuracy: 0.6754\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.7433 - accuracy: 0.6673\n",
      "\n",
      "Epoch:  4\n",
      "265/265 - 5s - loss: 0.6278 - accuracy: 0.7556 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.5452 - accuracy: 0.7856\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.5624 - accuracy: 0.7761\n",
      "\n",
      "Epoch:  5\n",
      "265/265 - 5s - loss: 0.5026 - accuracy: 0.8015 - 5s/epoch - 19ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.4598 - accuracy: 0.8137\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.4790 - accuracy: 0.8040\n",
      "\n",
      "Epoch:  6\n",
      "265/265 - 5s - loss: 0.4392 - accuracy: 0.8218 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.4038 - accuracy: 0.8388\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.4206 - accuracy: 0.8343\n",
      "\n",
      "Epoch:  7\n",
      "265/265 - 5s - loss: 0.3919 - accuracy: 0.8436 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.3848 - accuracy: 0.8486\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.4022 - accuracy: 0.8407\n",
      "\n",
      "Epoch:  8\n",
      "265/265 - 5s - loss: 0.3589 - accuracy: 0.8616 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.3434 - accuracy: 0.8645\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.3641 - accuracy: 0.8545\n",
      "\n",
      "Epoch:  9\n",
      "265/265 - 5s - loss: 0.3353 - accuracy: 0.8719 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.3195 - accuracy: 0.8810\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.3379 - accuracy: 0.8738\n",
      "\n",
      "Epoch:  10\n",
      "265/265 - 5s - loss: 0.3046 - accuracy: 0.8856 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2825 - accuracy: 0.8964\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.3010 - accuracy: 0.8864\n",
      "\n",
      "Epoch:  11\n",
      "265/265 - 5s - loss: 0.2853 - accuracy: 0.8924 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2642 - accuracy: 0.9032\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.2831 - accuracy: 0.8935\n",
      "\n",
      "Epoch:  12\n",
      "265/265 - 5s - loss: 0.2666 - accuracy: 0.9008 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2507 - accuracy: 0.9078\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.2692 - accuracy: 0.8994\n",
      "\n",
      "Epoch:  13\n",
      "265/265 - 5s - loss: 0.2513 - accuracy: 0.9067 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2330 - accuracy: 0.9172\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.2498 - accuracy: 0.9073\n",
      "\n",
      "Epoch:  14\n",
      "265/265 - 5s - loss: 0.2363 - accuracy: 0.9131 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2261 - accuracy: 0.9178\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.2429 - accuracy: 0.9082\n",
      "\n",
      "Epoch:  15\n",
      "265/265 - 5s - loss: 0.2296 - accuracy: 0.9153 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2195 - accuracy: 0.9180\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.2375 - accuracy: 0.9074\n",
      "\n",
      "Epoch:  16\n",
      "265/265 - 6s - loss: 0.2171 - accuracy: 0.9191 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2074 - accuracy: 0.9236\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.2240 - accuracy: 0.9147\n",
      "\n",
      "Epoch:  17\n",
      "265/265 - 5s - loss: 0.2080 - accuracy: 0.9246 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1973 - accuracy: 0.9307\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.2118 - accuracy: 0.9232\n",
      "\n",
      "Epoch:  18\n",
      "265/265 - 5s - loss: 0.2021 - accuracy: 0.9253 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1936 - accuracy: 0.9292\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.2089 - accuracy: 0.9224\n",
      "\n",
      "Epoch:  19\n",
      "265/265 - 5s - loss: 0.1964 - accuracy: 0.9283 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1977 - accuracy: 0.9287\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.2118 - accuracy: 0.9204\n",
      "\n",
      "Epoch:  20\n",
      "265/265 - 5s - loss: 0.1873 - accuracy: 0.9317 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1887 - accuracy: 0.9292\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.2040 - accuracy: 0.9210\n",
      "\n",
      "Epoch:  21\n",
      "265/265 - 5s - loss: 0.1855 - accuracy: 0.9306 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1754 - accuracy: 0.9362\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1877 - accuracy: 0.9300\n",
      "\n",
      "Epoch:  22\n",
      "265/265 - 5s - loss: 0.1811 - accuracy: 0.9332 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1695 - accuracy: 0.9383\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1827 - accuracy: 0.9320\n",
      "\n",
      "Epoch:  23\n",
      "265/265 - 5s - loss: 0.1764 - accuracy: 0.9344 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1690 - accuracy: 0.9398\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1816 - accuracy: 0.9341\n",
      "\n",
      "Epoch:  24\n",
      "265/265 - 5s - loss: 0.1712 - accuracy: 0.9378 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1631 - accuracy: 0.9408\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1749 - accuracy: 0.9352\n",
      "\n",
      "Epoch:  25\n",
      "265/265 - 5s - loss: 0.1724 - accuracy: 0.9358 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1612 - accuracy: 0.9409\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1735 - accuracy: 0.9361\n",
      "\n",
      "Epoch:  26\n",
      "265/265 - 5s - loss: 0.1661 - accuracy: 0.9387 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1541 - accuracy: 0.9435\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1659 - accuracy: 0.9379\n",
      "\n",
      "Epoch:  27\n",
      "265/265 - 5s - loss: 0.1599 - accuracy: 0.9415 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1584 - accuracy: 0.9416\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1701 - accuracy: 0.9343\n",
      "\n",
      "Epoch:  28\n",
      "265/265 - 5s - loss: 0.1556 - accuracy: 0.9420 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1606 - accuracy: 0.9390\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1718 - accuracy: 0.9356\n",
      "\n",
      "Epoch:  29\n",
      "265/265 - 5s - loss: 0.1571 - accuracy: 0.9404 - 5s/epoch - 20ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1541 - accuracy: 0.9432\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1655 - accuracy: 0.9387\n",
      "\n",
      "Epoch:  30\n",
      "265/265 - 5s - loss: 0.1521 - accuracy: 0.9434 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1422 - accuracy: 0.9495\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1530 - accuracy: 0.9433\n",
      "\n",
      "Epoch:  31\n",
      "265/265 - 5s - loss: 0.1516 - accuracy: 0.9431 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1481 - accuracy: 0.9438\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1587 - accuracy: 0.9386\n",
      "\n",
      "Epoch:  32\n",
      "265/265 - 5s - loss: 0.1482 - accuracy: 0.9462 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1494 - accuracy: 0.9426\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1608 - accuracy: 0.9372\n",
      "\n",
      "Epoch:  33\n",
      "265/265 - 5s - loss: 0.1430 - accuracy: 0.9476 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1357 - accuracy: 0.9507\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1463 - accuracy: 0.9449\n",
      "\n",
      "Epoch:  34\n",
      "265/265 - 5s - loss: 0.1413 - accuracy: 0.9483 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1758 - accuracy: 0.9306\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1884 - accuracy: 0.9256\n",
      "\n",
      "Epoch:  35\n",
      "265/265 - 5s - loss: 0.1418 - accuracy: 0.9467 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1361 - accuracy: 0.9491\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1473 - accuracy: 0.9440\n",
      "\n",
      "Epoch:  36\n",
      "265/265 - 5s - loss: 0.1369 - accuracy: 0.9493 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1531 - accuracy: 0.9412\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1687 - accuracy: 0.9338\n",
      "\n",
      "Epoch:  37\n",
      "265/265 - 5s - loss: 0.1341 - accuracy: 0.9507 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1351 - accuracy: 0.9492\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1455 - accuracy: 0.9449\n",
      "\n",
      "Epoch:  38\n",
      "265/265 - 5s - loss: 0.1335 - accuracy: 0.9506 - 5s/epoch - 19ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1252 - accuracy: 0.9543\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1361 - accuracy: 0.9487\n",
      "\n",
      "Epoch:  39\n",
      "265/265 - 5s - loss: 0.1305 - accuracy: 0.9515 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1225 - accuracy: 0.9558\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1319 - accuracy: 0.9513\n",
      "\n",
      "Epoch:  40\n",
      "265/265 - 5s - loss: 0.1288 - accuracy: 0.9518 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1184 - accuracy: 0.9574\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1283 - accuracy: 0.9525\n",
      "\n",
      "Epoch:  41\n",
      "265/265 - 5s - loss: 0.1276 - accuracy: 0.9522 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1238 - accuracy: 0.9547\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1341 - accuracy: 0.9500\n",
      "\n",
      "Epoch:  42\n",
      "265/265 - 5s - loss: 0.1228 - accuracy: 0.9552 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1195 - accuracy: 0.9565\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1294 - accuracy: 0.9503\n",
      "\n",
      "Epoch:  43\n",
      "265/265 - 5s - loss: 0.1237 - accuracy: 0.9539 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1416 - accuracy: 0.9433\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1521 - accuracy: 0.9404\n",
      "\n",
      "Epoch:  44\n",
      "265/265 - 5s - loss: 0.1209 - accuracy: 0.9551 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1144 - accuracy: 0.9570\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1243 - accuracy: 0.9541\n",
      "\n",
      "Epoch:  45\n",
      "265/265 - 5s - loss: 0.1238 - accuracy: 0.9545 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1387 - accuracy: 0.9501\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1482 - accuracy: 0.9437\n",
      "\n",
      "Epoch:  46\n",
      "265/265 - 5s - loss: 0.1183 - accuracy: 0.9562 - 5s/epoch - 19ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1142 - accuracy: 0.9602\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1237 - accuracy: 0.9549\n",
      "\n",
      "Epoch:  47\n",
      "265/265 - 5s - loss: 0.1139 - accuracy: 0.9585 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1113 - accuracy: 0.9591\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1208 - accuracy: 0.9550\n",
      "\n",
      "Epoch:  48\n",
      "265/265 - 5s - loss: 0.1173 - accuracy: 0.9563 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1243 - accuracy: 0.9537\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1376 - accuracy: 0.9462\n",
      "\n",
      "Epoch:  49\n",
      "265/265 - 5s - loss: 0.1170 - accuracy: 0.9568 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1145 - accuracy: 0.9585\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1267 - accuracy: 0.9519\n",
      "\n",
      "Epoch:  50\n",
      "265/265 - 5s - loss: 0.1099 - accuracy: 0.9600 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1052 - accuracy: 0.9621\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1156 - accuracy: 0.9581\n",
      "\n",
      "Epoch:  51\n",
      "265/265 - 5s - loss: 0.1125 - accuracy: 0.9582 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1098 - accuracy: 0.9606\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1203 - accuracy: 0.9547\n",
      "\n",
      "Epoch:  52\n",
      "265/265 - 5s - loss: 0.1084 - accuracy: 0.9599 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0981 - accuracy: 0.9651\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1062 - accuracy: 0.9615\n",
      "\n",
      "Epoch:  53\n",
      "265/265 - 5s - loss: 0.1049 - accuracy: 0.9621 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.1056 - accuracy: 0.9605\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1167 - accuracy: 0.9562\n",
      "\n",
      "Epoch:  54\n",
      "265/265 - 5s - loss: 0.1017 - accuracy: 0.9638 - 5s/epoch - 19ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0941 - accuracy: 0.9668\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1026 - accuracy: 0.9627\n",
      "\n",
      "Epoch:  55\n",
      "265/265 - 5s - loss: 0.1021 - accuracy: 0.9627 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0978 - accuracy: 0.9663\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1056 - accuracy: 0.9623\n",
      "\n",
      "Epoch:  56\n",
      "265/265 - 5s - loss: 0.0985 - accuracy: 0.9649 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1038 - accuracy: 0.9629\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1148 - accuracy: 0.9585\n",
      "\n",
      "Epoch:  57\n",
      "265/265 - 6s - loss: 0.1035 - accuracy: 0.9618 - 6s/epoch - 22ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0900 - accuracy: 0.9689\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0991 - accuracy: 0.9652\n",
      "\n",
      "Epoch:  58\n",
      "265/265 - 5s - loss: 0.0986 - accuracy: 0.9649 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0946 - accuracy: 0.9646\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1049 - accuracy: 0.9610\n",
      "\n",
      "Epoch:  59\n",
      "265/265 - 5s - loss: 0.0931 - accuracy: 0.9672 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0890 - accuracy: 0.9680\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0967 - accuracy: 0.9652\n",
      "\n",
      "Epoch:  60\n",
      "265/265 - 5s - loss: 0.0917 - accuracy: 0.9680 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0860 - accuracy: 0.9690\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0953 - accuracy: 0.9671\n",
      "\n",
      "Epoch:  61\n",
      "265/265 - 5s - loss: 0.0903 - accuracy: 0.9672 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1483 - accuracy: 0.9434\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1575 - accuracy: 0.9388\n",
      "\n",
      "Epoch:  62\n",
      "265/265 - 5s - loss: 0.0890 - accuracy: 0.9674 - 5s/epoch - 19ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0822 - accuracy: 0.9709\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0893 - accuracy: 0.9669\n",
      "\n",
      "Epoch:  63\n",
      "265/265 - 5s - loss: 0.0861 - accuracy: 0.9692 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0764 - accuracy: 0.9749\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0838 - accuracy: 0.9720\n",
      "\n",
      "Epoch:  64\n",
      "265/265 - 5s - loss: 0.0830 - accuracy: 0.9705 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0833 - accuracy: 0.9690\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0920 - accuracy: 0.9669\n",
      "\n",
      "Epoch:  65\n",
      "265/265 - 5s - loss: 0.0827 - accuracy: 0.9701 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0797 - accuracy: 0.9726\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0890 - accuracy: 0.9688\n",
      "\n",
      "Epoch:  66\n",
      "265/265 - 5s - loss: 0.0825 - accuracy: 0.9697 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0810 - accuracy: 0.9723\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0865 - accuracy: 0.9706\n",
      "\n",
      "Epoch:  67\n",
      "265/265 - 5s - loss: 0.0797 - accuracy: 0.9718 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0961 - accuracy: 0.9639\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1016 - accuracy: 0.9617\n",
      "\n",
      "Epoch:  68\n",
      "265/265 - 5s - loss: 0.0783 - accuracy: 0.9726 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0685 - accuracy: 0.9766\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0756 - accuracy: 0.9745\n",
      "\n",
      "Epoch:  69\n",
      "265/265 - 5s - loss: 0.0771 - accuracy: 0.9721 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0688 - accuracy: 0.9767\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0753 - accuracy: 0.9741\n",
      "\n",
      "Epoch:  70\n",
      "265/265 - 5s - loss: 0.0780 - accuracy: 0.9715 - 5s/epoch - 19ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0909 - accuracy: 0.9651\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0974 - accuracy: 0.9600\n",
      "\n",
      "Epoch:  71\n",
      "265/265 - 5s - loss: 0.0746 - accuracy: 0.9737 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0698 - accuracy: 0.9756\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0777 - accuracy: 0.9722\n",
      "\n",
      "Epoch:  72\n",
      "265/265 - 5s - loss: 0.0739 - accuracy: 0.9743 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0640 - accuracy: 0.9779\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0699 - accuracy: 0.9756\n",
      "\n",
      "Epoch:  73\n",
      "265/265 - 5s - loss: 0.0734 - accuracy: 0.9728 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0999 - accuracy: 0.9631\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.1103 - accuracy: 0.9589\n",
      "\n",
      "Epoch:  74\n",
      "265/265 - 5s - loss: 0.0709 - accuracy: 0.9749 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0603 - accuracy: 0.9800\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0675 - accuracy: 0.9772\n",
      "\n",
      "Epoch:  75\n",
      "265/265 - 5s - loss: 0.0662 - accuracy: 0.9762 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0775 - accuracy: 0.9709\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0840 - accuracy: 0.9689\n",
      "\n",
      "Epoch:  76\n",
      "265/265 - 5s - loss: 0.0683 - accuracy: 0.9761 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0819 - accuracy: 0.9707\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0904 - accuracy: 0.9666\n",
      "\n",
      "Epoch:  77\n",
      "265/265 - 5s - loss: 0.0689 - accuracy: 0.9750 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0675 - accuracy: 0.9763\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0739 - accuracy: 0.9730\n",
      "\n",
      "Epoch:  78\n",
      "265/265 - 5s - loss: 0.0666 - accuracy: 0.9763 - 5s/epoch - 19ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0767 - accuracy: 0.9712\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0828 - accuracy: 0.9692\n",
      "\n",
      "Epoch:  79\n",
      "265/265 - 5s - loss: 0.0649 - accuracy: 0.9765 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0585 - accuracy: 0.9789\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0647 - accuracy: 0.9766\n",
      "\n",
      "Epoch:  80\n",
      "265/265 - 6s - loss: 0.0663 - accuracy: 0.9763 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0655 - accuracy: 0.9777\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0731 - accuracy: 0.9750\n",
      "\n",
      "Epoch:  81\n",
      "265/265 - 5s - loss: 0.0618 - accuracy: 0.9785 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0648 - accuracy: 0.9775\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0710 - accuracy: 0.9756\n",
      "\n",
      "Epoch:  82\n",
      "265/265 - 5s - loss: 0.0611 - accuracy: 0.9777 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0534 - accuracy: 0.9818\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0602 - accuracy: 0.9792\n",
      "\n",
      "Epoch:  83\n",
      "265/265 - 5s - loss: 0.0620 - accuracy: 0.9779 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0578 - accuracy: 0.9805\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0660 - accuracy: 0.9783\n",
      "\n",
      "Epoch:  84\n",
      "265/265 - 6s - loss: 0.0631 - accuracy: 0.9779 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0646 - accuracy: 0.9753\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0714 - accuracy: 0.9728\n",
      "\n",
      "Epoch:  85\n",
      "265/265 - 5s - loss: 0.0603 - accuracy: 0.9786 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0512 - accuracy: 0.9826\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0573 - accuracy: 0.9802\n",
      "\n",
      "Epoch:  86\n",
      "265/265 - 5s - loss: 0.0603 - accuracy: 0.9779 - 5s/epoch - 19ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0538 - accuracy: 0.9805\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0604 - accuracy: 0.9787\n",
      "\n",
      "Epoch:  87\n",
      "265/265 - 5s - loss: 0.0565 - accuracy: 0.9799 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0513 - accuracy: 0.9817\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0586 - accuracy: 0.9797\n",
      "\n",
      "Epoch:  88\n",
      "265/265 - 5s - loss: 0.0565 - accuracy: 0.9795 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0510 - accuracy: 0.9820\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0563 - accuracy: 0.9802\n",
      "\n",
      "Epoch:  89\n",
      "265/265 - 5s - loss: 0.0531 - accuracy: 0.9813 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0495 - accuracy: 0.9822\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0555 - accuracy: 0.9806\n",
      "\n",
      "Epoch:  90\n",
      "265/265 - 5s - loss: 0.0546 - accuracy: 0.9803 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0494 - accuracy: 0.9825\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0554 - accuracy: 0.9810\n",
      "\n",
      "Epoch:  91\n",
      "265/265 - 5s - loss: 0.0564 - accuracy: 0.9794 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0471 - accuracy: 0.9844\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0539 - accuracy: 0.9821\n",
      "\n",
      "Epoch:  92\n",
      "265/265 - 5s - loss: 0.0580 - accuracy: 0.9800 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0561 - accuracy: 0.9804\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0637 - accuracy: 0.9774\n",
      "\n",
      "Epoch:  93\n",
      "265/265 - 5s - loss: 0.0561 - accuracy: 0.9801 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0588 - accuracy: 0.9782\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0652 - accuracy: 0.9767\n",
      "\n",
      "Epoch:  94\n",
      "265/265 - 5s - loss: 0.0546 - accuracy: 0.9805 - 5s/epoch - 19ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0480 - accuracy: 0.9833\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0538 - accuracy: 0.9824\n",
      "\n",
      "Epoch:  95\n",
      "265/265 - 5s - loss: 0.0519 - accuracy: 0.9814 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0500 - accuracy: 0.9820\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0564 - accuracy: 0.9804\n",
      "\n",
      "Epoch:  96\n",
      "265/265 - 5s - loss: 0.0553 - accuracy: 0.9805 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0631 - accuracy: 0.9763\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0705 - accuracy: 0.9750\n",
      "\n",
      "Epoch:  97\n",
      "265/265 - 5s - loss: 0.0520 - accuracy: 0.9815 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0436 - accuracy: 0.9848\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0493 - accuracy: 0.9830\n",
      "\n",
      "Epoch:  98\n",
      "265/265 - 5s - loss: 0.0502 - accuracy: 0.9825 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0544 - accuracy: 0.9801\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0609 - accuracy: 0.9782\n",
      "\n",
      "Epoch:  99\n",
      "265/265 - 5s - loss: 0.0504 - accuracy: 0.9819 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0527 - accuracy: 0.9819\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0583 - accuracy: 0.9799\n",
      "\n",
      "Epoch:  100\n",
      "265/265 - 5s - loss: 0.0532 - accuracy: 0.9804 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0456 - accuracy: 0.9837\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0519 - accuracy: 0.9828\n",
      "\n",
      "Epoch:  101\n",
      "265/265 - 5s - loss: 0.0479 - accuracy: 0.9833 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0440 - accuracy: 0.9842\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0512 - accuracy: 0.9819\n",
      "\n",
      "Epoch:  102\n",
      "265/265 - 5s - loss: 0.0511 - accuracy: 0.9815 - 5s/epoch - 19ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0415 - accuracy: 0.9859\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9838\n",
      "\n",
      "Epoch:  103\n",
      "265/265 - 5s - loss: 0.0486 - accuracy: 0.9826 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0443 - accuracy: 0.9844\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0525 - accuracy: 0.9817\n",
      "\n",
      "Epoch:  104\n",
      "265/265 - 5s - loss: 0.0498 - accuracy: 0.9821 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0446 - accuracy: 0.9837\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0506 - accuracy: 0.9824\n",
      "\n",
      "Epoch:  105\n",
      "265/265 - 5s - loss: 0.0483 - accuracy: 0.9826 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0720 - accuracy: 0.9740\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0800 - accuracy: 0.9702\n",
      "\n",
      "Epoch:  106\n",
      "265/265 - 5s - loss: 0.0482 - accuracy: 0.9827 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0677 - accuracy: 0.9738\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0741 - accuracy: 0.9720\n",
      "\n",
      "Epoch:  107\n",
      "265/265 - 5s - loss: 0.0502 - accuracy: 0.9818 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0517 - accuracy: 0.9810\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0588 - accuracy: 0.9789\n",
      "\n",
      "Epoch:  108\n",
      "265/265 - 6s - loss: 0.0499 - accuracy: 0.9815 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0418 - accuracy: 0.9851\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0484 - accuracy: 0.9826\n",
      "\n",
      "Epoch:  109\n",
      "265/265 - 5s - loss: 0.0453 - accuracy: 0.9837 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0461 - accuracy: 0.9834\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0540 - accuracy: 0.9826\n",
      "\n",
      "Epoch:  110\n",
      "265/265 - 5s - loss: 0.0495 - accuracy: 0.9821 - 5s/epoch - 19ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0397 - accuracy: 0.9862\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9857\n",
      "\n",
      "Epoch:  111\n",
      "265/265 - 5s - loss: 0.0458 - accuracy: 0.9842 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0409 - accuracy: 0.9865\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0460 - accuracy: 0.9844\n",
      "\n",
      "Epoch:  112\n",
      "265/265 - 5s - loss: 0.0469 - accuracy: 0.9823 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0509 - accuracy: 0.9823\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0577 - accuracy: 0.9798\n",
      "\n",
      "Epoch:  113\n",
      "265/265 - 5s - loss: 0.0475 - accuracy: 0.9832 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0546 - accuracy: 0.9795\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0607 - accuracy: 0.9791\n",
      "\n",
      "Epoch:  114\n",
      "265/265 - 5s - loss: 0.0488 - accuracy: 0.9821 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0492 - accuracy: 0.9825\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0552 - accuracy: 0.9798\n",
      "\n",
      "Epoch:  115\n",
      "265/265 - 5s - loss: 0.0472 - accuracy: 0.9824 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0520 - accuracy: 0.9808\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0592 - accuracy: 0.9792\n",
      "\n",
      "Epoch:  116\n",
      "265/265 - 5s - loss: 0.0489 - accuracy: 0.9823 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0404 - accuracy: 0.9857\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0460 - accuracy: 0.9843\n",
      "\n",
      "Epoch:  117\n",
      "265/265 - 5s - loss: 0.0439 - accuracy: 0.9837 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0421 - accuracy: 0.9851\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0484 - accuracy: 0.9831\n",
      "\n",
      "Epoch:  118\n",
      "265/265 - 5s - loss: 0.0448 - accuracy: 0.9841 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0399 - accuracy: 0.9854\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0461 - accuracy: 0.9839\n",
      "\n",
      "Epoch:  119\n",
      "265/265 - 5s - loss: 0.0427 - accuracy: 0.9851 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0460 - accuracy: 0.9833\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0548 - accuracy: 0.9812\n",
      "\n",
      "Epoch:  120\n",
      "265/265 - 5s - loss: 0.0457 - accuracy: 0.9831 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0526 - accuracy: 0.9795\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0583 - accuracy: 0.9779\n",
      "\n",
      "Epoch:  121\n",
      "265/265 - 5s - loss: 0.0428 - accuracy: 0.9845 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0354 - accuracy: 0.9871\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0411 - accuracy: 0.9858\n",
      "\n",
      "Epoch:  122\n",
      "265/265 - 5s - loss: 0.0417 - accuracy: 0.9849 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0531 - accuracy: 0.9809\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0615 - accuracy: 0.9777\n",
      "\n",
      "Epoch:  123\n",
      "265/265 - 5s - loss: 0.0438 - accuracy: 0.9844 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0579 - accuracy: 0.9775\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0657 - accuracy: 0.9747\n",
      "\n",
      "Epoch:  124\n",
      "265/265 - 5s - loss: 0.0434 - accuracy: 0.9845 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0362 - accuracy: 0.9869\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0428 - accuracy: 0.9838\n",
      "\n",
      "Epoch:  125\n",
      "265/265 - 5s - loss: 0.0418 - accuracy: 0.9849 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0361 - accuracy: 0.9876\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0430 - accuracy: 0.9852\n",
      "\n",
      "Epoch:  126\n",
      "265/265 - 5s - loss: 0.0418 - accuracy: 0.9849 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0402 - accuracy: 0.9848\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0454 - accuracy: 0.9831\n",
      "\n",
      "Epoch:  127\n",
      "265/265 - 5s - loss: 0.0452 - accuracy: 0.9835 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0421 - accuracy: 0.9845\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0486 - accuracy: 0.9819\n",
      "\n",
      "Epoch:  128\n",
      "265/265 - 5s - loss: 0.0432 - accuracy: 0.9848 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0403 - accuracy: 0.9850\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0460 - accuracy: 0.9843\n",
      "\n",
      "Epoch:  129\n",
      "265/265 - 5s - loss: 0.0419 - accuracy: 0.9847 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0328 - accuracy: 0.9881\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0384 - accuracy: 0.9863\n",
      "\n",
      "Epoch:  130\n",
      "265/265 - 5s - loss: 0.0393 - accuracy: 0.9869 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0422 - accuracy: 0.9841\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0495 - accuracy: 0.9829\n",
      "\n",
      "Epoch:  131\n",
      "265/265 - 5s - loss: 0.0447 - accuracy: 0.9832 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0368 - accuracy: 0.9867\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0433 - accuracy: 0.9844\n",
      "\n",
      "Epoch:  132\n",
      "265/265 - 5s - loss: 0.0400 - accuracy: 0.9855 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0345 - accuracy: 0.9883\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0407 - accuracy: 0.9862\n",
      "\n",
      "Epoch:  133\n",
      "265/265 - 5s - loss: 0.0415 - accuracy: 0.9849 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0358 - accuracy: 0.9877\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0420 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  134\n",
      "265/265 - 5s - loss: 0.0416 - accuracy: 0.9848 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0334 - accuracy: 0.9877\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0393 - accuracy: 0.9858\n",
      "\n",
      "Epoch:  135\n",
      "265/265 - 5s - loss: 0.0420 - accuracy: 0.9844 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0313 - accuracy: 0.9887\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0384 - accuracy: 0.9861\n",
      "\n",
      "Epoch:  136\n",
      "265/265 - 6s - loss: 0.0398 - accuracy: 0.9852 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0369 - accuracy: 0.9868\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0426 - accuracy: 0.9852\n",
      "\n",
      "Epoch:  137\n",
      "265/265 - 5s - loss: 0.0422 - accuracy: 0.9851 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0357 - accuracy: 0.9873\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0436 - accuracy: 0.9842\n",
      "\n",
      "Epoch:  138\n",
      "265/265 - 5s - loss: 0.0395 - accuracy: 0.9854 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0333 - accuracy: 0.9878\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0396 - accuracy: 0.9867\n",
      "\n",
      "Epoch:  139\n",
      "265/265 - 5s - loss: 0.0389 - accuracy: 0.9855 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0347 - accuracy: 0.9879\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0418 - accuracy: 0.9862\n",
      "\n",
      "Epoch:  140\n",
      "265/265 - 5s - loss: 0.0379 - accuracy: 0.9859 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0308 - accuracy: 0.9890\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0375 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  141\n",
      "265/265 - 5s - loss: 0.0375 - accuracy: 0.9867 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0365 - accuracy: 0.9866\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0437 - accuracy: 0.9841\n",
      "\n",
      "Epoch:  142\n",
      "265/265 - 5s - loss: 0.0388 - accuracy: 0.9864 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0479 - accuracy: 0.9823\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0546 - accuracy: 0.9809\n",
      "\n",
      "Epoch:  143\n",
      "265/265 - 5s - loss: 0.0414 - accuracy: 0.9848 - 5s/epoch - 20ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0316 - accuracy: 0.9884\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0368 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  144\n",
      "265/265 - 5s - loss: 0.0350 - accuracy: 0.9871 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0301 - accuracy: 0.9893\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0367 - accuracy: 0.9871\n",
      "\n",
      "Epoch:  145\n",
      "265/265 - 5s - loss: 0.0387 - accuracy: 0.9858 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0297 - accuracy: 0.9890\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0367 - accuracy: 0.9871\n",
      "\n",
      "Epoch:  146\n",
      "265/265 - 5s - loss: 0.0389 - accuracy: 0.9862 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0342 - accuracy: 0.9879\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0408 - accuracy: 0.9857\n",
      "\n",
      "Epoch:  147\n",
      "265/265 - 5s - loss: 0.0430 - accuracy: 0.9837 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0340 - accuracy: 0.9879\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0414 - accuracy: 0.9870\n",
      "\n",
      "Epoch:  148\n",
      "265/265 - 5s - loss: 0.0361 - accuracy: 0.9875 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0298 - accuracy: 0.9894\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0386 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  149\n",
      "265/265 - 5s - loss: 0.0360 - accuracy: 0.9876 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0314 - accuracy: 0.9886\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0381 - accuracy: 0.9867\n",
      "\n",
      "Epoch:  150\n",
      "265/265 - 5s - loss: 0.0377 - accuracy: 0.9860 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0348 - accuracy: 0.9872\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0424 - accuracy: 0.9851\n",
      "\n",
      "Epoch:  151\n",
      "265/265 - 6s - loss: 0.0358 - accuracy: 0.9871 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0300 - accuracy: 0.9896\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0379 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  152\n",
      "265/265 - 5s - loss: 0.0384 - accuracy: 0.9860 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0329 - accuracy: 0.9884\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0404 - accuracy: 0.9855\n",
      "\n",
      "Epoch:  153\n",
      "265/265 - 5s - loss: 0.0416 - accuracy: 0.9842 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0337 - accuracy: 0.9874\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0396 - accuracy: 0.9863\n",
      "\n",
      "Epoch:  154\n",
      "265/265 - 5s - loss: 0.0370 - accuracy: 0.9861 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0721 - accuracy: 0.9730\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0810 - accuracy: 0.9715\n",
      "\n",
      "Epoch:  155\n",
      "265/265 - 5s - loss: 0.0365 - accuracy: 0.9865 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0293 - accuracy: 0.9895\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0358 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  156\n",
      "265/265 - 5s - loss: 0.0386 - accuracy: 0.9859 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0436 - accuracy: 0.9838\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0517 - accuracy: 0.9821\n",
      "\n",
      "Epoch:  157\n",
      "265/265 - 5s - loss: 0.0383 - accuracy: 0.9863 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0311 - accuracy: 0.9895\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0380 - accuracy: 0.9869\n",
      "\n",
      "Epoch:  158\n",
      "265/265 - 5s - loss: 0.0351 - accuracy: 0.9875 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0387 - accuracy: 0.9850\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0450 - accuracy: 0.9838\n",
      "\n",
      "Epoch:  159\n",
      "265/265 - 5s - loss: 0.0325 - accuracy: 0.9883 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0268 - accuracy: 0.9908\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0323 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  160\n",
      "265/265 - 5s - loss: 0.0321 - accuracy: 0.9881 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0438 - accuracy: 0.9838\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0490 - accuracy: 0.9819\n",
      "\n",
      "Epoch:  161\n",
      "265/265 - 5s - loss: 0.0392 - accuracy: 0.9855 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0273 - accuracy: 0.9899\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0336 - accuracy: 0.9889\n",
      "\n",
      "Epoch:  162\n",
      "265/265 - 5s - loss: 0.0354 - accuracy: 0.9873 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0304 - accuracy: 0.9890\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0371 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  163\n",
      "265/265 - 5s - loss: 0.0328 - accuracy: 0.9880 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0266 - accuracy: 0.9899\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0338 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  164\n",
      "265/265 - 6s - loss: 0.0380 - accuracy: 0.9864 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0354 - accuracy: 0.9875\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0415 - accuracy: 0.9851\n",
      "\n",
      "Epoch:  165\n",
      "265/265 - 5s - loss: 0.0342 - accuracy: 0.9877 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0274 - accuracy: 0.9898\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0348 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  166\n",
      "265/265 - 5s - loss: 0.0338 - accuracy: 0.9878 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0481 - accuracy: 0.9812\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0546 - accuracy: 0.9793\n",
      "\n",
      "Epoch:  167\n",
      "265/265 - 5s - loss: 0.0330 - accuracy: 0.9879 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0399 - accuracy: 0.9866\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0481 - accuracy: 0.9828\n",
      "\n",
      "Epoch:  168\n",
      "265/265 - 5s - loss: 0.0348 - accuracy: 0.9869 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0303 - accuracy: 0.9888\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0366 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  169\n",
      "265/265 - 5s - loss: 0.0321 - accuracy: 0.9885 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0325 - accuracy: 0.9890\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0388 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  170\n",
      "265/265 - 5s - loss: 0.0327 - accuracy: 0.9874 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0380 - accuracy: 0.9859\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0454 - accuracy: 0.9830\n",
      "\n",
      "Epoch:  171\n",
      "265/265 - 5s - loss: 0.0374 - accuracy: 0.9864 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0478 - accuracy: 0.9818\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0553 - accuracy: 0.9815\n",
      "\n",
      "Epoch:  172\n",
      "265/265 - 5s - loss: 0.0343 - accuracy: 0.9875 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0255 - accuracy: 0.9915\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0332 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  173\n",
      "265/265 - 5s - loss: 0.0326 - accuracy: 0.9879 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0286 - accuracy: 0.9900\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0356 - accuracy: 0.9875\n",
      "\n",
      "Epoch:  174\n",
      "265/265 - 5s - loss: 0.0304 - accuracy: 0.9893 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0360 - accuracy: 0.9863\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0420 - accuracy: 0.9857\n",
      "\n",
      "Epoch:  175\n",
      "265/265 - 5s - loss: 0.0345 - accuracy: 0.9874 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0244 - accuracy: 0.9910\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  176\n",
      "265/265 - 5s - loss: 0.0300 - accuracy: 0.9888 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0365 - accuracy: 0.9864\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0422 - accuracy: 0.9854\n",
      "\n",
      "Epoch:  177\n",
      "265/265 - 5s - loss: 0.0359 - accuracy: 0.9864 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0267 - accuracy: 0.9903\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0337 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  178\n",
      "265/265 - 6s - loss: 0.0364 - accuracy: 0.9865 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0283 - accuracy: 0.9896\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0357 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  179\n",
      "265/265 - 5s - loss: 0.0336 - accuracy: 0.9877 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0297 - accuracy: 0.9888\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0354 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  180\n",
      "265/265 - 5s - loss: 0.0316 - accuracy: 0.9885 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0274 - accuracy: 0.9905\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0349 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  181\n",
      "265/265 - 5s - loss: 0.0336 - accuracy: 0.9872 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0288 - accuracy: 0.9891\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0355 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  182\n",
      "265/265 - 5s - loss: 0.0329 - accuracy: 0.9878 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0252 - accuracy: 0.9915\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  183\n",
      "265/265 - 5s - loss: 0.0304 - accuracy: 0.9895 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0273 - accuracy: 0.9908\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0342 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  184\n",
      "265/265 - 5s - loss: 0.0279 - accuracy: 0.9901 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0250 - accuracy: 0.9910\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0320 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  185\n",
      "265/265 - 5s - loss: 0.0328 - accuracy: 0.9880 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0246 - accuracy: 0.9912\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0304 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  186\n",
      "265/265 - 5s - loss: 0.0302 - accuracy: 0.9894 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0288 - accuracy: 0.9897\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0349 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  187\n",
      "265/265 - 5s - loss: 0.0314 - accuracy: 0.9885 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0488 - accuracy: 0.9819\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0543 - accuracy: 0.9809\n",
      "\n",
      "Epoch:  188\n",
      "265/265 - 5s - loss: 0.0301 - accuracy: 0.9892 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0230 - accuracy: 0.9916\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0299 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  189\n",
      "265/265 - 6s - loss: 0.0316 - accuracy: 0.9885 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0235 - accuracy: 0.9917\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  190\n",
      "265/265 - 5s - loss: 0.0296 - accuracy: 0.9891 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0256 - accuracy: 0.9911\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0331 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  191\n",
      "265/265 - 6s - loss: 0.0314 - accuracy: 0.9882 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0398 - accuracy: 0.9862\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0474 - accuracy: 0.9835\n",
      "\n",
      "Epoch:  192\n",
      "265/265 - 5s - loss: 0.0294 - accuracy: 0.9895 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0298 - accuracy: 0.9890\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0362 - accuracy: 0.9875\n",
      "\n",
      "Epoch:  193\n",
      "265/265 - 5s - loss: 0.0313 - accuracy: 0.9890 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0250 - accuracy: 0.9909\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0308 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  194\n",
      "265/265 - 5s - loss: 0.0302 - accuracy: 0.9891 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0261 - accuracy: 0.9913\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0334 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  195\n",
      "265/265 - 5s - loss: 0.0291 - accuracy: 0.9895 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0225 - accuracy: 0.9924\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0278 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  196\n",
      "265/265 - 6s - loss: 0.0291 - accuracy: 0.9892 - 6s/epoch - 22ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0354 - accuracy: 0.9871\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0429 - accuracy: 0.9843\n",
      "\n",
      "Epoch:  197\n",
      "265/265 - 6s - loss: 0.0313 - accuracy: 0.9886 - 6s/epoch - 22ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0282 - accuracy: 0.9901\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  198\n",
      "265/265 - 6s - loss: 0.0274 - accuracy: 0.9902 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0253 - accuracy: 0.9906\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0319 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  199\n",
      "265/265 - 5s - loss: 0.0310 - accuracy: 0.9891 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0366 - accuracy: 0.9869\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0431 - accuracy: 0.9844\n",
      "\n",
      "Epoch:  200\n",
      "265/265 - 5s - loss: 0.0299 - accuracy: 0.9893 - 5s/epoch - 20ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0240 - accuracy: 0.9904\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9889\n",
      "\n",
      "Epoch:  201\n",
      "265/265 - 5s - loss: 0.0318 - accuracy: 0.9880 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0248 - accuracy: 0.9912\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0312 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  202\n",
      "265/265 - 5s - loss: 0.0272 - accuracy: 0.9900 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0413 - accuracy: 0.9842\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0486 - accuracy: 0.9836\n",
      "\n",
      "Epoch:  203\n",
      "265/265 - 5s - loss: 0.0300 - accuracy: 0.9886 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0310 - accuracy: 0.9887\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0397 - accuracy: 0.9858\n",
      "\n",
      "Epoch:  204\n",
      "265/265 - 5s - loss: 0.0263 - accuracy: 0.9904 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0234 - accuracy: 0.9920\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0294 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  205\n",
      "265/265 - 5s - loss: 0.0324 - accuracy: 0.9883 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0224 - accuracy: 0.9916\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0288 - accuracy: 0.9904\n",
      "\n",
      "Epoch:  206\n",
      "265/265 - 5s - loss: 0.0280 - accuracy: 0.9896 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0228 - accuracy: 0.9920\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0294 - accuracy: 0.9904\n",
      "\n",
      "Epoch:  207\n",
      "265/265 - 5s - loss: 0.0309 - accuracy: 0.9886 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0368 - accuracy: 0.9864\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0428 - accuracy: 0.9843\n",
      "\n",
      "Epoch:  208\n",
      "265/265 - 5s - loss: 0.0295 - accuracy: 0.9895 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0223 - accuracy: 0.9921\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  209\n",
      "265/265 - 5s - loss: 0.0273 - accuracy: 0.9899 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0242 - accuracy: 0.9913\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0310 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  210\n",
      "265/265 - 5s - loss: 0.0278 - accuracy: 0.9900 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0430 - accuracy: 0.9840\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0530 - accuracy: 0.9812\n",
      "\n",
      "Epoch:  211\n",
      "265/265 - 5s - loss: 0.0263 - accuracy: 0.9905 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0228 - accuracy: 0.9919\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  212\n",
      "265/265 - 5s - loss: 0.0283 - accuracy: 0.9898 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0297 - accuracy: 0.9894\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0381 - accuracy: 0.9859\n",
      "\n",
      "Epoch:  213\n",
      "265/265 - 5s - loss: 0.0278 - accuracy: 0.9900 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0261 - accuracy: 0.9903\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9877\n",
      "\n",
      "Epoch:  214\n",
      "265/265 - 5s - loss: 0.0290 - accuracy: 0.9897 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0269 - accuracy: 0.9898\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0354 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  215\n",
      "265/265 - 5s - loss: 0.0274 - accuracy: 0.9904 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0274 - accuracy: 0.9894\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0353 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  216\n",
      "265/265 - 5s - loss: 0.0302 - accuracy: 0.9893 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0219 - accuracy: 0.9927\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0291 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  217\n",
      "265/265 - 5s - loss: 0.0278 - accuracy: 0.9898 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0236 - accuracy: 0.9913\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0302 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  218\n",
      "265/265 - 5s - loss: 0.0280 - accuracy: 0.9903 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0228 - accuracy: 0.9916\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0314 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  219\n",
      "265/265 - 6s - loss: 0.0243 - accuracy: 0.9917 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0242 - accuracy: 0.9914\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0307 - accuracy: 0.9894\n",
      "\n",
      "Epoch:  220\n",
      "265/265 - 5s - loss: 0.0312 - accuracy: 0.9885 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0218 - accuracy: 0.9916\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0278 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  221\n",
      "265/265 - 5s - loss: 0.0249 - accuracy: 0.9909 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0306 - accuracy: 0.9890\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0378 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  222\n",
      "265/265 - 5s - loss: 0.0289 - accuracy: 0.9895 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0290 - accuracy: 0.9898\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0368 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  223\n",
      "265/265 - 5s - loss: 0.0288 - accuracy: 0.9894 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0230 - accuracy: 0.9923\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0313 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  224\n",
      "265/265 - 5s - loss: 0.0252 - accuracy: 0.9912 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0207 - accuracy: 0.9921\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0277 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  225\n",
      "265/265 - 5s - loss: 0.0272 - accuracy: 0.9905 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0288 - accuracy: 0.9901\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0377 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  226\n",
      "265/265 - 5s - loss: 0.0275 - accuracy: 0.9899 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0240 - accuracy: 0.9917\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  227\n",
      "265/265 - 5s - loss: 0.0255 - accuracy: 0.9907 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0200 - accuracy: 0.9929\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0273 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  228\n",
      "265/265 - 5s - loss: 0.0238 - accuracy: 0.9919 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0229 - accuracy: 0.9914\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  229\n",
      "265/265 - 5s - loss: 0.0268 - accuracy: 0.9900 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0209 - accuracy: 0.9925\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0282 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  230\n",
      "265/265 - 5s - loss: 0.0300 - accuracy: 0.9888 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0283 - accuracy: 0.9898\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0336 - accuracy: 0.9889\n",
      "\n",
      "Epoch:  231\n",
      "265/265 - 5s - loss: 0.0277 - accuracy: 0.9898 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0266 - accuracy: 0.9903\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0333 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  232\n",
      "265/265 - 5s - loss: 0.0283 - accuracy: 0.9896 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0234 - accuracy: 0.9919\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0320 - accuracy: 0.9889\n",
      "\n",
      "Epoch:  233\n",
      "265/265 - 5s - loss: 0.0265 - accuracy: 0.9900 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0201 - accuracy: 0.9928\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0275 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  234\n",
      "265/265 - 5s - loss: 0.0241 - accuracy: 0.9915 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0283 - accuracy: 0.9892\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0367 - accuracy: 0.9865\n",
      "\n",
      "Epoch:  235\n",
      "265/265 - 5s - loss: 0.0257 - accuracy: 0.9903 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0336 - accuracy: 0.9878\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0428 - accuracy: 0.9857\n",
      "\n",
      "Epoch:  236\n",
      "265/265 - 5s - loss: 0.0234 - accuracy: 0.9914 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0237 - accuracy: 0.9910\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  237\n",
      "265/265 - 5s - loss: 0.0241 - accuracy: 0.9911 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0225 - accuracy: 0.9918\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  238\n",
      "265/265 - 5s - loss: 0.0246 - accuracy: 0.9911 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0175 - accuracy: 0.9938\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0246 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  239\n",
      "265/265 - 5s - loss: 0.0260 - accuracy: 0.9903 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0171 - accuracy: 0.9943\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0251 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  240\n",
      "265/265 - 5s - loss: 0.0261 - accuracy: 0.9903 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0357 - accuracy: 0.9865\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0447 - accuracy: 0.9830\n",
      "\n",
      "Epoch:  241\n",
      "265/265 - 5s - loss: 0.0276 - accuracy: 0.9901 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0222 - accuracy: 0.9921\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0303 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  242\n",
      "265/265 - 5s - loss: 0.0246 - accuracy: 0.9911 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0217 - accuracy: 0.9924\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  243\n",
      "265/265 - 5s - loss: 0.0284 - accuracy: 0.9892 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0224 - accuracy: 0.9919\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0298 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  244\n",
      "265/265 - 5s - loss: 0.0233 - accuracy: 0.9916 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0225 - accuracy: 0.9917\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0298 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  245\n",
      "265/265 - 5s - loss: 0.0256 - accuracy: 0.9914 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0249 - accuracy: 0.9913\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0332 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  246\n",
      "265/265 - 5s - loss: 0.0263 - accuracy: 0.9901 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0195 - accuracy: 0.9930\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0276 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  247\n",
      "265/265 - 6s - loss: 0.0277 - accuracy: 0.9895 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0186 - accuracy: 0.9935\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0276 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  248\n",
      "265/265 - 5s - loss: 0.0247 - accuracy: 0.9906 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0195 - accuracy: 0.9932\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0269 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  249\n",
      "265/265 - 5s - loss: 0.0235 - accuracy: 0.9917 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0274 - accuracy: 0.9900\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0344 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  250\n",
      "265/265 - 5s - loss: 0.0261 - accuracy: 0.9907 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0206 - accuracy: 0.9929\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9902\n",
      "\n",
      "Epoch:  251\n",
      "265/265 - 5s - loss: 0.0233 - accuracy: 0.9914 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0300 - accuracy: 0.9893\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0363 - accuracy: 0.9877\n",
      "\n",
      "Epoch:  252\n",
      "265/265 - 5s - loss: 0.0253 - accuracy: 0.9908 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0216 - accuracy: 0.9926\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  253\n",
      "265/265 - 5s - loss: 0.0251 - accuracy: 0.9906 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0186 - accuracy: 0.9932\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0251 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  254\n",
      "265/265 - 5s - loss: 0.0226 - accuracy: 0.9918 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0344 - accuracy: 0.9866\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0449 - accuracy: 0.9841\n",
      "\n",
      "Epoch:  255\n",
      "265/265 - 5s - loss: 0.0263 - accuracy: 0.9903 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0166 - accuracy: 0.9942\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0249 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  256\n",
      "265/265 - 5s - loss: 0.0247 - accuracy: 0.9909 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0282 - accuracy: 0.9899\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0352 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  257\n",
      "265/265 - 5s - loss: 0.0276 - accuracy: 0.9902 - 5s/epoch - 20ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0179 - accuracy: 0.9937\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0244 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  258\n",
      "265/265 - 5s - loss: 0.0256 - accuracy: 0.9906 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0279 - accuracy: 0.9901\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0357 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  259\n",
      "265/265 - 5s - loss: 0.0253 - accuracy: 0.9909 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0190 - accuracy: 0.9933\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0268 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  260\n",
      "265/265 - 6s - loss: 0.0217 - accuracy: 0.9923 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0203 - accuracy: 0.9922\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  261\n",
      "265/265 - 5s - loss: 0.0233 - accuracy: 0.9918 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0158 - accuracy: 0.9944\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0235 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  262\n",
      "265/265 - 5s - loss: 0.0246 - accuracy: 0.9914 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0766 - accuracy: 0.9735\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0829 - accuracy: 0.9715\n",
      "\n",
      "Epoch:  263\n",
      "265/265 - 5s - loss: 0.0234 - accuracy: 0.9914 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0203 - accuracy: 0.9927\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0284 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  264\n",
      "265/265 - 5s - loss: 0.0247 - accuracy: 0.9908 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0176 - accuracy: 0.9934\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0244 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  265\n",
      "265/265 - 5s - loss: 0.0248 - accuracy: 0.9911 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0252 - accuracy: 0.9908\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0326 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  266\n",
      "265/265 - 5s - loss: 0.0229 - accuracy: 0.9914 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0199 - accuracy: 0.9930\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0293 - accuracy: 0.9904\n",
      "\n",
      "Epoch:  267\n",
      "265/265 - 5s - loss: 0.0247 - accuracy: 0.9913 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0177 - accuracy: 0.9941\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0256 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  268\n",
      "265/265 - 5s - loss: 0.0240 - accuracy: 0.9912 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0354 - accuracy: 0.9857\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0441 - accuracy: 0.9842\n",
      "\n",
      "Epoch:  269\n",
      "265/265 - 5s - loss: 0.0256 - accuracy: 0.9910 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0160 - accuracy: 0.9942\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0239 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  270\n",
      "265/265 - 5s - loss: 0.0219 - accuracy: 0.9920 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0177 - accuracy: 0.9938\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0250 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  271\n",
      "265/265 - 5s - loss: 0.0258 - accuracy: 0.9905 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0200 - accuracy: 0.9931\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0276 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  272\n",
      "265/265 - 5s - loss: 0.0238 - accuracy: 0.9909 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0172 - accuracy: 0.9940\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0248 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  273\n",
      "265/265 - 5s - loss: 0.0238 - accuracy: 0.9915 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0275 - accuracy: 0.9902\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0331 - accuracy: 0.9887\n",
      "\n",
      "Epoch:  274\n",
      "265/265 - 6s - loss: 0.0222 - accuracy: 0.9919 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0207 - accuracy: 0.9928\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0295 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  275\n",
      "265/265 - 5s - loss: 0.0255 - accuracy: 0.9907 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0201 - accuracy: 0.9928\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  276\n",
      "265/265 - 6s - loss: 0.0222 - accuracy: 0.9917 - 6s/epoch - 22ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0293 - accuracy: 0.9893\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0381 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  277\n",
      "265/265 - 5s - loss: 0.0241 - accuracy: 0.9907 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0306 - accuracy: 0.9891\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0392 - accuracy: 0.9856\n",
      "\n",
      "Epoch:  278\n",
      "265/265 - 5s - loss: 0.0209 - accuracy: 0.9925 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0417 - accuracy: 0.9829\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0508 - accuracy: 0.9823\n",
      "\n",
      "Epoch:  279\n",
      "265/265 - 6s - loss: 0.0213 - accuracy: 0.9921 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0205 - accuracy: 0.9920\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0282 - accuracy: 0.9902\n",
      "\n",
      "Epoch:  280\n",
      "265/265 - 5s - loss: 0.0194 - accuracy: 0.9934 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0183 - accuracy: 0.9932\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0248 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  281\n",
      "265/265 - 5s - loss: 0.0238 - accuracy: 0.9909 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0243 - accuracy: 0.9916\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9889\n",
      "\n",
      "Epoch:  282\n",
      "265/265 - 5s - loss: 0.0232 - accuracy: 0.9919 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0320 - accuracy: 0.9886\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0397 - accuracy: 0.9865\n",
      "\n",
      "Epoch:  283\n",
      "265/265 - 5s - loss: 0.0220 - accuracy: 0.9918 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0285 - accuracy: 0.9903\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0378 - accuracy: 0.9863\n",
      "\n",
      "Epoch:  284\n",
      "265/265 - 5s - loss: 0.0226 - accuracy: 0.9920 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0172 - accuracy: 0.9939\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0245 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  285\n",
      "265/265 - 5s - loss: 0.0225 - accuracy: 0.9916 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0164 - accuracy: 0.9941\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0235 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  286\n",
      "265/265 - 5s - loss: 0.0222 - accuracy: 0.9919 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0168 - accuracy: 0.9950\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  287\n",
      "265/265 - 5s - loss: 0.0222 - accuracy: 0.9924 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0163 - accuracy: 0.9941\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  288\n",
      "265/265 - 5s - loss: 0.0199 - accuracy: 0.9931 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0189 - accuracy: 0.9937\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0261 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  289\n",
      "265/265 - 5s - loss: 0.0226 - accuracy: 0.9917 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0223 - accuracy: 0.9913\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0318 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  290\n",
      "265/265 - 5s - loss: 0.0206 - accuracy: 0.9926 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0306 - accuracy: 0.9885\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0404 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  291\n",
      "265/265 - 5s - loss: 0.0270 - accuracy: 0.9904 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0197 - accuracy: 0.9934\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0263 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  292\n",
      "265/265 - 5s - loss: 0.0266 - accuracy: 0.9900 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0245 - accuracy: 0.9913\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0323 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  293\n",
      "265/265 - 5s - loss: 0.0211 - accuracy: 0.9924 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0204 - accuracy: 0.9932\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  294\n",
      "265/265 - 5s - loss: 0.0206 - accuracy: 0.9921 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0199 - accuracy: 0.9931\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0286 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  295\n",
      "265/265 - 5s - loss: 0.0197 - accuracy: 0.9927 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0151 - accuracy: 0.9947\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0239 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  296\n",
      "265/265 - 5s - loss: 0.0203 - accuracy: 0.9929 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0227 - accuracy: 0.9916\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0323 - accuracy: 0.9894\n",
      "\n",
      "Epoch:  297\n",
      "265/265 - 5s - loss: 0.0223 - accuracy: 0.9920 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0247 - accuracy: 0.9911\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0334 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  298\n",
      "265/265 - 5s - loss: 0.0220 - accuracy: 0.9923 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0342 - accuracy: 0.9875\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0415 - accuracy: 0.9850\n",
      "\n",
      "Epoch:  299\n",
      "265/265 - 5s - loss: 0.0216 - accuracy: 0.9924 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0200 - accuracy: 0.9930\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0286 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  300\n",
      "265/265 - 5s - loss: 0.0201 - accuracy: 0.9924 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0197 - accuracy: 0.9928\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0269 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  301\n",
      "265/265 - 5s - loss: 0.0222 - accuracy: 0.9920 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0207 - accuracy: 0.9921\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0294 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  302\n",
      "265/265 - 6s - loss: 0.0229 - accuracy: 0.9917 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0174 - accuracy: 0.9933\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0262 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  303\n",
      "265/265 - 5s - loss: 0.0211 - accuracy: 0.9919 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0170 - accuracy: 0.9943\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0255 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  304\n",
      "265/265 - 5s - loss: 0.0225 - accuracy: 0.9918 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0199 - accuracy: 0.9929\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0277 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  305\n",
      "265/265 - 5s - loss: 0.0202 - accuracy: 0.9922 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0400 - accuracy: 0.9866\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0475 - accuracy: 0.9832\n",
      "\n",
      "Epoch:  306\n",
      "265/265 - 6s - loss: 0.0222 - accuracy: 0.9921 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0227 - accuracy: 0.9913\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0313 - accuracy: 0.9887\n",
      "\n",
      "Epoch:  307\n",
      "265/265 - 5s - loss: 0.0189 - accuracy: 0.9933 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0512 - accuracy: 0.9804\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0596 - accuracy: 0.9793\n",
      "\n",
      "Epoch:  308\n",
      "265/265 - 5s - loss: 0.0213 - accuracy: 0.9922 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0504 - accuracy: 0.9834\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0565 - accuracy: 0.9804\n",
      "\n",
      "Epoch:  309\n",
      "265/265 - 5s - loss: 0.0219 - accuracy: 0.9921 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0194 - accuracy: 0.9926\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0264 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  310\n",
      "265/265 - 5s - loss: 0.0204 - accuracy: 0.9928 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0212 - accuracy: 0.9924\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0288 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  311\n",
      "265/265 - 5s - loss: 0.0206 - accuracy: 0.9928 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0158 - accuracy: 0.9945\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0242 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  312\n",
      "265/265 - 5s - loss: 0.0211 - accuracy: 0.9924 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0206 - accuracy: 0.9933\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0299 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  313\n",
      "265/265 - 5s - loss: 0.0218 - accuracy: 0.9924 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0241 - accuracy: 0.9900\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0353 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  314\n",
      "265/265 - 6s - loss: 0.0209 - accuracy: 0.9926 - 6s/epoch - 23ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0202 - accuracy: 0.9926\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0282 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  315\n",
      "265/265 - 5s - loss: 0.0211 - accuracy: 0.9923 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0212 - accuracy: 0.9927\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9904\n",
      "\n",
      "Epoch:  316\n",
      "265/265 - 5s - loss: 0.0215 - accuracy: 0.9922 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0185 - accuracy: 0.9939\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0286 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  317\n",
      "265/265 - 5s - loss: 0.0201 - accuracy: 0.9928 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0166 - accuracy: 0.9942\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0244 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  318\n",
      "265/265 - 6s - loss: 0.0253 - accuracy: 0.9906 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0227 - accuracy: 0.9919\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  319\n",
      "265/265 - 5s - loss: 0.0185 - accuracy: 0.9933 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0216 - accuracy: 0.9923\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0282 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  320\n",
      "265/265 - 5s - loss: 0.0176 - accuracy: 0.9940 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0183 - accuracy: 0.9937\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0269 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  321\n",
      "265/265 - 5s - loss: 0.0200 - accuracy: 0.9925 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0198 - accuracy: 0.9918\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0297 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  322\n",
      "265/265 - 5s - loss: 0.0227 - accuracy: 0.9918 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0205 - accuracy: 0.9924\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0287 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  323\n",
      "265/265 - 5s - loss: 0.0196 - accuracy: 0.9926 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0250 - accuracy: 0.9911\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0339 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  324\n",
      "265/265 - 5s - loss: 0.0197 - accuracy: 0.9928 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0151 - accuracy: 0.9950\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0234 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  325\n",
      "265/265 - 5s - loss: 0.0207 - accuracy: 0.9925 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0223 - accuracy: 0.9913\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0309 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  326\n",
      "265/265 - 5s - loss: 0.0236 - accuracy: 0.9910 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0162 - accuracy: 0.9944\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0247 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  327\n",
      "265/265 - 5s - loss: 0.0182 - accuracy: 0.9931 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0164 - accuracy: 0.9942\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0243 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  328\n",
      "265/265 - 5s - loss: 0.0216 - accuracy: 0.9924 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0162 - accuracy: 0.9946\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  329\n",
      "265/265 - 5s - loss: 0.0171 - accuracy: 0.9938 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0197 - accuracy: 0.9933\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0261 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  330\n",
      "265/265 - 5s - loss: 0.0215 - accuracy: 0.9920 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0139 - accuracy: 0.9951\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0227 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  331\n",
      "265/265 - 5s - loss: 0.0204 - accuracy: 0.9925 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0339 - accuracy: 0.9862\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9846\n",
      "\n",
      "Epoch:  332\n",
      "265/265 - 5s - loss: 0.0173 - accuracy: 0.9939 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0155 - accuracy: 0.9947\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0223 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  333\n",
      "265/265 - 5s - loss: 0.0177 - accuracy: 0.9936 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0209 - accuracy: 0.9920\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0291 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  334\n",
      "265/265 - 5s - loss: 0.0205 - accuracy: 0.9922 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0175 - accuracy: 0.9939\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0253 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  335\n",
      "265/265 - 5s - loss: 0.0172 - accuracy: 0.9934 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0267 - accuracy: 0.9904\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0364 - accuracy: 0.9870\n",
      "\n",
      "Epoch:  336\n",
      "265/265 - 5s - loss: 0.0188 - accuracy: 0.9931 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0191 - accuracy: 0.9928\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0253 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  337\n",
      "265/265 - 5s - loss: 0.0190 - accuracy: 0.9930 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0144 - accuracy: 0.9952\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0217 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  338\n",
      "265/265 - 5s - loss: 0.0183 - accuracy: 0.9931 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0131 - accuracy: 0.9951\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0212 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  339\n",
      "265/265 - 5s - loss: 0.0204 - accuracy: 0.9924 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0213 - accuracy: 0.9918\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0312 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  340\n",
      "265/265 - 5s - loss: 0.0240 - accuracy: 0.9909 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0164 - accuracy: 0.9946\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0246 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  341\n",
      "265/265 - 6s - loss: 0.0187 - accuracy: 0.9929 - 6s/epoch - 22ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0224 - accuracy: 0.9920\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0299 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  342\n",
      "265/265 - 5s - loss: 0.0185 - accuracy: 0.9931 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0195 - accuracy: 0.9928\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  343\n",
      "265/265 - 5s - loss: 0.0184 - accuracy: 0.9932 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0132 - accuracy: 0.9958\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0215 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  344\n",
      "265/265 - 5s - loss: 0.0196 - accuracy: 0.9926 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0128 - accuracy: 0.9958\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0222 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  345\n",
      "265/265 - 5s - loss: 0.0201 - accuracy: 0.9929 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0139 - accuracy: 0.9952\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0229 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  346\n",
      "265/265 - 6s - loss: 0.0178 - accuracy: 0.9938 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0310 - accuracy: 0.9877\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0405 - accuracy: 0.9859\n",
      "\n",
      "Epoch:  347\n",
      "265/265 - 5s - loss: 0.0196 - accuracy: 0.9932 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0141 - accuracy: 0.9944\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  348\n",
      "265/265 - 5s - loss: 0.0209 - accuracy: 0.9919 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0308 - accuracy: 0.9883\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0398 - accuracy: 0.9859\n",
      "\n",
      "Epoch:  349\n",
      "265/265 - 5s - loss: 0.0180 - accuracy: 0.9937 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0150 - accuracy: 0.9945\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0235 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  350\n",
      "265/265 - 5s - loss: 0.0195 - accuracy: 0.9933 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0142 - accuracy: 0.9948\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0235 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  351\n",
      "265/265 - 5s - loss: 0.0160 - accuracy: 0.9942 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0204 - accuracy: 0.9918\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0298 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  352\n",
      "265/265 - 5s - loss: 0.0186 - accuracy: 0.9933 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0257 - accuracy: 0.9900\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0351 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  353\n",
      "265/265 - 5s - loss: 0.0196 - accuracy: 0.9924 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0144 - accuracy: 0.9948\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0230 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  354\n",
      "265/265 - 5s - loss: 0.0184 - accuracy: 0.9934 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0121 - accuracy: 0.9961\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0206 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  355\n",
      "265/265 - 6s - loss: 0.0193 - accuracy: 0.9929 - 6s/epoch - 22ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0141 - accuracy: 0.9954\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0227 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  356\n",
      "265/265 - 5s - loss: 0.0171 - accuracy: 0.9940 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0139 - accuracy: 0.9950\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0212 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  357\n",
      "265/265 - 5s - loss: 0.0166 - accuracy: 0.9939 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0121 - accuracy: 0.9957\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0207 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  358\n",
      "265/265 - 5s - loss: 0.0163 - accuracy: 0.9941 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0231 - accuracy: 0.9918\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0316 - accuracy: 0.9889\n",
      "\n",
      "Epoch:  359\n",
      "265/265 - 5s - loss: 0.0161 - accuracy: 0.9943 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0150 - accuracy: 0.9950\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0238 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  360\n",
      "265/265 - 6s - loss: 0.0196 - accuracy: 0.9928 - 6s/epoch - 22ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0127 - accuracy: 0.9956\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0212 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  361\n",
      "265/265 - 6s - loss: 0.0163 - accuracy: 0.9943 - 6s/epoch - 22ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0137 - accuracy: 0.9953\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0224 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  362\n",
      "265/265 - 5s - loss: 0.0179 - accuracy: 0.9938 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0154 - accuracy: 0.9945\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  363\n",
      "265/265 - 5s - loss: 0.0155 - accuracy: 0.9946 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0127 - accuracy: 0.9960\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0218 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  364\n",
      "265/265 - 6s - loss: 0.0196 - accuracy: 0.9930 - 6s/epoch - 23ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0123 - accuracy: 0.9959\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0201 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  365\n",
      "265/265 - 6s - loss: 0.0182 - accuracy: 0.9932 - 6s/epoch - 22ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0161 - accuracy: 0.9939\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0233 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  366\n",
      "265/265 - 6s - loss: 0.0158 - accuracy: 0.9944 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0230 - accuracy: 0.9919\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0312 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  367\n",
      "265/265 - 6s - loss: 0.0205 - accuracy: 0.9925 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0144 - accuracy: 0.9949\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0230 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  368\n",
      "265/265 - 5s - loss: 0.0183 - accuracy: 0.9938 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0126 - accuracy: 0.9957\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0213 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  369\n",
      "265/265 - 5s - loss: 0.0158 - accuracy: 0.9947 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0156 - accuracy: 0.9942\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0228 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  370\n",
      "265/265 - 6s - loss: 0.0206 - accuracy: 0.9918 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0190 - accuracy: 0.9926\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0268 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  371\n",
      "265/265 - 6s - loss: 0.0175 - accuracy: 0.9938 - 6s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0194 - accuracy: 0.9928\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0256 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  372\n",
      "265/265 - 5s - loss: 0.0157 - accuracy: 0.9941 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0135 - accuracy: 0.9953\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0205 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  373\n",
      "265/265 - 5s - loss: 0.0171 - accuracy: 0.9940 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0143 - accuracy: 0.9943\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0236 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  374\n",
      "265/265 - 5s - loss: 0.0213 - accuracy: 0.9925 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0202 - accuracy: 0.9926\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0283 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  375\n",
      "265/265 - 5s - loss: 0.0177 - accuracy: 0.9936 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0224 - accuracy: 0.9920\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0295 - accuracy: 0.9887\n",
      "\n",
      "Epoch:  376\n",
      "265/265 - 5s - loss: 0.0192 - accuracy: 0.9932 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0152 - accuracy: 0.9945\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0252 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  377\n",
      "265/265 - 5s - loss: 0.0168 - accuracy: 0.9943 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0213 - accuracy: 0.9918\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0305 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  378\n",
      "265/265 - 5s - loss: 0.0147 - accuracy: 0.9946 - 5s/epoch - 20ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0116 - accuracy: 0.9963\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0203 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  379\n",
      "265/265 - 5s - loss: 0.0150 - accuracy: 0.9949 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0127 - accuracy: 0.9951\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0216 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  380\n",
      "265/265 - 5s - loss: 0.0171 - accuracy: 0.9942 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0164 - accuracy: 0.9944\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0257 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  381\n",
      "265/265 - 5s - loss: 0.0181 - accuracy: 0.9936 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0148 - accuracy: 0.9954\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0235 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  382\n",
      "265/265 - 5s - loss: 0.0193 - accuracy: 0.9925 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0192 - accuracy: 0.9930\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0270 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  383\n",
      "265/265 - 5s - loss: 0.0195 - accuracy: 0.9927 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0163 - accuracy: 0.9939\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  384\n",
      "265/265 - 6s - loss: 0.0170 - accuracy: 0.9935 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0110 - accuracy: 0.9967\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0188 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  385\n",
      "265/265 - 5s - loss: 0.0145 - accuracy: 0.9947 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0172 - accuracy: 0.9939\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0282 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  386\n",
      "265/265 - 6s - loss: 0.0181 - accuracy: 0.9933 - 6s/epoch - 24ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0117 - accuracy: 0.9961\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0204 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  387\n",
      "265/265 - 5s - loss: 0.0178 - accuracy: 0.9933 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0164 - accuracy: 0.9937\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0262 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  388\n",
      "265/265 - 6s - loss: 0.0164 - accuracy: 0.9939 - 6s/epoch - 22ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0115 - accuracy: 0.9961\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0200 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  389\n",
      "265/265 - 5s - loss: 0.0172 - accuracy: 0.9938 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0121 - accuracy: 0.9961\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  390\n",
      "265/265 - 5s - loss: 0.0166 - accuracy: 0.9940 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0197 - accuracy: 0.9924\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0287 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  391\n",
      "265/265 - 5s - loss: 0.0183 - accuracy: 0.9935 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0140 - accuracy: 0.9956\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0233 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  392\n",
      "265/265 - 6s - loss: 0.0163 - accuracy: 0.9941 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0116 - accuracy: 0.9960\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0195 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  393\n",
      "265/265 - 5s - loss: 0.0176 - accuracy: 0.9932 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0124 - accuracy: 0.9957\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0214 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  394\n",
      "265/265 - 5s - loss: 0.0193 - accuracy: 0.9931 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0184 - accuracy: 0.9933\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0285 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  395\n",
      "265/265 - 6s - loss: 0.0155 - accuracy: 0.9944 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0110 - accuracy: 0.9969\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0205 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  396\n",
      "265/265 - 5s - loss: 0.0154 - accuracy: 0.9948 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0121 - accuracy: 0.9956\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0214 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  397\n",
      "265/265 - 5s - loss: 0.0160 - accuracy: 0.9945 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0144 - accuracy: 0.9952\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0239 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  398\n",
      "265/265 - 5s - loss: 0.0150 - accuracy: 0.9947 - 5s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0154 - accuracy: 0.9941\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0256 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  399\n",
      "265/265 - 6s - loss: 0.0149 - accuracy: 0.9944 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0139 - accuracy: 0.9951\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0221 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  400\n",
      "265/265 - 6s - loss: 0.0154 - accuracy: 0.9944 - 6s/epoch - 21ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0190 - accuracy: 0.9924\n",
      "for testing\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9901\n"
     ]
    }
   ],
   "source": [
    "for x in range(400):\n",
    "    print(\"\\nEpoch: \",x+1)\n",
    "    history = model.fit(X_train ,y_train ,batch_size=BATCH_SIZE ,epochs=1, verbose=2, shuffle=True)\n",
    "    if history_dataframe.size == 0:\n",
    "        history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    else:\n",
    "        history_dataframe = pd.concat([history_dataframe,pd.DataFrame.from_dict(history.history)],axis=0,ignore_index=True)\n",
    "    \n",
    "    print(\"for training\")\n",
    "    train_eva.append(model.evaluate(X_train,y_train))\n",
    "    print(\"for testing\")\n",
    "    test_eva.append(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ec37c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.042062</td>\n",
       "      <td>0.438526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.937123</td>\n",
       "      <td>0.533896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.807215</td>\n",
       "      <td>0.642790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.627837</td>\n",
       "      <td>0.755551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.502582</td>\n",
       "      <td>0.801524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.015409</td>\n",
       "      <td>0.994833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.016019</td>\n",
       "      <td>0.994538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.014962</td>\n",
       "      <td>0.994744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.014857</td>\n",
       "      <td>0.994390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.015448</td>\n",
       "      <td>0.994420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy\n",
       "0    1.042062  0.438526\n",
       "1    0.937123  0.533896\n",
       "2    0.807215  0.642790\n",
       "3    0.627837  0.755551\n",
       "4    0.502582  0.801524\n",
       "..        ...       ...\n",
       "395  0.015409  0.994833\n",
       "396  0.016019  0.994538\n",
       "397  0.014962  0.994744\n",
       "398  0.014857  0.994390\n",
       "399  0.015448  0.994420\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c8463e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva_df = pd.DataFrame(train_eva,columns=['loss','accuracy'])\n",
    "test_eva_df = pd.DataFrame(test_eva,columns=['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "708b9560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(df,title,xlabel,ylabel,values=['loss'],legends=[]):\n",
    "    \n",
    "    for value in values:\n",
    "        epoch_count = range(1, len(df.index) + 1)\n",
    "        plt.plot(epoch_count, df[value].tolist())\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    if legends==[]:\n",
    "        legends = values\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35c781fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(train_eva_df,'Train','Epoch','Loss',['loss','accuracy'])\n",
    "plot_graph(test_eva_df,'Test','Epoch','Loss',['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bab450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
