{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c4fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35daa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6aebd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'wheat_21_var_3_species'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "554bc6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class filter_method(Enum):\n",
    "    none = 0\n",
    "    snv = 1\n",
    "    msc = 2\n",
    "    savgol = 3\n",
    "\n",
    "FILT = 1\n",
    "FILTER = filter_method(FILT).name\n",
    "\n",
    "# to be set if filter chosen is savgol\n",
    "WINDOW = 7\n",
    "ORDER = 2\n",
    "DERIVATIVE = 1\n",
    "\n",
    "#will be used for test dataset in msc\n",
    "reference= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e7741c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_file_name(file_name):\n",
    "    name = \"./dataset/\"+str(file_name)\n",
    "    if FILT != 0:\n",
    "        name+=\"_FILTER_\"+str(FILTER)\n",
    "    if FILTER == \"savgol\":\n",
    "        name+=\"_WINDOW_\"+str(WINDOW)+\"_ORDER_\"+str(ORDER)+\"_DERIVATIVE_\"+str(DERIVATIVE)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b97b8927",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILE_NAME = dataset_file_name(file_name)\n",
    "X_train_file = DATASET_FILE_NAME+\"_train_dataset.npy\"\n",
    "y_train_file = DATASET_FILE_NAME+\"_train_dataset_label.npy\"\n",
    "X_test_file = DATASET_FILE_NAME+\"_test_dataset.npy\"\n",
    "y_test_file = DATASET_FILE_NAME+\"_test_dataset_label.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8dec1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =  np.load(X_train_file)\n",
    "y_train =  np.load(y_train_file)\n",
    "X_test  =  np.load(X_test_file)\n",
    "y_test  =  np.load(y_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58535347",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_set = set(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e8c8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_CLASSES = len(y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89f78cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33868, 147, 1)\n",
      "(8468, 147, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55a78e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Input, Conv1D, Flatten, Dense, MaxPooling1D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba682707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(input_shape,num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=5, input_shape=input_shape,activation='LeakyReLU'))\n",
    "    model.add(MaxPooling1D(pool_size=5 ))\n",
    "    model.add(Conv1D(filters=64, kernel_size=5, activation='LeakyReLU'))\n",
    "    model.add(MaxPooling1D(pool_size=5 ))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(800, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(400, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6a3400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(X_train.shape[1:],NUM_OF_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2a7d43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 143, 32)           192       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 28, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 24, 64)            10304     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 4, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              257000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 800)               800800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 400)               320400    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 1203      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,389,899\n",
      "Trainable params: 1,389,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34d6bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva = []\n",
    "test_eva = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fd5eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dataframe = pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "863f63f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  1\n",
      "199/199 - 12s - loss: 1.0894 - accuracy: 0.3750 - val_loss: 1.0417 - val_accuracy: 0.4721 - 12s/epoch - 63ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 1.0395 - accuracy: 0.4731\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 1.0465 - accuracy: 0.4708\n",
      "\n",
      "Epoch:  2\n",
      "199/199 - 8s - loss: 1.0105 - accuracy: 0.4867 - val_loss: 0.9867 - val_accuracy: 0.4938 - 8s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.9819 - accuracy: 0.4990\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.9882 - accuracy: 0.4909\n",
      "\n",
      "Epoch:  3\n",
      "199/199 - 7s - loss: 0.9181 - accuracy: 0.5647 - val_loss: 0.7963 - val_accuracy: 0.6353 - 7s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.7901 - accuracy: 0.6436\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.8027 - accuracy: 0.6336\n",
      "\n",
      "Epoch:  4\n",
      "199/199 - 7s - loss: 0.7713 - accuracy: 0.6485 - val_loss: 0.5945 - val_accuracy: 0.7161 - 7s/epoch - 37ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.5961 - accuracy: 0.7146\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.6070 - accuracy: 0.7111\n",
      "\n",
      "Epoch:  5\n",
      "199/199 - 8s - loss: 0.6322 - accuracy: 0.7181 - val_loss: 0.5596 - val_accuracy: 0.7455 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.5613 - accuracy: 0.7444\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.5754 - accuracy: 0.7403\n",
      "\n",
      "Epoch:  6\n",
      "199/199 - 8s - loss: 0.5604 - accuracy: 0.7494 - val_loss: 0.4410 - val_accuracy: 0.8126 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.4388 - accuracy: 0.8115\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.4506 - accuracy: 0.8095\n",
      "\n",
      "Epoch:  7\n",
      "199/199 - 8s - loss: 0.5263 - accuracy: 0.7662 - val_loss: 0.4107 - val_accuracy: 0.8238 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.4083 - accuracy: 0.8252\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.4193 - accuracy: 0.8235\n",
      "\n",
      "Epoch:  8\n",
      "199/199 - 8s - loss: 0.4869 - accuracy: 0.7855 - val_loss: 0.4066 - val_accuracy: 0.8212 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.4021 - accuracy: 0.8240\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.4147 - accuracy: 0.8132\n",
      "\n",
      "Epoch:  9\n",
      "199/199 - 8s - loss: 0.4665 - accuracy: 0.7945 - val_loss: 0.3531 - val_accuracy: 0.8526 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.3529 - accuracy: 0.8527\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.3639 - accuracy: 0.8458\n",
      "\n",
      "Epoch:  10\n",
      "199/199 - 9s - loss: 0.4347 - accuracy: 0.8064 - val_loss: 0.3639 - val_accuracy: 0.8407 - 9s/epoch - 45ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.3633 - accuracy: 0.8384\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.3745 - accuracy: 0.8355\n",
      "\n",
      "Epoch:  11\n",
      "199/199 - 8s - loss: 0.4263 - accuracy: 0.8144 - val_loss: 0.3802 - val_accuracy: 0.8322 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.3813 - accuracy: 0.8286\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.3934 - accuracy: 0.8219\n",
      "\n",
      "Epoch:  12\n",
      "199/199 - 8s - loss: 0.4144 - accuracy: 0.8152 - val_loss: 0.3118 - val_accuracy: 0.8719 - 8s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.3106 - accuracy: 0.8723\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.3216 - accuracy: 0.8699\n",
      "\n",
      "Epoch:  13\n",
      "199/199 - 8s - loss: 0.3967 - accuracy: 0.8244 - val_loss: 0.2932 - val_accuracy: 0.8858 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.2929 - accuracy: 0.8854\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.3031 - accuracy: 0.8774\n",
      "\n",
      "Epoch:  14\n",
      "199/199 - 8s - loss: 0.3913 - accuracy: 0.8275 - val_loss: 0.3177 - val_accuracy: 0.8612 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.3156 - accuracy: 0.8604\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.3295 - accuracy: 0.8582\n",
      "\n",
      "Epoch:  15\n",
      "199/199 - 8s - loss: 0.3743 - accuracy: 0.8361 - val_loss: 0.2894 - val_accuracy: 0.8805 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.2869 - accuracy: 0.8803\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.3027 - accuracy: 0.8714\n",
      "\n",
      "Epoch:  16\n",
      "199/199 - 8s - loss: 0.3672 - accuracy: 0.8400 - val_loss: 0.3262 - val_accuracy: 0.8517 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.3261 - accuracy: 0.8484\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.3366 - accuracy: 0.8453\n",
      "\n",
      "Epoch:  17\n",
      "199/199 - 8s - loss: 0.3583 - accuracy: 0.8428 - val_loss: 0.2874 - val_accuracy: 0.8734 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.2881 - accuracy: 0.8708\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.2996 - accuracy: 0.8692\n",
      "\n",
      "Epoch:  18\n",
      "199/199 - 8s - loss: 0.3552 - accuracy: 0.8486 - val_loss: 0.2689 - val_accuracy: 0.8839 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.2677 - accuracy: 0.8861\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.2819 - accuracy: 0.8765\n",
      "\n",
      "Epoch:  19\n",
      "199/199 - 8s - loss: 0.3437 - accuracy: 0.8529 - val_loss: 0.2622 - val_accuracy: 0.9071 - 8s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.2624 - accuracy: 0.9065\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.2720 - accuracy: 0.9020\n",
      "\n",
      "Epoch:  20\n",
      "199/199 - 8s - loss: 0.3405 - accuracy: 0.8521 - val_loss: 0.2782 - val_accuracy: 0.8921 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.2764 - accuracy: 0.8917\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.2874 - accuracy: 0.8903\n",
      "\n",
      "Epoch:  21\n",
      "199/199 - 8s - loss: 0.3276 - accuracy: 0.8622 - val_loss: 0.2405 - val_accuracy: 0.9119 - 8s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.2362 - accuracy: 0.9135\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.2466 - accuracy: 0.9064\n",
      "\n",
      "Epoch:  22\n",
      "199/199 - 8s - loss: 0.3120 - accuracy: 0.8667 - val_loss: 0.2624 - val_accuracy: 0.8932 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.2588 - accuracy: 0.8939\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.2723 - accuracy: 0.8912\n",
      "\n",
      "Epoch:  23\n",
      "199/199 - 8s - loss: 0.3076 - accuracy: 0.8693 - val_loss: 0.2264 - val_accuracy: 0.9121 - 8s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.2188 - accuracy: 0.9130\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.2323 - accuracy: 0.9079\n",
      "\n",
      "Epoch:  24\n",
      "199/199 - 8s - loss: 0.3072 - accuracy: 0.8685 - val_loss: 0.2594 - val_accuracy: 0.8938 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.2543 - accuracy: 0.8961\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.2655 - accuracy: 0.8870\n",
      "\n",
      "Epoch:  25\n",
      "199/199 - 8s - loss: 0.3031 - accuracy: 0.8715 - val_loss: 0.2326 - val_accuracy: 0.9049 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.2273 - accuracy: 0.9084\n",
      "for testing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/265 [==============================] - 1s 5ms/step - loss: 0.2377 - accuracy: 0.9040\n",
      "\n",
      "Epoch:  26\n",
      "199/199 - 8s - loss: 0.2879 - accuracy: 0.8784 - val_loss: 0.2550 - val_accuracy: 0.8765 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.2472 - accuracy: 0.8827\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.2580 - accuracy: 0.8784\n",
      "\n",
      "Epoch:  27\n",
      "199/199 - 8s - loss: 0.2909 - accuracy: 0.8771 - val_loss: 0.2255 - val_accuracy: 0.9138 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.2199 - accuracy: 0.9162\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.2298 - accuracy: 0.9147\n",
      "\n",
      "Epoch:  28\n",
      "199/199 - 8s - loss: 0.2961 - accuracy: 0.8748 - val_loss: 0.2050 - val_accuracy: 0.9190 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1960 - accuracy: 0.9242\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.2064 - accuracy: 0.9215\n",
      "\n",
      "Epoch:  29\n",
      "199/199 - 8s - loss: 0.2758 - accuracy: 0.8829 - val_loss: 0.1957 - val_accuracy: 0.9277 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.1903 - accuracy: 0.9306\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.2029 - accuracy: 0.9244\n",
      "\n",
      "Epoch:  30\n",
      "199/199 - 8s - loss: 0.2784 - accuracy: 0.8852 - val_loss: 0.1947 - val_accuracy: 0.9369 - 8s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1903 - accuracy: 0.9396\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.2006 - accuracy: 0.9349\n",
      "\n",
      "Epoch:  31\n",
      "199/199 - 8s - loss: 0.2538 - accuracy: 0.8958 - val_loss: 0.1769 - val_accuracy: 0.9352 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1708 - accuracy: 0.9365\n",
      "for testing\n",
      "265/265 [==============================] - 2s 8ms/step - loss: 0.1811 - accuracy: 0.9320\n",
      "\n",
      "Epoch:  32\n",
      "199/199 - 9s - loss: 0.2673 - accuracy: 0.8893 - val_loss: 0.1790 - val_accuracy: 0.9345 - 9s/epoch - 46ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1694 - accuracy: 0.9410\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.1813 - accuracy: 0.9338\n",
      "\n",
      "Epoch:  33\n",
      "199/199 - 9s - loss: 0.2535 - accuracy: 0.8934 - val_loss: 0.2205 - val_accuracy: 0.9059 - 9s/epoch - 44ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.2121 - accuracy: 0.9102\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.2279 - accuracy: 0.9007\n",
      "\n",
      "Epoch:  34\n",
      "199/199 - 8s - loss: 0.2438 - accuracy: 0.9016 - val_loss: 0.1673 - val_accuracy: 0.9417 - 8s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1591 - accuracy: 0.9437\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1715 - accuracy: 0.9365\n",
      "\n",
      "Epoch:  35\n",
      "199/199 - 7s - loss: 0.2352 - accuracy: 0.9034 - val_loss: 0.1667 - val_accuracy: 0.9441 - 7s/epoch - 37ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1607 - accuracy: 0.9464\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1672 - accuracy: 0.9436\n",
      "\n",
      "Epoch:  36\n",
      "199/199 - 8s - loss: 0.2364 - accuracy: 0.9021 - val_loss: 0.1899 - val_accuracy: 0.9239 - 8s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1803 - accuracy: 0.9300\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1874 - accuracy: 0.9315\n",
      "\n",
      "Epoch:  37\n",
      "199/199 - 7s - loss: 0.2441 - accuracy: 0.8983 - val_loss: 0.2055 - val_accuracy: 0.9199 - 7s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1985 - accuracy: 0.9220\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.2070 - accuracy: 0.9178\n",
      "\n",
      "Epoch:  38\n",
      "199/199 - 7s - loss: 0.2398 - accuracy: 0.9026 - val_loss: 0.2020 - val_accuracy: 0.9285 - 7s/epoch - 37ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1915 - accuracy: 0.9306\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.2009 - accuracy: 0.9248\n",
      "\n",
      "Epoch:  39\n",
      "199/199 - 7s - loss: 0.2337 - accuracy: 0.9033 - val_loss: 0.1515 - val_accuracy: 0.9465 - 7s/epoch - 37ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1463 - accuracy: 0.9477\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1531 - accuracy: 0.9437\n",
      "\n",
      "Epoch:  40\n",
      "199/199 - 7s - loss: 0.2255 - accuracy: 0.9077 - val_loss: 0.1987 - val_accuracy: 0.9159 - 7s/epoch - 37ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1941 - accuracy: 0.9180\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.2038 - accuracy: 0.9156\n",
      "\n",
      "Epoch:  41\n",
      "199/199 - 7s - loss: 0.2141 - accuracy: 0.9127 - val_loss: 0.1471 - val_accuracy: 0.9504 - 7s/epoch - 37ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1398 - accuracy: 0.9509\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1480 - accuracy: 0.9471\n",
      "\n",
      "Epoch:  42\n",
      "199/199 - 8s - loss: 0.2229 - accuracy: 0.9078 - val_loss: 0.1409 - val_accuracy: 0.9450 - 8s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1343 - accuracy: 0.9489\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1410 - accuracy: 0.9458\n",
      "\n",
      "Epoch:  43\n",
      "199/199 - 8s - loss: 0.2126 - accuracy: 0.9130 - val_loss: 0.1282 - val_accuracy: 0.9578 - 8s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1229 - accuracy: 0.9611\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1301 - accuracy: 0.9577\n",
      "\n",
      "Epoch:  44\n",
      "199/199 - 8s - loss: 0.2029 - accuracy: 0.9195 - val_loss: 0.1440 - val_accuracy: 0.9441 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1392 - accuracy: 0.9469\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1451 - accuracy: 0.9456\n",
      "\n",
      "Epoch:  45\n",
      "199/199 - 8s - loss: 0.2150 - accuracy: 0.9120 - val_loss: 0.1615 - val_accuracy: 0.9379 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1524 - accuracy: 0.9410\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1567 - accuracy: 0.9430\n",
      "\n",
      "Epoch:  46\n",
      "199/199 - 8s - loss: 0.1993 - accuracy: 0.9189 - val_loss: 0.1228 - val_accuracy: 0.9575 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1159 - accuracy: 0.9612\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1196 - accuracy: 0.9607\n",
      "\n",
      "Epoch:  47\n",
      "199/199 - 8s - loss: 0.1993 - accuracy: 0.9188 - val_loss: 0.1201 - val_accuracy: 0.9558 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1121 - accuracy: 0.9596\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1181 - accuracy: 0.9567\n",
      "\n",
      "Epoch:  48\n",
      "199/199 - 8s - loss: 0.2010 - accuracy: 0.9192 - val_loss: 0.1627 - val_accuracy: 0.9333 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1572 - accuracy: 0.9357\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.1676 - accuracy: 0.9314\n",
      "\n",
      "Epoch:  49\n",
      "199/199 - 8s - loss: 0.1953 - accuracy: 0.9200 - val_loss: 0.1251 - val_accuracy: 0.9543 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1134 - accuracy: 0.9594\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1207 - accuracy: 0.9568\n",
      "\n",
      "Epoch:  50\n",
      "199/199 - 8s - loss: 0.1905 - accuracy: 0.9234 - val_loss: 0.1246 - val_accuracy: 0.9541 - 8s/epoch - 40ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1158 - accuracy: 0.9590\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1253 - accuracy: 0.9549\n",
      "\n",
      "Epoch:  51\n",
      "199/199 - 8s - loss: 0.1847 - accuracy: 0.9247 - val_loss: 0.1227 - val_accuracy: 0.9563 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1134 - accuracy: 0.9592\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1206 - accuracy: 0.9564\n",
      "\n",
      "Epoch:  52\n",
      "199/199 - 8s - loss: 0.1848 - accuracy: 0.9260 - val_loss: 0.1184 - val_accuracy: 0.9563 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1100 - accuracy: 0.9595\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.1213 - accuracy: 0.9556\n",
      "\n",
      "Epoch:  53\n",
      "199/199 - 8s - loss: 0.1888 - accuracy: 0.9241 - val_loss: 0.1214 - val_accuracy: 0.9558 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1158 - accuracy: 0.9588\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1245 - accuracy: 0.9529\n",
      "\n",
      "Epoch:  54\n",
      "199/199 - 8s - loss: 0.1792 - accuracy: 0.9279 - val_loss: 0.1040 - val_accuracy: 0.9621 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0985 - accuracy: 0.9668\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.1060 - accuracy: 0.9642\n",
      "\n",
      "Epoch:  55\n",
      "199/199 - 8s - loss: 0.1720 - accuracy: 0.9324 - val_loss: 0.1173 - val_accuracy: 0.9621 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1102 - accuracy: 0.9659\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1155 - accuracy: 0.9628\n",
      "\n",
      "Epoch:  56\n",
      "199/199 - 8s - loss: 0.1786 - accuracy: 0.9302 - val_loss: 0.1309 - val_accuracy: 0.9495 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1199 - accuracy: 0.9537\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.1294 - accuracy: 0.9503\n",
      "\n",
      "Epoch:  57\n",
      "199/199 - 8s - loss: 0.1839 - accuracy: 0.9253 - val_loss: 0.1377 - val_accuracy: 0.9528 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1315 - accuracy: 0.9540\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1387 - accuracy: 0.9506\n",
      "\n",
      "Epoch:  58\n",
      "199/199 - 8s - loss: 0.1693 - accuracy: 0.9324 - val_loss: 0.1032 - val_accuracy: 0.9650 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0932 - accuracy: 0.9680\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1015 - accuracy: 0.9637\n",
      "\n",
      "Epoch:  59\n",
      "199/199 - 8s - loss: 0.1816 - accuracy: 0.9269 - val_loss: 0.1080 - val_accuracy: 0.9624 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0994 - accuracy: 0.9652\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.1109 - accuracy: 0.9580\n",
      "\n",
      "Epoch:  60\n",
      "199/199 - 8s - loss: 0.1637 - accuracy: 0.9351 - val_loss: 0.1240 - val_accuracy: 0.9568 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1155 - accuracy: 0.9589\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.1240 - accuracy: 0.9560\n",
      "\n",
      "Epoch:  61\n",
      "199/199 - 8s - loss: 0.1704 - accuracy: 0.9326 - val_loss: 0.0976 - val_accuracy: 0.9672 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0900 - accuracy: 0.9711\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0990 - accuracy: 0.9659\n",
      "\n",
      "Epoch:  62\n",
      "199/199 - 8s - loss: 0.1672 - accuracy: 0.9341 - val_loss: 0.0962 - val_accuracy: 0.9689 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0870 - accuracy: 0.9733\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0947 - accuracy: 0.9687\n",
      "\n",
      "Epoch:  63\n",
      "199/199 - 8s - loss: 0.1646 - accuracy: 0.9342 - val_loss: 0.0972 - val_accuracy: 0.9660 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0880 - accuracy: 0.9694\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0953 - accuracy: 0.9646\n",
      "\n",
      "Epoch:  64\n",
      "199/199 - 8s - loss: 0.1636 - accuracy: 0.9367 - val_loss: 0.1144 - val_accuracy: 0.9600 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1020 - accuracy: 0.9633\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.1151 - accuracy: 0.9611\n",
      "\n",
      "Epoch:  65\n",
      "199/199 - 8s - loss: 0.1552 - accuracy: 0.9379 - val_loss: 0.1478 - val_accuracy: 0.9398 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1372 - accuracy: 0.9430\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.1498 - accuracy: 0.9385\n",
      "\n",
      "Epoch:  66\n",
      "199/199 - 8s - loss: 0.1680 - accuracy: 0.9334 - val_loss: 0.1231 - val_accuracy: 0.9548 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1177 - accuracy: 0.9578\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.1287 - accuracy: 0.9548\n",
      "\n",
      "Epoch:  67\n",
      "199/199 - 8s - loss: 0.1607 - accuracy: 0.9367 - val_loss: 0.0919 - val_accuracy: 0.9685 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0805 - accuracy: 0.9734\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0879 - accuracy: 0.9700\n",
      "\n",
      "Epoch:  68\n",
      "199/199 - 8s - loss: 0.1523 - accuracy: 0.9408 - val_loss: 0.0962 - val_accuracy: 0.9667 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0892 - accuracy: 0.9694\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0965 - accuracy: 0.9665\n",
      "\n",
      "Epoch:  69\n",
      "199/199 - 8s - loss: 0.1550 - accuracy: 0.9384 - val_loss: 0.0895 - val_accuracy: 0.9689 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0780 - accuracy: 0.9737\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0858 - accuracy: 0.9712\n",
      "\n",
      "Epoch:  70\n",
      "199/199 - 8s - loss: 0.1521 - accuracy: 0.9402 - val_loss: 0.1068 - val_accuracy: 0.9602 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0973 - accuracy: 0.9630\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.1086 - accuracy: 0.9603\n",
      "\n",
      "Epoch:  71\n",
      "199/199 - 8s - loss: 0.1507 - accuracy: 0.9405 - val_loss: 0.0887 - val_accuracy: 0.9712 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0776 - accuracy: 0.9745\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0868 - accuracy: 0.9714\n",
      "\n",
      "Epoch:  72\n",
      "199/199 - 8s - loss: 0.1587 - accuracy: 0.9367 - val_loss: 0.1062 - val_accuracy: 0.9622 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0940 - accuracy: 0.9667\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.1082 - accuracy: 0.9607\n",
      "\n",
      "Epoch:  73\n",
      "199/199 - 8s - loss: 0.1502 - accuracy: 0.9406 - val_loss: 0.0860 - val_accuracy: 0.9722 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0789 - accuracy: 0.9743\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0870 - accuracy: 0.9709\n",
      "\n",
      "Epoch:  74\n",
      "199/199 - 8s - loss: 0.1428 - accuracy: 0.9440 - val_loss: 0.0772 - val_accuracy: 0.9737 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0700 - accuracy: 0.9765\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0765 - accuracy: 0.9741\n",
      "\n",
      "Epoch:  75\n",
      "199/199 - 8s - loss: 0.1483 - accuracy: 0.9424 - val_loss: 0.0842 - val_accuracy: 0.9717 - 8s/epoch - 40ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0733 - accuracy: 0.9758\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0806 - accuracy: 0.9728\n",
      "\n",
      "Epoch:  76\n",
      "199/199 - 8s - loss: 0.1469 - accuracy: 0.9418 - val_loss: 0.1014 - val_accuracy: 0.9643 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0917 - accuracy: 0.9674\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.1013 - accuracy: 0.9647\n",
      "\n",
      "Epoch:  77\n",
      "199/199 - 8s - loss: 0.1455 - accuracy: 0.9424 - val_loss: 0.0858 - val_accuracy: 0.9702 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0784 - accuracy: 0.9730\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0882 - accuracy: 0.9699\n",
      "\n",
      "Epoch:  78\n",
      "199/199 - 8s - loss: 0.1408 - accuracy: 0.9437 - val_loss: 0.0757 - val_accuracy: 0.9748 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0680 - accuracy: 0.9766\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0736 - accuracy: 0.9735\n",
      "\n",
      "Epoch:  79\n",
      "199/199 - 8s - loss: 0.1523 - accuracy: 0.9402 - val_loss: 0.0722 - val_accuracy: 0.9772 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0617 - accuracy: 0.9803\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0675 - accuracy: 0.9773\n",
      "\n",
      "Epoch:  80\n",
      "199/199 - 8s - loss: 0.1406 - accuracy: 0.9450 - val_loss: 0.0801 - val_accuracy: 0.9741 - 8s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0695 - accuracy: 0.9777\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0763 - accuracy: 0.9761\n",
      "\n",
      "Epoch:  81\n",
      "199/199 - 8s - loss: 0.1362 - accuracy: 0.9469 - val_loss: 0.0812 - val_accuracy: 0.9706 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0726 - accuracy: 0.9740\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0810 - accuracy: 0.9698\n",
      "\n",
      "Epoch:  82\n",
      "199/199 - 8s - loss: 0.1388 - accuracy: 0.9449 - val_loss: 0.0820 - val_accuracy: 0.9707 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0723 - accuracy: 0.9744\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0761 - accuracy: 0.9741\n",
      "\n",
      "Epoch:  83\n",
      "199/199 - 8s - loss: 0.1373 - accuracy: 0.9460 - val_loss: 0.0933 - val_accuracy: 0.9679 - 8s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0821 - accuracy: 0.9721\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0894 - accuracy: 0.9693\n",
      "\n",
      "Epoch:  84\n",
      "199/199 - 8s - loss: 0.1326 - accuracy: 0.9499 - val_loss: 0.0753 - val_accuracy: 0.9731 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0695 - accuracy: 0.9758\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0756 - accuracy: 0.9714\n",
      "\n",
      "Epoch:  85\n",
      "199/199 - 8s - loss: 0.1482 - accuracy: 0.9439 - val_loss: 0.0811 - val_accuracy: 0.9728 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0723 - accuracy: 0.9746\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0791 - accuracy: 0.9727\n",
      "\n",
      "Epoch:  86\n",
      "199/199 - 8s - loss: 0.1446 - accuracy: 0.9443 - val_loss: 0.0925 - val_accuracy: 0.9694 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0830 - accuracy: 0.9732\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0927 - accuracy: 0.9706\n",
      "\n",
      "Epoch:  87\n",
      "199/199 - 8s - loss: 0.1287 - accuracy: 0.9497 - val_loss: 0.0730 - val_accuracy: 0.9752 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0650 - accuracy: 0.9782\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0714 - accuracy: 0.9740\n",
      "\n",
      "Epoch:  88\n",
      "199/199 - 8s - loss: 0.1366 - accuracy: 0.9473 - val_loss: 0.0868 - val_accuracy: 0.9691 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0778 - accuracy: 0.9721\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0859 - accuracy: 0.9719\n",
      "\n",
      "Epoch:  89\n",
      "199/199 - 8s - loss: 0.1310 - accuracy: 0.9474 - val_loss: 0.0865 - val_accuracy: 0.9698 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0785 - accuracy: 0.9732\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0863 - accuracy: 0.9699\n",
      "\n",
      "Epoch:  90\n",
      "199/199 - 8s - loss: 0.1278 - accuracy: 0.9488 - val_loss: 0.1266 - val_accuracy: 0.9482 - 8s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1134 - accuracy: 0.9544\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.1208 - accuracy: 0.9522\n",
      "\n",
      "Epoch:  91\n",
      "199/199 - 8s - loss: 0.1286 - accuracy: 0.9504 - val_loss: 0.0783 - val_accuracy: 0.9726 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0686 - accuracy: 0.9746\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0746 - accuracy: 0.9733\n",
      "\n",
      "Epoch:  92\n",
      "199/199 - 8s - loss: 0.1212 - accuracy: 0.9544 - val_loss: 0.0757 - val_accuracy: 0.9741 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0693 - accuracy: 0.9760\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0795 - accuracy: 0.9717\n",
      "\n",
      "Epoch:  93\n",
      "199/199 - 8s - loss: 0.1225 - accuracy: 0.9530 - val_loss: 0.0753 - val_accuracy: 0.9724 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0654 - accuracy: 0.9771\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0758 - accuracy: 0.9730\n",
      "\n",
      "Epoch:  94\n",
      "199/199 - 8s - loss: 0.1251 - accuracy: 0.9522 - val_loss: 0.0640 - val_accuracy: 0.9786 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0561 - accuracy: 0.9826\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0660 - accuracy: 0.9776\n",
      "\n",
      "Epoch:  95\n",
      "199/199 - 8s - loss: 0.1244 - accuracy: 0.9522 - val_loss: 0.0753 - val_accuracy: 0.9764 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0650 - accuracy: 0.9788\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0705 - accuracy: 0.9802\n",
      "\n",
      "Epoch:  96\n",
      "199/199 - 8s - loss: 0.1242 - accuracy: 0.9517 - val_loss: 0.0605 - val_accuracy: 0.9815 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0512 - accuracy: 0.9852\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0567 - accuracy: 0.9830\n",
      "\n",
      "Epoch:  97\n",
      "199/199 - 8s - loss: 0.1233 - accuracy: 0.9530 - val_loss: 0.0701 - val_accuracy: 0.9779 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0619 - accuracy: 0.9795\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0671 - accuracy: 0.9784\n",
      "\n",
      "Epoch:  98\n",
      "199/199 - 8s - loss: 0.1216 - accuracy: 0.9523 - val_loss: 0.0754 - val_accuracy: 0.9733 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0633 - accuracy: 0.9774\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0697 - accuracy: 0.9734\n",
      "\n",
      "Epoch:  99\n",
      "199/199 - 8s - loss: 0.1243 - accuracy: 0.9515 - val_loss: 0.0713 - val_accuracy: 0.9745 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0603 - accuracy: 0.9789\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0673 - accuracy: 0.9760\n",
      "\n",
      "Epoch:  100\n",
      "199/199 - 8s - loss: 0.1192 - accuracy: 0.9549 - val_loss: 0.0781 - val_accuracy: 0.9730 - 8s/epoch - 39ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0710 - accuracy: 0.9755\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0757 - accuracy: 0.9737\n",
      "\n",
      "Epoch:  101\n",
      "199/199 - 8s - loss: 0.1263 - accuracy: 0.9517 - val_loss: 0.0663 - val_accuracy: 0.9791 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0578 - accuracy: 0.9822\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0655 - accuracy: 0.9812\n",
      "\n",
      "Epoch:  102\n",
      "199/199 - 8s - loss: 0.1185 - accuracy: 0.9537 - val_loss: 0.0657 - val_accuracy: 0.9783 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0536 - accuracy: 0.9819\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0654 - accuracy: 0.9778\n",
      "\n",
      "Epoch:  103\n",
      "199/199 - 8s - loss: 0.1169 - accuracy: 0.9556 - val_loss: 0.0708 - val_accuracy: 0.9764 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0613 - accuracy: 0.9803\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0693 - accuracy: 0.9757\n",
      "\n",
      "Epoch:  104\n",
      "199/199 - 8s - loss: 0.1212 - accuracy: 0.9524 - val_loss: 0.0668 - val_accuracy: 0.9769 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0573 - accuracy: 0.9814\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0627 - accuracy: 0.9791\n",
      "\n",
      "Epoch:  105\n",
      "199/199 - 8s - loss: 0.1189 - accuracy: 0.9561 - val_loss: 0.0747 - val_accuracy: 0.9734 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0641 - accuracy: 0.9785\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0703 - accuracy: 0.9761\n",
      "\n",
      "Epoch:  106\n",
      "199/199 - 8s - loss: 0.1206 - accuracy: 0.9527 - val_loss: 0.0710 - val_accuracy: 0.9757 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0611 - accuracy: 0.9795\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0696 - accuracy: 0.9773\n",
      "\n",
      "Epoch:  107\n",
      "199/199 - 8s - loss: 0.1217 - accuracy: 0.9539 - val_loss: 0.0605 - val_accuracy: 0.9804 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0504 - accuracy: 0.9841\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0580 - accuracy: 0.9806\n",
      "\n",
      "Epoch:  108\n",
      "199/199 - 8s - loss: 0.1159 - accuracy: 0.9553 - val_loss: 0.0662 - val_accuracy: 0.9765 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0548 - accuracy: 0.9810\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0628 - accuracy: 0.9789\n",
      "\n",
      "Epoch:  109\n",
      "199/199 - 8s - loss: 0.1112 - accuracy: 0.9563 - val_loss: 0.0686 - val_accuracy: 0.9748 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0599 - accuracy: 0.9789\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0683 - accuracy: 0.9751\n",
      "\n",
      "Epoch:  110\n",
      "199/199 - 8s - loss: 0.1124 - accuracy: 0.9570 - val_loss: 0.0657 - val_accuracy: 0.9778 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0565 - accuracy: 0.9813\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0621 - accuracy: 0.9795\n",
      "\n",
      "Epoch:  111\n",
      "199/199 - 8s - loss: 0.1113 - accuracy: 0.9581 - val_loss: 0.0548 - val_accuracy: 0.9830 - 8s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0477 - accuracy: 0.9857\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0534 - accuracy: 0.9837\n",
      "\n",
      "Epoch:  112\n",
      "199/199 - 8s - loss: 0.1098 - accuracy: 0.9578 - val_loss: 0.1001 - val_accuracy: 0.9642 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0855 - accuracy: 0.9682\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0966 - accuracy: 0.9663\n",
      "\n",
      "Epoch:  113\n",
      "199/199 - 8s - loss: 0.1087 - accuracy: 0.9571 - val_loss: 0.0735 - val_accuracy: 0.9735 - 8s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0590 - accuracy: 0.9779\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0726 - accuracy: 0.9750\n",
      "\n",
      "Epoch:  114\n",
      "199/199 - 8s - loss: 0.1097 - accuracy: 0.9583 - val_loss: 0.0752 - val_accuracy: 0.9746 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0628 - accuracy: 0.9789\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0719 - accuracy: 0.9757\n",
      "\n",
      "Epoch:  115\n",
      "199/199 - 8s - loss: 0.1033 - accuracy: 0.9602 - val_loss: 0.0586 - val_accuracy: 0.9794 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0466 - accuracy: 0.9841\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0571 - accuracy: 0.9815\n",
      "\n",
      "Epoch:  116\n",
      "199/199 - 8s - loss: 0.1033 - accuracy: 0.9611 - val_loss: 0.0686 - val_accuracy: 0.9771 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0543 - accuracy: 0.9817\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0643 - accuracy: 0.9802\n",
      "\n",
      "Epoch:  117\n",
      "199/199 - 8s - loss: 0.1077 - accuracy: 0.9593 - val_loss: 0.0548 - val_accuracy: 0.9823 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0461 - accuracy: 0.9861\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0544 - accuracy: 0.9830\n",
      "\n",
      "Epoch:  118\n",
      "199/199 - 8s - loss: 0.1136 - accuracy: 0.9576 - val_loss: 0.0632 - val_accuracy: 0.9811 - 8s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0555 - accuracy: 0.9830\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0651 - accuracy: 0.9785\n",
      "\n",
      "Epoch:  119\n",
      "199/199 - 8s - loss: 0.1076 - accuracy: 0.9589 - val_loss: 0.0565 - val_accuracy: 0.9813 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0488 - accuracy: 0.9833\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0548 - accuracy: 0.9797\n",
      "\n",
      "Epoch:  120\n",
      "199/199 - 8s - loss: 0.1060 - accuracy: 0.9598 - val_loss: 0.0609 - val_accuracy: 0.9792 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0501 - accuracy: 0.9824\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0613 - accuracy: 0.9789\n",
      "\n",
      "Epoch:  121\n",
      "199/199 - 8s - loss: 0.1108 - accuracy: 0.9583 - val_loss: 0.0611 - val_accuracy: 0.9782 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0525 - accuracy: 0.9813\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0616 - accuracy: 0.9791\n",
      "\n",
      "Epoch:  122\n",
      "199/199 - 8s - loss: 0.1051 - accuracy: 0.9575 - val_loss: 0.0669 - val_accuracy: 0.9765 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0576 - accuracy: 0.9797\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0648 - accuracy: 0.9780\n",
      "\n",
      "Epoch:  123\n",
      "199/199 - 8s - loss: 0.1031 - accuracy: 0.9604 - val_loss: 0.0581 - val_accuracy: 0.9803 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0496 - accuracy: 0.9825\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0574 - accuracy: 0.9795\n",
      "\n",
      "Epoch:  124\n",
      "199/199 - 8s - loss: 0.1094 - accuracy: 0.9598 - val_loss: 0.0514 - val_accuracy: 0.9830 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0412 - accuracy: 0.9866\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0495 - accuracy: 0.9826\n",
      "\n",
      "Epoch:  125\n",
      "199/199 - 8s - loss: 0.0963 - accuracy: 0.9633 - val_loss: 0.0610 - val_accuracy: 0.9802 - 8s/epoch - 39ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0505 - accuracy: 0.9829\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0612 - accuracy: 0.9786\n",
      "\n",
      "Epoch:  126\n",
      "199/199 - 8s - loss: 0.0981 - accuracy: 0.9622 - val_loss: 0.0582 - val_accuracy: 0.9798 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0465 - accuracy: 0.9839\n",
      "for testing\n",
      "265/265 [==============================] - 2s 8ms/step - loss: 0.0558 - accuracy: 0.9824\n",
      "\n",
      "Epoch:  127\n",
      "199/199 - 8s - loss: 0.1034 - accuracy: 0.9600 - val_loss: 0.0567 - val_accuracy: 0.9817 - 8s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0453 - accuracy: 0.9854\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0543 - accuracy: 0.9823\n",
      "\n",
      "Epoch:  128\n",
      "199/199 - 8s - loss: 0.0992 - accuracy: 0.9630 - val_loss: 0.0575 - val_accuracy: 0.9803 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0462 - accuracy: 0.9847\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0519 - accuracy: 0.9821\n",
      "\n",
      "Epoch:  129\n",
      "199/199 - 8s - loss: 0.1016 - accuracy: 0.9607 - val_loss: 0.0657 - val_accuracy: 0.9774 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0530 - accuracy: 0.9815\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0644 - accuracy: 0.9782\n",
      "\n",
      "Epoch:  130\n",
      "199/199 - 8s - loss: 0.1024 - accuracy: 0.9617 - val_loss: 0.0527 - val_accuracy: 0.9825 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0414 - accuracy: 0.9867\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0501 - accuracy: 0.9828\n",
      "\n",
      "Epoch:  131\n",
      "199/199 - 8s - loss: 0.0982 - accuracy: 0.9625 - val_loss: 0.0471 - val_accuracy: 0.9839 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0376 - accuracy: 0.9887\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0446 - accuracy: 0.9855\n",
      "\n",
      "Epoch:  132\n",
      "199/199 - 8s - loss: 0.0943 - accuracy: 0.9649 - val_loss: 0.0563 - val_accuracy: 0.9797 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0427 - accuracy: 0.9857\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0519 - accuracy: 0.9822\n",
      "\n",
      "Epoch:  133\n",
      "199/199 - 8s - loss: 0.1000 - accuracy: 0.9611 - val_loss: 0.0553 - val_accuracy: 0.9797 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0460 - accuracy: 0.9839\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0548 - accuracy: 0.9789\n",
      "\n",
      "Epoch:  134\n",
      "199/199 - 8s - loss: 0.0934 - accuracy: 0.9639 - val_loss: 0.0671 - val_accuracy: 0.9769 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0549 - accuracy: 0.9805\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0667 - accuracy: 0.9759\n",
      "\n",
      "Epoch:  135\n",
      "199/199 - 8s - loss: 0.0940 - accuracy: 0.9643 - val_loss: 0.0719 - val_accuracy: 0.9725 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0563 - accuracy: 0.9787\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0690 - accuracy: 0.9741\n",
      "\n",
      "Epoch:  136\n",
      "199/199 - 8s - loss: 0.0984 - accuracy: 0.9622 - val_loss: 0.0467 - val_accuracy: 0.9848 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0371 - accuracy: 0.9878\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0430 - accuracy: 0.9852\n",
      "\n",
      "Epoch:  137\n",
      "199/199 - 8s - loss: 0.0897 - accuracy: 0.9656 - val_loss: 0.0613 - val_accuracy: 0.9791 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0511 - accuracy: 0.9838\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0570 - accuracy: 0.9815\n",
      "\n",
      "Epoch:  138\n",
      "199/199 - 8s - loss: 0.0947 - accuracy: 0.9635 - val_loss: 0.0598 - val_accuracy: 0.9796 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0497 - accuracy: 0.9832\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0559 - accuracy: 0.9798\n",
      "\n",
      "Epoch:  139\n",
      "199/199 - 8s - loss: 0.0966 - accuracy: 0.9632 - val_loss: 0.0513 - val_accuracy: 0.9828 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0414 - accuracy: 0.9860\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0468 - accuracy: 0.9859\n",
      "\n",
      "Epoch:  140\n",
      "199/199 - 8s - loss: 0.0893 - accuracy: 0.9663 - val_loss: 0.0572 - val_accuracy: 0.9809 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0454 - accuracy: 0.9850\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0502 - accuracy: 0.9839\n",
      "\n",
      "Epoch:  141\n",
      "199/199 - 8s - loss: 0.0976 - accuracy: 0.9620 - val_loss: 0.0457 - val_accuracy: 0.9851 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0380 - accuracy: 0.9874\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0456 - accuracy: 0.9851\n",
      "\n",
      "Epoch:  142\n",
      "199/199 - 8s - loss: 0.0957 - accuracy: 0.9643 - val_loss: 0.0769 - val_accuracy: 0.9727 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0602 - accuracy: 0.9785\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0713 - accuracy: 0.9750\n",
      "\n",
      "Epoch:  143\n",
      "199/199 - 8s - loss: 0.0912 - accuracy: 0.9653 - val_loss: 0.0471 - val_accuracy: 0.9848 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0376 - accuracy: 0.9885\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0432 - accuracy: 0.9858\n",
      "\n",
      "Epoch:  144\n",
      "199/199 - 8s - loss: 0.0880 - accuracy: 0.9667 - val_loss: 0.0392 - val_accuracy: 0.9863 - 8s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0292 - accuracy: 0.9910\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0350 - accuracy: 0.9885\n",
      "\n",
      "Epoch:  145\n",
      "199/199 - 8s - loss: 0.0894 - accuracy: 0.9670 - val_loss: 0.0477 - val_accuracy: 0.9829 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0365 - accuracy: 0.9877\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0427 - accuracy: 0.9848\n",
      "\n",
      "Epoch:  146\n",
      "199/199 - 8s - loss: 0.0857 - accuracy: 0.9680 - val_loss: 0.0521 - val_accuracy: 0.9810 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0384 - accuracy: 0.9863\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0433 - accuracy: 0.9844\n",
      "\n",
      "Epoch:  147\n",
      "199/199 - 8s - loss: 0.0905 - accuracy: 0.9654 - val_loss: 0.0462 - val_accuracy: 0.9849 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0362 - accuracy: 0.9882\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0432 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  148\n",
      "199/199 - 8s - loss: 0.0910 - accuracy: 0.9651 - val_loss: 0.0441 - val_accuracy: 0.9864 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0345 - accuracy: 0.9899\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0416 - accuracy: 0.9861\n",
      "\n",
      "Epoch:  149\n",
      "199/199 - 8s - loss: 0.0908 - accuracy: 0.9663 - val_loss: 0.0511 - val_accuracy: 0.9828 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0407 - accuracy: 0.9865\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0497 - accuracy: 0.9837\n",
      "\n",
      "Epoch:  150\n",
      "199/199 - 8s - loss: 0.0939 - accuracy: 0.9634 - val_loss: 0.0598 - val_accuracy: 0.9794 - 8s/epoch - 39ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0475 - accuracy: 0.9839\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0573 - accuracy: 0.9810\n",
      "\n",
      "Epoch:  151\n",
      "199/199 - 8s - loss: 0.0845 - accuracy: 0.9680 - val_loss: 0.0499 - val_accuracy: 0.9832 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0383 - accuracy: 0.9872\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0478 - accuracy: 0.9835\n",
      "\n",
      "Epoch:  152\n",
      "199/199 - 8s - loss: 0.0874 - accuracy: 0.9672 - val_loss: 0.0529 - val_accuracy: 0.9823 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0403 - accuracy: 0.9875\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0491 - accuracy: 0.9849\n",
      "\n",
      "Epoch:  153\n",
      "199/199 - 8s - loss: 0.0881 - accuracy: 0.9666 - val_loss: 0.0643 - val_accuracy: 0.9777 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0514 - accuracy: 0.9814\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0614 - accuracy: 0.9785\n",
      "\n",
      "Epoch:  154\n",
      "199/199 - 8s - loss: 0.0852 - accuracy: 0.9683 - val_loss: 0.0474 - val_accuracy: 0.9833 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0361 - accuracy: 0.9886\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0419 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  155\n",
      "199/199 - 8s - loss: 0.0851 - accuracy: 0.9673 - val_loss: 0.0632 - val_accuracy: 0.9767 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0508 - accuracy: 0.9807\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0614 - accuracy: 0.9760\n",
      "\n",
      "Epoch:  156\n",
      "199/199 - 8s - loss: 0.0890 - accuracy: 0.9666 - val_loss: 0.0465 - val_accuracy: 0.9826 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0356 - accuracy: 0.9881\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0409 - accuracy: 0.9863\n",
      "\n",
      "Epoch:  157\n",
      "199/199 - 8s - loss: 0.0864 - accuracy: 0.9674 - val_loss: 0.0464 - val_accuracy: 0.9837 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0362 - accuracy: 0.9877\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0474 - accuracy: 0.9830\n",
      "\n",
      "Epoch:  158\n",
      "199/199 - 8s - loss: 0.0863 - accuracy: 0.9668 - val_loss: 0.0464 - val_accuracy: 0.9846 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0348 - accuracy: 0.9889\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0434 - accuracy: 0.9856\n",
      "\n",
      "Epoch:  159\n",
      "199/199 - 8s - loss: 0.0839 - accuracy: 0.9678 - val_loss: 0.0591 - val_accuracy: 0.9809 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0450 - accuracy: 0.9847\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0546 - accuracy: 0.9810\n",
      "\n",
      "Epoch:  160\n",
      "199/199 - 8s - loss: 0.0905 - accuracy: 0.9667 - val_loss: 0.0505 - val_accuracy: 0.9835 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0387 - accuracy: 0.9874\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0487 - accuracy: 0.9843\n",
      "\n",
      "Epoch:  161\n",
      "199/199 - 8s - loss: 0.0779 - accuracy: 0.9717 - val_loss: 0.0501 - val_accuracy: 0.9822 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0384 - accuracy: 0.9864\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0476 - accuracy: 0.9833\n",
      "\n",
      "Epoch:  162\n",
      "199/199 - 8s - loss: 0.0804 - accuracy: 0.9699 - val_loss: 0.0425 - val_accuracy: 0.9848 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0324 - accuracy: 0.9895\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0404 - accuracy: 0.9856\n",
      "\n",
      "Epoch:  163\n",
      "199/199 - 8s - loss: 0.0816 - accuracy: 0.9696 - val_loss: 0.0462 - val_accuracy: 0.9854 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0350 - accuracy: 0.9888\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0426 - accuracy: 0.9845\n",
      "\n",
      "Epoch:  164\n",
      "199/199 - 8s - loss: 0.0811 - accuracy: 0.9686 - val_loss: 0.0497 - val_accuracy: 0.9817 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0385 - accuracy: 0.9868\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0460 - accuracy: 0.9848\n",
      "\n",
      "Epoch:  165\n",
      "199/199 - 8s - loss: 0.0883 - accuracy: 0.9663 - val_loss: 0.0418 - val_accuracy: 0.9857 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0319 - accuracy: 0.9896\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0402 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  166\n",
      "199/199 - 8s - loss: 0.0781 - accuracy: 0.9705 - val_loss: 0.0453 - val_accuracy: 0.9843 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0328 - accuracy: 0.9884\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0404 - accuracy: 0.9855\n",
      "\n",
      "Epoch:  167\n",
      "199/199 - 8s - loss: 0.0778 - accuracy: 0.9711 - val_loss: 0.0420 - val_accuracy: 0.9863 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0329 - accuracy: 0.9894\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0401 - accuracy: 0.9858\n",
      "\n",
      "Epoch:  168\n",
      "199/199 - 8s - loss: 0.0863 - accuracy: 0.9667 - val_loss: 0.0714 - val_accuracy: 0.9743 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0575 - accuracy: 0.9785\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0688 - accuracy: 0.9752\n",
      "\n",
      "Epoch:  169\n",
      "199/199 - 8s - loss: 0.0823 - accuracy: 0.9685 - val_loss: 0.0545 - val_accuracy: 0.9812 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0437 - accuracy: 0.9852\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0518 - accuracy: 0.9818\n",
      "\n",
      "Epoch:  170\n",
      "199/199 - 8s - loss: 0.0773 - accuracy: 0.9717 - val_loss: 0.0390 - val_accuracy: 0.9878 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0276 - accuracy: 0.9916\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0361 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  171\n",
      "199/199 - 8s - loss: 0.0777 - accuracy: 0.9709 - val_loss: 0.0467 - val_accuracy: 0.9839 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0312 - accuracy: 0.9897\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0416 - accuracy: 0.9862\n",
      "\n",
      "Epoch:  172\n",
      "199/199 - 8s - loss: 0.0828 - accuracy: 0.9683 - val_loss: 0.0494 - val_accuracy: 0.9823 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0350 - accuracy: 0.9878\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0473 - accuracy: 0.9856\n",
      "\n",
      "Epoch:  173\n",
      "199/199 - 8s - loss: 0.0755 - accuracy: 0.9711 - val_loss: 0.0464 - val_accuracy: 0.9852 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0315 - accuracy: 0.9901\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0367 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  174\n",
      "199/199 - 8s - loss: 0.0825 - accuracy: 0.9683 - val_loss: 0.0406 - val_accuracy: 0.9864 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0284 - accuracy: 0.9903\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0363 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  175\n",
      "199/199 - 8s - loss: 0.0681 - accuracy: 0.9737 - val_loss: 0.0395 - val_accuracy: 0.9864 - 8s/epoch - 39ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0272 - accuracy: 0.9906\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0334 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  176\n",
      "199/199 - 8s - loss: 0.0795 - accuracy: 0.9706 - val_loss: 0.0424 - val_accuracy: 0.9856 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0300 - accuracy: 0.9904\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0392 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  177\n",
      "199/199 - 8s - loss: 0.0753 - accuracy: 0.9710 - val_loss: 0.0452 - val_accuracy: 0.9854 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0347 - accuracy: 0.9883\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0436 - accuracy: 0.9850\n",
      "\n",
      "Epoch:  178\n",
      "199/199 - 8s - loss: 0.0745 - accuracy: 0.9720 - val_loss: 0.0378 - val_accuracy: 0.9870 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0256 - accuracy: 0.9918\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0369 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  179\n",
      "199/199 - 8s - loss: 0.0861 - accuracy: 0.9684 - val_loss: 0.0562 - val_accuracy: 0.9815 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0415 - accuracy: 0.9862\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0519 - accuracy: 0.9826\n",
      "\n",
      "Epoch:  180\n",
      "199/199 - 8s - loss: 0.0750 - accuracy: 0.9719 - val_loss: 0.0476 - val_accuracy: 0.9830 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0355 - accuracy: 0.9877\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0456 - accuracy: 0.9843\n",
      "\n",
      "Epoch:  181\n",
      "199/199 - 8s - loss: 0.0730 - accuracy: 0.9725 - val_loss: 0.0467 - val_accuracy: 0.9839 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0325 - accuracy: 0.9894\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0421 - accuracy: 0.9862\n",
      "\n",
      "Epoch:  182\n",
      "199/199 - 8s - loss: 0.0780 - accuracy: 0.9714 - val_loss: 0.0513 - val_accuracy: 0.9816 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0383 - accuracy: 0.9876\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0446 - accuracy: 0.9842\n",
      "\n",
      "Epoch:  183\n",
      "199/199 - 8s - loss: 0.0767 - accuracy: 0.9711 - val_loss: 0.0419 - val_accuracy: 0.9862 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0300 - accuracy: 0.9906\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0373 - accuracy: 0.9870\n",
      "\n",
      "Epoch:  184\n",
      "199/199 - 8s - loss: 0.0690 - accuracy: 0.9741 - val_loss: 0.0465 - val_accuracy: 0.9842 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0318 - accuracy: 0.9892\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0418 - accuracy: 0.9861\n",
      "\n",
      "Epoch:  185\n",
      "199/199 - 8s - loss: 0.0700 - accuracy: 0.9728 - val_loss: 0.0365 - val_accuracy: 0.9876 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0270 - accuracy: 0.9915\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0354 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  186\n",
      "199/199 - 8s - loss: 0.0743 - accuracy: 0.9708 - val_loss: 0.0374 - val_accuracy: 0.9865 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0277 - accuracy: 0.9910\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0327 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  187\n",
      "199/199 - 8s - loss: 0.0758 - accuracy: 0.9720 - val_loss: 0.0470 - val_accuracy: 0.9824 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0370 - accuracy: 0.9869\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0431 - accuracy: 0.9851\n",
      "\n",
      "Epoch:  188\n",
      "199/199 - 8s - loss: 0.0735 - accuracy: 0.9714 - val_loss: 0.0440 - val_accuracy: 0.9837 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0355 - accuracy: 0.9866\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0468 - accuracy: 0.9829\n",
      "\n",
      "Epoch:  189\n",
      "199/199 - 8s - loss: 0.0741 - accuracy: 0.9727 - val_loss: 0.0378 - val_accuracy: 0.9863 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0268 - accuracy: 0.9907\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0374 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  190\n",
      "199/199 - 8s - loss: 0.0705 - accuracy: 0.9720 - val_loss: 0.0428 - val_accuracy: 0.9841 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0333 - accuracy: 0.9881\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0434 - accuracy: 0.9864\n",
      "\n",
      "Epoch:  191\n",
      "199/199 - 8s - loss: 0.0737 - accuracy: 0.9722 - val_loss: 0.0435 - val_accuracy: 0.9851 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0303 - accuracy: 0.9901\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0421 - accuracy: 0.9863\n",
      "\n",
      "Epoch:  192\n",
      "199/199 - 8s - loss: 0.0713 - accuracy: 0.9737 - val_loss: 0.0378 - val_accuracy: 0.9864 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0261 - accuracy: 0.9915\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0350 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  193\n",
      "199/199 - 8s - loss: 0.0712 - accuracy: 0.9733 - val_loss: 0.0535 - val_accuracy: 0.9815 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0359 - accuracy: 0.9875\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0468 - accuracy: 0.9835\n",
      "\n",
      "Epoch:  194\n",
      "199/199 - 8s - loss: 0.0721 - accuracy: 0.9732 - val_loss: 0.0376 - val_accuracy: 0.9862 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0253 - accuracy: 0.9914\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0364 - accuracy: 0.9889\n",
      "\n",
      "Epoch:  195\n",
      "199/199 - 8s - loss: 0.0745 - accuracy: 0.9724 - val_loss: 0.0477 - val_accuracy: 0.9831 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0353 - accuracy: 0.9880\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0503 - accuracy: 0.9839\n",
      "\n",
      "Epoch:  196\n",
      "199/199 - 8s - loss: 0.0795 - accuracy: 0.9699 - val_loss: 0.0411 - val_accuracy: 0.9864 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0302 - accuracy: 0.9908\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0411 - accuracy: 0.9877\n",
      "\n",
      "Epoch:  197\n",
      "199/199 - 8s - loss: 0.0697 - accuracy: 0.9748 - val_loss: 0.0424 - val_accuracy: 0.9861 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0304 - accuracy: 0.9900\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0396 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  198\n",
      "199/199 - 8s - loss: 0.0692 - accuracy: 0.9742 - val_loss: 0.0500 - val_accuracy: 0.9833 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0355 - accuracy: 0.9875\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0495 - accuracy: 0.9825\n",
      "\n",
      "Epoch:  199\n",
      "199/199 - 8s - loss: 0.0744 - accuracy: 0.9726 - val_loss: 0.0367 - val_accuracy: 0.9875 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0252 - accuracy: 0.9925\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0335 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  200\n",
      "199/199 - 8s - loss: 0.0691 - accuracy: 0.9732 - val_loss: 0.0428 - val_accuracy: 0.9863 - 8s/epoch - 40ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0291 - accuracy: 0.9907\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0381 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  201\n",
      "199/199 - 8s - loss: 0.0682 - accuracy: 0.9754 - val_loss: 0.0500 - val_accuracy: 0.9824 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0361 - accuracy: 0.9875\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0483 - accuracy: 0.9818\n",
      "\n",
      "Epoch:  202\n",
      "199/199 - 8s - loss: 0.0752 - accuracy: 0.9718 - val_loss: 0.0381 - val_accuracy: 0.9876 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0241 - accuracy: 0.9928\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0345 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  203\n",
      "199/199 - 8s - loss: 0.0702 - accuracy: 0.9741 - val_loss: 0.0353 - val_accuracy: 0.9880 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0249 - accuracy: 0.9924\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0332 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  204\n",
      "199/199 - 8s - loss: 0.0654 - accuracy: 0.9761 - val_loss: 0.0366 - val_accuracy: 0.9875 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0251 - accuracy: 0.9923\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0340 - accuracy: 0.9889\n",
      "\n",
      "Epoch:  205\n",
      "199/199 - 8s - loss: 0.0646 - accuracy: 0.9753 - val_loss: 0.0452 - val_accuracy: 0.9845 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0307 - accuracy: 0.9891\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0446 - accuracy: 0.9849\n",
      "\n",
      "Epoch:  206\n",
      "199/199 - 8s - loss: 0.0732 - accuracy: 0.9724 - val_loss: 0.0388 - val_accuracy: 0.9862 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0271 - accuracy: 0.9907\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0376 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  207\n",
      "199/199 - 8s - loss: 0.0688 - accuracy: 0.9735 - val_loss: 0.0410 - val_accuracy: 0.9859 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0281 - accuracy: 0.9906\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0381 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  208\n",
      "199/199 - 8s - loss: 0.0689 - accuracy: 0.9738 - val_loss: 0.0519 - val_accuracy: 0.9824 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0365 - accuracy: 0.9873\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0489 - accuracy: 0.9832\n",
      "\n",
      "Epoch:  209\n",
      "199/199 - 8s - loss: 0.0707 - accuracy: 0.9741 - val_loss: 0.0379 - val_accuracy: 0.9871 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0253 - accuracy: 0.9912\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0361 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  210\n",
      "199/199 - 8s - loss: 0.0748 - accuracy: 0.9720 - val_loss: 0.0424 - val_accuracy: 0.9850 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0265 - accuracy: 0.9911\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0366 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  211\n",
      "199/199 - 8s - loss: 0.0656 - accuracy: 0.9752 - val_loss: 0.0408 - val_accuracy: 0.9869 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0281 - accuracy: 0.9908\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0387 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  212\n",
      "199/199 - 8s - loss: 0.0687 - accuracy: 0.9748 - val_loss: 0.0354 - val_accuracy: 0.9876 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0257 - accuracy: 0.9915\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0333 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  213\n",
      "199/199 - 8s - loss: 0.0668 - accuracy: 0.9745 - val_loss: 0.0461 - val_accuracy: 0.9846 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0318 - accuracy: 0.9899\n",
      "for testing\n",
      "265/265 [==============================] - 2s 8ms/step - loss: 0.0410 - accuracy: 0.9863\n",
      "\n",
      "Epoch:  214\n",
      "199/199 - 8s - loss: 0.0712 - accuracy: 0.9733 - val_loss: 0.0514 - val_accuracy: 0.9811 - 8s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0414 - accuracy: 0.9855\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0499 - accuracy: 0.9819\n",
      "\n",
      "Epoch:  215\n",
      "199/199 - 8s - loss: 0.0677 - accuracy: 0.9749 - val_loss: 0.0346 - val_accuracy: 0.9885 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0241 - accuracy: 0.9920\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0316 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  216\n",
      "199/199 - 8s - loss: 0.0616 - accuracy: 0.9768 - val_loss: 0.0346 - val_accuracy: 0.9885 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0235 - accuracy: 0.9923\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0330 - accuracy: 0.9889\n",
      "\n",
      "Epoch:  217\n",
      "199/199 - 8s - loss: 0.0666 - accuracy: 0.9743 - val_loss: 0.0420 - val_accuracy: 0.9861 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0256 - accuracy: 0.9919\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0403 - accuracy: 0.9876\n",
      "\n",
      "Epoch:  218\n",
      "199/199 - 8s - loss: 0.0658 - accuracy: 0.9744 - val_loss: 0.0403 - val_accuracy: 0.9858 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0292 - accuracy: 0.9900\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0421 - accuracy: 0.9857\n",
      "\n",
      "Epoch:  219\n",
      "199/199 - 8s - loss: 0.0669 - accuracy: 0.9750 - val_loss: 0.0400 - val_accuracy: 0.9871 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0260 - accuracy: 0.9913\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0351 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  220\n",
      "199/199 - 8s - loss: 0.0680 - accuracy: 0.9750 - val_loss: 0.0411 - val_accuracy: 0.9855 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0275 - accuracy: 0.9904\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0378 - accuracy: 0.9865\n",
      "\n",
      "Epoch:  221\n",
      "199/199 - 8s - loss: 0.0700 - accuracy: 0.9746 - val_loss: 0.0426 - val_accuracy: 0.9849 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0279 - accuracy: 0.9910\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0367 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  222\n",
      "199/199 - 8s - loss: 0.0686 - accuracy: 0.9744 - val_loss: 0.0437 - val_accuracy: 0.9856 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0290 - accuracy: 0.9906\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0421 - accuracy: 0.9863\n",
      "\n",
      "Epoch:  223\n",
      "199/199 - 8s - loss: 0.0638 - accuracy: 0.9763 - val_loss: 0.0340 - val_accuracy: 0.9872 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0209 - accuracy: 0.9930\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0326 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  224\n",
      "199/199 - 8s - loss: 0.0678 - accuracy: 0.9745 - val_loss: 0.0526 - val_accuracy: 0.9813 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0372 - accuracy: 0.9860\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0523 - accuracy: 0.9822\n",
      "\n",
      "Epoch:  225\n",
      "199/199 - 8s - loss: 0.0654 - accuracy: 0.9754 - val_loss: 0.0324 - val_accuracy: 0.9894 - 8s/epoch - 40ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0214 - accuracy: 0.9938\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0308 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  226\n",
      "199/199 - 8s - loss: 0.0664 - accuracy: 0.9756 - val_loss: 0.0377 - val_accuracy: 0.9880 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0238 - accuracy: 0.9929\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0358 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  227\n",
      "199/199 - 8s - loss: 0.0668 - accuracy: 0.9750 - val_loss: 0.0373 - val_accuracy: 0.9869 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0240 - accuracy: 0.9922\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0372 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  228\n",
      "199/199 - 8s - loss: 0.0679 - accuracy: 0.9757 - val_loss: 0.0392 - val_accuracy: 0.9865 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0257 - accuracy: 0.9920\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0353 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  229\n",
      "199/199 - 8s - loss: 0.0679 - accuracy: 0.9744 - val_loss: 0.0378 - val_accuracy: 0.9874 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0246 - accuracy: 0.9921\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0382 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  230\n",
      "199/199 - 8s - loss: 0.0596 - accuracy: 0.9780 - val_loss: 0.0422 - val_accuracy: 0.9859 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0269 - accuracy: 0.9907\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0430 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  231\n",
      "199/199 - 8s - loss: 0.0647 - accuracy: 0.9755 - val_loss: 0.0359 - val_accuracy: 0.9880 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0220 - accuracy: 0.9931\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0315 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  232\n",
      "199/199 - 8s - loss: 0.0617 - accuracy: 0.9770 - val_loss: 0.0359 - val_accuracy: 0.9875 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0229 - accuracy: 0.9926\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0330 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  233\n",
      "199/199 - 8s - loss: 0.0621 - accuracy: 0.9763 - val_loss: 0.0410 - val_accuracy: 0.9858 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0257 - accuracy: 0.9917\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0372 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  234\n",
      "199/199 - 8s - loss: 0.0623 - accuracy: 0.9765 - val_loss: 0.0328 - val_accuracy: 0.9891 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0192 - accuracy: 0.9937\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0323 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  235\n",
      "199/199 - 8s - loss: 0.0621 - accuracy: 0.9765 - val_loss: 0.0537 - val_accuracy: 0.9825 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0344 - accuracy: 0.9883\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0476 - accuracy: 0.9854\n",
      "\n",
      "Epoch:  236\n",
      "199/199 - 8s - loss: 0.0661 - accuracy: 0.9753 - val_loss: 0.0369 - val_accuracy: 0.9878 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0231 - accuracy: 0.9928\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0345 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  237\n",
      "199/199 - 8s - loss: 0.0656 - accuracy: 0.9758 - val_loss: 0.0340 - val_accuracy: 0.9882 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0206 - accuracy: 0.9931\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0323 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  238\n",
      "199/199 - 8s - loss: 0.0612 - accuracy: 0.9772 - val_loss: 0.0382 - val_accuracy: 0.9863 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0247 - accuracy: 0.9919\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0361 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  239\n",
      "199/199 - 8s - loss: 0.0619 - accuracy: 0.9772 - val_loss: 0.0296 - val_accuracy: 0.9898 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0180 - accuracy: 0.9942\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0257 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  240\n",
      "199/199 - 8s - loss: 0.0582 - accuracy: 0.9784 - val_loss: 0.0379 - val_accuracy: 0.9867 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0231 - accuracy: 0.9923\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0373 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  241\n",
      "199/199 - 8s - loss: 0.0645 - accuracy: 0.9765 - val_loss: 0.0353 - val_accuracy: 0.9882 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0227 - accuracy: 0.9929\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0315 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  242\n",
      "199/199 - 8s - loss: 0.0588 - accuracy: 0.9777 - val_loss: 0.0365 - val_accuracy: 0.9883 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0233 - accuracy: 0.9927\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0341 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  243\n",
      "199/199 - 8s - loss: 0.0642 - accuracy: 0.9754 - val_loss: 0.0423 - val_accuracy: 0.9849 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0273 - accuracy: 0.9911\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0352 - accuracy: 0.9875\n",
      "\n",
      "Epoch:  244\n",
      "199/199 - 8s - loss: 0.0612 - accuracy: 0.9776 - val_loss: 0.0346 - val_accuracy: 0.9882 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0206 - accuracy: 0.9939\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0312 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  245\n",
      "199/199 - 8s - loss: 0.0582 - accuracy: 0.9793 - val_loss: 0.0311 - val_accuracy: 0.9902 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0183 - accuracy: 0.9945\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0274 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  246\n",
      "199/199 - 8s - loss: 0.0602 - accuracy: 0.9785 - val_loss: 0.0442 - val_accuracy: 0.9842 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0265 - accuracy: 0.9907\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0431 - accuracy: 0.9854\n",
      "\n",
      "Epoch:  247\n",
      "199/199 - 8s - loss: 0.0621 - accuracy: 0.9769 - val_loss: 0.0345 - val_accuracy: 0.9883 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0190 - accuracy: 0.9940\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0272 - accuracy: 0.9902\n",
      "\n",
      "Epoch:  248\n",
      "199/199 - 8s - loss: 0.0600 - accuracy: 0.9777 - val_loss: 0.0430 - val_accuracy: 0.9857 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0259 - accuracy: 0.9914\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0410 - accuracy: 0.9877\n",
      "\n",
      "Epoch:  249\n",
      "199/199 - 8s - loss: 0.0599 - accuracy: 0.9776 - val_loss: 0.0324 - val_accuracy: 0.9883 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0192 - accuracy: 0.9943\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0298 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  250\n",
      "199/199 - 8s - loss: 0.0600 - accuracy: 0.9776 - val_loss: 0.0366 - val_accuracy: 0.9874 - 8s/epoch - 40ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0220 - accuracy: 0.9931\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0335 - accuracy: 0.9885\n",
      "\n",
      "Epoch:  251\n",
      "199/199 - 8s - loss: 0.0581 - accuracy: 0.9786 - val_loss: 0.0391 - val_accuracy: 0.9876 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0247 - accuracy: 0.9922\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0313 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  252\n",
      "199/199 - 8s - loss: 0.0611 - accuracy: 0.9764 - val_loss: 0.0383 - val_accuracy: 0.9864 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0258 - accuracy: 0.9913\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0376 - accuracy: 0.9869\n",
      "\n",
      "Epoch:  253\n",
      "199/199 - 8s - loss: 0.0596 - accuracy: 0.9780 - val_loss: 0.0423 - val_accuracy: 0.9869 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0287 - accuracy: 0.9906\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0431 - accuracy: 0.9852\n",
      "\n",
      "Epoch:  254\n",
      "199/199 - 8s - loss: 0.0606 - accuracy: 0.9775 - val_loss: 0.0385 - val_accuracy: 0.9870 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0229 - accuracy: 0.9930\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0339 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  255\n",
      "199/199 - 8s - loss: 0.0576 - accuracy: 0.9791 - val_loss: 0.0320 - val_accuracy: 0.9894 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0209 - accuracy: 0.9931\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0315 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  256\n",
      "199/199 - 8s - loss: 0.0580 - accuracy: 0.9792 - val_loss: 0.0466 - val_accuracy: 0.9839 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0326 - accuracy: 0.9888\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0460 - accuracy: 0.9837\n",
      "\n",
      "Epoch:  257\n",
      "199/199 - 8s - loss: 0.0682 - accuracy: 0.9745 - val_loss: 0.0342 - val_accuracy: 0.9876 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0211 - accuracy: 0.9933\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0297 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  258\n",
      "199/199 - 8s - loss: 0.0572 - accuracy: 0.9784 - val_loss: 0.0273 - val_accuracy: 0.9903 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0152 - accuracy: 0.9954\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0244 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  259\n",
      "199/199 - 8s - loss: 0.0585 - accuracy: 0.9789 - val_loss: 0.0350 - val_accuracy: 0.9881 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0210 - accuracy: 0.9927\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0311 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  260\n",
      "199/199 - 8s - loss: 0.0626 - accuracy: 0.9770 - val_loss: 0.0312 - val_accuracy: 0.9903 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0184 - accuracy: 0.9947\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0305 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  261\n",
      "199/199 - 8s - loss: 0.0588 - accuracy: 0.9777 - val_loss: 0.0330 - val_accuracy: 0.9887 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0191 - accuracy: 0.9940\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0304 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  262\n",
      "199/199 - 8s - loss: 0.0612 - accuracy: 0.9770 - val_loss: 0.0324 - val_accuracy: 0.9888 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0191 - accuracy: 0.9940\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0308 - accuracy: 0.9894\n",
      "\n",
      "Epoch:  263\n",
      "199/199 - 8s - loss: 0.0547 - accuracy: 0.9805 - val_loss: 0.0404 - val_accuracy: 0.9869 - 8s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0233 - accuracy: 0.9921\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0371 - accuracy: 0.9877\n",
      "\n",
      "Epoch:  264\n",
      "199/199 - 8s - loss: 0.0578 - accuracy: 0.9791 - val_loss: 0.0457 - val_accuracy: 0.9842 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0306 - accuracy: 0.9900\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0409 - accuracy: 0.9849\n",
      "\n",
      "Epoch:  265\n",
      "199/199 - 8s - loss: 0.0575 - accuracy: 0.9783 - val_loss: 0.0394 - val_accuracy: 0.9874 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0251 - accuracy: 0.9916\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0402 - accuracy: 0.9870\n",
      "\n",
      "Epoch:  266\n",
      "199/199 - 8s - loss: 0.0611 - accuracy: 0.9792 - val_loss: 0.0330 - val_accuracy: 0.9881 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0191 - accuracy: 0.9935\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0294 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  267\n",
      "199/199 - 8s - loss: 0.0604 - accuracy: 0.9775 - val_loss: 0.0445 - val_accuracy: 0.9843 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0295 - accuracy: 0.9901\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0379 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  268\n",
      "199/199 - 8s - loss: 0.0527 - accuracy: 0.9805 - val_loss: 0.0334 - val_accuracy: 0.9883 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0189 - accuracy: 0.9939\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0289 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  269\n",
      "199/199 - 8s - loss: 0.0547 - accuracy: 0.9798 - val_loss: 0.0296 - val_accuracy: 0.9901 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0175 - accuracy: 0.9949\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0252 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  270\n",
      "199/199 - 8s - loss: 0.0552 - accuracy: 0.9805 - val_loss: 0.0344 - val_accuracy: 0.9876 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0184 - accuracy: 0.9940\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0313 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  271\n",
      "199/199 - 8s - loss: 0.0578 - accuracy: 0.9782 - val_loss: 0.0384 - val_accuracy: 0.9880 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0250 - accuracy: 0.9923\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0382 - accuracy: 0.9863\n",
      "\n",
      "Epoch:  272\n",
      "199/199 - 8s - loss: 0.0592 - accuracy: 0.9778 - val_loss: 0.0456 - val_accuracy: 0.9845 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0273 - accuracy: 0.9906\n",
      "for testing\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.0393 - accuracy: 0.9865\n",
      "\n",
      "Epoch:  273\n",
      "199/199 - 8s - loss: 0.0552 - accuracy: 0.9793 - val_loss: 0.0373 - val_accuracy: 0.9876 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0207 - accuracy: 0.9935\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0315 - accuracy: 0.9902\n",
      "\n",
      "Epoch:  274\n",
      "199/199 - 8s - loss: 0.0592 - accuracy: 0.9785 - val_loss: 0.0420 - val_accuracy: 0.9857 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0252 - accuracy: 0.9917\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0359 - accuracy: 0.9883\n",
      "\n",
      "Epoch:  275\n",
      "199/199 - 8s - loss: 0.0526 - accuracy: 0.9797 - val_loss: 0.0369 - val_accuracy: 0.9863 - 8s/epoch - 40ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0232 - accuracy: 0.9925\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0357 - accuracy: 0.9871\n",
      "\n",
      "Epoch:  276\n",
      "199/199 - 8s - loss: 0.0569 - accuracy: 0.9794 - val_loss: 0.0410 - val_accuracy: 0.9863 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0253 - accuracy: 0.9916\n",
      "for testing\n",
      "265/265 [==============================] - 1s 6ms/step - loss: 0.0395 - accuracy: 0.9868\n",
      "\n",
      "Epoch:  277\n",
      "199/199 - 8s - loss: 0.0624 - accuracy: 0.9787 - val_loss: 0.0362 - val_accuracy: 0.9876 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0247 - accuracy: 0.9929\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0346 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  278\n",
      "199/199 - 8s - loss: 0.0547 - accuracy: 0.9791 - val_loss: 0.0419 - val_accuracy: 0.9859 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0264 - accuracy: 0.9914\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0345 - accuracy: 0.9871\n",
      "\n",
      "Epoch:  279\n",
      "199/199 - 8s - loss: 0.0535 - accuracy: 0.9807 - val_loss: 0.0430 - val_accuracy: 0.9851 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0262 - accuracy: 0.9903\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0405 - accuracy: 0.9852\n",
      "\n",
      "Epoch:  280\n",
      "199/199 - 8s - loss: 0.0545 - accuracy: 0.9787 - val_loss: 0.0340 - val_accuracy: 0.9885 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0188 - accuracy: 0.9941\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0286 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  281\n",
      "199/199 - 8s - loss: 0.0559 - accuracy: 0.9799 - val_loss: 0.0417 - val_accuracy: 0.9846 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0259 - accuracy: 0.9911\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0356 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  282\n",
      "199/199 - 8s - loss: 0.0567 - accuracy: 0.9782 - val_loss: 0.0391 - val_accuracy: 0.9871 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0226 - accuracy: 0.9932\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0357 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  283\n",
      "199/199 - 8s - loss: 0.0535 - accuracy: 0.9802 - val_loss: 0.0377 - val_accuracy: 0.9871 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0226 - accuracy: 0.9925\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0327 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  284\n",
      "199/199 - 8s - loss: 0.0559 - accuracy: 0.9791 - val_loss: 0.0392 - val_accuracy: 0.9874 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0239 - accuracy: 0.9929\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0344 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  285\n",
      "199/199 - 8s - loss: 0.0536 - accuracy: 0.9794 - val_loss: 0.0321 - val_accuracy: 0.9894 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0179 - accuracy: 0.9946\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0267 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  286\n",
      "199/199 - 8s - loss: 0.0569 - accuracy: 0.9800 - val_loss: 0.0327 - val_accuracy: 0.9894 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0171 - accuracy: 0.9945\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0292 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  287\n",
      "199/199 - 8s - loss: 0.0556 - accuracy: 0.9798 - val_loss: 0.0344 - val_accuracy: 0.9882 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0204 - accuracy: 0.9939\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0307 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  288\n",
      "199/199 - 8s - loss: 0.0514 - accuracy: 0.9811 - val_loss: 0.0295 - val_accuracy: 0.9909 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0162 - accuracy: 0.9951\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0232 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  289\n",
      "199/199 - 8s - loss: 0.0585 - accuracy: 0.9788 - val_loss: 0.0395 - val_accuracy: 0.9872 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0205 - accuracy: 0.9933\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0331 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  290\n",
      "199/199 - 8s - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0285 - val_accuracy: 0.9911 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0155 - accuracy: 0.9955\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0255 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  291\n",
      "199/199 - 8s - loss: 0.0543 - accuracy: 0.9795 - val_loss: 0.0308 - val_accuracy: 0.9901 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0168 - accuracy: 0.9952\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0253 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  292\n",
      "199/199 - 8s - loss: 0.0573 - accuracy: 0.9788 - val_loss: 0.0393 - val_accuracy: 0.9865 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0229 - accuracy: 0.9926\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0347 - accuracy: 0.9902\n",
      "\n",
      "Epoch:  293\n",
      "199/199 - 8s - loss: 0.0500 - accuracy: 0.9813 - val_loss: 0.0284 - val_accuracy: 0.9906 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0150 - accuracy: 0.9957\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0292 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  294\n",
      "199/199 - 8s - loss: 0.0548 - accuracy: 0.9805 - val_loss: 0.0284 - val_accuracy: 0.9901 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0150 - accuracy: 0.9956\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0274 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  295\n",
      "199/199 - 8s - loss: 0.0482 - accuracy: 0.9822 - val_loss: 0.0351 - val_accuracy: 0.9888 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0182 - accuracy: 0.9942\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0353 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  296\n",
      "199/199 - 8s - loss: 0.0481 - accuracy: 0.9825 - val_loss: 0.0330 - val_accuracy: 0.9883 - 8s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0183 - accuracy: 0.9937\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0301 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  297\n",
      "199/199 - 8s - loss: 0.0556 - accuracy: 0.9797 - val_loss: 0.0388 - val_accuracy: 0.9863 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0231 - accuracy: 0.9926\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0377 - accuracy: 0.9881\n",
      "\n",
      "Epoch:  298\n",
      "199/199 - 8s - loss: 0.0519 - accuracy: 0.9810 - val_loss: 0.0343 - val_accuracy: 0.9883 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0168 - accuracy: 0.9947\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0316 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  299\n",
      "199/199 - 8s - loss: 0.0502 - accuracy: 0.9799 - val_loss: 0.0344 - val_accuracy: 0.9870 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0188 - accuracy: 0.9937\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0329 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  300\n",
      "199/199 - 8s - loss: 0.0575 - accuracy: 0.9785 - val_loss: 0.0274 - val_accuracy: 0.9907 - 8s/epoch - 40ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0141 - accuracy: 0.9959\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0257 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  301\n",
      "199/199 - 8s - loss: 0.0500 - accuracy: 0.9821 - val_loss: 0.0287 - val_accuracy: 0.9902 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0146 - accuracy: 0.9957\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0276 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  302\n",
      "199/199 - 8s - loss: 0.0506 - accuracy: 0.9811 - val_loss: 0.0332 - val_accuracy: 0.9890 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0183 - accuracy: 0.9945\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0285 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  303\n",
      "199/199 - 8s - loss: 0.0499 - accuracy: 0.9822 - val_loss: 0.0285 - val_accuracy: 0.9894 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0148 - accuracy: 0.9953\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0294 - accuracy: 0.9902\n",
      "\n",
      "Epoch:  304\n",
      "199/199 - 8s - loss: 0.0494 - accuracy: 0.9816 - val_loss: 0.0349 - val_accuracy: 0.9898 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0197 - accuracy: 0.9945\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0330 - accuracy: 0.9902\n",
      "\n",
      "Epoch:  305\n",
      "199/199 - 8s - loss: 0.0565 - accuracy: 0.9782 - val_loss: 0.0372 - val_accuracy: 0.9884 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0209 - accuracy: 0.9935\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0358 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  306\n",
      "199/199 - 8s - loss: 0.0452 - accuracy: 0.9830 - val_loss: 0.0370 - val_accuracy: 0.9861 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0203 - accuracy: 0.9929\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0341 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  307\n",
      "199/199 - 8s - loss: 0.0514 - accuracy: 0.9811 - val_loss: 0.0351 - val_accuracy: 0.9878 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0189 - accuracy: 0.9942\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0304 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  308\n",
      "199/199 - 8s - loss: 0.0530 - accuracy: 0.9807 - val_loss: 0.0301 - val_accuracy: 0.9897 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0163 - accuracy: 0.9951\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0296 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  309\n",
      "199/199 - 8s - loss: 0.0522 - accuracy: 0.9808 - val_loss: 0.0273 - val_accuracy: 0.9896 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0135 - accuracy: 0.9957\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0295 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  310\n",
      "199/199 - 8s - loss: 0.0552 - accuracy: 0.9800 - val_loss: 0.0546 - val_accuracy: 0.9813 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0369 - accuracy: 0.9862\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0572 - accuracy: 0.9815\n",
      "\n",
      "Epoch:  311\n",
      "199/199 - 8s - loss: 0.0554 - accuracy: 0.9796 - val_loss: 0.0366 - val_accuracy: 0.9867 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0224 - accuracy: 0.9929\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0378 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  312\n",
      "199/199 - 8s - loss: 0.0493 - accuracy: 0.9807 - val_loss: 0.0325 - val_accuracy: 0.9893 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0168 - accuracy: 0.9946\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0374 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  313\n",
      "199/199 - 8s - loss: 0.0482 - accuracy: 0.9812 - val_loss: 0.0350 - val_accuracy: 0.9887 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0170 - accuracy: 0.9945\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0336 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  314\n",
      "199/199 - 8s - loss: 0.0504 - accuracy: 0.9819 - val_loss: 0.0307 - val_accuracy: 0.9895 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0160 - accuracy: 0.9955\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0352 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  315\n",
      "199/199 - 8s - loss: 0.0472 - accuracy: 0.9823 - val_loss: 0.0348 - val_accuracy: 0.9881 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0188 - accuracy: 0.9942\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0358 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  316\n",
      "199/199 - 8s - loss: 0.0730 - accuracy: 0.9763 - val_loss: 0.0342 - val_accuracy: 0.9890 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0185 - accuracy: 0.9944\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0289 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  317\n",
      "199/199 - 8s - loss: 0.0495 - accuracy: 0.9810 - val_loss: 0.0359 - val_accuracy: 0.9882 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0193 - accuracy: 0.9939\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0319 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  318\n",
      "199/199 - 8s - loss: 0.0491 - accuracy: 0.9812 - val_loss: 0.0310 - val_accuracy: 0.9900 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0173 - accuracy: 0.9944\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0286 - accuracy: 0.9904\n",
      "\n",
      "Epoch:  319\n",
      "199/199 - 8s - loss: 0.0485 - accuracy: 0.9819 - val_loss: 0.0270 - val_accuracy: 0.9908 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0137 - accuracy: 0.9961\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0237 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  320\n",
      "199/199 - 8s - loss: 0.0479 - accuracy: 0.9828 - val_loss: 0.0288 - val_accuracy: 0.9903 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0148 - accuracy: 0.9957\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0273 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  321\n",
      "199/199 - 8s - loss: 0.0516 - accuracy: 0.9806 - val_loss: 0.0385 - val_accuracy: 0.9857 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0237 - accuracy: 0.9921\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0364 - accuracy: 0.9867\n",
      "\n",
      "Epoch:  322\n",
      "199/199 - 8s - loss: 0.0573 - accuracy: 0.9795 - val_loss: 0.0364 - val_accuracy: 0.9870 - 8s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0206 - accuracy: 0.9933\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0366 - accuracy: 0.9887\n",
      "\n",
      "Epoch:  323\n",
      "199/199 - 8s - loss: 0.0511 - accuracy: 0.9815 - val_loss: 0.0283 - val_accuracy: 0.9908 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0150 - accuracy: 0.9954\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0278 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  324\n",
      "199/199 - 8s - loss: 0.0446 - accuracy: 0.9831 - val_loss: 0.0278 - val_accuracy: 0.9909 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0144 - accuracy: 0.9959\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0244 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  325\n",
      "199/199 - 8s - loss: 0.0447 - accuracy: 0.9826 - val_loss: 0.0331 - val_accuracy: 0.9895 - 8s/epoch - 41ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0167 - accuracy: 0.9950\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0334 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  326\n",
      "199/199 - 8s - loss: 0.0532 - accuracy: 0.9805 - val_loss: 0.0313 - val_accuracy: 0.9878 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0180 - accuracy: 0.9941\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0324 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  327\n",
      "199/199 - 8s - loss: 0.0551 - accuracy: 0.9800 - val_loss: 0.0275 - val_accuracy: 0.9911 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0141 - accuracy: 0.9960\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0283 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  328\n",
      "199/199 - 8s - loss: 0.0537 - accuracy: 0.9795 - val_loss: 0.0399 - val_accuracy: 0.9875 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0240 - accuracy: 0.9923\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0381 - accuracy: 0.9865\n",
      "\n",
      "Epoch:  329\n",
      "199/199 - 8s - loss: 0.0483 - accuracy: 0.9821 - val_loss: 0.0357 - val_accuracy: 0.9881 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0194 - accuracy: 0.9939\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0338 - accuracy: 0.9887\n",
      "\n",
      "Epoch:  330\n",
      "199/199 - 8s - loss: 0.0484 - accuracy: 0.9826 - val_loss: 0.0316 - val_accuracy: 0.9889 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0188 - accuracy: 0.9936\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0304 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  331\n",
      "199/199 - 8s - loss: 0.0479 - accuracy: 0.9822 - val_loss: 0.0259 - val_accuracy: 0.9907 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0128 - accuracy: 0.9962\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0219 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  332\n",
      "199/199 - 8s - loss: 0.0553 - accuracy: 0.9802 - val_loss: 0.0276 - val_accuracy: 0.9900 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0137 - accuracy: 0.9956\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0274 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  333\n",
      "199/199 - 8s - loss: 0.0466 - accuracy: 0.9820 - val_loss: 0.0290 - val_accuracy: 0.9904 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0155 - accuracy: 0.9950\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0247 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  334\n",
      "199/199 - 8s - loss: 0.0527 - accuracy: 0.9812 - val_loss: 0.0376 - val_accuracy: 0.9872 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0199 - accuracy: 0.9937\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0343 - accuracy: 0.9884\n",
      "\n",
      "Epoch:  335\n",
      "199/199 - 8s - loss: 0.0480 - accuracy: 0.9828 - val_loss: 0.0293 - val_accuracy: 0.9903 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0154 - accuracy: 0.9961\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0265 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  336\n",
      "199/199 - 8s - loss: 0.0467 - accuracy: 0.9823 - val_loss: 0.0295 - val_accuracy: 0.9893 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0147 - accuracy: 0.9954\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0283 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  337\n",
      "199/199 - 8s - loss: 0.0433 - accuracy: 0.9842 - val_loss: 0.0343 - val_accuracy: 0.9868 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0168 - accuracy: 0.9944\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0306 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  338\n",
      "199/199 - 8s - loss: 0.0494 - accuracy: 0.9825 - val_loss: 0.0323 - val_accuracy: 0.9893 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0158 - accuracy: 0.9954\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0291 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  339\n",
      "199/199 - 9s - loss: 0.0485 - accuracy: 0.9822 - val_loss: 0.0292 - val_accuracy: 0.9895 - 9s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0136 - accuracy: 0.9960\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0259 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  340\n",
      "199/199 - 9s - loss: 0.0485 - accuracy: 0.9820 - val_loss: 0.0360 - val_accuracy: 0.9888 - 9s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0193 - accuracy: 0.9941\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0343 - accuracy: 0.9874\n",
      "\n",
      "Epoch:  341\n",
      "199/199 - 8s - loss: 0.0459 - accuracy: 0.9832 - val_loss: 0.0316 - val_accuracy: 0.9897 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0145 - accuracy: 0.9959\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0278 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  342\n",
      "199/199 - 8s - loss: 0.0479 - accuracy: 0.9829 - val_loss: 0.0293 - val_accuracy: 0.9902 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0145 - accuracy: 0.9960\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0273 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  343\n",
      "199/199 - 8s - loss: 0.0486 - accuracy: 0.9829 - val_loss: 0.0302 - val_accuracy: 0.9897 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0139 - accuracy: 0.9957\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0243 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  344\n",
      "199/199 - 8s - loss: 0.0452 - accuracy: 0.9832 - val_loss: 0.0348 - val_accuracy: 0.9882 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0184 - accuracy: 0.9943\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0295 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  345\n",
      "199/199 - 8s - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0277 - val_accuracy: 0.9900 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0143 - accuracy: 0.9952\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0273 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  346\n",
      "199/199 - 8s - loss: 0.0490 - accuracy: 0.9813 - val_loss: 0.0396 - val_accuracy: 0.9864 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0197 - accuracy: 0.9934\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0346 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  347\n",
      "199/199 - 8s - loss: 0.0461 - accuracy: 0.9830 - val_loss: 0.0284 - val_accuracy: 0.9909 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0132 - accuracy: 0.9968\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0231 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  348\n",
      "199/199 - 8s - loss: 0.0473 - accuracy: 0.9825 - val_loss: 0.0371 - val_accuracy: 0.9869 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0187 - accuracy: 0.9939\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0310 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  349\n",
      "199/199 - 8s - loss: 0.0489 - accuracy: 0.9816 - val_loss: 0.0317 - val_accuracy: 0.9891 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0179 - accuracy: 0.9950\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0283 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  350\n",
      "199/199 - 8s - loss: 0.0429 - accuracy: 0.9854 - val_loss: 0.0322 - val_accuracy: 0.9902 - 8s/epoch - 41ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0154 - accuracy: 0.9956\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0270 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  351\n",
      "199/199 - 8s - loss: 0.0480 - accuracy: 0.9823 - val_loss: 0.0283 - val_accuracy: 0.9891 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0139 - accuracy: 0.9952\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0299 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  352\n",
      "199/199 - 8s - loss: 0.0427 - accuracy: 0.9847 - val_loss: 0.0264 - val_accuracy: 0.9906 - 8s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0118 - accuracy: 0.9965\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0254 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  353\n",
      "199/199 - 8s - loss: 0.0463 - accuracy: 0.9821 - val_loss: 0.0293 - val_accuracy: 0.9893 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0152 - accuracy: 0.9953\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0289 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  354\n",
      "199/199 - 8s - loss: 0.0453 - accuracy: 0.9825 - val_loss: 0.0378 - val_accuracy: 0.9876 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0219 - accuracy: 0.9929\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0364 - accuracy: 0.9871\n",
      "\n",
      "Epoch:  355\n",
      "199/199 - 8s - loss: 0.0512 - accuracy: 0.9809 - val_loss: 0.0357 - val_accuracy: 0.9876 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0204 - accuracy: 0.9932\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0342 - accuracy: 0.9890\n",
      "\n",
      "Epoch:  356\n",
      "199/199 - 8s - loss: 0.0492 - accuracy: 0.9823 - val_loss: 0.0288 - val_accuracy: 0.9895 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0156 - accuracy: 0.9953\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0285 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  357\n",
      "199/199 - 8s - loss: 0.0434 - accuracy: 0.9832 - val_loss: 0.0325 - val_accuracy: 0.9887 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0152 - accuracy: 0.9955\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0307 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  358\n",
      "199/199 - 8s - loss: 0.0443 - accuracy: 0.9840 - val_loss: 0.0285 - val_accuracy: 0.9895 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0128 - accuracy: 0.9959\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0278 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  359\n",
      "199/199 - 8s - loss: 0.0472 - accuracy: 0.9824 - val_loss: 0.0332 - val_accuracy: 0.9902 - 8s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0165 - accuracy: 0.9954\n",
      "for testing\n",
      "265/265 [==============================] - 2s 8ms/step - loss: 0.0275 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  360\n",
      "199/199 - 10s - loss: 0.0434 - accuracy: 0.9832 - val_loss: 0.0335 - val_accuracy: 0.9878 - 10s/epoch - 49ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0175 - accuracy: 0.9943\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0347 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  361\n",
      "199/199 - 9s - loss: 0.0474 - accuracy: 0.9822 - val_loss: 0.0300 - val_accuracy: 0.9897 - 9s/epoch - 45ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0143 - accuracy: 0.9958\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0317 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  362\n",
      "199/199 - 9s - loss: 0.0431 - accuracy: 0.9844 - val_loss: 0.0391 - val_accuracy: 0.9863 - 9s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0209 - accuracy: 0.9929\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0387 - accuracy: 0.9869\n",
      "\n",
      "Epoch:  363\n",
      "199/199 - 8s - loss: 0.0458 - accuracy: 0.9830 - val_loss: 0.0386 - val_accuracy: 0.9859 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0206 - accuracy: 0.9930\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0385 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  364\n",
      "199/199 - 8s - loss: 0.0441 - accuracy: 0.9836 - val_loss: 0.0311 - val_accuracy: 0.9883 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0145 - accuracy: 0.9954\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0289 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  365\n",
      "199/199 - 8s - loss: 0.0452 - accuracy: 0.9826 - val_loss: 0.0291 - val_accuracy: 0.9897 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0133 - accuracy: 0.9961\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0313 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  366\n",
      "199/199 - 8s - loss: 0.0483 - accuracy: 0.9820 - val_loss: 0.0287 - val_accuracy: 0.9903 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0140 - accuracy: 0.9963\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0306 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  367\n",
      "199/199 - 8s - loss: 0.0432 - accuracy: 0.9847 - val_loss: 0.0351 - val_accuracy: 0.9869 - 8s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0177 - accuracy: 0.9945\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0323 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  368\n",
      "199/199 - 8s - loss: 0.0459 - accuracy: 0.9830 - val_loss: 0.0268 - val_accuracy: 0.9897 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0137 - accuracy: 0.9957\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0279 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  369\n",
      "199/199 - 8s - loss: 0.0447 - accuracy: 0.9843 - val_loss: 0.0334 - val_accuracy: 0.9883 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0198 - accuracy: 0.9934\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0345 - accuracy: 0.9882\n",
      "\n",
      "Epoch:  370\n",
      "199/199 - 9s - loss: 0.0433 - accuracy: 0.9843 - val_loss: 0.0350 - val_accuracy: 0.9883 - 9s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0185 - accuracy: 0.9945\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0356 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  371\n",
      "199/199 - 8s - loss: 0.0467 - accuracy: 0.9819 - val_loss: 0.0310 - val_accuracy: 0.9893 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0141 - accuracy: 0.9957\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0278 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  372\n",
      "199/199 - 8s - loss: 0.0435 - accuracy: 0.9835 - val_loss: 0.0293 - val_accuracy: 0.9884 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0144 - accuracy: 0.9953\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0310 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  373\n",
      "199/199 - 8s - loss: 0.0421 - accuracy: 0.9840 - val_loss: 0.0323 - val_accuracy: 0.9898 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0141 - accuracy: 0.9957\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0296 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  374\n",
      "199/199 - 8s - loss: 0.0477 - accuracy: 0.9822 - val_loss: 0.0265 - val_accuracy: 0.9919 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0115 - accuracy: 0.9973\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0250 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  375\n",
      "199/199 - 8s - loss: 0.0457 - accuracy: 0.9838 - val_loss: 0.0282 - val_accuracy: 0.9910 - 8s/epoch - 41ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0140 - accuracy: 0.9961\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0286 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  376\n",
      "199/199 - 8s - loss: 0.0431 - accuracy: 0.9848 - val_loss: 0.0380 - val_accuracy: 0.9871 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0235 - accuracy: 0.9917\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0374 - accuracy: 0.9862\n",
      "\n",
      "Epoch:  377\n",
      "199/199 - 9s - loss: 0.0421 - accuracy: 0.9843 - val_loss: 0.0381 - val_accuracy: 0.9875 - 9s/epoch - 45ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0194 - accuracy: 0.9937\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0367 - accuracy: 0.9885\n",
      "\n",
      "Epoch:  378\n",
      "199/199 - 8s - loss: 0.0498 - accuracy: 0.9820 - val_loss: 0.0301 - val_accuracy: 0.9902 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0147 - accuracy: 0.9956\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0278 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  379\n",
      "199/199 - 8s - loss: 0.0418 - accuracy: 0.9851 - val_loss: 0.0288 - val_accuracy: 0.9902 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0132 - accuracy: 0.9961\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0250 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  380\n",
      "199/199 - 8s - loss: 0.0494 - accuracy: 0.9815 - val_loss: 0.0265 - val_accuracy: 0.9907 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0128 - accuracy: 0.9966\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0269 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  381\n",
      "199/199 - 8s - loss: 0.0410 - accuracy: 0.9853 - val_loss: 0.0297 - val_accuracy: 0.9898 - 8s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0127 - accuracy: 0.9962\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0290 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  382\n",
      "199/199 - 8s - loss: 0.0420 - accuracy: 0.9850 - val_loss: 0.0278 - val_accuracy: 0.9916 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0133 - accuracy: 0.9965\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0281 - accuracy: 0.9902\n",
      "\n",
      "Epoch:  383\n",
      "199/199 - 8s - loss: 0.0447 - accuracy: 0.9839 - val_loss: 0.0322 - val_accuracy: 0.9894 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0155 - accuracy: 0.9954\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0327 - accuracy: 0.9904\n",
      "\n",
      "Epoch:  384\n",
      "199/199 - 8s - loss: 0.0478 - accuracy: 0.9834 - val_loss: 0.0403 - val_accuracy: 0.9855 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0217 - accuracy: 0.9922\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0404 - accuracy: 0.9878\n",
      "\n",
      "Epoch:  385\n",
      "199/199 - 8s - loss: 0.0449 - accuracy: 0.9842 - val_loss: 0.0287 - val_accuracy: 0.9893 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0126 - accuracy: 0.9960\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0261 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  386\n",
      "199/199 - 8s - loss: 0.0485 - accuracy: 0.9820 - val_loss: 0.0306 - val_accuracy: 0.9894 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0154 - accuracy: 0.9950\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0300 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  387\n",
      "199/199 - 8s - loss: 0.0462 - accuracy: 0.9836 - val_loss: 0.0264 - val_accuracy: 0.9908 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0123 - accuracy: 0.9965\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0288 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  388\n",
      "199/199 - 8s - loss: 0.0401 - accuracy: 0.9854 - val_loss: 0.0262 - val_accuracy: 0.9916 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0121 - accuracy: 0.9967\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0244 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  389\n",
      "199/199 - 8s - loss: 0.0420 - accuracy: 0.9841 - val_loss: 0.0276 - val_accuracy: 0.9903 - 8s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0125 - accuracy: 0.9960\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0243 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  390\n",
      "199/199 - 8s - loss: 0.0444 - accuracy: 0.9842 - val_loss: 0.0355 - val_accuracy: 0.9885 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0172 - accuracy: 0.9945\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0301 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  391\n",
      "199/199 - 8s - loss: 0.0409 - accuracy: 0.9854 - val_loss: 0.0265 - val_accuracy: 0.9907 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0135 - accuracy: 0.9963\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0246 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  392\n",
      "199/199 - 8s - loss: 0.0442 - accuracy: 0.9835 - val_loss: 0.0306 - val_accuracy: 0.9904 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0137 - accuracy: 0.9963\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0281 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  393\n",
      "199/199 - 8s - loss: 0.0437 - accuracy: 0.9833 - val_loss: 0.0347 - val_accuracy: 0.9885 - 8s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0170 - accuracy: 0.9943\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0346 - accuracy: 0.9885\n",
      "\n",
      "Epoch:  394\n",
      "199/199 - 8s - loss: 0.0430 - accuracy: 0.9839 - val_loss: 0.0268 - val_accuracy: 0.9915 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0113 - accuracy: 0.9968\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0247 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  395\n",
      "199/199 - 8s - loss: 0.0407 - accuracy: 0.9848 - val_loss: 0.0306 - val_accuracy: 0.9883 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0136 - accuracy: 0.9954\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0296 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  396\n",
      "199/199 - 8s - loss: 0.0445 - accuracy: 0.9840 - val_loss: 0.0312 - val_accuracy: 0.9883 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0147 - accuracy: 0.9954\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0297 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  397\n",
      "199/199 - 8s - loss: 0.0403 - accuracy: 0.9844 - val_loss: 0.0343 - val_accuracy: 0.9894 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0165 - accuracy: 0.9953\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0300 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  398\n",
      "199/199 - 8s - loss: 0.0423 - accuracy: 0.9839 - val_loss: 0.0240 - val_accuracy: 0.9921 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0111 - accuracy: 0.9970\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0242 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  399\n",
      "199/199 - 8s - loss: 0.0460 - accuracy: 0.9829 - val_loss: 0.0403 - val_accuracy: 0.9869 - 8s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0216 - accuracy: 0.9935\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0365 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  400\n",
      "199/199 - 8s - loss: 0.0477 - accuracy: 0.9828 - val_loss: 0.0343 - val_accuracy: 0.9881 - 8s/epoch - 41ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0165 - accuracy: 0.9948\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0321 - accuracy: 0.9894\n"
     ]
    }
   ],
   "source": [
    "for x in range(400):\n",
    "    print(\"\\nEpoch: \",x+1)\n",
    "    history = model.fit(X_train ,y_train ,batch_size=BATCH_SIZE ,epochs=1, verbose=2, shuffle=True, validation_split = 0.25)\n",
    "    if history_dataframe.size == 0:\n",
    "        history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    else:\n",
    "        history_dataframe = pd.concat([history_dataframe,pd.DataFrame.from_dict(history.history)],axis=0,ignore_index=True)\n",
    "    \n",
    "    print(\"for training\")\n",
    "    train_eva.append(model.evaluate(X_train,y_train))\n",
    "    print(\"for testing\")\n",
    "    test_eva.append(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c8463e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva_df = pd.DataFrame(train_eva,columns=['loss','accuracy'])\n",
    "test_eva_df = pd.DataFrame(test_eva,columns=['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "708b9560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(df,title,xlabel,ylabel,values=['loss'],legends=[]):\n",
    "    \n",
    "    for value in values:\n",
    "        epoch_count = range(1, len(df.index) + 1)\n",
    "        plt.plot(epoch_count, df[value].tolist())\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    if legends==[]:\n",
    "        legends = values\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35c781fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(train_eva_df,'Train','Epoch','Loss',['loss','accuracy'])\n",
    "plot_graph(test_eva_df,'Test','Epoch','Loss',['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8db1e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9973426461219788"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eva_df['accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7560c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss          0\n",
       "accuracy    373\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eva_df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd060757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9930325746536255"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eva_df['accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9601cff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss          0\n",
       "accuracy    330\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eva_df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f71d4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  401\n",
      "265/265 - 10s - loss: 0.0546 - accuracy: 0.9806 - 10s/epoch - 37ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0155 - accuracy: 0.9954\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0287 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  402\n",
      "265/265 - 10s - loss: 0.0456 - accuracy: 0.9836 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0142 - accuracy: 0.9956\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0278 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  403\n",
      "265/265 - 10s - loss: 0.0550 - accuracy: 0.9810 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0171 - accuracy: 0.9950\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0294 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  404\n",
      "265/265 - 10s - loss: 0.0479 - accuracy: 0.9828 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0160 - accuracy: 0.9949\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0339 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  405\n",
      "265/265 - 10s - loss: 0.0468 - accuracy: 0.9833 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0111 - accuracy: 0.9970\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0250 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  406\n",
      "265/265 - 10s - loss: 0.0467 - accuracy: 0.9827 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0114 - accuracy: 0.9971\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0233 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  407\n",
      "265/265 - 10s - loss: 0.0469 - accuracy: 0.9834 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0133 - accuracy: 0.9960\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0296 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  408\n",
      "265/265 - 10s - loss: 0.0508 - accuracy: 0.9821 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0115 - accuracy: 0.9971\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0252 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  409\n",
      "265/265 - 10s - loss: 0.0482 - accuracy: 0.9822 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0085 - accuracy: 0.9977\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0232 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  410\n",
      "265/265 - 10s - loss: 0.0469 - accuracy: 0.9824 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0119 - accuracy: 0.9964\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0246 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  411\n",
      "265/265 - 10s - loss: 0.0450 - accuracy: 0.9841 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0098 - accuracy: 0.9973\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0234 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  412\n",
      "265/265 - 10s - loss: 0.0464 - accuracy: 0.9834 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0202 - accuracy: 0.9931\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0382 - accuracy: 0.9863\n",
      "\n",
      "Epoch:  413\n",
      "265/265 - 10s - loss: 0.0497 - accuracy: 0.9819 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0118 - accuracy: 0.9966\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0253 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  414\n",
      "265/265 - 10s - loss: 0.0439 - accuracy: 0.9843 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0083 - accuracy: 0.9977\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0242 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  415\n",
      "265/265 - 10s - loss: 0.0451 - accuracy: 0.9831 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0086 - accuracy: 0.9979\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0244 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  416\n",
      "265/265 - 10s - loss: 0.0471 - accuracy: 0.9828 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0105 - accuracy: 0.9970\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0239 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  417\n",
      "265/265 - 10s - loss: 0.0465 - accuracy: 0.9832 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0085 - accuracy: 0.9978\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0233 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  418\n",
      "265/265 - 10s - loss: 0.0447 - accuracy: 0.9836 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0089 - accuracy: 0.9974\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0226 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  419\n",
      "265/265 - 10s - loss: 0.0470 - accuracy: 0.9836 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0091 - accuracy: 0.9976\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0248 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  420\n",
      "265/265 - 10s - loss: 0.0447 - accuracy: 0.9838 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0097 - accuracy: 0.9976\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0243 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  421\n",
      "265/265 - 10s - loss: 0.0441 - accuracy: 0.9838 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0121 - accuracy: 0.9963\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0271 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  422\n",
      "265/265 - 11s - loss: 0.0473 - accuracy: 0.9824 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0120 - accuracy: 0.9963\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0288 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  423\n",
      "265/265 - 10s - loss: 0.0427 - accuracy: 0.9838 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0105 - accuracy: 0.9971\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0265 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  424\n",
      "265/265 - 10s - loss: 0.0478 - accuracy: 0.9819 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0089 - accuracy: 0.9978\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0285 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  425\n",
      "265/265 - 10s - loss: 0.0467 - accuracy: 0.9837 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0124 - accuracy: 0.9967\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0246 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  426\n",
      "265/265 - 10s - loss: 0.0462 - accuracy: 0.9835 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0087 - accuracy: 0.9979\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0214 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  427\n",
      "265/265 - 10s - loss: 0.0444 - accuracy: 0.9844 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0096 - accuracy: 0.9972\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0242 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  428\n",
      "265/265 - 11s - loss: 0.0458 - accuracy: 0.9830 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0107 - accuracy: 0.9966\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0276 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  429\n",
      "265/265 - 11s - loss: 0.0407 - accuracy: 0.9851 - 11s/epoch - 42ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0098 - accuracy: 0.9972\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0237 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  430\n",
      "265/265 - 10s - loss: 0.0525 - accuracy: 0.9816 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0094 - accuracy: 0.9973\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0233 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  431\n",
      "265/265 - 10s - loss: 0.0440 - accuracy: 0.9840 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0197 - accuracy: 0.9929\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0372 - accuracy: 0.9872\n",
      "\n",
      "Epoch:  432\n",
      "265/265 - 10s - loss: 0.0455 - accuracy: 0.9831 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0118 - accuracy: 0.9960\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0257 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  433\n",
      "265/265 - 10s - loss: 0.0412 - accuracy: 0.9857 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0085 - accuracy: 0.9977\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0220 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  434\n",
      "265/265 - 10s - loss: 0.0432 - accuracy: 0.9840 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0139 - accuracy: 0.9959\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0266 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  435\n",
      "265/265 - 11s - loss: 0.0425 - accuracy: 0.9844 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0135 - accuracy: 0.9954\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0303 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  436\n",
      "265/265 - 10s - loss: 0.0429 - accuracy: 0.9851 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0170 - accuracy: 0.9942\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0407 - accuracy: 0.9880\n",
      "\n",
      "Epoch:  437\n",
      "265/265 - 10s - loss: 0.0462 - accuracy: 0.9831 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0093 - accuracy: 0.9977\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0255 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  438\n",
      "265/265 - 11s - loss: 0.0457 - accuracy: 0.9830 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0144 - accuracy: 0.9962\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0339 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  439\n",
      "265/265 - 10s - loss: 0.0434 - accuracy: 0.9844 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0096 - accuracy: 0.9971\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0273 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  440\n",
      "265/265 - 10s - loss: 0.0423 - accuracy: 0.9843 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0106 - accuracy: 0.9970\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0242 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  441\n",
      "265/265 - 10s - loss: 0.0461 - accuracy: 0.9831 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0145 - accuracy: 0.9955\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0311 - accuracy: 0.9898\n",
      "\n",
      "Epoch:  442\n",
      "265/265 - 10s - loss: 0.0440 - accuracy: 0.9835 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0100 - accuracy: 0.9973\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0278 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  443\n",
      "265/265 - 10s - loss: 0.0446 - accuracy: 0.9833 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0085 - accuracy: 0.9980\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0253 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  444\n",
      "265/265 - 10s - loss: 0.0426 - accuracy: 0.9837 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0088 - accuracy: 0.9976\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0286 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  445\n",
      "265/265 - 10s - loss: 0.0434 - accuracy: 0.9845 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0088 - accuracy: 0.9974\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0229 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  446\n",
      "265/265 - 10s - loss: 0.0400 - accuracy: 0.9858 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0085 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0222 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  447\n",
      "265/265 - 10s - loss: 0.0431 - accuracy: 0.9849 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0078 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0233 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  448\n",
      "265/265 - 10s - loss: 0.0415 - accuracy: 0.9849 - 10s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0114 - accuracy: 0.9966\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0355 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  449\n",
      "265/265 - 10s - loss: 0.0462 - accuracy: 0.9839 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0098 - accuracy: 0.9977\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0273 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  450\n",
      "265/265 - 10s - loss: 0.0413 - accuracy: 0.9853 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0079 - accuracy: 0.9983\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0187 - accuracy: 0.9940\n",
      "\n",
      "Epoch:  451\n",
      "265/265 - 10s - loss: 0.0449 - accuracy: 0.9830 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0110 - accuracy: 0.9972\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0291 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  452\n",
      "265/265 - 10s - loss: 0.0407 - accuracy: 0.9850 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0087 - accuracy: 0.9975\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0289 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  453\n",
      "265/265 - 10s - loss: 0.0426 - accuracy: 0.9845 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0082 - accuracy: 0.9983\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0241 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  454\n",
      "265/265 - 10s - loss: 0.0413 - accuracy: 0.9846 - 10s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0172 - accuracy: 0.9947\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0339 - accuracy: 0.9894\n",
      "\n",
      "Epoch:  455\n",
      "265/265 - 10s - loss: 0.0383 - accuracy: 0.9859 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0090 - accuracy: 0.9979\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0228 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  456\n",
      "265/265 - 10s - loss: 0.0445 - accuracy: 0.9855 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0083 - accuracy: 0.9979\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0226 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  457\n",
      "265/265 - 10s - loss: 0.0421 - accuracy: 0.9843 - 10s/epoch - 39ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0118 - accuracy: 0.9964\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0297 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  458\n",
      "265/265 - 11s - loss: 0.0438 - accuracy: 0.9840 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0127 - accuracy: 0.9958\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0276 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  459\n",
      "265/265 - 11s - loss: 0.0442 - accuracy: 0.9843 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0076 - accuracy: 0.9985\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0235 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  460\n",
      "265/265 - 10s - loss: 0.0382 - accuracy: 0.9859 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0066 - accuracy: 0.9985\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0200 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  461\n",
      "265/265 - 10s - loss: 0.0420 - accuracy: 0.9841 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0095 - accuracy: 0.9976\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0235 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  462\n",
      "265/265 - 10s - loss: 0.0373 - accuracy: 0.9863 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0109 - accuracy: 0.9964\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0246 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  463\n",
      "265/265 - 10s - loss: 0.0449 - accuracy: 0.9836 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0068 - accuracy: 0.9984\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0229 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  464\n",
      "265/265 - 10s - loss: 0.0395 - accuracy: 0.9863 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0097 - accuracy: 0.9974\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0234 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  465\n",
      "265/265 - 10s - loss: 0.0419 - accuracy: 0.9843 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0075 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0292 - accuracy: 0.9906\n",
      "\n",
      "Epoch:  466\n",
      "265/265 - 10s - loss: 0.0378 - accuracy: 0.9860 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0064 - accuracy: 0.9984\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0204 - accuracy: 0.9946\n",
      "\n",
      "Epoch:  467\n",
      "265/265 - 10s - loss: 0.0400 - accuracy: 0.9850 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0054 - accuracy: 0.9989\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0217 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  468\n",
      "265/265 - 10s - loss: 0.0398 - accuracy: 0.9851 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0087 - accuracy: 0.9973\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0313 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  469\n",
      "265/265 - 10s - loss: 0.0422 - accuracy: 0.9840 - 10s/epoch - 38ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0103 - accuracy: 0.9967\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0275 - accuracy: 0.9907\n",
      "\n",
      "Epoch:  470\n",
      "265/265 - 10s - loss: 0.0414 - accuracy: 0.9858 - 10s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0060 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0195 - accuracy: 0.9942\n",
      "\n",
      "Epoch:  471\n",
      "265/265 - 10s - loss: 0.0412 - accuracy: 0.9854 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0091 - accuracy: 0.9977\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0289 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  472\n",
      "265/265 - 10s - loss: 0.0426 - accuracy: 0.9840 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0095 - accuracy: 0.9975\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0267 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  473\n",
      "265/265 - 10s - loss: 0.0387 - accuracy: 0.9858 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0099 - accuracy: 0.9970\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0270 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  474\n",
      "265/265 - 10s - loss: 0.0374 - accuracy: 0.9859 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0092 - accuracy: 0.9970\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0287 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  475\n",
      "265/265 - 10s - loss: 0.0397 - accuracy: 0.9855 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0082 - accuracy: 0.9978\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0248 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  476\n",
      "265/265 - 10s - loss: 0.0472 - accuracy: 0.9832 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0073 - accuracy: 0.9979\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0235 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  477\n",
      "265/265 - 10s - loss: 0.0407 - accuracy: 0.9858 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0091 - accuracy: 0.9978\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0233 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  478\n",
      "265/265 - 10s - loss: 0.0395 - accuracy: 0.9860 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0080 - accuracy: 0.9977\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0229 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  479\n",
      "265/265 - 10s - loss: 0.0421 - accuracy: 0.9839 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0087 - accuracy: 0.9979\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0254 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  480\n",
      "265/265 - 10s - loss: 0.0397 - accuracy: 0.9859 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0079 - accuracy: 0.9975\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0238 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  481\n",
      "265/265 - 10s - loss: 0.0372 - accuracy: 0.9864 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0106 - accuracy: 0.9972\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0254 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  482\n",
      "265/265 - 10s - loss: 0.0400 - accuracy: 0.9859 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0073 - accuracy: 0.9981\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0232 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  483\n",
      "265/265 - 10s - loss: 0.0379 - accuracy: 0.9867 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0071 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0268 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  484\n",
      "265/265 - 10s - loss: 0.0405 - accuracy: 0.9849 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0057 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0296 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  485\n",
      "265/265 - 11s - loss: 0.0351 - accuracy: 0.9868 - 11s/epoch - 41ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0060 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0253 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  486\n",
      "265/265 - 11s - loss: 0.0397 - accuracy: 0.9853 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0065 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0230 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  487\n",
      "265/265 - 10s - loss: 0.0405 - accuracy: 0.9850 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0081 - accuracy: 0.9979\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0253 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  488\n",
      "265/265 - 10s - loss: 0.0448 - accuracy: 0.9842 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0064 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0270 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  489\n",
      "265/265 - 10s - loss: 0.0355 - accuracy: 0.9872 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0101 - accuracy: 0.9964\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0341 - accuracy: 0.9893\n",
      "\n",
      "Epoch:  490\n",
      "265/265 - 11s - loss: 0.0395 - accuracy: 0.9862 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0064 - accuracy: 0.9984\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0219 - accuracy: 0.9937\n",
      "\n",
      "Epoch:  491\n",
      "265/265 - 11s - loss: 0.0373 - accuracy: 0.9864 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0086 - accuracy: 0.9976\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0264 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  492\n",
      "265/265 - 10s - loss: 0.0383 - accuracy: 0.9858 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0052 - accuracy: 0.9989\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0237 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  493\n",
      "265/265 - 10s - loss: 0.0380 - accuracy: 0.9869 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0078 - accuracy: 0.9978\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0242 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  494\n",
      "265/265 - 10s - loss: 0.0426 - accuracy: 0.9841 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0075 - accuracy: 0.9983\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0231 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  495\n",
      "265/265 - 10s - loss: 0.0379 - accuracy: 0.9863 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0111 - accuracy: 0.9965\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0362 - accuracy: 0.9894\n",
      "\n",
      "Epoch:  496\n",
      "265/265 - 10s - loss: 0.0548 - accuracy: 0.9825 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0071 - accuracy: 0.9980\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0225 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  497\n",
      "265/265 - 10s - loss: 0.0413 - accuracy: 0.9850 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0061 - accuracy: 0.9984\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0188 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  498\n",
      "265/265 - 10s - loss: 0.0354 - accuracy: 0.9874 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0082 - accuracy: 0.9974\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0245 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  499\n",
      "265/265 - 10s - loss: 0.0391 - accuracy: 0.9861 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0078 - accuracy: 0.9981\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0228 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  500\n",
      "265/265 - 10s - loss: 0.0366 - accuracy: 0.9871 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0064 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0225 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  501\n",
      "265/265 - 10s - loss: 0.0349 - accuracy: 0.9876 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0096 - accuracy: 0.9968\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0324 - accuracy: 0.9895\n",
      "\n",
      "Epoch:  502\n",
      "265/265 - 10s - loss: 0.0363 - accuracy: 0.9866 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0072 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0218 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  503\n",
      "265/265 - 10s - loss: 0.0375 - accuracy: 0.9860 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0100 - accuracy: 0.9971\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0301 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  504\n",
      "265/265 - 10s - loss: 0.0388 - accuracy: 0.9864 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0070 - accuracy: 0.9981\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0224 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  505\n",
      "265/265 - 10s - loss: 0.0370 - accuracy: 0.9859 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0072 - accuracy: 0.9981\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0225 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  506\n",
      "265/265 - 10s - loss: 0.0411 - accuracy: 0.9853 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0081 - accuracy: 0.9980\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0222 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  507\n",
      "265/265 - 10s - loss: 0.0409 - accuracy: 0.9857 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0054 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0198 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  508\n",
      "265/265 - 10s - loss: 0.0367 - accuracy: 0.9861 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0063 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0248 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  509\n",
      "265/265 - 11s - loss: 0.0369 - accuracy: 0.9875 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0088 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0229 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  510\n",
      "265/265 - 10s - loss: 0.0378 - accuracy: 0.9863 - 10s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0066 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0204 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  511\n",
      "265/265 - 11s - loss: 0.0349 - accuracy: 0.9866 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0062 - accuracy: 0.9985\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0210 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  512\n",
      "265/265 - 10s - loss: 0.0385 - accuracy: 0.9865 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0062 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0213 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  513\n",
      "265/265 - 11s - loss: 0.0373 - accuracy: 0.9864 - 11s/epoch - 40ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0071 - accuracy: 0.9980\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0222 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  514\n",
      "265/265 - 10s - loss: 0.0348 - accuracy: 0.9874 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0047 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0196 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  515\n",
      "265/265 - 10s - loss: 0.0374 - accuracy: 0.9861 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0058 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0193 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  516\n",
      "265/265 - 10s - loss: 0.0387 - accuracy: 0.9865 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0051 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0206 - accuracy: 0.9940\n",
      "\n",
      "Epoch:  517\n",
      "265/265 - 11s - loss: 0.0407 - accuracy: 0.9853 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0120 - accuracy: 0.9968\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0301 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  518\n",
      "265/265 - 10s - loss: 0.0383 - accuracy: 0.9863 - 10s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0077 - accuracy: 0.9978\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0280 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  519\n",
      "265/265 - 10s - loss: 0.0350 - accuracy: 0.9870 - 10s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0048 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0218 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  520\n",
      "265/265 - 10s - loss: 0.0421 - accuracy: 0.9852 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0068 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0238 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  521\n",
      "265/265 - 10s - loss: 0.0356 - accuracy: 0.9875 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0054 - accuracy: 0.9989\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0206 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  522\n",
      "265/265 - 10s - loss: 0.0376 - accuracy: 0.9864 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0069 - accuracy: 0.9981\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0221 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  523\n",
      "265/265 - 10s - loss: 0.0350 - accuracy: 0.9870 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0067 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0253 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  524\n",
      "265/265 - 11s - loss: 0.0359 - accuracy: 0.9873 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0101 - accuracy: 0.9973\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0271 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  525\n",
      "265/265 - 11s - loss: 0.0364 - accuracy: 0.9869 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0111 - accuracy: 0.9963\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0372 - accuracy: 0.9888\n",
      "\n",
      "Epoch:  526\n",
      "265/265 - 11s - loss: 0.0387 - accuracy: 0.9861 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0065 - accuracy: 0.9983\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0233 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  527\n",
      "265/265 - 10s - loss: 0.0365 - accuracy: 0.9863 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0077 - accuracy: 0.9979\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0261 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  528\n",
      "265/265 - 11s - loss: 0.0337 - accuracy: 0.9878 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0042 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0217 - accuracy: 0.9937\n",
      "\n",
      "Epoch:  529\n",
      "265/265 - 11s - loss: 0.0398 - accuracy: 0.9856 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0074 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0229 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  530\n",
      "265/265 - 10s - loss: 0.0369 - accuracy: 0.9867 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0165 - accuracy: 0.9941\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0363 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  531\n",
      "265/265 - 10s - loss: 0.0392 - accuracy: 0.9862 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0084 - accuracy: 0.9977\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0302 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  532\n",
      "265/265 - 10s - loss: 0.0403 - accuracy: 0.9848 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0072 - accuracy: 0.9981\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0244 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  533\n",
      "265/265 - 10s - loss: 0.0337 - accuracy: 0.9876 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0055 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0246 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  534\n",
      "265/265 - 10s - loss: 0.0320 - accuracy: 0.9885 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0048 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0225 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  535\n",
      "265/265 - 10s - loss: 0.0379 - accuracy: 0.9857 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0074 - accuracy: 0.9978\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0254 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  536\n",
      "265/265 - 10s - loss: 0.0357 - accuracy: 0.9869 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0066 - accuracy: 0.9983\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0297 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  537\n",
      "265/265 - 12s - loss: 0.0346 - accuracy: 0.9878 - 12s/epoch - 44ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0086 - accuracy: 0.9975\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0255 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  538\n",
      "265/265 - 11s - loss: 0.0359 - accuracy: 0.9871 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0073 - accuracy: 0.9981\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0239 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  539\n",
      "265/265 - 10s - loss: 0.0342 - accuracy: 0.9880 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0093 - accuracy: 0.9971\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0340 - accuracy: 0.9904\n",
      "\n",
      "Epoch:  540\n",
      "265/265 - 11s - loss: 0.0397 - accuracy: 0.9844 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0058 - accuracy: 0.9989\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0243 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  541\n",
      "265/265 - 10s - loss: 0.0378 - accuracy: 0.9865 - 10s/epoch - 40ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0076 - accuracy: 0.9979\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0253 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  542\n",
      "265/265 - 11s - loss: 0.0319 - accuracy: 0.9886 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0041 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0204 - accuracy: 0.9941\n",
      "\n",
      "Epoch:  543\n",
      "265/265 - 10s - loss: 0.0342 - accuracy: 0.9876 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0066 - accuracy: 0.9984\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0297 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  544\n",
      "265/265 - 10s - loss: 0.0403 - accuracy: 0.9858 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0064 - accuracy: 0.9990\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0291 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  545\n",
      "265/265 - 10s - loss: 0.0397 - accuracy: 0.9861 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0077 - accuracy: 0.9980\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0294 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  546\n",
      "265/265 - 10s - loss: 0.0362 - accuracy: 0.9866 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0057 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0202 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  547\n",
      "265/265 - 10s - loss: 0.0336 - accuracy: 0.9879 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0110 - accuracy: 0.9967\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0284 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  548\n",
      "265/265 - 11s - loss: 0.0351 - accuracy: 0.9875 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0050 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0256 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  549\n",
      "265/265 - 10s - loss: 0.0378 - accuracy: 0.9869 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0057 - accuracy: 0.9990\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0224 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  550\n",
      "265/265 - 10s - loss: 0.0351 - accuracy: 0.9877 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0054 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0226 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  551\n",
      "265/265 - 10s - loss: 0.0349 - accuracy: 0.9869 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0052 - accuracy: 0.9990\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0247 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  552\n",
      "265/265 - 10s - loss: 0.0361 - accuracy: 0.9865 - 10s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0116 - accuracy: 0.9959\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0358 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  553\n",
      "265/265 - 10s - loss: 0.0380 - accuracy: 0.9858 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0056 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0241 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  554\n",
      "265/265 - 10s - loss: 0.0483 - accuracy: 0.9833 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0096 - accuracy: 0.9978\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0268 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  555\n",
      "265/265 - 10s - loss: 0.0348 - accuracy: 0.9879 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0073 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0272 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  556\n",
      "265/265 - 10s - loss: 0.0348 - accuracy: 0.9870 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0089 - accuracy: 0.9973\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0319 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  557\n",
      "265/265 - 11s - loss: 0.0313 - accuracy: 0.9888 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0053 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0263 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  558\n",
      "265/265 - 10s - loss: 0.0328 - accuracy: 0.9885 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0058 - accuracy: 0.9990\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0240 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  559\n",
      "265/265 - 11s - loss: 0.0347 - accuracy: 0.9874 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0065 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0328 - accuracy: 0.9909\n",
      "\n",
      "Epoch:  560\n",
      "265/265 - 10s - loss: 0.0325 - accuracy: 0.9881 - 10s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0049 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0245 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  561\n",
      "265/265 - 10s - loss: 0.0338 - accuracy: 0.9875 - 10s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0047 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0264 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  562\n",
      "265/265 - 11s - loss: 0.0331 - accuracy: 0.9881 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0054 - accuracy: 0.9989\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0260 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  563\n",
      "265/265 - 10s - loss: 0.0317 - accuracy: 0.9890 - 10s/epoch - 39ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0053 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0206 - accuracy: 0.9937\n",
      "\n",
      "Epoch:  564\n",
      "265/265 - 11s - loss: 0.0354 - accuracy: 0.9873 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0081 - accuracy: 0.9980\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0262 - accuracy: 0.9915\n",
      "\n",
      "Epoch:  565\n",
      "265/265 - 11s - loss: 0.0382 - accuracy: 0.9860 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0062 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0238 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  566\n",
      "265/265 - 11s - loss: 0.0337 - accuracy: 0.9878 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0055 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0218 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  567\n",
      "265/265 - 11s - loss: 0.0347 - accuracy: 0.9875 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0054 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0240 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  568\n",
      "265/265 - 10s - loss: 0.0403 - accuracy: 0.9856 - 10s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0054 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0224 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  569\n",
      "265/265 - 11s - loss: 0.0332 - accuracy: 0.9882 - 11s/epoch - 40ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0038 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0243 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  570\n",
      "265/265 - 11s - loss: 0.0344 - accuracy: 0.9877 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0049 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0236 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  571\n",
      "265/265 - 11s - loss: 0.0313 - accuracy: 0.9882 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0062 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0296 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  572\n",
      "265/265 - 11s - loss: 0.0336 - accuracy: 0.9882 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0049 - accuracy: 0.9989\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0212 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  573\n",
      "265/265 - 11s - loss: 0.0323 - accuracy: 0.9885 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0049 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0215 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  574\n",
      "265/265 - 11s - loss: 0.0351 - accuracy: 0.9871 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0219 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  575\n",
      "265/265 - 11s - loss: 0.0322 - accuracy: 0.9886 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0047 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0205 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  576\n",
      "265/265 - 11s - loss: 0.0378 - accuracy: 0.9865 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0105 - accuracy: 0.9966\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0384 - accuracy: 0.9891\n",
      "\n",
      "Epoch:  577\n",
      "265/265 - 11s - loss: 0.0327 - accuracy: 0.9887 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0071 - accuracy: 0.9984\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0242 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  578\n",
      "265/265 - 11s - loss: 0.0361 - accuracy: 0.9872 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0055 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0298 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  579\n",
      "265/265 - 11s - loss: 0.0365 - accuracy: 0.9870 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0081 - accuracy: 0.9978\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0301 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  580\n",
      "265/265 - 11s - loss: 0.0385 - accuracy: 0.9860 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0042 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0187 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  581\n",
      "265/265 - 11s - loss: 0.0307 - accuracy: 0.9888 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0055 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0250 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  582\n",
      "265/265 - 11s - loss: 0.0335 - accuracy: 0.9876 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0057 - accuracy: 0.9983\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0254 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  583\n",
      "265/265 - 11s - loss: 0.0354 - accuracy: 0.9873 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0085 - accuracy: 0.9973\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0294 - accuracy: 0.9903\n",
      "\n",
      "Epoch:  584\n",
      "265/265 - 11s - loss: 0.0337 - accuracy: 0.9881 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0036 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0195 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  585\n",
      "265/265 - 11s - loss: 0.0375 - accuracy: 0.9869 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0057 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0233 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  586\n",
      "265/265 - 11s - loss: 0.0342 - accuracy: 0.9885 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0124 - accuracy: 0.9957\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0314 - accuracy: 0.9896\n",
      "\n",
      "Epoch:  587\n",
      "265/265 - 11s - loss: 0.0377 - accuracy: 0.9868 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0052 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0224 - accuracy: 0.9937\n",
      "\n",
      "Epoch:  588\n",
      "265/265 - 11s - loss: 0.0337 - accuracy: 0.9876 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0046 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0198 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  589\n",
      "265/265 - 11s - loss: 0.0311 - accuracy: 0.9887 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0045 - accuracy: 0.9989\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0219 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  590\n",
      "265/265 - 11s - loss: 0.0336 - accuracy: 0.9877 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0057 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0254 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  591\n",
      "265/265 - 11s - loss: 0.0328 - accuracy: 0.9884 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0054 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0264 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  592\n",
      "265/265 - 11s - loss: 0.0317 - accuracy: 0.9885 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0039 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0235 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  593\n",
      "265/265 - 11s - loss: 0.0322 - accuracy: 0.9877 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0055 - accuracy: 0.9989\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0228 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  594\n",
      "265/265 - 11s - loss: 0.0363 - accuracy: 0.9871 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0122 - accuracy: 0.9955\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0339 - accuracy: 0.9885\n",
      "\n",
      "Epoch:  595\n",
      "265/265 - 11s - loss: 0.0349 - accuracy: 0.9875 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0061 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0243 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  596\n",
      "265/265 - 11s - loss: 0.0325 - accuracy: 0.9880 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0042 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0189 - accuracy: 0.9941\n",
      "\n",
      "Epoch:  597\n",
      "265/265 - 11s - loss: 0.0311 - accuracy: 0.9885 - 11s/epoch - 40ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0064 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0292 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  598\n",
      "265/265 - 11s - loss: 0.0344 - accuracy: 0.9878 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0053 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0207 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  599\n",
      "265/265 - 11s - loss: 0.0336 - accuracy: 0.9883 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0047 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0211 - accuracy: 0.9937\n",
      "\n",
      "Epoch:  600\n",
      "265/265 - 11s - loss: 0.0300 - accuracy: 0.9892 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0081 - accuracy: 0.9978\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0281 - accuracy: 0.9908\n"
     ]
    }
   ],
   "source": [
    "for x in range(400,600):\n",
    "    print(\"\\nEpoch: \",x+1)\n",
    "    history = model.fit(X_train ,y_train ,batch_size=BATCH_SIZE ,epochs=1, verbose=2, shuffle=True)\n",
    "    if history_dataframe.size == 0:\n",
    "        history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    else:\n",
    "        history_dataframe = pd.concat([history_dataframe,pd.DataFrame.from_dict(history.history)],axis=0,ignore_index=True)\n",
    "    \n",
    "    print(\"for training\")\n",
    "    train_eva.append(model.evaluate(X_train,y_train))\n",
    "    print(\"for testing\")\n",
    "    test_eva.append(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25c1c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva_df = pd.DataFrame(train_eva,columns=['loss','accuracy'])\n",
    "test_eva_df = pd.DataFrame(test_eva,columns=['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "647073ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(train_eva_df,'Train','Epoch','Loss',['loss','accuracy'])\n",
    "plot_graph(test_eva_df,'Test','Epoch','Loss',['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53c1e776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994980692863464"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eva_df['accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "645878a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss          0\n",
       "accuracy    595\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eva_df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d540b4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9945678114891052"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eva_df['accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8e32836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss          0\n",
       "accuracy    465\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eva_df.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b4ab25",
   "metadata": {},
   "source": [
    "### Its not 401 to 600, its 601 to 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "532711b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  401\n",
      "265/265 - 11s - loss: 0.0344 - accuracy: 0.9879 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0070 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0245 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  402\n",
      "265/265 - 11s - loss: 0.0318 - accuracy: 0.9880 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0038 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0213 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  403\n",
      "265/265 - 11s - loss: 0.0395 - accuracy: 0.9865 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0093 - accuracy: 0.9973\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0293 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  404\n",
      "265/265 - 11s - loss: 0.0311 - accuracy: 0.9889 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0063 - accuracy: 0.9985\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0272 - accuracy: 0.9910\n",
      "\n",
      "Epoch:  405\n",
      "265/265 - 11s - loss: 0.0329 - accuracy: 0.9888 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0043 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0236 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  406\n",
      "265/265 - 11s - loss: 0.0274 - accuracy: 0.9899 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0032 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0206 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  407\n",
      "265/265 - 11s - loss: 0.0358 - accuracy: 0.9868 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0069 - accuracy: 0.9985\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0281 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  408\n",
      "265/265 - 11s - loss: 0.0330 - accuracy: 0.9888 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0080 - accuracy: 0.9974\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0308 - accuracy: 0.9911\n",
      "\n",
      "Epoch:  409\n",
      "265/265 - 11s - loss: 0.0310 - accuracy: 0.9889 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0056 - accuracy: 0.9983\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0280 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  410\n",
      "265/265 - 11s - loss: 0.0336 - accuracy: 0.9876 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0059 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0289 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  411\n",
      "265/265 - 11s - loss: 0.0331 - accuracy: 0.9884 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0043 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0271 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  412\n",
      "265/265 - 11s - loss: 0.0301 - accuracy: 0.9899 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0048 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0266 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  413\n",
      "265/265 - 11s - loss: 0.0301 - accuracy: 0.9894 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0047 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0251 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  414\n",
      "265/265 - 11s - loss: 0.0321 - accuracy: 0.9887 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0056 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0302 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  415\n",
      "265/265 - 11s - loss: 0.0348 - accuracy: 0.9877 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0060 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0342 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  416\n",
      "265/265 - 11s - loss: 0.0323 - accuracy: 0.9891 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0034 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0209 - accuracy: 0.9947\n",
      "\n",
      "Epoch:  417\n",
      "265/265 - 11s - loss: 0.0364 - accuracy: 0.9870 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0043 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0300 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  418\n",
      "265/265 - 11s - loss: 0.0334 - accuracy: 0.9880 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0077 - accuracy: 0.9981\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0374 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  419\n",
      "265/265 - 11s - loss: 0.0324 - accuracy: 0.9882 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0033 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0307 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  420\n",
      "265/265 - 11s - loss: 0.0345 - accuracy: 0.9880 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0055 - accuracy: 0.9990\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0265 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  421\n",
      "265/265 - 11s - loss: 0.0297 - accuracy: 0.9894 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0027 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0233 - accuracy: 0.9942\n",
      "\n",
      "Epoch:  422\n",
      "265/265 - 11s - loss: 0.0341 - accuracy: 0.9874 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0056 - accuracy: 0.9983\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0287 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  423\n",
      "265/265 - 11s - loss: 0.0327 - accuracy: 0.9881 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0065 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0304 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  424\n",
      "265/265 - 11s - loss: 0.0303 - accuracy: 0.9893 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0056 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0228 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  425\n",
      "265/265 - 11s - loss: 0.0300 - accuracy: 0.9888 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0037 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0199 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  426\n",
      "265/265 - 11s - loss: 0.0281 - accuracy: 0.9895 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0063 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0284 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  427\n",
      "265/265 - 11s - loss: 0.0333 - accuracy: 0.9883 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0034 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0202 - accuracy: 0.9946\n",
      "\n",
      "Epoch:  428\n",
      "265/265 - 11s - loss: 0.0344 - accuracy: 0.9879 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0037 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 8ms/step - loss: 0.0233 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  429\n",
      "265/265 - 11s - loss: 0.0342 - accuracy: 0.9881 - 11s/epoch - 43ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0070 - accuracy: 0.9985\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0262 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  430\n",
      "265/265 - 11s - loss: 0.0325 - accuracy: 0.9888 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0052 - accuracy: 0.9985\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0247 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  431\n",
      "265/265 - 11s - loss: 0.0310 - accuracy: 0.9885 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0096 - accuracy: 0.9972\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0349 - accuracy: 0.9900\n",
      "\n",
      "Epoch:  432\n",
      "265/265 - 12s - loss: 0.0298 - accuracy: 0.9891 - 12s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0030 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0202 - accuracy: 0.9944\n",
      "\n",
      "Epoch:  433\n",
      "265/265 - 11s - loss: 0.0317 - accuracy: 0.9890 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0042 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0250 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  434\n",
      "265/265 - 11s - loss: 0.0337 - accuracy: 0.9881 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0041 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0215 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  435\n",
      "265/265 - 11s - loss: 0.0311 - accuracy: 0.9893 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0048 - accuracy: 0.9989\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0281 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  436\n",
      "265/265 - 11s - loss: 0.0482 - accuracy: 0.9835 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0074 - accuracy: 0.9981\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0248 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  437\n",
      "265/265 - 11s - loss: 0.0304 - accuracy: 0.9888 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0036 - accuracy: 0.9990\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0219 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  438\n",
      "265/265 - 11s - loss: 0.0753 - accuracy: 0.9773 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0040 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0212 - accuracy: 0.9940\n",
      "\n",
      "Epoch:  439\n",
      "265/265 - 11s - loss: 0.0326 - accuracy: 0.9880 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0031 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0201 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  440\n",
      "265/265 - 11s - loss: 0.0286 - accuracy: 0.9890 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0033 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0206 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  441\n",
      "265/265 - 11s - loss: 0.0268 - accuracy: 0.9904 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0024 - accuracy: 0.9997\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0217 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  442\n",
      "265/265 - 11s - loss: 0.0273 - accuracy: 0.9906 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0028 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0194 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  443\n",
      "265/265 - 11s - loss: 0.0280 - accuracy: 0.9898 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0039 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0219 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  444\n",
      "265/265 - 11s - loss: 0.0307 - accuracy: 0.9898 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0027 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0195 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  445\n",
      "265/265 - 11s - loss: 0.0278 - accuracy: 0.9897 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0027 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0247 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  446\n",
      "265/265 - 11s - loss: 0.0319 - accuracy: 0.9888 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0026 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0191 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  447\n",
      "265/265 - 11s - loss: 0.0292 - accuracy: 0.9893 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0033 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0206 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  448\n",
      "265/265 - 11s - loss: 0.0315 - accuracy: 0.9888 - 11s/epoch - 40ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0043 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0260 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  449\n",
      "265/265 - 11s - loss: 0.0425 - accuracy: 0.9861 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0056 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0190 - accuracy: 0.9940\n",
      "\n",
      "Epoch:  450\n",
      "265/265 - 11s - loss: 0.0278 - accuracy: 0.9902 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0055 - accuracy: 0.9990\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0290 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  451\n",
      "265/265 - 11s - loss: 0.0288 - accuracy: 0.9895 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0029 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0256 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  452\n",
      "265/265 - 11s - loss: 0.0304 - accuracy: 0.9893 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0049 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0246 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  453\n",
      "265/265 - 11s - loss: 0.0289 - accuracy: 0.9900 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0070 - accuracy: 0.9980\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0373 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  454\n",
      "265/265 - 11s - loss: 0.0363 - accuracy: 0.9872 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0052 - accuracy: 0.9990\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0265 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  455\n",
      "265/265 - 11s - loss: 0.0299 - accuracy: 0.9896 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0047 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0217 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  456\n",
      "265/265 - 11s - loss: 0.0340 - accuracy: 0.9881 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0037 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0221 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  457\n",
      "265/265 - 11s - loss: 0.0295 - accuracy: 0.9891 - 11s/epoch - 43ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0042 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0237 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  458\n",
      "265/265 - 11s - loss: 0.0282 - accuracy: 0.9894 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0038 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0257 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  459\n",
      "265/265 - 11s - loss: 0.0329 - accuracy: 0.9883 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0036 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0212 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  460\n",
      "265/265 - 11s - loss: 0.0307 - accuracy: 0.9895 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0073 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0266 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  461\n",
      "265/265 - 11s - loss: 0.0295 - accuracy: 0.9896 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0039 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0234 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  462\n",
      "265/265 - 12s - loss: 0.0315 - accuracy: 0.9887 - 12s/epoch - 44ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0056 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0253 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  463\n",
      "265/265 - 11s - loss: 0.0333 - accuracy: 0.9886 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0035 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0202 - accuracy: 0.9941\n",
      "\n",
      "Epoch:  464\n",
      "265/265 - 11s - loss: 0.0311 - accuracy: 0.9892 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0091 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0325 - accuracy: 0.9894\n",
      "\n",
      "Epoch:  465\n",
      "265/265 - 11s - loss: 0.0306 - accuracy: 0.9892 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0044 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0203 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  466\n",
      "265/265 - 11s - loss: 0.0292 - accuracy: 0.9894 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0053 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0247 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  467\n",
      "265/265 - 11s - loss: 0.0316 - accuracy: 0.9885 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0059 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0229 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  468\n",
      "265/265 - 11s - loss: 0.0315 - accuracy: 0.9879 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0069 - accuracy: 0.9984\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0293 - accuracy: 0.9908\n",
      "\n",
      "Epoch:  469\n",
      "265/265 - 11s - loss: 0.0340 - accuracy: 0.9880 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0038 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0184 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  470\n",
      "265/265 - 11s - loss: 0.0306 - accuracy: 0.9886 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0065 - accuracy: 0.9983\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0237 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  471\n",
      "265/265 - 11s - loss: 0.0288 - accuracy: 0.9895 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0032 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0234 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  472\n",
      "265/265 - 11s - loss: 0.0280 - accuracy: 0.9903 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0068 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0284 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  473\n",
      "265/265 - 11s - loss: 0.0308 - accuracy: 0.9888 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0056 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0217 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  474\n",
      "265/265 - 11s - loss: 0.0355 - accuracy: 0.9872 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0029 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 8ms/step - loss: 0.0216 - accuracy: 0.9937\n",
      "\n",
      "Epoch:  475\n",
      "265/265 - 12s - loss: 0.0352 - accuracy: 0.9884 - 12s/epoch - 44ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0044 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0254 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  476\n",
      "265/265 - 11s - loss: 0.0340 - accuracy: 0.9878 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0032 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0231 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  477\n",
      "265/265 - 11s - loss: 0.0256 - accuracy: 0.9908 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0044 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0218 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  478\n",
      "265/265 - 11s - loss: 0.0298 - accuracy: 0.9896 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0031 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0205 - accuracy: 0.9942\n",
      "\n",
      "Epoch:  479\n",
      "265/265 - 11s - loss: 0.0279 - accuracy: 0.9898 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0063 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0303 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  480\n",
      "265/265 - 11s - loss: 0.0326 - accuracy: 0.9883 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0042 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0201 - accuracy: 0.9937\n",
      "\n",
      "Epoch:  481\n",
      "265/265 - 11s - loss: 0.0303 - accuracy: 0.9886 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0042 - accuracy: 0.9989\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0236 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  482\n",
      "265/265 - 11s - loss: 0.0373 - accuracy: 0.9877 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0064 - accuracy: 0.9984\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0262 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  483\n",
      "265/265 - 11s - loss: 0.0345 - accuracy: 0.9880 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0036 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0205 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  484\n",
      "265/265 - 11s - loss: 0.0294 - accuracy: 0.9892 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0055 - accuracy: 0.9984\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0313 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  485\n",
      "265/265 - 11s - loss: 0.0280 - accuracy: 0.9897 - 11s/epoch - 41ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0034 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 6ms/step - loss: 0.0197 - accuracy: 0.9941\n",
      "\n",
      "Epoch:  486\n",
      "265/265 - 11s - loss: 0.0276 - accuracy: 0.9903 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0042 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0259 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  487\n",
      "265/265 - 11s - loss: 0.0304 - accuracy: 0.9895 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0066 - accuracy: 0.9983\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0262 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  488\n",
      "265/265 - 11s - loss: 0.0349 - accuracy: 0.9873 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0061 - accuracy: 0.9989\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0219 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  489\n",
      "265/265 - 11s - loss: 0.0286 - accuracy: 0.9900 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0023 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0220 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  490\n",
      "265/265 - 11s - loss: 0.0297 - accuracy: 0.9897 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0036 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0223 - accuracy: 0.9937\n",
      "\n",
      "Epoch:  491\n",
      "265/265 - 11s - loss: 0.0292 - accuracy: 0.9896 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0054 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0286 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  492\n",
      "265/265 - 11s - loss: 0.0309 - accuracy: 0.9882 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0051 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0254 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  493\n",
      "265/265 - 11s - loss: 0.0274 - accuracy: 0.9902 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0031 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0234 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  494\n",
      "265/265 - 11s - loss: 0.0294 - accuracy: 0.9897 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0032 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0255 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  495\n",
      "265/265 - 11s - loss: 0.0281 - accuracy: 0.9906 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0040 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0267 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  496\n",
      "265/265 - 11s - loss: 0.0307 - accuracy: 0.9886 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0049 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0272 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  497\n",
      "265/265 - 11s - loss: 0.0312 - accuracy: 0.9887 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0037 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0228 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  498\n",
      "265/265 - 11s - loss: 0.0278 - accuracy: 0.9895 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0034 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0273 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  499\n",
      "265/265 - 11s - loss: 0.0283 - accuracy: 0.9901 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0033 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0281 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  500\n",
      "265/265 - 11s - loss: 0.0322 - accuracy: 0.9879 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0037 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0221 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  501\n",
      "265/265 - 11s - loss: 0.0293 - accuracy: 0.9899 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0030 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0199 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  502\n",
      "265/265 - 12s - loss: 0.0298 - accuracy: 0.9894 - 12s/epoch - 46ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0025 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0199 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  503\n",
      "265/265 - 11s - loss: 0.0270 - accuracy: 0.9906 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0024 - accuracy: 0.9997\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0212 - accuracy: 0.9941\n",
      "\n",
      "Epoch:  504\n",
      "265/265 - 11s - loss: 0.0274 - accuracy: 0.9905 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0033 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0239 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  505\n",
      "265/265 - 11s - loss: 0.0283 - accuracy: 0.9899 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0121 - accuracy: 0.9957\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0440 - accuracy: 0.9877\n",
      "\n",
      "Epoch:  506\n",
      "265/265 - 11s - loss: 0.0289 - accuracy: 0.9895 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0220 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  507\n",
      "265/265 - 11s - loss: 0.0313 - accuracy: 0.9893 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0128 - accuracy: 0.9963\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0360 - accuracy: 0.9887\n",
      "\n",
      "Epoch:  508\n",
      "265/265 - 11s - loss: 0.0278 - accuracy: 0.9898 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0040 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0259 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  509\n",
      "265/265 - 11s - loss: 0.0259 - accuracy: 0.9913 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0046 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0292 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  510\n",
      "265/265 - 11s - loss: 0.0304 - accuracy: 0.9885 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0040 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0256 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  511\n",
      "265/265 - 11s - loss: 0.0282 - accuracy: 0.9904 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0285 - accuracy: 0.9921\n",
      "\n",
      "Epoch:  512\n",
      "265/265 - 11s - loss: 0.0316 - accuracy: 0.9888 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0034 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0221 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  513\n",
      "265/265 - 11s - loss: 0.0276 - accuracy: 0.9901 - 11s/epoch - 42ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0054 - accuracy: 0.9985\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0248 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  514\n",
      "265/265 - 11s - loss: 0.0279 - accuracy: 0.9900 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0033 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0208 - accuracy: 0.9943\n",
      "\n",
      "Epoch:  515\n",
      "265/265 - 11s - loss: 0.0312 - accuracy: 0.9887 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0039 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0185 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  516\n",
      "265/265 - 11s - loss: 0.0283 - accuracy: 0.9900 - 11s/epoch - 41ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0036 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0223 - accuracy: 0.9943\n",
      "\n",
      "Epoch:  517\n",
      "265/265 - 11s - loss: 0.0289 - accuracy: 0.9892 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0027 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0242 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  518\n",
      "265/265 - 11s - loss: 0.0311 - accuracy: 0.9888 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0065 - accuracy: 0.9978\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0289 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  519\n",
      "265/265 - 11s - loss: 0.0317 - accuracy: 0.9888 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0047 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0257 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  520\n",
      "265/265 - 11s - loss: 0.0281 - accuracy: 0.9898 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0269 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  521\n",
      "265/265 - 11s - loss: 0.0352 - accuracy: 0.9883 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0037 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0306 - accuracy: 0.9924\n",
      "\n",
      "Epoch:  522\n",
      "265/265 - 11s - loss: 0.0255 - accuracy: 0.9906 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0027 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0212 - accuracy: 0.9944\n",
      "\n",
      "Epoch:  523\n",
      "265/265 - 11s - loss: 0.0281 - accuracy: 0.9898 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0030 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 8ms/step - loss: 0.0248 - accuracy: 0.9941\n",
      "\n",
      "Epoch:  524\n",
      "265/265 - 12s - loss: 0.0307 - accuracy: 0.9887 - 12s/epoch - 45ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0030 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0198 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  525\n",
      "265/265 - 11s - loss: 0.0295 - accuracy: 0.9898 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0040 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0228 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  526\n",
      "265/265 - 11s - loss: 0.0313 - accuracy: 0.9890 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0036 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0213 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  527\n",
      "265/265 - 11s - loss: 0.0248 - accuracy: 0.9908 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0036 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0260 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  528\n",
      "265/265 - 11s - loss: 0.0311 - accuracy: 0.9893 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0040 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0213 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  529\n",
      "265/265 - 12s - loss: 0.0254 - accuracy: 0.9912 - 12s/epoch - 46ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0034 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0241 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  530\n",
      "265/265 - 11s - loss: 0.0341 - accuracy: 0.9878 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0036 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0247 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  531\n",
      "265/265 - 11s - loss: 0.0309 - accuracy: 0.9887 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0024 - accuracy: 0.9998\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0230 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  532\n",
      "265/265 - 11s - loss: 0.0315 - accuracy: 0.9893 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0028 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0221 - accuracy: 0.9940\n",
      "\n",
      "Epoch:  533\n",
      "265/265 - 11s - loss: 0.0242 - accuracy: 0.9910 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0042 - accuracy: 0.9989\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0273 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  534\n",
      "265/265 - 11s - loss: 0.0266 - accuracy: 0.9906 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0045 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0308 - accuracy: 0.9922\n",
      "\n",
      "Epoch:  535\n",
      "265/265 - 11s - loss: 0.0374 - accuracy: 0.9875 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0062 - accuracy: 0.9990\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0246 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  536\n",
      "265/265 - 11s - loss: 0.0282 - accuracy: 0.9900 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0056 - accuracy: 0.9982\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0263 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  537\n",
      "265/265 - 11s - loss: 0.0286 - accuracy: 0.9902 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0035 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0218 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  538\n",
      "265/265 - 11s - loss: 0.0285 - accuracy: 0.9896 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0055 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0287 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  539\n",
      "265/265 - 11s - loss: 0.0271 - accuracy: 0.9903 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0047 - accuracy: 0.9990\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0279 - accuracy: 0.9920\n",
      "\n",
      "Epoch:  540\n",
      "265/265 - 11s - loss: 0.0342 - accuracy: 0.9884 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0038 - accuracy: 0.9997\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0262 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  541\n",
      "265/265 - 11s - loss: 0.0259 - accuracy: 0.9908 - 11s/epoch - 42ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0025 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0282 - accuracy: 0.9940\n",
      "\n",
      "Epoch:  542\n",
      "265/265 - 11s - loss: 0.0465 - accuracy: 0.9850 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0027 - accuracy: 0.9998\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0206 - accuracy: 0.9946\n",
      "\n",
      "Epoch:  543\n",
      "265/265 - 11s - loss: 0.0733 - accuracy: 0.9823 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0045 - accuracy: 0.9988\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0220 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  544\n",
      "265/265 - 11s - loss: 0.0265 - accuracy: 0.9906 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0029 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0224 - accuracy: 0.9932\n",
      "\n",
      "Epoch:  545\n",
      "265/265 - 11s - loss: 0.0408 - accuracy: 0.9859 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0044 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0226 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  546\n",
      "265/265 - 11s - loss: 0.0288 - accuracy: 0.9892 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0033 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0177 - accuracy: 0.9940\n",
      "\n",
      "Epoch:  547\n",
      "265/265 - 11s - loss: 0.0262 - accuracy: 0.9908 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0032 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0215 - accuracy: 0.9937\n",
      "\n",
      "Epoch:  548\n",
      "265/265 - 11s - loss: 0.0231 - accuracy: 0.9920 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0026 - accuracy: 0.9997\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0236 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  549\n",
      "265/265 - 11s - loss: 0.0258 - accuracy: 0.9907 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0034 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0238 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  550\n",
      "265/265 - 11s - loss: 0.0288 - accuracy: 0.9890 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0037 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0227 - accuracy: 0.9940\n",
      "\n",
      "Epoch:  551\n",
      "265/265 - 11s - loss: 0.0234 - accuracy: 0.9917 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0047 - accuracy: 0.9987\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0340 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  552\n",
      "265/265 - 11s - loss: 0.0294 - accuracy: 0.9898 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0032 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0223 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  553\n",
      "265/265 - 11s - loss: 0.0265 - accuracy: 0.9908 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0023 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0214 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  554\n",
      "265/265 - 11s - loss: 0.0302 - accuracy: 0.9896 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0212 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  555\n",
      "265/265 - 11s - loss: 0.0253 - accuracy: 0.9907 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0038 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 8ms/step - loss: 0.0267 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  556\n",
      "265/265 - 12s - loss: 0.0236 - accuracy: 0.9919 - 12s/epoch - 46ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0019 - accuracy: 0.9998\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0167 - accuracy: 0.9947\n",
      "\n",
      "Epoch:  557\n",
      "265/265 - 11s - loss: 0.0273 - accuracy: 0.9905 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0024 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0242 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  558\n",
      "265/265 - 11s - loss: 0.0286 - accuracy: 0.9901 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0035 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0171 - accuracy: 0.9943\n",
      "\n",
      "Epoch:  559\n",
      "265/265 - 11s - loss: 0.0261 - accuracy: 0.9910 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0023 - accuracy: 0.9997\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0209 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  560\n",
      "265/265 - 12s - loss: 0.0286 - accuracy: 0.9895 - 12s/epoch - 44ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0029 - accuracy: 0.9997\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0214 - accuracy: 0.9940\n",
      "\n",
      "Epoch:  561\n",
      "265/265 - 12s - loss: 0.0269 - accuracy: 0.9902 - 12s/epoch - 44ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0023 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0183 - accuracy: 0.9942\n",
      "\n",
      "Epoch:  562\n",
      "265/265 - 11s - loss: 0.0279 - accuracy: 0.9900 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0030 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0201 - accuracy: 0.9934\n",
      "\n",
      "Epoch:  563\n",
      "265/265 - 11s - loss: 0.0340 - accuracy: 0.9883 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0043 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0272 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  564\n",
      "265/265 - 11s - loss: 0.0262 - accuracy: 0.9907 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0025 - accuracy: 0.9997\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0251 - accuracy: 0.9937\n",
      "\n",
      "Epoch:  565\n",
      "265/265 - 11s - loss: 0.0264 - accuracy: 0.9905 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0039 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0313 - accuracy: 0.9917\n",
      "\n",
      "Epoch:  566\n",
      "265/265 - 11s - loss: 0.0297 - accuracy: 0.9896 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0027 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0226 - accuracy: 0.9941\n",
      "\n",
      "Epoch:  567\n",
      "265/265 - 11s - loss: 0.0283 - accuracy: 0.9906 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0043 - accuracy: 0.9990\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0245 - accuracy: 0.9923\n",
      "\n",
      "Epoch:  568\n",
      "265/265 - 11s - loss: 0.0250 - accuracy: 0.9912 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0072 - accuracy: 0.9981\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0367 - accuracy: 0.9897\n",
      "\n",
      "Epoch:  569\n",
      "265/265 - 11s - loss: 0.0292 - accuracy: 0.9893 - 11s/epoch - 43ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0061 - accuracy: 0.9981\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0290 - accuracy: 0.9914\n",
      "\n",
      "Epoch:  570\n",
      "265/265 - 11s - loss: 0.0239 - accuracy: 0.9916 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0282 - accuracy: 0.9941\n",
      "\n",
      "Epoch:  571\n",
      "265/265 - 11s - loss: 0.0279 - accuracy: 0.9901 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0025 - accuracy: 0.9997\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0227 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  572\n",
      "265/265 - 11s - loss: 0.0285 - accuracy: 0.9901 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0033 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0269 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  573\n",
      "265/265 - 11s - loss: 0.0266 - accuracy: 0.9906 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0049 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0267 - accuracy: 0.9919\n",
      "\n",
      "Epoch:  574\n",
      "265/265 - 11s - loss: 0.0299 - accuracy: 0.9898 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0026 - accuracy: 0.9998\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0209 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  575\n",
      "265/265 - 11s - loss: 0.0312 - accuracy: 0.9898 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0070 - accuracy: 0.9979\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0314 - accuracy: 0.9901\n",
      "\n",
      "Epoch:  576\n",
      "265/265 - 11s - loss: 0.0303 - accuracy: 0.9897 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0033 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0252 - accuracy: 0.9928\n",
      "\n",
      "Epoch:  577\n",
      "265/265 - 11s - loss: 0.0350 - accuracy: 0.9879 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0043 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0233 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  578\n",
      "265/265 - 11s - loss: 0.0240 - accuracy: 0.9911 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0019 - accuracy: 0.9997\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0255 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  579\n",
      "265/265 - 11s - loss: 0.0263 - accuracy: 0.9906 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0032 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0258 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  580\n",
      "265/265 - 11s - loss: 0.0290 - accuracy: 0.9894 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0035 - accuracy: 0.9992\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0232 - accuracy: 0.9930\n",
      "\n",
      "Epoch:  581\n",
      "265/265 - 11s - loss: 0.0260 - accuracy: 0.9909 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0027 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0227 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  582\n",
      "265/265 - 12s - loss: 0.0288 - accuracy: 0.9897 - 12s/epoch - 47ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0029 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0222 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  583\n",
      "265/265 - 11s - loss: 0.0261 - accuracy: 0.9912 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0017 - accuracy: 0.9998\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0211 - accuracy: 0.9944\n",
      "\n",
      "Epoch:  584\n",
      "265/265 - 11s - loss: 0.0284 - accuracy: 0.9899 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0044 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0211 - accuracy: 0.9926\n",
      "\n",
      "Epoch:  585\n",
      "265/265 - 11s - loss: 0.0222 - accuracy: 0.9922 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0017 - accuracy: 0.9997\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0197 - accuracy: 0.9942\n",
      "\n",
      "Epoch:  586\n",
      "265/265 - 11s - loss: 0.0273 - accuracy: 0.9900 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0020 - accuracy: 0.9998\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0247 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  587\n",
      "265/265 - 11s - loss: 0.0248 - accuracy: 0.9910 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0023 - accuracy: 0.9997\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0250 - accuracy: 0.9939\n",
      "\n",
      "Epoch:  588\n",
      "265/265 - 11s - loss: 0.0261 - accuracy: 0.9907 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0038 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0244 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  589\n",
      "265/265 - 11s - loss: 0.0292 - accuracy: 0.9897 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0031 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0228 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  590\n",
      "265/265 - 12s - loss: 0.0248 - accuracy: 0.9913 - 12s/epoch - 44ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0023 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0227 - accuracy: 0.9935\n",
      "\n",
      "Epoch:  591\n",
      "265/265 - 11s - loss: 0.0311 - accuracy: 0.9895 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0047 - accuracy: 0.9991\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0284 - accuracy: 0.9916\n",
      "\n",
      "Epoch:  592\n",
      "265/265 - 11s - loss: 0.0271 - accuracy: 0.9904 - 11s/epoch - 42ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0027 - accuracy: 0.9995\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0241 - accuracy: 0.9927\n",
      "\n",
      "Epoch:  593\n",
      "265/265 - 11s - loss: 0.0271 - accuracy: 0.9906 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0032 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0261 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  594\n",
      "265/265 - 11s - loss: 0.0265 - accuracy: 0.9911 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0281 - accuracy: 0.9913\n",
      "\n",
      "Epoch:  595\n",
      "265/265 - 11s - loss: 0.0272 - accuracy: 0.9901 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0025 - accuracy: 0.9998\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0277 - accuracy: 0.9933\n",
      "\n",
      "Epoch:  596\n",
      "265/265 - 11s - loss: 0.0251 - accuracy: 0.9917 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0029 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0286 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  597\n",
      "265/265 - 11s - loss: 0.0273 - accuracy: 0.9905 - 11s/epoch - 43ms/step\n",
      "for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0035 - accuracy: 0.9993\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0273 - accuracy: 0.9929\n",
      "\n",
      "Epoch:  598\n",
      "265/265 - 11s - loss: 0.0224 - accuracy: 0.9919 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0027 - accuracy: 0.9994\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0220 - accuracy: 0.9936\n",
      "\n",
      "Epoch:  599\n",
      "265/265 - 11s - loss: 0.0303 - accuracy: 0.9896 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0031 - accuracy: 0.9997\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0222 - accuracy: 0.9937\n",
      "\n",
      "Epoch:  600\n",
      "265/265 - 11s - loss: 0.0267 - accuracy: 0.9906 - 11s/epoch - 43ms/step\n",
      "for training\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0023 - accuracy: 0.9996\n",
      "for testing\n",
      "265/265 [==============================] - 2s 7ms/step - loss: 0.0248 - accuracy: 0.9941\n"
     ]
    }
   ],
   "source": [
    "for x in range(400,600):\n",
    "    print(\"\\nEpoch: \",x+1)\n",
    "    history = model.fit(X_train ,y_train ,batch_size=BATCH_SIZE ,epochs=1, verbose=2, shuffle=True)\n",
    "    if history_dataframe.size == 0:\n",
    "        history_dataframe = pd.DataFrame.from_dict(history.history)\n",
    "    else:\n",
    "        history_dataframe = pd.concat([history_dataframe,pd.DataFrame.from_dict(history.history)],axis=0,ignore_index=True)\n",
    "    \n",
    "    print(\"for training\")\n",
    "    train_eva.append(model.evaluate(X_train,y_train))\n",
    "    print(\"for testing\")\n",
    "    test_eva.append(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9e2293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eva_df = pd.DataFrame(train_eva,columns=['loss','accuracy'])\n",
    "test_eva_df = pd.DataFrame(test_eva,columns=['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc16c81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(train_eva_df,'Train','Epoch','Loss',['loss','accuracy'])\n",
    "plot_graph(test_eva_df,'Test','Epoch','Loss',['loss','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e7808a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999793291091919"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eva_df['accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efb2d60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss          0\n",
       "accuracy    741\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eva_df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48e192ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9946858882904053"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eva_df['accuracy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2496cde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss          0\n",
       "accuracy    615\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eva_df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722a5191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
